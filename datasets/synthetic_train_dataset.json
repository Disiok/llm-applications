{
    "queries": {
        "fd0a174e-6e05-4bbc-96a1-2f84fb8b6220": "What is the purpose of the `get_best_checkpoint` function in the `ExperimentAnalysis` class?",
        "136a8d2d-1c2a-4c05-ab73-e33c0c12d37e": "How does the `get_best_checkpoint` function handle checkpoints with a metric value of `nan`?",
        "e604d93b-1ea9-449d-9e83-a90632e3cf0a": "What does the function `_best_trial_str` return? Provide an example of the output.",
        "d4aee739-45bf-4325-a5ae-b5accf9479ee": "How does the function `_fair_filter_trials` determine the number of trials to keep per state?",
        "d15e8a6e-8896-4823-8cc2-3cd2bdd77a7f": "How can you use the @serve.batch decorator in Ray Serve to batch together function calls?",
        "64c6f995-60a3-45be-ae47-cd0cfb8cdb10": "In the provided code, what is the purpose of the MyBackend class and its __call__ method?",
        "737dedbb-dce3-4cef-ac63-a6204d7f55a6": "How does DD-PPO differ from APPO and PPO in terms of policy improvement?",
        "9b82ed3b-3691-4c41-86dc-64bc39337052": "What are the advantages of using DD-PPO over standard PPO in terms of GPU utilization and scalability?",
        "55c7da48-be69-41d1-999b-1e0b9eb32cd2": "What is the purpose of the `on_learn_on_batch` method in the `_MultiCallbacks` class? How is it used in the given code?",
        "b564d7ce-1288-4322-adf3-2e839183e878": "Can you explain the role of the `RE3UpdateCallbacks` class in the code? What are the main parameters used in its initialization?",
        "878ec173-f6fe-4521-a68e-ae6b40a05785": "What is the purpose of the function Q(theta) in the given code? How does it relate to the quadratic function we are trying to maximize?",
        "9a449243-6dcc-4d84-90e4-262340b7bd26": "Explain the role of the hyperparameters h in the function Qhat(theta, h). How do they affect the estimation of the empirical loss/reward?",
        "bcbc0203-c37a-4802-b64e-e518852d7466": "What is the purpose of the function \"try_import_tf\" in the given context?",
        "b13f5157-7e86-4033-8ba7-aa745debd49d": "How does the function \"try_import_tf\" handle the case when the \"tf\" module cannot be imported?",
        "0ca94a11-e52c-4b33-b3d6-d82e45386a44": "What is the significance of the \"worker_launched_time_ms\" attribute in the context information? How does it impact the overall functioning of the worker?",
        "4ba54d8c-d3c0-4d2b-a1de-d60cfafae0a4": "Explain the purpose of the \"end_time_ms\" attribute in the context information. How does it help in monitoring the performance of the worker?",
        "d2110d98-b296-4fea-9ea9-2d5fdc46a76a": "What is the purpose of Grafana and how does it support advanced visualizations of Prometheus metrics?",
        "0e5c56a1-e9fc-4dde-8fc9-1b7680e05fe2": "How can you create a new Grafana server on a macOS machine?",
        "30db5f0f-d4cc-44c0-9e81-aab44f9b1779": "What is the purpose of the argparse module in the given code?",
        "776a5a22-b0c3-4cc3-b1f4-a88c5f642b9e": "How does the TrainMNIST class in the code inherit from the tune.Trainable class?",
        "b26974b9-b266-4a86-a9da-188072f87a2e": "How does agent grouping help in leveraging algorithms such as Q-Mix? Provide examples from the given context information.",
        "0cc1352a-cf72-4f06-8e24-80facf10ad3b": "Explain the concept of agent grouping and its significance in the context of multi-agent environments. How does it impact the observation and action spaces?",
        "8666afe2-642b-4a62-8d52-2a278e5fba87": "What is the purpose of the `from_checkpoint` method in the `TorchPolicyV2` class?",
        "08f8ae5f-ebfa-40bf-b2e7-340f3444fa7b": "How does the `from_checkpoint` method handle different types of checkpoints, such as Policy or Algorithm checkpoints?",
        "c2eb2e5d-b14d-49d1-910f-0cb09e1d13cc": "What is the purpose of the HyperBandScheduler in Ray Tune?",
        "5ab5cb7d-3ecf-4966-a998-a71048caa9ff": "How does the HyperBandScheduler handle trials that finish before the bracket iteration is complete?",
        "e11b76f6-0c8e-4e9a-a6ef-648d1e9c6c93": "What is the purpose of the `self._enable_record_actor_task_log` attribute in the given code?",
        "a340ca80-a09b-4177-84b8-7c5cf0f460cf": "How does the `self._filter_logs_by_job` attribute affect the logging behavior in the code?",
        "9f60f638-54c2-4147-9a9d-e8b8de153267": "What is the purpose of the \"prepare_dataset_shard\" function in the Tensorflow/Keras Training Loop Utilities?",
        "2edfa25c-1e64-4d1e-a2dc-38056d4f5e21": "How does the \"ReportCheckpointCallback\" function in the Tensorflow/Keras Training Loop Utilities contribute to the overall training process?",
        "5b58a9df-771e-4265-84b2-e517c9ac4a5a": "What is the purpose of the `from_dict` function in the given code? How is it used?",
        "b48413bc-2b03-4f83-b405-ac906b789487": "Explain the role of the `scaling_config` parameter in the `TensorflowTrainer` initialization. How does it affect the training process?",
        "b9d8aba2-7e15-4c59-8298-96b3661007ec": "What does the method `SampleBatch.keys()` return in the Ray RLlib library?",
        "93e472c9-1a3e-4cd3-a810-94753748bf45": "How can the `SampleBatch.keys()` method be used to access the keys of a dictionary-like object in Ray RLlib?",
        "1c0934ec-56aa-4bc4-86d7-a5d6594fd8c2": "What is the purpose of the `__ray_num_returns__` attribute in the given code? How does it affect the behavior of the program?",
        "44887e3e-c92f-4dda-89a1-1e34bf923eee": "Explain the significance of the `__ray_concurrency_group__` attribute in the context of the actor class. How does it impact the execution of methods within the class?",
        "eb43cbec-3395-4edc-9965-eeb8e58deedb": "Explain the purpose of the `_BackwardsCompatibleNumpyRng` class in the given code.",
        "cf9caaac-dd9a-4599-b45f-e80aa65a1e01": "How does the `sample_from` function work and what is its purpose in the code?",
        "d46bcadb-e915-4ced-bdb6-4d1fec857102": "What is the purpose of the `remove_module` function in the `MultiAgentRLModule` class?",
        "f77f88eb-a155-4d92-b6fd-fa6f683e26f1": "What exception will be raised if the `module_id` does not exist and `raise_err_if_not_found` is set to True?",
        "6b8826e1-0625-4332-9574-0fb027a64dbb": "What is the purpose of the \"scheduling_strategy_large_args\" parameter in the given context information?",
        "f607ddc0-0530-4b97-a296-862527fa2e1c": "How does the \"large_args_threshold\" parameter affect the execution of the program?",
        "73ef397f-a8f3-4b07-9da6-a42e046a8f01": "How does the property \"Partitioning.normalized_base_dir\" in the Ray data source module help ensure compatibility with a filesystem?",
        "f3a9250c-861e-45a4-b8a2-36b3ffbaa498": "Can you explain the purpose and significance of normalizing the base directory in the context of the \"Partitioning.normalized_base_dir\" property in the Ray data source module?",
        "32251ce8-47d3-4f11-b3f9-ca2755675e23": "What is the purpose of the \"observation_fn\" parameter in the code snippet?",
        "6e51481d-a42f-4b6f-9879-431184b722f9": "How does the \"render\" parameter affect the behavior of the code?",
        "5dde49c1-a573-4f55-93ec-be7ba62e6df7": "What is the purpose of the `Concatenator` class in the given context? Explain its functionality and how it is used.",
        "14a09bde-50fa-4bbc-aa2d-afab59f097cd": "How can you specify the columns to be included or excluded during concatenation using the `Concatenator` class? Provide an example to illustrate your answer.",
        "53069e8b-d6f3-4024-b745-9a8e12106952": "What is the purpose of the `WorkerSet.add_policy()` method?",
        "abaf1c18-7244-4abb-89e1-efd1016a2dcc": "Why is the `workers` argument in the `WorkerSet.add_policy()` method deprecated?",
        "0a46e181-4460-4a9f-8907-2c4ec97ed0f2": "What is the purpose of the `serialize()` method in the `UniformKBinsDiscretizer` class?",
        "5320f57c-1eb6-4e9e-96cd-676475d57f06": "Why is it mentioned that the serialization format used in the `serialize()` method is not stable?",
        "7758178a-1211-4a9b-879c-b4f4e3b33b13": "What is the purpose of the HyperBandScheduler.on_trial_complete method in the Ray Tune library?",
        "ddaa73e9-9197-47d0-8a1c-b8ef19f6f5ac": "How does the HyperBandScheduler.on_trial_complete method handle trials that are completed early?",
        "34484cc6-3aea-40bb-b914-03c380ac4cb7": "What is the purpose of the \"if\" statement in the given code snippet?",
        "eb0c4892-86be-4797-850c-231e340edf39": "How does the code handle the case when the policy ID is already present in the policy map?",
        "f3425306-97dc-47df-8fb9-9490ccb1db55": "What is the purpose of the \"upscaling_speed\" parameter in the AWS cluster configuration?",
        "fece11c6-78d4-4f8a-b3fd-d653c621d6ed": "How does the \"docker\" configuration in the AWS cluster setup ensure that all necessary ports are opened to support the Ray cluster?",
        "53ef319f-a9b6-4f6f-b7be-4cb52c128a9c": "What is the purpose of the \"_get_report_dict\" function in the given code?",
        "2ee255cb-25f7-4338-8e4a-1388eb946d95": "How does the code handle different versions of the xgboost library?",
        "d541080a-7b23-46c5-ad76-fd452bef4316": "What is the purpose of the `validation_step` method in the given code?",
        "497802d7-9cff-46d9-96eb-4f715e6bce87": "How does the `configure_optimizers` method help in optimizing the model's parameters?",
        "8bf623a5-578f-4200-b3a2-7755d1c856b1": "What are some examples of methods available in the `ray.rllib.utils.schedules` module?",
        "f8440976-c516-4ac6-b7fb-67e267cad70c": "How do the `ray.train.lightning.RayDeepSpeedStrategy` and `ray.train.lightning.RayFSDPStrategy` methods differ in their functionality?",
        "195ad306-03b9-4a7e-893e-ab87c0678bb4": "What is the purpose of the `TuneReportCallback` class in the given code?",
        "181462b2-d298-430c-abb0-ae1bd38b5df6": "Why is the `TuneReportCallback` class deprecated and what should be used instead?",
        "5accf0bb-ab77-44e9-8cda-ac8acda6b1d4": "What is the purpose of the `ray.serve.http_adapters` module in the given source code?",
        "d95be6ed-31de-4355-8faa-4384a4f3271a": "How are the `_1DArray`, `_2DArray`, `_3DArray`, and `_4DArray` types defined in the source code?",
        "c4e474f8-afd0-4be1-936f-11f73c45436f": "What is the purpose of the `apply_gradients` function in the given code? How does it differ when `gradients` is equal to `_directStepOptimizerSingleton`?",
        "e8178707-89f8-4432-bea5-244a7372f682": "How does the code handle the case when `gradients` is not equal to `_directStepOptimizerSingleton`? What is the limitation mentioned in the comment?",
        "c656ee78-ec9e-46a6-b8bb-3b0927ab0ef7": "What is the purpose of the `wait()` method in the given context? How does it relate to synchronizing tasks?",
        "44838465-5b78-4a1d-94f9-1fd0b32ec7c5": "Explain the functionality of the `sync_up()` method in the context. How does it synchronize a local directory with a remote directory?",
        "030d44e0-1768-4dbf-a624-2ce459a00f3e": "What is the purpose of the `capacity` parameter in the `ReplayBuffer` class constructor?",
        "98f5ccba-1dd9-4aec-92bd-ddb5031a2a1d": "Can you explain the different options for the `storage_unit` parameter in the `ReplayBuffer` class constructor?",
        "7f71136a-ec4b-48d8-a564-a0170eeb5e4c": "What is the purpose of the KubeRay controller in the deployment process of a Serve application?",
        "d87d360b-a528-4471-b2f7-7c1145723f4d": "How can dependencies be installed during the deployment of a Serve application?",
        "5939bdf2-ff00-4d36-a9ff-3fcdfa2f4119": "What is the purpose of the `read_json` function in the given context? How does it handle multiple local files and directories?",
        "5b5d7c68-cb09-4853-91b9-135ca06a448f": "How can the `partitioning` parameter be used to handle data that adheres to a different partitioning scheme?",
        "8c8a30e6-7075-4b9b-928b-39e57880e70f": "How can you change the default behavior of Ray actors and actor tasks when they crash unexpectedly?",
        "acdee202-408e-4c95-99b0-753790b0bd96": "What options can you set in ray.remote() and .options() to modify the fault tolerance behavior of Ray actors and actor tasks?",
        "90bb8c96-7144-4f6c-89ae-79cdfc081cf3": "What is the value of the mean loss for the trial with the trial_id \"dd4b4e94\"?",
        "a63be437-a9ab-4aed-a90e-c75c4f5fe6f2": "How many iterations were completed for the trial with the trial_id \"dd487b56\"?",
        "365065e7-c8e3-4ca8-babd-90cd8b3c0ab9": "What is the purpose of converting the curiosity feature net, curiosity inverse fcnet, and curiosity forward fcnet to the device in the first part of the code?",
        "e8df35d7-6c23-410c-b3f1-b5a24d8745db": "How does the setup of the curiosity feature net differ from the setup of the curiosity inverse fcnet and curiosity forward fcnet in the else part of the code?",
        "5bf2f3d1-2692-4dcf-b985-f7db6e7c4b65": "What is the purpose of the \"PUT /api/serve/deployments/\"# endpoint in the Serve application?",
        "b6167645-5aa4-4167-b0a1-154bd452909b": "How can the Serve application be started on the Ray cluster if it's not already running?",
        "57d14b59-293d-4073-95ff-581a8b1a5a37": "How can models be used in various fields and industries?",
        "5b52b549-e503-479c-ba87-33574f3bc6c6": "What are the key steps involved in creating a model?",
        "76491a52-ac5e-4caa-b745-f81bc1e238ed": "What is the purpose of the `_setup_tensorflow_environment` function in the given source code?",
        "9f620350-2a9c-40f4-b3aa-f0fb5f52de7e": "How does the `TensorflowConfig` class differ from the `BackendConfig` class in the given source code?",
        "2759be71-65b4-4a84-a80e-441036cac3ec": "What are the key features of the BaseEnv API?",
        "3f9486e8-0039-4104-b33c-697ca45c3e18": "How does the BaseEnv API assist teachers and professors in their tasks?",
        "6709100f-9952-4d05-8b71-c7ae95c62c93": "What is the purpose of the `prepare_trainer` function in the HuggingFace Transformers library?",
        "8e95f5f6-e502-465a-aa7a-c68ab56ee802": "How does the `prepare_trainer` function enable integration with Ray Data in the HuggingFace Transformer Trainer?",
        "02e08896-6aec-43ab-ac34-e2af63e1ba2b": "How does the Catalog class in RLlib's native RLModules obtain its Models?",
        "39364e1c-0979-4b1c-a303-18bbb2afeab0": "What is the purpose of the Catalog class in RLlib's native RLModules and how can it be customized?",
        "39a607b1-03ab-48b0-8f53-e18dd9ef1efd": "What is the purpose of the \"ray monitor\" command in a Ray cluster? Explain its functionality and the options available to customize its output.",
        "88c932df-c458-4468-82b1-f87482caf8b2": "How can the \"ray monitor\" command be used to tail the autoscaler logs of a Ray cluster? Describe the steps involved and provide an example of how to use this command with the required arguments.",
        "aa3e73ae-6b29-4bbf-ac15-6d2b1ec1293e": "How does the field \"num-gpus#\" in the context information specify the number of GPUs available to the Ray container?",
        "f1a072f4-4da2-4c51-87ba-e12c603623dc": "In future versions of KubeRay, how will the number of GPUs be determined for the Ray container?",
        "2331f21a-a2b3-43eb-94a6-7a4534c3a296": "What is the main difference between Population Based Bandits (PB2) and PBT in terms of hyperparameter selection?",
        "eceb7350-0d14-4f15-9c2b-ecc313790fbe": "What are the required dependencies for the Tune implementation of PB2 and how can they be installed?",
        "54e81db0-a5e4-4484-a116-513f511c67c8": "What is the minimum version of Ray that supports deploying multiple independent Serve applications?",
        "8e813724-b1bc-4549-9c42-3eee935a02e2": "How can you monitor your applications when using Ray Serve?",
        "ec14660b-eb53-417a-9d1b-fde4b6e5b046": "Explain the purpose of the \"get_connector_metrics\" method in the given code. How does it contribute to the overall functionality of the program?",
        "6cf2b02d-2f99-4f8a-b1b9-bd2f2cc5e0a5": "Describe the steps performed in the \"reset_connectors\" method. How does it ensure the proper functioning of the action- and agent-connectors in the policy?",
        "09927f17-1685-45d3-9974-c24bedcfce0d": "What is the purpose of the `get_initial_state` function in the given code?",
        "e6b64f92-c6c8-4943-92e4-e06063f41f02": "Can you explain the meaning and purpose of the `view_requirements` attribute in the code?",
        "2f9694e7-3231-49bc-837a-5a0298eac12b": "How does the Exploration class in the ray.rllib.utils.exploration.exploration module contribute to the implementation of exploration strategies for Policies? Provide an overview of its methods and their purposes.",
        "4c8888e2-108b-49e5-b408-1848ab496196": "Explain the role of the get_exploration_action() method in the Exploration class. How does it compute exploratory actions and log-likelihoods?",
        "7e7923b6-f9f4-4e84-9f6e-68aca27ee810": "What is the purpose of the Ray cluster launcher in AWS and how does it work?",
        "33350ec6-5fa0-4c66-a5da-263277da898d": "Explain the steps involved in launching a Ray cluster using the cluster launcher in AWS.",
        "681056f1-eceb-4abd-8355-6204b7c3db44": "How does Ray Scheduling support GPU resources in its execution framework? Explain the role of GPU support in enhancing performance and scalability.",
        "7dc7fc28-af14-4019-b61e-3863008e778f": "Discuss the importance of Placement Groups in Ray Scheduling. How do Placement Groups contribute to efficient resource allocation and task scheduling in distributed computing environments?",
        "288531a5-d2ae-4cfe-a0eb-569e81e0ba7e": "What is the purpose of the `on_trial_error` method in the given context? When is it called and what is its expected behavior?",
        "a17cfc19-351b-4e2a-b7bc-0864d95f7510": "Explain the role of the `on_trial_result` method in the context. When is it called and what decision can the trial scheduler make based on its return value?",
        "8bd243b8-72f4-4d16-bcb3-fe647977654b": "What is the purpose of the BlendSearch example in the given context?",
        "cd8c76d0-171f-495c-8e07-fa5c860dbea6": "How does the evaluation function in the code work?",
        "dc3a0e27-7ef7-40ed-9115-d5c25043a969": "What is the purpose of the join() method in the AsyncSampler class?",
        "62d54059-933a-43af-9989-de0590559342": "Can a thread be join()ed multiple times? If yes, what happens when a thread is join()ed multiple times?",
        "69d30129-8977-4e0a-929a-659a588b8243": "What is the purpose of the `on_trial_complete` method in the given code?",
        "b4dffca0-d48f-4b37-86d6-ec89bc1af2d9": "How does the `save` method fit into the overall functionality of the code?",
        "a61db22e-33f5-4971-b597-e14bb07932f8": "What is the purpose of the `forward()` method in the `TorchModelV2` class?",
        "a3f98618-76fb-49bb-a272-407c473c2100": "Can you explain the difference between eager execution and symbolic execution in the context of the `forward()` method?",
        "fa156a45-5c4e-4940-880f-f984de89c51e": "What is the purpose of the \"local_shuffle_buffer_size\" parameter in the given context? How does it affect the data processing?",
        "0f1617c9-7b07-46c8-a7dd-190af42f375c": "How does the \"local_shuffle_seed\" parameter contribute to the random shuffle process in the context? Explain its significance.",
        "23a794f2-4e4b-4f49-b14a-41497b6d1b45": "What is the purpose of the \"from_checkpoint\" function in the Policy class?",
        "078a1960-2f26-4ba7-92d5-c66b824d6361": "How can the \"loss\" function be used in the Policy class?",
        "e419c581-36fa-4146-9cdc-b454cb5d0c51": "How does Ray handle memory usage when scheduling tasks or actors? Explain the concept of memory-aware scheduling.",
        "0ed2d0b8-e556-40ce-9838-0cededc9581d": "What is the purpose of specifying a memory requirement for a task or actor in Ray? How does it affect the scheduling process?",
        "e9399756-331b-4d7e-8b0d-7fc1f17ffb12": "What is the purpose of the \"head_node_options\" parameter in the context information? How should the options be formatted when passed to the ray start script?",
        "802b7c4a-f25b-4b17-a378-228fc1dde82e": "Explain the significance of the \"strict_mode\" parameter in the context information. What happens when it is set to true and when it is set to false?",
        "74f44529-6beb-409a-9468-638c5deb2134": "What is the purpose of the \"if\" statements in the given code snippet? How do they affect the values of \"init_args\" and \"init_kwargs\"?",
        "1d8f6141-59fd-4946-95bb-75233d776e9f": "How does the \"replica_config\" object get created in the given code? What parameters are passed to the \"create\" method of the \"ReplicaConfig\" class?",
        "73eff3a6-c527-4bcb-884e-21ee022c2329": "What is the purpose of the `SingleAgentRLModuleSpec` class in the given code? How does it relate to the `DiscreteBCTorchModule` class?",
        "fef54bfa-19a1-4fa2-b1ed-f4126600140c": "Can you explain the difference between the single agent and multi-agent setups in the provided code? How does the `MultiAgentRLModuleSpec` class fit into the multi-agent setup?",
        "f7ec42c8-7a2f-4e16-b38d-b0534766f3ef": "What is the value of the mean loss for the objective_f59fe9d6 result?",
        "63fd84ef-f81c-4ccb-9516-54f1a47b37a9": "How many iterations have been completed for the objective_f5b1ec08 result?",
        "81d7592e-0249-422e-94b5-0b24487def6e": "What is the purpose of the `metrics` parameter in the given context?",
        "c20ba6c1-b57b-4e3b-b8d6-5d2ab660b1c8": "How does the presence of a `checkpoint` affect the reporting process in the given context?",
        "daaa508a-c611-430c-8999-f5c641514c70": "What is the purpose of the `_check_registered_optimizer` method in the `Learner` class?",
        "6da660f4-9c53-4db6-800d-b5a75b15481d": "Can you explain the parameters of the `_check_registered_optimizer` method and their significance in the context of the function?",
        "682adfe9-3f2b-4eee-bdc8-3874fe8cc52b": "What is the purpose of the get_preprocessor() method in the TensorflowCheckpoint class?",
        "c583b571-55b6-449c-a37d-ae77e555dbf7": "How can you determine if a preprocessor was stored in the checkpoint using the get_preprocessor() method?",
        "074aab18-d58f-4d0d-bc86-8cc9250857f5": "What is the difference between the deployment code in the 1.x API and the 2.0 API?",
        "f8375970-8955-4bf2-b72a-5f2d209f754d": "How does the new deployment API in version 2.0 update the code for deployment compared to the previous version?",
        "6468104d-4f98-4472-8cd2-5fcaa67bd41e": "What is the purpose of the `_create_local_replay_buffer_if_necessary` method in the given code?",
        "01cf6793-c48e-402f-9e36-2995e4e6a851": "Explain the role of the `local_replay_buffer` variable in the `_kwargs_for_execution_plan` method.",
        "78d197ac-f382-4f7d-828f-21d4e5e36e7d": "What is the value of the mean loss for the objective_402f9534 result?",
        "dd07bb71-f454-4c19-89fd-f0df5c104707": "How many training iterations have been completed for the trial with trial_id 421d81ee?",
        "95aa7e34-f56e-4577-810f-1018c9d016a9": "What is the purpose of the `_call_placement_group_ready` function in the given code? How does it determine whether the placement group is created or not?",
        "82192c0c-1941-49a9-8a46-c983949f463b": "How does the `bundle_specs` property in the `PlacementGroup` class retrieve the bundles belonging to the placement group?",
        "68a3ffc0-bd10-4374-95f1-30870c1eb83d": "What is the purpose of the `user_config` field in the given context information? How can it be updated without restarting replicas?",
        "c5557f9d-5ebc-4a6a-b1c8-9b12df7eb4c9": "Explain the role of the `autoscaling_config` field in the context information. What happens if this field is set to null?",
        "22085049-4e83-476f-b5b9-dd8e50ba02fd": "What are the differences between the \"restore_from_object()\" and \"restore_workers()\" methods in the \"Algorithm\" class of the Ray library?",
        "e4179b80-f787-40a2-ae4b-d6f22e271066": "How does the \"results_df\" property in the \"ExperimentAnalysis\" class of the Ray Tune library differ from the \"results\" property?",
        "ab38b4c4-b45c-466c-8105-5e387b787993": "What are the different ways to monitor spilling in Ray? Explain each method and provide an example of when each method would be useful.",
        "a4079e49-bcf2-4634-b523-3efc02d5c33c": "How can you view cluster-wide spill stats in Ray? Describe the command to use and provide an example of the output it would generate.",
        "64e14736-ce45-4a7e-85a6-9482fb82ebdf": "What is the purpose of the `__init__()` method in the given code?",
        "a9e81ea1-22e8-4781-b0dd-f660181325e5": "How does the code handle the `runtime_env` dictionary?",
        "2fd233c3-9577-41f0-9e34-c6c6329747d4": "What is the purpose of the `set_policy_mapping_fn` method in the given code?",
        "71fae422-2eba-4da9-a5c0-4b98c67e521a": "How does the `set_is_policy_to_train` method affect the training of policies in the code?",
        "f3dae851-ea29-4091-b418-11ec3b5972b6": "What is the purpose of the \"serve\" command in the CLI for managing Serve applications on a Ray cluster?",
        "f2fb37c9-5600-4a8c-b89e-5c54a3d59fa8": "How can the \"serve\" command be used to manage applications on a Ray cluster?",
        "31b51dde-7049-438c-b3b2-408648a25546": "What is the purpose of wrapping application-level failures as Python-level exceptions in Ray?",
        "071c4f2f-23f8-4425-8cf8-9d51b8bd6af1": "How does Ray handle failures in tasks executed on remote workers or actors?",
        "61c60bbe-05aa-42b1-8eed-4e0373004281": "What are the possible fit statuses of the preprocessor class? Explain each fit status briefly.",
        "c5b2b116-4397-4557-a3dc-5c4422bc22c7": "Why is the `transform_stats()` method deprecated in Ray 2.4? What alternative approach is suggested for obtaining dataset stats?",
        "355487dc-9de2-4093-925b-cc683dda0512": "What is the purpose of the `transform` variable in the `train_func` function?",
        "d2fce595-663f-45b2-bd56-439839bffb7b": "How is the `trainer` object configured in the `train_func` function?",
        "5883bcfe-4838-4dfd-a1cb-8d065c89d166": "What are the possible values for the \"mode\" attribute in the TuneConfig class? How does it affect the optimization process?",
        "9b30c572-cd88-4638-99e2-8754ebf4070a": "Can you explain the difference between the \"search_alg\" and \"scheduler\" attributes in the TuneConfig class? How do they contribute to the optimization process?",
        "4d9a01eb-eb3c-45d5-8d24-df6c81308f32": "What is the purpose of the TorchPolicyV2.action_sampler_fn function in the Ray RLlib library? Explain its parameters and return values.",
        "9da955e1-20d2-4cb9-918e-c0afb10c74bc": "How does the TorchPolicyV2.action_sampler_fn function contribute to the overall process of sampling new actions in reinforcement learning? Describe its role in the context of the provided information.",
        "d24f1142-1262-4918-bee8-bf20b017d821": "What is the purpose of the \"prefetch_batches\" parameter in the given context? How does it affect the data fetching process?",
        "b607d8e8-4c78-4eff-98fd-6d44be331d60": "Explain the difference between setting \"drop_last\" to True and False in the given context. How does it impact the handling of incomplete batches?",
        "ed61f0f2-2a9d-4b5e-ad4d-c1ad7e542ae7": "What are the key components of the QMixConfig object in the given example?",
        "bb0c77a9-a310-4952-9997-e681e4e214da": "How can the QMixConfig object be customized for training the algorithm?",
        "a8db73f7-490c-437a-80f6-3a4991957eaf": "What is the purpose of the \"Total optimization steps\" parameter in the training process?",
        "30ef8ecd-4642-4721-855c-f0f8a39890ca": "How does the availability of CUDA affect the training process in this context?",
        "5af260df-ea4a-4273-9250-c0008e265c54": "How does the \"update\" method in the SingleAgentRLModuleSpec class work? Provide an example to illustrate its functionality.",
        "f274303c-749e-4ce8-b908-1001ece4936b": "In what way does the \"update\" method in the SingleAgentRLModuleSpec class differ from the \"update\" method in a dictionary? Explain with an example.",
        "a3abfa97-39f7-4002-b0f2-cd4b2d5b1ad4": "What is the purpose of the \"update_default_view_requirements\" method in the given code?",
        "c8cf0196-2e14-4ea4-b299-8b3889920171": "How does the code handle backward compatibility for the Policy class?",
        "ae17d6ad-9860-448f-803f-ccac64a7a98b": "What is the purpose of the `label_column` parameter in the given code? Can it be set to `None`? Explain.",
        "98908899-8195-4d5f-9946-c7d3b6a98cee": "How does the `prefetch_batches` parameter affect the data fetching process in the code?",
        "decac94b-49c5-47fb-94c9-3eaa47c5cb8d": "What is the purpose of setting the \"remote_worker_envs\" parameter to True when using multiple environments per worker in RLlib?",
        "aeaf13d3-5b9c-45b1-a816-be0f612883e3": "How can the \"remote_env_batch_wait_ms\" parameter be optimized for better performance in RLlib?",
        "14a49440-05e5-4ad0-b486-31c451e58a62": "What is the purpose of the `CheckpointConfig` in the given code?",
        "6d6edfff-be41-4ab3-b5cf-ee9779d507fa": "How does the `tune_config` parameter in the code affect the tuning process?",
        "9a099e49-8c7b-4a4e-ab60-356852700045": "What is the purpose of the `env_steps()` method in the given code?",
        "b78f983e-235d-4e36-bc1b-de8355c7394e": "How does the `agent_steps()` method differ from the `env_steps()` method in terms of the information it provides?",
        "4bbef8d8-ea9f-425c-b89f-0788c4887543": "How does setting the `use_legacy_iter_batches` parameter to True affect the prefetching behavior in the dataset?",
        "ac1a8e57-b2a6-42e8-bcd1-686c4b811967": "In the context of local shuffling, what is the significance of the `local_shuffle_buffer_size` parameter?",
        "82a7eb96-7ea7-456b-b7a9-7915ef52a516": "What is the purpose of the DefaultCallbacks class in the ray.rllib.algorithms.callbacks module?",
        "a2149854-f182-4e93-bb38-b22d61405378": "How does the DefaultCallbacks class differ from the Algorithm class in the ray.rllib.algorithms module?",
        "93d23266-54d0-4a24-bd53-0fb419bf5c58": "What is the purpose of adding the Sonatype repository in the pom.xml file when using the latest Ray Java snapshot in an application?",
        "886e03a6-351d-49fc-8a97-5bbc0e0e6d19": "Why is it recommended to exclude Ray jars when packaging Java code for running in a multi-node Ray cluster?",
        "f657be53-aa1d-43a9-9b65-1a64e24cb0d7": "What are the three main differences between the training loop defined in the code and the original PyTorch Lightning code?",
        "3b624636-caf9-438c-b67c-314d6198e23b": "How does the Ray Train provide checkpoint reporting and what is the purpose of the RayTrainReportCallback?",
        "2bbbd2ba-96b2-43af-b9b9-1b939064cecb": "What is the purpose of the `copy_torch_tensors` function?",
        "2d0fec54-a5f1-41f8-91d9-f501848bd667": "How does the `copy_torch_tensors` function handle objects that are not torch.Tensors?",
        "221e90fa-9d59-4763-9eab-a6242ce7cd08": "What is the purpose of the \"read_csv\" function in the given context? How does it contribute to the creation of a Dataset?",
        "2e7c54aa-2a2e-499f-8bfd-37463dfc2dc3": "Explain the functionality of the \"write_csv\" method in the context of the provided information. How does it enable the writing of a Dataset to CSV files?",
        "19740f2f-f3b8-403b-bd60-f8ce4f1a92ed": "What is the purpose of the `attempt_number` parameter in the given context information?",
        "c41fbefb-23a7-4237-b9bf-76fafd17f34d": "How does the `follow=True` parameter affect the behavior of the function?",
        "6944aa3d-0920-4d4c-be1b-dc52dc72704c": "Can you explain what the `Generator` return type means in the context of this function?",
        "9b12ee52-c046-49b8-a9f6-b9686127daac": "What exception is raised if the CLI fails to query the data?",
        "79d1e307-d4b0-4df3-a41a-07af7c1e7339": "How would you describe the overall functionality of the function based on the context information provided?",
        "d9be8b48-9a91-45be-9a9a-065fffdf89a0": "What does the `sum` method in the `ray.data.Dataset` class do? Provide an example of how it can be used.",
        "96220907-da7a-42bf-8e08-123a4c7851c1": "What are the parameters that can be passed to the `sum` method in the `ray.data.Dataset` class? Explain the purpose of the `ignore_nulls` parameter.",
        "29b2f76f-a356-4aca-af41-952cef5c4154": "How can the Memory Monitor tool be used to analyze memory usage in a software application?",
        "e09d9fdc-1d6f-4876-903e-ba03115f501b": "What are the benefits of using the Memory Monitor tool for developers and software testers?",
        "393b6491-edea-4f45-9af2-3b9c730a233f": "What is the purpose of the code snippet provided?",
        "f774c312-0052-4ef1-bbd3-1824da37d1fe": "How are the values of `unsquash_actions` and `clip_actions` determined in the code?",
        "69c10e03-204d-41e2-a355-a1cebc2a1193": "How does enabling TLS authentication impact performance in a distributed system like Ray? Provide examples of when the performance overhead is large and when it becomes relatively smaller.",
        "fc06444c-f6eb-4819-979b-d3a02060cdf5": "What error message would you expect to see if the head Pod's certificate does not include the service-ray-head in the alt_names section? How can this error be resolved?",
        "7a98d460-3969-4b45-984a-c0b0af7d0b3e": "What is the purpose of the lambda function assigned to `self.policy_mapping_fn` in the given code?",
        "2e309c86-bead-4e35-99c4-de504776f2aa": "How is the `total_rollout_fragment_length` calculated in the code?",
        "bbb429b7-7a6d-4fd3-9af5-a230a96eb093": "What is the purpose of the code snippet provided?",
        "9bb1b232-40de-4559-bff4-fea78312ee45": "How does the code snippet ensure that only specific parameters have their gradients reset to zero?",
        "90b72fe5-0196-4153-89da-f3b8ff1585c6": "What is the purpose of the `_prefetch_next_batch` function in the given code?",
        "082c78b5-d821-46af-a929-6bf3d5c7dfe2": "How does the `__iter__` function work in the given code?",
        "da52716b-8411-4703-8afc-2540afaa8e96": "How does Ray provide fault tolerance at the application level?",
        "c3577ecd-7b24-4a0e-847f-317a44a7b344": "What is the purpose of setting up an external Redis instance as a data store for the Ray head?",
        "38027964-7fdc-4ff5-ad00-b5607645ad5c": "What is the purpose of the `to_pandas_refs` method in the given code? How does it convert a `Dataset` into a distributed set of Pandas dataframes?",
        "3c688d68-a361-412c-87eb-7b165d6059de": "Explain the time complexity of the `to_pandas_refs` method. How does it depend on the dataset size and parallelism?",
        "e5e95cce-0782-4edb-8ab1-a7a9ec0f58d5": "What is the purpose of auto configuring locality in the given context information?",
        "0c484f41-d088-4c8d-a909-fb3986000545": "How many different locality configurations are mentioned in the context information?",
        "cfb2807d-3a63-4ca7-8c05-ceb3052eff27": "What is the purpose of setting the AUTOSCALER_MAX_NUM_FAILURES environment variable to a large number (or inf) in the context of configuring the autoscaler for long running clusters?",
        "c33dc332-b76f-41ab-836f-1271c66478b2": "In the context of configuring the autoscaler for large clusters, what parameter can be tuned to achieve faster autoscaling and why is it important?",
        "d1e32e70-dfad-400a-a216-7ab6d04bb20b": "What is the purpose of the `tuner` object in the given code?",
        "b596053c-79ec-45e2-ab97-306130ee0cbc": "How does the `param_space` parameter in the `tuner` object affect the tuning process?",
        "798e9809-1fcd-41f9-ada1-3c5ad8b2c124": "What is the purpose of the `MyModelDeployment` class in the given code?",
        "e71ee23e-5d35-4f17-92f4-c853993352ef": "How can you deploy the Ray Serve application locally?",
        "8e81b9b2-0fff-4295-8e58-edd23f62b2f4": "What is the purpose of the on_evaluate_end callback function in the Algorithm class? How can you modify the evaluation_metrics object within this function?",
        "a6807b19-7b57-4e10-a01f-8a838b5e77c6": "Explain the role of the on_postprocess_trajectory callback function in the RolloutWorker class. How can you use this function to perform additional postprocessing for a policy?",
        "4914dfc0-2187-4dab-abe7-b9a9b8bdc464": "What is the purpose of the `forward` method in the `TFModelV2` class?",
        "1e102c09-361c-4e0f-a669-5d9b203671e4": "How can you import weights from an h5 file into the `TFModelV2` class?",
        "b5db08e6-f7ea-4df2-ac55-ec7303a41a60": "What is the purpose of the `if key == SampleBatch.DONES` condition in the code?",
        "41b35444-2c28-4fef-81c0-0213ad9ada38": "How does the code handle backward compatibility for the \"is_training\" key in the SampleBatch?",
        "632042b8-f965-4e45-bccc-442e5f616af0": "What is the purpose of the `iter_torch_batches` function? How does it differ from the `lazy` function?",
        "b58019ad-dcf0-4a36-9748-37b86c70efea": "How can you compute the mean of one or more columns using the `mean` function? Can you provide an example?",
        "f21a1cf3-2637-4711-b1ca-ddc4e86ae1b6": "How does the function \"_prepare_progress_reporter_for_ray_client\" prepare the progress reporter for Ray Client?",
        "3f9bfe9f-8cca-49ec-8801-6146345c73b1": "Why is a string queue created in the function \"_prepare_progress_reporter_for_ray_client\" for Ray Client?",
        "3dc0aa33-4afb-40a1-b4ee-773d5bc80f49": "How does specifying a working directory in the runtime environment affect the behavior of the Ray client when running ray.init()?",
        "a5ebe3eb-65bf-42cc-af60-21b800a6d1f6": "Explain how the use of relative paths in remote task definitions allows for seamless execution of code on both the laptop and the cluster.",
        "a54ebbc6-5c08-4fcc-84bf-51ded8ec8642": "Explain the purpose of the ExponentialSchedule.value function. What are the parameters it takes and what does it return?",
        "c86f1472-be6b-42a8-8991-da44fe9a96dd": "How does the ExponentialSchedule.value function generate the calculated value based on the timestep? Can you provide an example to illustrate its logic?",
        "adb73783-2bff-4936-94f8-85e9e2aa6369": "What is the purpose of the code snippet provided?",
        "d0240698-2084-4130-a0a6-a7d92da1d247": "How does the code handle the case when the `seq_lens_` variable is either None or an empty list?",
        "3a3307e5-726d-4d2a-b00b-74d4f9b6cdff": "What is the purpose of the `_opt.observe` method in the given code?",
        "75584f2f-42fc-407d-874a-d0eaa4dbbda3": "How does the `set_search_properties` method contribute to the overall functionality of the code?",
        "832f9f80-8177-434e-a042-6718a00bfe4b": "What is the purpose of the `TuneReportCheckpointCallback` class in the `ray.tune.integration.lightgbm` module?",
        "353756af-c641-4dfc-8e25-55060f0a9d4c": "How does the `TuneReportCheckpointCallback` class in the `ray.tune.integration.lightgbm` module handle metrics reporting and checkpointing during model training?",
        "3ce341e4-d1e9-49e3-8297-d116c3f43ed6": "How does the Preprocessor class in the ray.data.preprocessor module transform a single batch of data? What are the input and output types of the transform_batch method?",
        "54e17a88-24b4-472c-a9d4-4338976d4619": "Can you explain the purpose of the _transform_* methods in the Preprocessor class? How do they affect the transformed data batch returned by the transform_batch method?",
        "61beb636-46ba-456d-a777-33f1ec2b8fd2": "What are the different file formats supported by Ray Data for reading files from local disk or cloud storage?",
        "2f2e7878-40f4-41ee-8db5-a033fa7dda6c": "How does Ray Data represent images when reading raw images?",
        "66f43b02-73a0-4f2d-b62c-6918241ca240": "What is the purpose of the variable \"SampleBatch.CUR_OBS\" in the given context?",
        "36e2e533-279f-440d-8b58-99bf00a469b5": "How does the variable \"SampleBatch.CUR_OBS\" relate to the overall functionality of the Ray RLlib policy?",
        "8a510204-f12f-47ed-ad04-7c30375c0f68": "Explain the concept of parallel execution in Java using the given code snippet. How does it contribute to improving performance?",
        "2879e9f8-6639-4ad4-b3db-307f82354e5d": "Describe the difference between executing tasks in parallel and executing tasks serially in the context of the given code. How does it affect the outcome of the program?",
        "2259fa3c-01bb-413e-a368-b2348ab658e3": "What is the purpose of the \"aggregated_results\" dictionary in the given code?",
        "e66e24c5-cdeb-4b42-bd0d-83532d8aa8e8": "How does the code calculate the mean results for each model?",
        "feba3902-986a-4c1b-a823-5e55b89fd7ee": "What is the average download speed, in MB/s, shown in the context information?",
        "da6126f5-94b4-4b47-b2a0-ee6bace80306": "How much data, in MB, has been downloaded so far according to the context information?",
        "9f830925-6ced-4865-b875-e965839ee526": "How can you use the `setup_mlflow` function to integrate MLflow into your code?",
        "e98712e2-2e63-4eab-8ba5-a951640e5711": "What is the benefit of utilizing the return value of `setup_mlflow` in distributed data parallel training?",
        "3a8c5782-f80f-47bc-b395-d02e3a6a7a32": "What are the different types of search optimization methods mentioned in the context?",
        "d24e8f81-3262-4184-8162-08885408db5d": "How does TuneSearchCV differ from GridSearchCV in terms of parameter settings sampling?",
        "e3047da0-c55a-49e9-be6b-8df5b0470515": "What is the purpose of the `training` method in the given code?",
        "c612c7b9-ff4d-4787-9682-cfdd9b3a28a1": "How is action noise added to computed actions in the training process?",
        "16a2ead7-7c89-4135-8204-714f3642c7d2": "What is the purpose of the `TransformersCheckpoint.get_model` function?",
        "e61979a3-9f5f-4629-8a3b-067895e5a16d": "How can you retrieve the model stored in a checkpoint using the `TransformersCheckpoint` class?",
        "58612c9d-dd7a-4c9e-80b7-d695795a63fc": "Explain the difference between the pipeline without windowing and the pipeline with windowing in the given context. How does windowing affect the preprocessing, inference, and writing stages?",
        "266f0637-fc2c-4b3a-bf2b-be497d64b4a6": "How does the stage parallelism impact the length of the pipeline in the given context? Provide an explanation with an example.",
        "7b407290-a2f5-4c09-990e-4afc7f375be3": "What is Dragonfly and how does it contribute to optimizing hyperparameters in machine learning?",
        "ccc77ec4-a43c-4b13-ab65-d3aeb336ebb0": "How can Dragonfly be used to scale up Bayesian optimization for large-scale and high-dimensional problems?",
        "ac1c2976-d794-41e0-ad5d-564e7a1d8d0c": "What is the default value returned by the method `get_assigned_resources` for tasks?",
        "475c3dec-9c33-4a9d-bfa5-4c7329a4fd97": "Why do actors not have CPUs assigned to them by default according to the `get_assigned_resources` method?",
        "e3fc049d-f4c7-4722-9d52-d8c7239996ce": "What is the purpose of the `fully_executed` method in the given code? Why is it deprecated?",
        "8bc88cd1-380d-4b37-81f8-d08c43fcd810": "How can you determine if a `Dataset` object is fully executed? Why is the `is_fully_executed` method deprecated?",
        "0f95384e-7357-49c0-ba7f-ac209a4de6d0": "How can hyperparameter tuning improve the performance of a PyTorch model? Provide examples of hyperparameters that can be tuned and their potential impact on model accuracy.",
        "752a1247-cab2-4e16-a8eb-2a7fdf6168b0": "Explain the modifications that need to be made to integrate Tune into a PyTorch training workflow. Include the steps involved in wrapping data loading and training in functions, making network parameters configurable, and defining the search space for model tuning.",
        "f93569a3-726b-42e0-a26f-71dce182d3d5": "What is the purpose of the `update_from_dict` method in the `AlgorithmConfig` class?",
        "6d9a1c95-0baf-48e0-b103-dbf2fe121260": "How can the `update_from_dict` method be used to configure custom Policies that do not have their own specific `AlgorithmConfig` classes?",
        "df3d44b7-875b-4e18-b650-5b3710b649f8": "What is the purpose of the `stats_fn` function in the `TorchPolicyV2` class?",
        "d456bf84-9c81-435f-9ca5-46cb64727a5c": "How does the `stats_fn` function in the `TorchPolicyV2` class contribute to the training process?",
        "114abf11-1ff1-4258-acd8-885056bb2fd5": "How can the return value of setup_mlflow be utilized in distributed data parallel training?",
        "46569864-ca8c-4f03-aeed-eaa78fcb819d": "What is the purpose of using MlFlow's autologging feature in training frameworks like Pytorch Lightning and XGBoost?",
        "1168b393-71d6-4bb0-b16b-7db68e38e7f4": "What is the purpose of the \"finalize\" function in the given code? Explain its role in the computation of the final standard deviation.",
        "ed4569cb-1d35-4905-963b-9b93da217929": "In the \"finalize\" function, what values are used to compute the final standard deviation? Explain how these values are obtained and their significance in the calculation.",
        "81a7c463-373e-48b9-986f-e8681fce6476": "Calculate the value of variable \"y\" using the given context information.",
        "4a7a7b82-212f-45ba-b6b5-e87c688782bf": "Explain the purpose and significance of the variable \"alpha\" in the given code.",
        "32b7257f-1baf-466b-8a92-e199819bd57f": "What is the value of the neg_mean_loss in the context information?",
        "08639778-13ba-48a0-83ca-b2b194e98fbb": "How many training iterations have been completed in the context information?",
        "8c174f80-fdee-40a7-b55c-7e7c6913ef68": "What is the purpose of the `init_collective_group` function?",
        "6a7e0d75-0d81-4b29-8f35-efaa85f3324d": "How does the `create_collective_group` function differ from the `init_collective_group` function?",
        "e87fca33-4188-442a-a8bf-2a3cf2a516f4": "What are the possible fields included in the `RuntimeEnvConfig.known_fields` set?",
        "06159a75-d764-4e01-a46f-49cf83c24fff": "How can the `RuntimeEnvConfig.known_fields` set be used in a runtime environment configuration?",
        "55e9e5cc-c8cb-4477-ad83-e3f775caa31a": "What is the purpose of the `std` method in the given context? Explain its parameters and their significance.",
        "cd066a5e-b5b1-466b-945c-532b5da3372b": "How does the `std` method differ from the `mean` method in terms of the aggregation it performs?",
        "9075d957-cf21-4de2-bb55-5c8cc144b894": "What is the average download speed, in MB/s, for the file \"l-00001-of-00003.bin\" based on the given context information?",
        "746fbf50-d0d2-4fb7-93e4-36854b0c0c00": "How many times was the file \"l-00001-of-00003.bin\" downloaded across the cluster according to the context information?",
        "2a2d397e-88fb-44f8-bfef-ffcbe07733e6": "How can you use GPUs for inference in your code? Provide the necessary changes to the code.",
        "9e9cbfbd-e4b4-4d86-9b26-d99452c12dec": "What changes should be made to the class implementation to move the model and data to and from the GPU?",
        "d97274fc-aebe-449b-9752-9d9ef736ff1a": "Explain the workflow described in the context information. What are the initial tasks and how do they generate additional tasks?",
        "c881ea7f-5135-45bb-b7c8-2f975b74b90a": "Describe the execution order of the tasks in the workflow. How does the final task, finalize_or_cancel, obtain its input?",
        "d4e02a55-3f61-4c74-b96a-7ccbfdb491fe": "What is the purpose of the \"raise ValueError\" statement in the code?",
        "8cb864fc-86aa-442d-a10b-1330810ae161": "How does the code handle the situation when more than one dataset is specified to be fit?",
        "b0ec4672-3417-44e5-9fb4-5da16352c764": "What does the code do if a dataset is given that is not expected?",
        "68159d91-6ec2-4838-b457-422b91aea363": "Can you explain the purpose of the \"_merge\" method in the code?",
        "2c2d8177-9333-4734-b9fc-d39db08ffe97": "Explain the purpose and functionality of the `transform` function in the given code.",
        "8e1f9a0d-1c0b-4acb-9f93-4610467e0e37": "How does the `load` function retrieve the total order value from the `data_dict` parameter?",
        "3630d05d-e95e-4de8-ab04-c750f19091f6": "How are GPUs important in machine learning applications?",
        "eca24b82-a03e-42a8-9ffb-9267a780a1db": "How does Ray support GPU usage in tasks and actors?",
        "0ff63a35-fa15-40f9-911f-cb5d1c2b270e": "How does the HyperBandScheduler.metric# property impact the scheduling process in Ray Tune?",
        "713e381b-1408-4805-b42a-617153a7ac02": "Can you explain the role and significance of the HyperBandScheduler.metric# in the context of Ray Tune's scheduling algorithm?",
        "667f4f8b-e2a7-469e-bf35-cb7f98435015": "How does the Ray autoscaler react to resource demands in a cluster? Does it increase or decrease the number of worker nodes?",
        "b6c43a08-a7e4-4b24-a956-ae60e842eaa6": "What factors does the Ray autoscaler consider when making decisions to add or remove worker nodes from the cluster? Does it take into account application metrics or physical resource utilization?",
        "e7b6c848-2c1d-45c8-b5e5-45c7270b3119": "Why is the Ray image being changed from rayproject/ray:${RAY_VERSION} to rayproject/ray-ml:${RAY_VERSION} in Step 5?",
        "bb179de5-4556-4646-ae08-6e15d7367bf3": "What is the reason for using an image with TensorFlow as the base instead of installing it within Runtime Environments in Step 5?",
        "a87891a4-3f3b-4099-b984-786181fbec01": "What are the possible values that can be set for `evaluation_strategy` and `save_strategy`?",
        "e1d14d2c-956a-4062-a6b9-6493322ccb44": "What are the conditions that need to be satisfied when using the 'steps' `save_strategy`?",
        "949b4a7d-6bcf-4bcd-aa48-a686fe3dc0c1": "What is the purpose of the put_nowait() method in the ray.util.queue.Queue class?",
        "b0138896-4de9-4e75-b5fa-16372ed53737": "How does the put_nowait() method differ from the put() method in the ray.util.queue.Queue class?",
        "6e3e88a4-d30d-44c6-8006-49c815450529": "What is the purpose of the `RunConfig` class in the given context?",
        "0da5e6e7-ebed-4986-ad67-e94de47f0610": "How does the `max_height` parameter affect the output of the `_tune_legacy_checkpoint_score_attr` method?",
        "b7338f7e-8c8a-4e73-b839-6272d926d485": "What is the purpose of the `is_driver_deployment` field in the given code snippet? How is it different from other deployment types?",
        "04b511da-bc73-4184-bdec-a09d85005ed1": "Explain the purpose and functionality of the `num_replicas_and_autoscaling_config_mutually_exclusive` root validator method in the code. How does it ensure the correct usage of the `num_replicas` and `autoscaling_config` fields?",
        "bf9cb9bf-927a-4493-9044-71023d1a9a97": "How can you ensure heavy computation is done efficiently within Ray tasks, actors, or Ray libraries?",
        "6eb44506-1ab6-4547-90fe-8b841781d2c5": "What arguments can be used to specify CPU and GPU resources for the entrypoint script in Ray?",
        "895b02cd-c4e5-4bfb-8bd5-06de8870f92f": "What is the purpose of updating the target network in the given code snippet?",
        "dd9257c4-39a7-4062-9ce1-41989e0c5e0d": "How does the code ensure that the total number of timesteps reaches the specified train batch size?",
        "fc37c54f-31e9-4d9f-a0a9-9816c0c0d855": "Why is it recommended to include the preStopHook configuration in every Ray container's configuration?",
        "04babad9-563f-4f94-9012-d5a8a3e8f4d9": "What is the purpose of executing \"ray stop\" command in the preStopHook configuration?",
        "4695a2e4-c4c0-4267-8d42-75b0636d4de8": "What is the purpose of the `from_dask` function in the given code? Explain its input and output parameters.",
        "15e3cdbe-656e-409f-ba9f-8e5f86201ca3": "How does the `from_dask` function handle different types of input data? Explain the logic behind the `to_ref` function and its usage in the code.",
        "6d32bf8a-9f66-47f1-9ca1-2f818382ffe1": "What is the purpose of the \"name\" property in the deployment configuration?",
        "a6492ccf-a09b-477d-ae84-577fcf5fabd9": "How does the \"num_replicas\" property affect the handling of requests in a deployment?",
        "80f05b53-be47-4e90-8245-8fb8e8ed8f6f": "What is the purpose of the \"common_path\" variable in the given code snippet? How does it contribute to the execution of the code?",
        "a49ab74f-2804-4b0a-8864-ebc30ea64488": "Explain the difference between the execution flow when the condition \"partitioning is not None and common_path == _unwrap_protocol(partitioning.base_dir)\" is true and when it is false. How does it affect the behavior of the code?",
        "c982ad73-6282-40be-bcb2-97a2a24160df": "What is the difference between the \"run\" and \"run_async\" methods in the Workflow Execution API?",
        "02a3cc1a-a0ab-4adb-bc51-3c21ec481160": "How does the \"run_async\" method in the Workflow Execution API differ from the \"run\" method in terms of workflow execution?",
        "8db50e5c-c8d7-4c4c-862c-a6797e7e3e6f": "How can contributors identify issues to work on in the Tune project on Github?",
        "9b6f3584-626d-488d-938e-9aa1779ddc82": "What steps should contributors follow when raising a new issue or PR related to Tune on Github?",
        "54ceb8af-c4c3-47fc-a123-bb6cd19643e0": "How can the PopulationBasedTrainingReplay utility in Ray's Tune library be used to replay hyperparameter schedules of Population Based Training runs?",
        "14dbeea3-bd1b-437c-a684-66b2318b14d1": "What is the purpose of the PopulationBasedTrainingReplay class in Ray's Tune library and how does it work?",
        "8d77d2a2-5ae8-4aa2-bbba-25e4418c2e0f": "What does the `get_state()` method in the `Policy` class return? How is it different from an RNN model's internal state?",
        "db107d7e-b4e3-4022-83ef-5e7e40be3cd8": "Why is it recommended to use `deepcopy()` on the state returned by the `get_state()` method before mutating it?",
        "3a83aa56-d76f-45d3-8980-e74c08ad8a72": "What is the purpose of the code snippet provided?",
        "a8295e1c-e2d4-4d98-83bc-e8f0f87f70ed": "How does the code handle multiple policies in a multi-agent environment?",
        "f51eb4c5-5c01-4843-a27b-c1950c7116d4": "What is the purpose of the \"search_optimization\" function in the given code?",
        "1808a6b3-b84d-45f4-8ac1-44b0805a19f0": "How does the code handle different types of \"dist\" variables in the \"search_optimization\" function?",
        "2f59aec1-45f5-49e7-aac8-129001a1ebd3": "What is the purpose of the first \"if\" statement in the code?",
        "d40c4676-1d9a-4ecd-8452-a72dfcf53cde": "How does the code handle the case when the \"evaluated_rewards\" variable is not a list?",
        "338da2c0-f42a-4f14-9236-8c560beba869": "What does the property `RayDeepSpeedStrategy.root_device` return?",
        "7225f03a-b629-4596-861e-bf92ebfaaae7": "How can we access the root device using the `RayDeepSpeedStrategy` in the Ray library?",
        "b6fa7703-ce97-44df-be66-8bd044cf91d0": "What is the purpose of the \"Bottleneck\" module in the given context information?",
        "532e4d20-882d-454d-8a45-416647faa8bf": "How does the \"BatchNorm2d\" function contribute to the overall functionality of the model described in the context information?",
        "b25be35a-ec61-41db-b347-7b4c2794839f": "How does Ray Core's distributed APIs simplify the orchestration of large scale workloads? Provide examples from the highlighted feature projects.",
        "bebda70c-e225-4afd-af9f-7c796bd99955": "What are some notable achievements and use cases mentioned in the context information that demonstrate the capabilities of Ray Core in handling large scale workloads?",
        "a5df538d-e3b5-41cc-8f31-5dd54a33e5ff": "What is the purpose of the `Checkpoint.to_directory` method in the Ray library?",
        "d7ec1695-5744-4400-b7ae-6fa40418c0ca": "Can you explain the difference between specifying a target directory and not specifying one when using the `Checkpoint.to_directory` method?",
        "122800a2-ef46-473a-b0e7-58555c298dc1": "What is the purpose of the \"stop\" parameter in the RunConfig? How does it affect the execution of the program?",
        "2285a409-15ab-4e17-81ff-a3dab5f10256": "Explain the significance of the \"metric\" and \"mode\" parameters in the TuneConfig. How do they impact the optimization process?",
        "08199d87-ddad-4438-9ed7-26c4ae27f7ca": "What is the purpose of the `tune_with_setup` function in the given code?",
        "db8e2723-9d0f-4093-b62b-df9d81ee818e": "How does the `tune.Tuner` object in the `tune_with_setup` function work?",
        "0620e33f-6d41-4579-8baf-1c519bb37f02": "What is the significance of the `metric` and `mode` parameters in the `tune.TuneConfig` object?",
        "5b62c036-9863-40ae-ab40-bf9c6016af6a": "Explain the `param_space` dictionary in the `tune.Tuner` object and its role in the tuning process.",
        "276cc1d3-4629-4d18-ab4c-95ae0613de37": "How does the `tuner.fit()` method work and what does it do?",
        "1766f593-04bb-4e1b-9083-b9c6191b6595": "Can you provide an example of how to define a class-based Tune Trainable using the `setup_wandb` utility?",
        "091fa6f2-9518-4f93-98c5-c69d04d52b56": "What information needs to be passed separately when using a class-based Tune Trainable?",
        "fbf2b23f-93e0-406b-8c1d-4fa84f3d802b": "How does the `setup()` method and the `run` object attribute relate to each other in a class-based Tune Trainable?",
        "9670396c-4dbe-4d43-bdcd-af745a0f0a01": "Can you explain the purpose of the `trial id`, `name`, and `group` parameters in the class-based Tune Trainable?",
        "1b62906e-e39f-4f0d-b85c-458b4afd9384": "What is the purpose of the \"beta\" hyperparameter in the given context information?",
        "62a638b5-56a4-497a-a7e7-5d87cee4e7b0": "How does the \"beta_schedule\" affect the decay of the \"beta\" hyperparameter?",
        "475dbcde-25f6-45e3-9cbd-cbdca4a5ded2": "How does the OneHotEncoder.fit() method in the ray.data.preprocessors module work? Explain the purpose of this method and its parameters.",
        "86eb00f2-e206-4e3b-8616-5b9ee8095eaa": "Can you explain the concept of fitting a preprocessor to a dataset? How does the OneHotEncoder.fit() method fit the Preprocessor to the Dataset?",
        "f9ac6f5b-0b6c-4637-a8db-d7f96b1009fd": "What is the purpose of the \"pytorch_model.bin\" file being downloaded in the given context?",
        "69cc25d2-20ca-4ecb-a8ba-62b75d771bd3": "How does the download progress of the \"pytorch_model.bin\" file change over time in the given context?",
        "81ccbd6f-0219-419c-8d5b-f7c513c90215": "What is the purpose of the \"ServeDeploySchema\" in the Ray cluster? How does it relate to the v2 REST API?",
        "94fc7842-0456-4292-b02a-acf514a361da": "What are the different options available for the \"proxy_location\" parameter in the ServeDeploySchema? Explain each option briefly.",
        "b5ea5750-b978-407a-a131-926f2686e61d": "What is the purpose of the \"ray.train.lightning._lightning_utils\" module in the source code?",
        "2766fc0a-a47a-4c82-a25f-2ca479c14ca0": "Can you explain the difference between the \"LightningCheckpoint\" and \"LegacyLightningCheckpoint\" classes in the source code?",
        "596da1d5-761d-484f-802c-b86e088fea5d": "What is the purpose of the `@Deprecated` decorator in the given code?",
        "6e998006-306f-4275-9ae7-19e5126934fb": "How does the `A3C` class inherit from the `Algorithm` class?",
        "7f205a2e-e8e2-4545-8429-c301f06b7868": "Can you explain the purpose of the `get_default_config` method in the `A3C` class?",
        "1f76e0b4-3d57-474e-8144-d51993968ef6": "What are the different policy classes that can be returned by the `get_default_policy_class` method in the `A3C` class?",
        "4b79de81-1b14-466c-aadf-0a53d827b2e8": "How does the `training_step` method contribute to the functionality of the `A3C` class?",
        "6c3bfc21-d4bd-429c-94cc-940a3b711425": "What is the purpose of the following code snippet: \"if num_replicas == 0: raise ValueError(\"num_replicas is expected to larger than 0\")\"? Explain why this check is important in the context of the code.",
        "73af72ce-0261-4b7e-be71-1def78e03020": "Why are the \"DeprecationWarning\" messages being displayed in the code? How can these warnings be addressed to avoid errors in the future?",
        "4db43461-5609-46b4-a625-51108f469477": "What is the purpose of the `ReplayBuffer.apply` method in the `ReplayBuffer` class? Explain its parameters and return value.",
        "6afe6ca0-075f-4889-9151-efc79992e0ae": "How does the `ReplayBuffer.apply` method allow for the execution of arbitrary member functions on a remote actor? Explain the role of the `func` parameter and how additional arguments can be passed to the function call.",
        "218fe62f-f5c6-47d7-bfb9-65933e82fbd9": "What is the purpose of creating a new stub for each new child in the GreetingWorkflowImpl class?",
        "af149d25-5296-4899-85fa-84aebf068e85": "How does the GreetingWorkflowImpl class handle the asynchronous call to the child workflow in the demoAsyncChildRun method?",
        "cafac4b3-e2e2-4742-b7be-0108a66cd60e": "What are the two types of log files mentioned in the context information?",
        "8e9d7c27-9f42-4104-9e88-32b52dd8632f": "How can system log files provide information about applications?",
        "57ff6cb7-8f24-42af-a3b7-df236b97494b": "What is the role of the head node in a Ray cluster? How does it differ from other worker nodes?",
        "b337e054-9d86-46e3-8c17-b7aebea9d10f": "Why is it not desired for tasks and actors to be scheduled on the head node in large-scale clusters? What are the potential drawbacks of this?",
        "fc4b50d9-9241-42e7-b1ee-6971d6b3dced": "What is the purpose of the TD3 algorithm and how does it differ from the DDPG algorithm?",
        "bad1d6bf-1dab-477b-a7b1-52c3fae061e0": "Can you explain the configuration class used to build a TD3 algorithm and provide an example of how it can be used?",
        "292696f8-bd0a-4130-8bbc-57b46f908ce4": "Explain the purpose and functionality of the `ray.wait()` function in the given code snippet. How does it contribute to the overall execution flow?",
        "b6a82f1d-e0c8-4968-b1c5-1b6db251a459": "What is the significance of the `on_experiment_end()` method in the code? How does it ensure that all logs and artifacts are uploaded to wandb?",
        "092efc77-b4b5-42bc-9d17-c56eedf1e696": "What is the purpose of setting a minimum training time or timesteps for models before perturbing them?",
        "9e2c950b-a419-4c93-a865-672e11de3233": "How can hyperparameters be mutated in the context of model training?",
        "41a632e7-49fc-4900-bb4a-e8d6fc61e0b7": "What is the purpose of specifying the list of columns explicitly when calling ray.data.read_parquet()?",
        "0c689663-ff04-4222-991a-f62f47e88235": "How can you avoid loading unnecessary data when reading a Parquet dataset using ray.data.read_parquet()?",
        "ea32513e-adbc-4608-8d6c-21549d0eb5dc": "What is the purpose of the \"results.update(results[\"sampler_results\"])\" line of code in the given context?",
        "87312900-6264-43e8-81f3-de36a011e826": "How can the \"num_remote_worker_restarts\" metric be useful in evaluating the performance of the workers in this code?",
        "48ead8da-eaa9-4772-ae75-33701b070e62": "What is the minimum version of the 'transformers' library required for the 'TransformersTrainer' class?",
        "85a72149-866b-4f47-896a-015060ebdb5e": "How can you update the 'transformers' library to a compatible version for the 'TransformersTrainer' class?",
        "061ea14d-e5a2-4184-8b26-4de0b8d85b08": "What is the purpose of the `Tuner` class in the given code?",
        "88bfde33-5c40-402a-845c-f247ba7eced0": "How can we obtain the best ever reported accuracy per trial using the `result_grid` object?",
        "5760f666-d7dd-41d3-8f53-1596d33aced1": "What is the purpose of the OneHotEncoder.transform method in the given context?",
        "2bbc981a-61f4-4e79-ab88-a777ac1038c9": "What exception will be raised if the fit method is not called before calling the transform method in the given context?",
        "7935a5b1-eb5d-4f84-94c7-7e311f349804": "What is the purpose of the \"BlockMetadata.exec_stats\" field in the given context?",
        "e9305d34-fb1d-42ce-b700-d548832656ee": "How does the \"BlockMetadata.exec_stats\" field contribute to the overall functionality of the block in the context of Ray data?",
        "df786523-b788-4e4f-8eff-6c6c86e68dba": "Explain the purpose of the `assign_value` function and how it handles the special case of tuples.",
        "d51b423b-feef-40ef-9f54-14090cc87536": "Describe the functionality of the `_get_value` function and how it is used in the code.",
        "4aa5e879-6fed-4413-96bc-4ad476babc3d": "How can the trial ID be accessed for a Trainable object in Ray Tune?",
        "828786da-428d-44f9-8aac-9628d5fa09e6": "What is the purpose of the trial ID in the context of Ray Tune's Trainable class?",
        "099a971e-b58a-4e03-84e7-4e626d619c6e": "What information is displayed on the Serve Replica Detail page?",
        "673e6d04-84c7-43b1-9d8a-1937f0ef0fa8": "How can Grafana and Prometheus be configured to display high-level metrics about the Serve replica?",
        "b046c739-73d4-4223-bc37-eb398336ca80": "How does the policy_mapping_fn function in the given code determine which policy controls the traffic lights and which policies control the cars?",
        "2f726a1b-1b1c-4606-916c-85b6fe517c02": "Can you explain the purpose and functionality of the multiagent.policies_to_train setting mentioned in the context information?",
        "709dbf6d-6381-4a89-ae2b-6891ff27cbd8": "What is the purpose of the method `_maybe_save_artifacts_to_cloud` in the given code?",
        "efc72820-2bfa-4669-a21d-88f40892cccc": "How does the `logdir` property in the code work and what is its significance?",
        "13bfc5fd-05c8-45b2-a38e-58d3d41cb39c": "What was the loss value after the second epoch of training?",
        "1532dd17-e924-4de0-9ea5-7ccedd6a125b": "What was the Matthews correlation coefficient after evaluation?",
        "68713d88-4ad3-4ffa-9e0a-0cd532f1fdf6": "What are the hyperparameters used in the training process for the model \"train_mnist_tune_63ecc_00006\"?",
        "e67428f4-f822-4405-afd5-74fe672be6a2": "Compare the performance of the models \"train_mnist_tune_63ecc_00007\" and \"train_mnist_tune_63ecc_00008\" based on their accuracy and learning rate.",
        "c6f9a6c4-b916-4656-88f4-6cf0647f182e": "What is the purpose of the `save` method in the given code example?",
        "ffb9f3f7-a0f3-4d80-a1a1-6d815fee7ce9": "How is the `set_max_concurrency` method used in the code example?",
        "d305b81e-e45a-4809-bf42-15eead753c7e": "Can you explain the role of the `ConcurrencyLimiter` class in the code example?",
        "0de1bc4e-975e-460f-88c9-8e45136319c0": "What is the significance of the `restore` method in the code example?",
        "f28133cd-7fb6-40da-91a7-9d58a667fafb": "How does the `Tuner` class utilize the `search_alg` parameter in the code example?",
        "cd1830fe-7128-4453-92e1-37f2a916bc91": "What does it mean if the `set_max_concurrency` method returns False in the code example?",
        "85063366-4971-4981-9ab0-a6ab76608f46": "Can you explain the purpose of the `fit` method in the code example?",
        "49972e01-77fe-4cc4-96f4-1e1067d21dc9": "How does the `TuneConfig` object affect the behavior of the `Tuner` class in the code example?",
        "54e6ba1e-d65e-4c53-bcd3-8fa3241c7d0c": "What is the expected behavior if the `search_alg` parameter is not provided to the `TuneConfig` object in the code example?",
        "e6360042-7bfc-405b-b59a-7ba252810970": "Can you describe the intended use of the `num_samples` parameter in the `TuneConfig` object?",
        "9e66279b-d552-415c-8e34-d0d145aba54b": "What is the purpose of the line \"serve.run(StreamingResponder.bind())\" in the given code?",
        "64531d89-3a7b-4e3d-9e87-588d739f900f": "How does the \"requests.get\" function in the code differ from a regular HTTP GET request?",
        "762829f5-6e23-4766-97b4-804af07a277e": "Based on the context information provided, what is the current best trial in terms of mean loss and its corresponding parameters?",
        "9e27e484-233a-4112-bf26-12ac6e8cf31b": "How many trials have been terminated in the current round and what is the reason for termination?",
        "c74f0c86-4e31-483f-b685-8b19fb9747ec": "What is the purpose of the \"_optimizer_variables\" variable in the given code?",
        "c8154fd2-5e0d-43cd-85c3-436773ee32b4": "How does the \"set_state\" function handle the restoration of an optimizer's state for tf eager?",
        "6b95f697-42be-40cc-be14-fa30fca5fc2a": "What information does the \"msg\" variable contain in the given code? How is it generated?",
        "f3e22096-da53-42f9-881e-096e448f6ce8": "How does the \"_find_le\" function work? Explain its purpose and functionality.",
        "b1ed2906-9640-4377-9de2-622e889ab26f": "What is the purpose of RLlib's train() function and what information does it provide in the return?",
        "b13605ee-ba50-41f7-a944-f63606790a0d": "Can you explain how to use multiple training methods simultaneously in RLlib, using the example of DQN and PPO trainers?",
        "bdbf2427-152a-43ef-87e4-0812da13141c": "What is the purpose of preprocessing the data on EFS for training in the given context?",
        "0fc1dba1-6b46-473c-be3a-964cc3ec6486": "How can you access the head node of the cluster and download or preprocess the data for training?",
        "db769226-b775-4510-ba15-d85b4d53c4aa": "Explain the purpose of the \"synchronous_parallel_sample\" function in the given source code. How does it contribute to the AlphaZero algorithm?",
        "7d85c81c-2f56-4be4-9f2b-e6292755a07f": "Discuss the role of the \"TorchCategorical\" class in the AlphaZero algorithm. How does it relate to the modeling of action distributions?",
        "a87262b2-3c04-482f-8e6d-8d42110f3707": "How many CPU cores are available in the cluster?",
        "e93250dc-77df-4a5c-9853-d03021bc5029": "What is the total amount of memory available in the cluster?",
        "416ddba2-221d-4777-b4bd-1e040e74c905": "What is the purpose of the `evaluation_interval` parameter in the `evaluation_config`?",
        "321dbc49-5aa9-45b1-a0fc-b115ad331131": "How can the `evaluation_duration` parameter be used in the `evaluation_config`?",
        "9f73620b-e7cc-4f9d-a6e7-e1ce00b3f84d": "Explain the purpose and functionality of the `_process_observations` function. What are its input parameters and what does it return?",
        "976d90c9-9e60-4016-a5a4-0d67690e580c": "Describe the structure of the `unfiltered_obs` parameter in the `_process_observations` function. How is it organized and what information does it contain?",
        "9973bd43-ca44-4e91-b25f-16927d69398e": "What is the purpose of the `get_learner_hyperparameters` method in the `AlgorithmConfig` class?",
        "5754ecaa-1d52-49fe-a0ce-ef14ac50ae78": "How does the `LearnerHyperparameters` class differ from the `AlgorithmConfig` class in terms of the settings it contains?",
        "cb7bb2d1-cbbf-4cb5-808f-ff939153d34d": "What is the purpose of the `get_actor_id` method in the given code? In which mode is this method available?",
        "b5e263f2-ad21-41c0-bea5-2bbac2fe2714": "What does the `namespace` property return in the given code?",
        "baceeb1c-7019-43d7-bbbe-3ef12df02f21": "Explain the anti-pattern in the given code example and why it is considered an anti-pattern.",
        "a726d4f8-20b8-4f2e-b266-9c278ff3ee6d": "Compare and contrast the two better approaches suggested in the code example. Which approach would you recommend and why?",
        "5d860af1-4136-4b8b-8e96-e98248bd9454": "What is the purpose of the template field in a headGroupSpec or workerGroupSpec configuration?",
        "5a0d3b55-e5c2-4572-95b5-2a57b822c811": "Can you explain the role of the pod template in determining the configuration for pods in a group?",
        "149db263-097e-4e2d-b876-7138ff0374f0": "How does a Ray cluster handle distributed scheduling and memory management?",
        "51e58b15-efa9-4be9-8687-d4aa3f8b0ff8": "Can the number of worker nodes in a Ray cluster be automatically scaled based on application demand?",
        "4c15171c-011b-4b47-ba78-e1ca6df9aaa0": "What is the purpose of the \"new_policy_instance_kwargs\" dictionary in the code?",
        "45c99fdf-4ab3-44a9-97b0-48b59fa76749": "How does the \"_create_new_policy_fn\" function contribute to the overall functionality of the code?",
        "683c89ce-1f79-4d73-8e1c-09ad38d28ecf": "What is a bundle in the context of resource allocation in Ray cluster?",
        "7bb3ab5b-a0ca-4357-a135-e860be39029c": "Can a bundle that requires more resources than available on a single node be scheduled in Ray cluster?",
        "8fb8e450-601d-4b69-ab4f-94e8b53c29a9": "What is the purpose of setting the \"is_module_trainable\" attribute in the Learner class? How does it relate to the communication between the driver and the remote learner actors?",
        "9d619532-56b8-4521-8efc-f3858a77e2b9": "Can you explain the difference between the \"simple_optimizer\" and \"multi_gpu_train_one_step\" methods used for training in the given code? How do they affect the training process?",
        "a100d70d-6a4e-41ab-b037-6bdc36e9c75f": "What are the parameters specified in the experiment_spec?",
        "f0477083-9e1f-49e8-9ccf-8f68cdf45b4d": "What is the purpose of the \"stop\" parameter in the experiment_spec?",
        "0b922f76-c7a6-4dbf-99b3-2043c6f43f07": "What is the purpose of the `cleanup()` method in the `Trainable` class? How does it relate to the overall functionality of the class?",
        "412bbbb9-dd45-44f0-b7a8-1502abc0c758": "Explain the difference between the `train()` and `train_buffered()` methods in the `Trainable` class. How are they used in the training process?",
        "2c903d2b-4108-43fc-8b91-35d66b6c372a": "What is the purpose of the \"grad_clip\" parameter in the DreamerConfig class?",
        "48c42f60-b4a3-413c-9432-0028dcdaa746": "How does the \"batch_size\" parameter affect the calculation of loss in the DreamerConfig class?",
        "458a6654-58a6-44ef-843b-45cff2342eda": "What are the two formats in which you can write Ray documentation?",
        "3fe6f122-5c88-4abc-9aab-014866122cdb": "How can you verify that the document you're reading is a notebook?",
        "165942a4-8e14-467a-9417-1020b23b4011": "What is the purpose of the `vectorize_gym_envs` function in the given context? Explain its parameters and return value.",
        "5690246b-c679-41f6-8452-5349ab1d522d": "How does the `restart_failed_sub_environments` parameter in the `vectorize_gym_envs` function ensure the stability of the VectorizedEnv?",
        "7de9c5f1-82fe-4a94-90cd-9ed0b7721f9d": "What are the two possible values for the \"style\" parameter in the \"PathPartitionParser.of\" method?",
        "a9a6206e-fc42-41af-ad84-cca720299aca": "What is the purpose of the \"base_dir\" parameter in the \"PathPartitionParser.of\" method?",
        "0ff09109-cc57-498d-8247-1a243ff8bd20": "What is the purpose of setting the `beta` parameter to 0.0 in the given code snippet? How does it affect the calculation of advantages during postprocessing?",
        "2eb1e2de-ee53-4e3b-9a37-020075e17e24": "How does the `tune.grid_search` function work in the `config.training` method? Explain how it is used to search for the learning rate (`lr`) parameter.",
        "e64acac7-e77c-4af9-b00c-826d5f35a8be": "What is the purpose of the \"ray.rllib.core.learner.learner_group\" module in the given source code?",
        "8f89458e-361c-429e-b3c5-b9408a4ecbcf": "How does the \"ray.rllib.core.learner.learner_group\" module handle multi-agent training?",
        "90004619-7484-4f95-a7d4-0693a2ba809e": "What is the purpose of the code snippet provided?",
        "f1d45a9d-296d-428d-81ca-e8f2669bf71b": "How does the code handle the situation when there are results added after the trial stop condition?",
        "6bc52614-1771-4d9e-966b-de2fa9d00bc8": "How can Ray Tune be used for experiment management? Provide two different code examples from the context information to support your answer.",
        "24df6a4d-a9e1-4fad-ac19-77b638e401e8": "Explain the process of scaling Instacart fulfillment ML on Ray. Provide a brief overview of the video and highlight the key points discussed.",
        "1c8f7624-365d-4d98-8953-b312c3b65987": "What is the purpose of the `checkpoint` variable in the given code?",
        "33e1c989-9dd4-4934-87a2-f66de8999c08": "How does the `train.report()` function use the `checkpoint` variable?",
        "522fcc24-44a2-467b-bcb0-acbb9ed95aa9": "What is the purpose of the \"run_config\" variable in the given code snippet?",
        "9c69f72a-2ba6-4981-bb3a-8cf2cb0b2f59": "How does the code handle the \"scaling_config\" parameter?",
        "c2dfc80c-1184-4ddb-ae4f-ddaffd7a635a": "What is the purpose of the \"dict_keys_snake_to_camel_case\" function in the given code?",
        "7d80245e-04b0-4710-8991-4e8ffeb3ce48": "How does the code handle the conversion of keys in the \"ray_actor_options\" dictionary?",
        "2525a9ac-8b4a-4285-bbe4-a28d60bb548e": "What is the purpose of the code snippet provided?",
        "03f205d5-b4fe-4349-afb4-f035f847e693": "How does the code handle the previous actions and rewards in the input?",
        "e042fa45-abc6-4b07-aebc-72462f0d6dbe": "How can the JobInfo.metadata field be used in the job submission process?",
        "12c70957-9cfa-4c7f-bb50-d95089978659": "Why is it important for the JobInfo.metadata field to be optional in the job submission process?",
        "d592f2fc-1f40-442f-a1d2-a9a2e7ed5b01": "What is the purpose of the \"actor_placement_resources\" dictionary in the given code snippet? How is it modified based on the value of \"actor_method_cpu\"?",
        "ccfd344d-f00f-4a9d-a4f8-af4c03492917": "Explain the difference between the \"creation_args\" variable when \"meta.is_cross_language\" is True and when it is False. How is the \"function_signature\" used to determine the value of \"creation_args\"?",
        "e94d02ab-3596-4f86-a257-db48a651bfde": "What does the completion_percentage() method do in the given context?",
        "646546ec-7486-400d-8d4e-64f95d113dd2": "How does the join() function work in the given context?",
        "d8482a72-4e7b-4e83-96b1-2ca3ca255871": "What is the purpose of the `sample_min_n_steps_from_buffer` function in the given code? How does it contribute to the QMIX algorithm?",
        "6917fa8d-08a3-475c-ae53-fa54cfe1d16a": "Explain the role of the `prio_dict` variable in the code snippet. How is it used to update the priority weights on all policies?",
        "2c6348e6-577e-41f9-956c-90b294500eaa": "How does the parallelism parameter affect the number of read tasks returned by the Reader.get_read_tasks method?",
        "16320090-bbc2-4633-9791-e7db1326ec23": "What is the purpose of the read_args parameter in the Reader.get_read_tasks method?",
        "af8c95ce-c262-4f1d-90de-c130d4cc19af": "What is the purpose of the ResultGrid class in Ray Tune?",
        "0c545402-41f6-4c4c-b8cd-da5017a9206c": "Can you provide an example of how the ResultGrid class is used in the given context?",
        "d6e3e5c4-fd14-4a82-9174-8e98e035e65f": "What is the purpose of the property \"RayFSDPStrategy.checkpoint_io\" in the given context? How does it relate to the \"pytorch_lightning.plugins.io.checkpoint_plugin.CheckpointIO\"?",
        "5704315a-8980-4fc7-b338-73e559d24a68": "Can you explain the role of the \"RayFSDPStrategy.checkpoint_io\" property in the overall functionality of the \"ray.train.lightning.RayFSDPStrategy\" module? How does it contribute to the checkpointing process?",
        "f0a61a14-378a-4a3c-aac5-9092510addd9": "What file format is currently supported for importing a model in the Algorithm.import_model method?",
        "c87e70a0-7209-400c-a652-10083de53284": "How does the Algorithm.import_model method handle the import of models from different file formats?",
        "e9d77733-02c3-471a-8c3b-6c161cf5a80b": "What are the default hyperparameters used in the initialization of the Curiosity object?",
        "6900360f-f27f-45a9-8ce2-509df3ff0971": "How can the feature network be configured to process different observation spaces?",
        "419c0704-9a73-4453-9224-594f30489f99": "What is the purpose of the \"scheduler\" parameter in the deepspeed configuration?",
        "d5bb28c1-c07e-443e-905a-5f5d6ca89e79": "How does enabling the \"bf16\" parameter affect the performance of the model?",
        "79cee793-ad75-4238-99dd-fe1637a32b62": "What is the purpose of the `set_optimizer_state` method in the given code? How is it different from the `get_optimizer_state` method?",
        "2cc9a56e-2943-4e8b-b72d-7555d431fcb6": "How does the `_set_slicing_by_batch_id` method enable slicing by batch id in the given batch? Why is it important to slice via batch id and not timestamp when dealing with batches of sequences?",
        "8b196101-7d4f-458a-b522-7c026072eaf5": "What is the purpose of the \"train_batch\" variable in the given code snippet?",
        "77a98426-e92d-4e9b-9848-ee5728435f26": "How does the choice of optimizer differ based on the value of the \"simple_optimizer\" configuration parameter?",
        "60d4aac6-4370-41d4-9432-a569ac56ab82": "What is the default location for deployment of the Ray cluster in Azure?",
        "196108ad-94d4-4437-bc67-6e20400975cd": "What is the importance level of specifying the location for deployment of the Ray cluster in Azure?",
        "7a16f1ff-058d-4e97-8a5a-a5e08fa556ff": "How does Ray redirect Worker logs to the Driver by default?",
        "4a481c83-85ca-486d-b3c3-519086e902f2": "What is the purpose of redirecting Worker logs to the Driver in a distributed Ray application?",
        "f46128e7-790f-47f8-baca-e3ca4221684e": "What does the job status \"STOPPED\" indicate in the context of ray.job_submission?",
        "32bb9f4f-bea8-46c0-99f0-1cf84c025c22": "Why would a user intentionally stop a job in ray.job_submission?",
        "70e1bfe0-5e46-4f7b-b8e6-29d1d782ce34": "Explain the purpose of the RLModule class in the RLlib library. How does it serve as a base class for other modules?",
        "c6be1df4-4b8a-46bf-98fb-d02a838227c0": "Describe the pseudocode for how the forward methods are called in the RLModule class. How does this relate to creating a sampling loop in RLlib?",
        "7d4852b0-eec8-414a-b57c-4d13f90dc114": "What is the default lifetime of a placement group in Ray? How does it differ when the placement group is created from a driver versus a detached actor?",
        "3062270e-8781-40f8-97f0-4e18c7ee87bf": "How can you ensure that a placement group remains alive regardless of its job or detached actor? Provide an example code snippet in Python.",
        "15034cc2-d4e8-45a8-9e34-bbdea4bcde75": "What is the value of the 'training_iteration' parameter in the given context information?",
        "b8ffd34a-27fb-45a2-9180-ba4e84dacc5d": "What are the best hyperparameters found in the given context information?",
        "4351bb96-c867-4c0e-8008-e1aafbd104ea": "What is the purpose of the property \"RayDeepSpeedStrategy.world_size\" in the RayDeepSpeedStrategy class?",
        "9c87ac30-89f8-4ffc-a2aa-242d718d942c": "How can the property \"RayDeepSpeedStrategy.world_size\" be used to configure the world size in the RayDeepSpeedStrategy class?",
        "64ecae78-97f9-40c1-a569-a00c55b58c64": "What is the purpose of the job-driver-[submission_id].log file in the Ray Jobs API?",
        "df969523-a6f9-45e5-8d2f-8afa14763452": "How are the stdout and stderr from Tasks or Actors streamed in the Ray drivers and workers?",
        "b48c9b8f-5e31-4860-9276-0fdcecb16509": "What is the purpose of the `raise ValueError` statement in the code?",
        "903ab68c-d7e2-4c1d-898d-3365b7d52150": "How does the code ensure that the search space is not empty before running the `HEBOSearch` algorithm?",
        "91e95589-a552-4a2c-9c13-29a6e5f78c0b": "How does the Queue.put() method handle a situation when the queue is full?",
        "b3befe78-8f18-42fb-8954-c4f92da1c7bb": "What are the possible exceptions that can be raised by the Queue.put() method and under what conditions are they raised?",
        "4ecc8f8f-f337-4cb5-9125-90acc22e3076": "What is the purpose of the \"observe\" method in the given code snippet? How does it contribute to the optimization process?",
        "7b2b1f6a-0cea-4bf2-8bd8-5ba3df8a97da": "In what scenario would the \"save\" method be called? What is the significance of storing the optimizer state?",
        "c3dc7409-76c1-4091-bdea-67aef57b441a": "What is the value of the mean loss for the objective_ed2322be trial?",
        "2f1b2927-6eab-4d9a-82ae-025615191e6e": "How many iterations have been completed for the objective_ed217cf2 trial?",
        "cbe9e607-9cbe-4559-81bc-3851d10a625d": "What is the purpose of the sleep command in the script?",
        "9068dab9-709e-439a-9fd0-ac5b193193c1": "How does the script ensure that the Ray head and Ray worker processes are not started on the same node?",
        "768a1e87-2a4e-47bb-9ff0-b42004f0838d": "What is the purpose of loading modules or a conda environment at the beginning of a script? How does it help in enabling the right set of dependencies?",
        "024b7552-898f-4446-b608-e8c3c9afc136": "Why is it important to activate a specific conda environment, such as \"my-env,\" before executing the script?",
        "8d0514a1-968d-48ad-a25a-d9373e184a79": "What is the purpose of the \"Driver\" in the given context information?",
        "1f50bf14-fcf6-4c28-8a72-d3cf2e2a9f7c": "Based on the context information, what is the significance of the IP address \"192.168.0.15\" and the port number \"6465\"?",
        "af9766ff-7bcc-44c9-b36c-3c925142e06b": "What is the purpose of setting the parameter \"fn_args\" to False in the given context?",
        "ff256a89-58d3-4596-8c7d-7743dad863cd": "How can you specify the number of GPUs to reserve for each parallel map worker in the context?",
        "b19faa0d-f4f6-4723-9f60-07bc6bb95191": "What are the attributes of the `ObjectSummaryPerKey` class in the given context? Explain each attribute briefly.",
        "5586f85e-2e29-4cd9-bc00-46598934d826": "How is the `ObjectSummaries` class structured in the given context? Explain the purpose of each attribute in the class.",
        "031da581-61ea-4ecd-9de6-963f503c15be": "What is the value of the \"eval-error\" for the trial with trial_id \"c28a3_00003\"?",
        "0b7438b6-5b77-48a7-a0d1-00f4930ebae4": "How many training iterations have been completed for the trial with trial_id \"c28a3_00005\"?",
        "4f55a342-5445-4de4-a768-fa35e699ff44": "What is the purpose of the method `RayFSDPStrategy.on_train_end()` in the `ray.train.lightning` module?",
        "e428a095-f085-49ac-87e9-3fd833bcc544": "Can you explain the significance of the `on_train_end()` method in the training process?",
        "403a621f-1940-4953-a56c-02355300d498": "What is the purpose of the `step` function in the given code?",
        "9388379b-1ea1-41a1-8aa4-f27ea601317a": "How does the `load_checkpoint` function work in the given code?",
        "14ae70d4-0454-461d-8b95-19ce50c59671": "What is the purpose of the `RayTrainReportCallback.on_configure_sharded_model` method in the PyTorch Lightning framework?",
        "2177f27a-b9a8-4588-a719-67cf5c183163": "Why was the `RayTrainReportCallback.on_configure_sharded_model` method deprecated in version 1.6 of PyTorch Lightning?",
        "b91d013a-0639-423e-939e-1fca62022e75": "What is the purpose of the `read_sql` function?",
        "1e240f3b-2e12-42ec-a5e1-8c50c2ced5a7": "How can the `read_sql` function be used to read data from a database?",
        "e04b42b7-7fe4-4f0f-97a8-c2fa7bccc531": "What is the purpose of the `num_labels` variable in the given code?",
        "365d6873-e4d6-47b4-a03e-bec5eb35fedc": "How is the `metric_name` variable determined based on the `task` variable?",
        "4007918b-5684-4c2e-aee9-207dc1b66cd2": "What is the purpose of the `TensorflowCheckpoint` class in the `ray.train.tensorflow` module?",
        "bb2b4b5b-d707-4518-9d9f-e9d51865dc36": "How can you create a `Checkpoint` object from a local directory using the `from_directory` method in the `TensorflowCheckpoint` class?",
        "27fca8ef-92c8-4755-be02-6c304cc817d7": "What is the purpose of using the --shm-size option when launching Ray in Docker? How does it affect the performance of Ray's Object Store?",
        "4c3e4ffe-70d5-4952-8c65-5f2aa41adbbf": "Why is it important to adjust the <shm-size> parameter based on the available memory in your system when launching Ray in Docker? How does it impact the size of the object store?",
        "56ed0355-990a-46ce-85b3-7d9bac1efb97": "How can you utilize Ray AIR with your existing PyTorch code without starting from scratch?",
        "59ae5358-40a9-4d4c-ac4d-30ddeaa002fd": "What are some benefits of using Ray AIR with your existing PyTorch training code?",
        "4c7780f5-8b4a-43bb-8d7b-c2801e87a058": "What is the purpose of the `WandbLoggerCallback` class in the given context?",
        "2eb9bd7a-eed8-4cb4-9492-1e70b4894e19": "How does the `WandbLoggerCallback` class contribute to experiment tracking and visualization in the context of Ray Tune?",
        "6769e55d-caab-4314-a0ad-bfcc9e0dfc54": "What is the difference between ObjectStoreFullError and OutOfDiskError in the context of RayError? How do these errors indicate different storage limitations?",
        "fbb9c2c0-9967-443a-8657-157c7d2afc55": "How can you check the memory usage of the object store and disk in the Ray cluster? Provide the commands or tools that can be used for this purpose.",
        "210719f3-175b-437b-80e2-82f4fedbece6": "Explain the purpose and functionality of the \"autoscaling_config\" field in the given context. How does it affect the number of replicas in a deployment?",
        "e4e5ba5a-9012-4fd8-984c-8a30b99c1723": "What is the significance of the \"graceful_shutdown_timeout_s\" field in the context of the Serve controller? How does it impact the shutdown process of a deployment replica?",
        "a2486d56-2863-4a2a-b667-92db9f64f7e5": "What is the purpose of the `object_transfer_timeline` function? How can the information generated by this function be viewed as a timeline?",
        "b96e2c47-7742-4bcc-9e2f-c3a0b3b8fe46": "What is the difference between the `cluster_resources` and `available_resources` functions? How can the information returned by these functions be useful in a cluster environment?",
        "734056ec-8a87-4e09-b2f9-118a5ff97613": "What are the different methods or strategies used in the training process according to the given context information?",
        "879d2e20-7398-45ec-aee8-afda6c3e9b88": "Which methods or strategies are involved in the beginning and end of the training process, as mentioned in the context information?",
        "54cd0fd9-3ca7-4f54-83be-2593edb1b2b5": "What is the purpose of the `range` function in the given context? How can it be used to create synthetic datasets?",
        "dee5aa71-bd2a-4b1d-ac98-50f63d048806": "Explain the significance of the `parallelism` parameter in the `range` function. How does it affect the performance of the dataset creation process?",
        "76b9e321-943f-4a8f-8987-30e29314c3e2": "What is the purpose of the evaluation set in the context information?",
        "d3597438-080a-48d8-a65f-25f6362b9270": "How does the evaluation loss value in the context information affect the model's performance?",
        "7cd93d56-ffb2-4924-854d-7f04da391d27": "What is the purpose of the `add_hyperparameter` function in the given code snippet? How does it contribute to the overall functionality of the code?",
        "a08b7bcb-01b2-494d-b55d-48cd34ab85bf": "Explain the role of the `TuneBOHB` class in the code. How does it relate to the `config_space` and the specified metric and mode?",
        "8e82c668-2fd4-4153-8aea-caf7d15a4ffe": "What is the purpose of the `HyperBandForBOHB` class in the code? How does it determine the maximum number of iterations (`max_t`) for the optimization process?",
        "22490d08-8f26-4232-b991-00bc4c4a896a": "Describe the role of the `run` function in the code. How does it utilize the `my_trainable` object along with the specified scheduler and search algorithm?",
        "c7827027-ee08-4c7c-8600-59007cd21700": "Why is the `assert` statement used in the `__init__` method? What is the purpose of the `BOHB` module and how does it relate to the installation requirement mentioned in the assert statement?",
        "d666e383-300d-47e3-9b04-e91c5238f117": "What is the purpose of the `num_rollout_workers` parameter in the given context information?",
        "005361f1-e695-47da-b986-1996e2ba8962": "How does the `replay_proportion` parameter affect the training process in the given context information?",
        "76aa5f17-033d-4839-8ddb-8f90a83af0fb": "What is the purpose of the OptunaSearch.FINISHED attribute in the Ray Tune library?",
        "ca01d708-a7be-4b42-8a53-72349bc93d8a": "How does the OptunaSearch.FINISHED attribute contribute to the functionality of the Ray Tune library?",
        "07e26ce3-483f-425b-9aba-fa52dff246cb": "Based on the context information provided, what is the activation function used in the first objective, and what is its value?",
        "497ccc1b-c37b-41b5-afaa-87699d27ff36": "For the objective with experiment ID \"objective_e532d6e0\", what is the mean loss value and its negation?",
        "dd73c7bd-bf40-4452-870b-4bcc0d03a009": "What is the purpose of the `config_overrides` dictionary in the `__init__` method?",
        "7211a79d-ec04-4ccd-b775-4a149569c59c": "How does the `placement_strategy` variable affect resource allocation in the algorithm configuration?",
        "4c8d62a8-e980-408f-91ed-edbd24692670": "What is the purpose of wrapping a PyTorch model in an objective function when using Optuna for hyperparameter tuning?",
        "c8c4e305-6767-4f8b-9dcb-23ffef864f40": "How can you define the search space for hyperparameter tuning in PyTorch with Optuna?",
        "8a1b7fd3-b2cc-4de2-a084-a78d0b58be7c": "What are the conditions that could cause the message \"It may be waiting for resources (CPUs, GPUs, custom resources) to become available\" to be added to the message?",
        "fdfc643c-7344-4791-b3ab-5485430c8147": "In what situation would the message \"Job is currently running\" be displayed?",
        "da8d20f6-da69-4bc1-9ea6-7ac5266263c8": "How does the forward method in the ModelV2 class of ray.rllib.models.modelv2 work?",
        "58b12790-e0c3-41a2-8128-d32a28f71727": "Can you explain the significance of the ModelV2 class in the ray.rllib.models.modelv2 module and how it relates to the forward method?",
        "81a6f7cf-483f-44c8-904e-064fccad0670": "What is the purpose of the `config.environment(env=\"CartPole-v1\")` line of code in the given context?",
        "4e3b7d05-d460-4ab3-ac7d-bebd916a7d4d": "How does the `replay_buffer_config` parameter in the `AlphaZero` configuration affect the storage of data in the replay buffer?",
        "7ff8e921-2175-4c98-863a-4d7e107bdeb8": "What is the purpose of the Preprocessor and Filter components in RLlib? How do they contribute to the data flow in RLlib?",
        "ff9e0b4f-465c-4c95-aa43-07e99eaadf1d": "Can the components highlighted in green in the diagram be customized by users? If so, how can users replace them with their own implementations?",
        "0f894297-80d8-4e1f-b4f8-490e7f056740": "What is the value of the l2norm in the result for objective_34b7abda?",
        "c9e40cec-e3fd-4a98-98b7-4e29aca5b231": "How many training iterations were performed for trial_id 34adf04a?",
        "49cf8639-d1b8-4494-aa1e-b65443c30247": "What is the purpose of initializing workers with Horovod environment variables in the given code?",
        "b6c19c8c-9e05-4115-9f5e-4afda1777953": "How does the code register each hostname to the coordinator?",
        "6e30336e-a297-4a06-aea2-de0e10452cba": "How is the `block_size` parameter used in the given code?",
        "ca2ebf0c-8d32-4a82-9ed8-37df59a321e8": "What is the purpose of the `tokenize_function` in the code?",
        "98813e73-86b7-4a61-aed8-c16c3b29d300": "What is the purpose of the `GroupManager` class in the `ray.util.collective.collective` module?",
        "0f3ceda2-dfd8-4452-889a-26e141eea82d": "How does the `_group_mgr` object store membership information and other metadata for collective groups in the `GroupManager` class?",
        "d9035f6e-027e-44a7-b1b6-4fc7fbda6557": "What information does the BlockExecStats class provide in the given context?",
        "7eaba21b-fd3a-430f-9260-36c8f9de7a09": "How can the wall_time_s attribute of the BlockExecStats class be useful in analyzing the performance of a block computation?",
        "009904c3-3c6c-4852-b88c-3d667865785f": "What is the purpose of the `train()` method in the `algo` object?",
        "7553fc2c-bf27-4bd6-a676-b8fb4c5a95d9": "How can you update the `config` object to set the learning rate (`lr`) parameter to either 0.001 or 0.0001?",
        "ac993544-fe41-4805-913f-c8e1d2a450bf": "What are the potential issues that can arise when using the `from_tf` function to read large datasets? How can these issues be mitigated?",
        "8848bcb4-21cf-40de-9e70-c4275dee5d1d": "Explain the process of loading a dataset into the local node's memory using the `from_tf` function. What are the limitations of this approach?",
        "05f57811-1356-4945-a853-770e95ba8f74": "What is the purpose of the `RuntimeEnv.clear()` method in the Ray library?",
        "1600f545-49cd-4578-a5d3-0e76bbf652ee": "How does the `RuntimeEnv.clear()` method in the Ray library differ from other methods that remove items from a dictionary?",
        "fe185ccf-1fcd-4abe-b9ca-43f920547654": "What is the value of the mean loss for the trial with the trial_id '12342770'?",
        "d96c8741-fcc4-40d1-b4ce-83e6c2679505": "How many iterations have been completed for the trial with the trial_id '12374d7e'?",
        "792147bc-73b5-4d15-9b36-2d513cf8f017": "What is the purpose of the `list_runtime_envs` function in the given code? Explain its arguments and their significance.",
        "e05c5853-1e89-4b8f-8731-6169b51204e4": "What exception is raised if the CLI fails to query the data in the `list_objects` function? How is this exception handled in the code?",
        "78ab1784-ee5b-4027-ba73-57d98539da93": "How does the Ray cluster handle a raylet process failure?",
        "c42bdcc7-ca0f-449b-8f59-93d641d675b3": "What happens to a node in the Ray cluster when its corresponding raylet process fails?",
        "92cfd3c1-1ffb-4561-a6db-832f95a05b2d": "What is the purpose of the `optimizer` method in the given code?",
        "2049badf-9372-4860-bcab-1ebb85d79738": "How does the `Policy.postprocess_trajectory` method contribute to the overall functionality of the code?",
        "5777f05b-df38-4824-889d-140a686bdb57": "How can you create a dataset that represents the images in the dataset?",
        "313c04fc-b383-4520-b8ed-c2fecd34ea8a": "What are the steps involved in performing various NLP operations on the text in the dataset?",
        "339181b3-43fc-4d1c-a707-5821aa25e0a5": "How does Ray Serve allow you to deploy models as multiple deployments?",
        "569f54dd-6720-4489-a3b2-b1163266d425": "Can you explain the process of loading the PyTorch MNIST model from a checkpoint and how it predicts the digit from an input image?",
        "456baaf1-0cf6-409a-83b0-fba99ee2b44c": "In the SimpleCorridor environment, what are the possible actions that the agent can choose from? How are these actions represented?",
        "607c76d4-1db9-4e73-9cbb-837ad0132c29": "What is the reward structure in the SimpleCorridor environment? How much reward does the agent receive for each step and for reaching the goal?",
        "51b2b0b3-fd3f-4c53-affe-27b911fdbdb2": "What is the purpose of the JobSubmissionClient class in the given context?",
        "15a45b31-05c1-4a81-8d36-bda3354c92f8": "How can you retrieve the logs produced by a job using the JobSubmissionClient class?",
        "d94aef91-bf58-4db4-a41e-dd0724946694": "What is the purpose of the `HyperOptSearch` algorithm in the given context?",
        "b438a067-ced1-4767-9162-f71cefad798a": "How does the `ConcurrencyLimiter` algorithm affect the execution of the experiment?",
        "b16ef337-3fe0-4311-8827-52268179718e": "What is the role of the `tune.Tuner` object in the code snippet?",
        "ab6ae1c4-f123-4900-a3fd-2044647fd25f": "Can you explain the significance of the `metric` and `mode` parameters in the `tune.TuneConfig`?",
        "75654974-7977-4eec-bcc4-015138829ed1": "How many trials were conducted in the experiment?",
        "1d9f792a-29be-49db-a79f-116d2f9ac3d6": "What is the best trial so far and what are its corresponding parameters and mean loss?",
        "61e19421-e47c-4a73-b8d6-7d3f56d0f456": "How does the `search_alg` parameter in the `tune.TuneConfig` relate to the `algo` variable defined earlier?",
        "201658c2-cd27-42bb-900e-24bbd85cbdf1": "What is the purpose of the `num_samples` parameter in the `tune.TuneConfig`?",
        "dba8aee6-7b45-41f4-ad32-073929359b94": "How is the best trial determined in the experiment?",
        "affcfa0b-9f7c-4194-9777-1b1037582c56": "What is the current status of the experiment?",
        "8990e30a-5fa1-4e0d-bb3c-ab1b6299ad00": "What is the significance of the \"Searcher.FINISHED\" status in the context of Ray Tune's search functionality?",
        "371612a5-f318-4a52-8b2f-65a74b444b5f": "How does the \"Searcher.FINISHED\" status impact the overall search process in Ray Tune?",
        "97682ee6-46ea-4cc1-bbb4-760e23bf2357": "What are the environment variables that need to be set in order to enable TLS authentication in a Ray cluster?",
        "0390fe2c-39e5-44ce-9a9e-0f59cc3487c8": "What is the purpose of the RAY_TLS_CA_CERT environment variable in the context of Ray TLS authentication?",
        "9301c610-0299-4072-b074-23e45ed1eccb": "What are the different methods available in the Ray library for stopping experiments, jobs, and trials?",
        "ec685c51-ddec-4df2-be23-0fec789b0d22": "How can the Ray library be used for data aggregation and grouping?",
        "13b51452-792a-4804-89e5-8fb2208142df": "What is the purpose of establishing an agreement between the encoder and heads regarding the latent dimensions in the Catalog class?",
        "af6fb0ce-8a4a-4117-91b5-05e6582931f5": "How can the latent_dims property in the Catalog class be used to ensure compatibility between encoders and heads in a machine learning model?",
        "726f2ff4-4ff0-42c0-8977-6c16671d26b9": "What is the purpose of the \"action_dist\" variable in the given code snippet? How is it calculated and modified?",
        "1aa422d5-9bde-4740-be34-e5e1523ee617": "Explain the logic behind the conditional statement that checks for the presence of \"fwd_out[SampleBatch.ACTIONS]\" and determines whether to use the returned actions or sample actions from the distribution.",
        "1eb49956-43bb-40e8-935f-2ec248b12867": "What is the purpose of the `LocalRayletDiedError` class in the given code? How is it different from the `WorkerCrashedError` class?",
        "a20f04ab-4de3-4305-a64e-c370d43835ef": "Explain the functionality of the `RayActorError` class and its different possible causes. How is it used to handle exceptions in actor processes?",
        "1414df9e-4313-4aa1-8724-5601efc6cf27": "Explain the purpose of the \"Model.bind\" function in the given code.",
        "ba28ed94-7783-4e85-b8c6-d1c1dad8f579": "What is the significance of the \"combine_output\" variable in the code?",
        "fa2952ea-17d6-4462-b273-c549bb89b4b7": "What is the purpose of the `ready` method in the `Actor` class?",
        "2b8764cf-0c1d-4f8c-9ed6-02e136d55f6a": "In what scenarios would the `f` function be used?",
        "cde66041-1226-4405-803e-566d3e136e43": "What is the purpose of the \"pop\" method used in the first line of code?",
        "288aa216-5cde-4d20-802a-40b0345236d2": "How does the \"bind\" method in the \"ActorOptionWrapper\" class contribute to Ray DAG building?",
        "d21f766c-7f6b-4e3e-8a9e-1f9999f572ca": "What information can be obtained from the \"job_info\" dictionary in the given code snippet?",
        "62272161-e142-4317-800a-d5fbbf6ba593": "How can the \"StartTime\" and \"StopTime\" be represented in a human-readable format using the UNIX timestamps provided in the code?",
        "1c9107f4-75ec-4ede-893b-adc42a65d74d": "How can the ray.util.collective library be leveraged efficiently? Provide some examples.",
        "6e163dc3-3d0e-4d2c-a3fe-ba2ea3dfc06a": "Explain the AllReduce strategy for data-parallel distributed ML training and its implementation using the ray.util.collective library.",
        "0c4c8a85-5090-4c86-8a5d-840b18ed8dde": "What is the purpose of the Callback.setup method in the Ray Tune library? How does it contribute to the training process?",
        "fffc30fe-b363-468c-adb8-1aa167b6ecb0": "Explain the parameters \"stop\", \"num_samples\", and \"total_num_samples\" in the Callback.setup method. How do these parameters affect the hyperparameter sampling and stopping criteria in the training process?",
        "bc04e6a5-0a59-465f-96f4-4eb373151125": "What is the purpose of the \"ScalingConfig.num_workers\" parameter in the given context information?",
        "786d56b9-a595-4ea4-a9d3-ba96086153d7": "Can you explain the possible values that can be assigned to the \"ScalingConfig.num_workers\" parameter?",
        "82dd0f80-989a-495e-9b06-f820e331ecd8": "What is the purpose of the `get_config()` method in the `Trainable` class of Ray Tune?",
        "c2a30696-1fda-487b-812d-4c5fd9e606af": "How can the `get_config()` method be used in the context of Ray Tune?",
        "a0863b68-b6d0-4b14-a090-3d0e3db32a5f": "What is the purpose of the property \"ScalingConfig.total_resources#\" in the ray.train module?",
        "951c7c22-4cd2-405e-a32c-6ce1a53d972b": "Can you explain the significance of the map of total resources required for the trainer in the ScalingConfig class of the ray.train module?",
        "4ba67166-3f27-486c-badc-1bf39214e1de": "What is the purpose of the \"name\" parameter in the actor creation process? How can it be used to retrieve the actor?",
        "922e8b90-4775-4128-9294-6d5368453244": "Explain the difference between the \"lifetime\" options for an actor. How does the \"detached\" option affect the actor's lifespan?",
        "a8fffaa8-9554-45c2-b766-28bb7c64bda6": "What is the purpose of using the Function API in Ray Tune for training models?",
        "5981b948-f965-45b8-8b8a-76d1c70ea185": "How can intermediate metrics be reported in the Function API?",
        "3257951c-7709-432a-83b7-ef47a711ce4d": "What is the purpose of fine-tuning the dolly-v2-7b model using Ray AIR LightningTrainer and FSDP?",
        "78821e0f-1c68-477a-83dc-adcf549139eb": "How does the dolly-v2-12b model differ from EleutherAI's Pythia-12b and what was it fine-tuned on?",
        "6840fb49-8a41-4009-b831-2c107a7d6eb4": "What is the purpose of the function \"concat_samples\" in the given context?",
        "bfff69e4-87ae-4c54-b4af-7029cd6ac006": "How does the function \"concat_samples\" handle the case when any of the samples is an instance of the \"MultiAgentBatch\" class?",
        "9ed98555-51cc-4373-a78f-ad416084cd16": "What is the purpose of the function described in the context information?",
        "96cdaa44-ebfd-45ea-8c1c-66a3b36e271e": "Why is it mentioned that the function cannot be called when running in local mode with num_workers=0?",
        "2acc5302-565d-4af8-90f1-f3f92f0ec7de": "What is the purpose of the variable \"need_unwrap_path_protocol\" in the given code snippet? How does it affect the execution of the program?",
        "825a4da7-6ddf-440f-b1df-557d28465a94": "How does the code handle exceptions related to invalid or unrecognized file system paths? Explain the steps taken to resolve these issues.",
        "8bed96b3-1660-447e-863a-3a646f89c892": "What is the purpose of setting the local caching directory in the example script?",
        "c55d4b0c-260e-471c-9a2b-f4895510be86": "How does cloud storage checkpointing benefit the experiment in the example script?",
        "67888b7b-f246-4706-8dda-18f8e6ee62ee": "What is the purpose of the \"ServeApplicationSchema\" in the given context? How is it used in the Ray cluster deployment process?",
        "3bba7b3f-220b-4f8b-b623-74846041e086": "Explain the difference between the \"is_driver_deployment\" and \"num_replicas\" properties in the ServeApplicationSchema. How do these properties affect the deployment of applications in a Ray cluster?",
        "11fa95db-bbc4-4050-b173-c1a6e7cef9fb": "What is the purpose of the \"get_next_unordered\" function?",
        "49e829e5-dae7-4e5f-8e3c-01d70b129b60": "How does the \"get_next_unordered\" function handle timeouts?",
        "2bb82ed2-5883-416d-b0ca-61df3bb88ce5": "What happens if the \"ignore_if_timedout\" parameter is set to True?",
        "f386bc9f-5716-4fba-a061-487654586f54": "How does the function handle the \"future\" variable?",
        "c50c3b79-3c80-4134-bbd8-753a24985e99": "What is the purpose of the \"raise_timeout_after_ignore\" variable?",
        "de9b5e82-aa07-479f-8629-52eeaed804ed": "How does the function handle the \"future_key\" variable?",
        "9895324b-421f-41bb-acec-a7e3504e7d87": "What does the function do with the \"a\" variable?",
        "e30f7daa-3f1e-483c-9b48-c7a3d0552514": "What is the purpose of the \"raise TimeoutError\" statement?",
        "030688c7-15ba-433d-bf81-f53bc819220f": "What does the \"return ray.get(future)\" statement do?",
        "d8642a0f-970f-4784-8d91-9c77166bfd85": "How does the function handle the \"timeout\" parameter?",
        "482b7373-d1d2-4600-8ccf-325e643660d0": "What is the purpose of using the Ray State API in the given context? How does it help in checking the controller's status?",
        "ab740159-7c3d-49cd-a316-0e27391f4ddf": "How can you query your deployments while the controller is recovering? Explain the steps involved in accessing the deployments and retrieving the desired information.",
        "6956ce71-8829-4a9a-b70b-05a947158815": "What is the purpose of serving a text summarizer on Kubernetes?",
        "f1265b7d-5c99-4d42-a238-cb6333ad1120": "Where can the Python files for the Ray Serve application and its client be found?",
        "78ee80cc-9e95-4738-8dd1-df52c06c3dcf": "What does the method `get_num_samples_loaded_into_buffer` in the `Policy` class return?",
        "a3deb7c0-497c-4ba9-aba2-1260fa41276c": "How does the number of buffers on each device depend on the value of the `num_multi_gpu_tower_stacks` config key?",
        "84421c5a-c5a7-4c85-91d8-b4df3d120266": "What is the purpose of the `rollouts` function in the `AlgorithmConfig` class?",
        "9c2f9510-ec77-4aa5-bfea-94f781769d8e": "Can you explain the significance of the `num_rollout_workers` parameter in the `rollouts` function of the `AlgorithmConfig` class?",
        "bb04242f-b744-4826-9e20-ae05006022df": "Explain the purpose of standardizing the rewards to be unit normal in the given code snippet. How does it help control the gradient estimator variance?",
        "8de7c6c9-346f-4c32-8616-7f12d4ac1700": "Describe the role of the \"discounted_epr\" variable in the computation of the gradient in the given code. How does it affect the policy gradient estimation?",
        "4afaf275-221e-4c62-a77e-0ba08145dbc8": "What is the purpose of the \"parse_spec_vars\" function in the given code?",
        "86f595a8-b842-4f35-954d-767b033ede10": "How does the code handle unresolved search space variables?",
        "061b2e74-b31a-4299-baa4-c8ec8ab061ef": "What is the anti-pattern in the given code example? How does the better approach improve upon it?",
        "54442706-c0f1-4c0a-a2ad-073966e84b9a": "Why is it important to define the remote function or class outside of the loop in the better approach?",
        "12eba783-def8-4bc3-9f94-18a090ea733d": "What is the purpose of the `get_module_state` function in the given code?",
        "40fde95a-b184-4868-a0a3-76a7daab393a": "How does the `get_module_state` function return the state of the underlying MultiAgentRLModule?",
        "111ecef4-c316-43ff-95f0-8d349657f63c": "What is the purpose of the `ParameterNoise` Exploration object's `initial_stddev` parameter? How does it affect the noise in the next episode?",
        "d84e1b72-c719-4e08-8006-5c84cfefdcbc": "Explain the significance of the `random_timesteps` parameter in the `ParameterNoise` Exploration object. How does it impact the exploration process?",
        "8b74d414-a9e2-47c0-a9e2-024141279c72": "How does Ray enable seamless scaling of workloads from a laptop to a large cluster?",
        "081ba77b-4833-43e6-8e7a-1652824c74da": "What is the difference between a fixed-size Ray cluster and an autoscaling Ray cluster?",
        "75fcdd1c-0566-4c80-8c02-579c57b464a2": "What is the purpose of the `_get_encoder_config` method in the given code? How does it differ from the `_get_dist_cls_from_action_space` method?",
        "028417e3-f182-4885-ada4-45af09418f77": "Explain the significance of the `view_requirements` parameter in the `_get_encoder_config` method. How does it affect the encoding process?",
        "24596305-2553-4bb2-b65e-de96d343d868": "What is the purpose of the RAY_REDIS_ADDRESS environment variable in the Fault Tolerant Config?",
        "a8b3eb45-f43b-49c2-88a5-bf57e4992fa9": "How does the Redis database address in the RAY_REDIS_ADDRESS variable ensure fault tolerance in the Ray cluster?",
        "e99efe3e-9b61-4542-afa8-af0dc88dec84": "What is the purpose of the `get_rollout_fragment_length` method in the given code?",
        "85996b69-fc7f-4909-8719-6d91f61dce00": "How does the `get_rollout_fragment_length` method calculate the value of `rollout_fragment_length` when `self.rollout_fragment_length` is set to \"auto\"?",
        "62e55d28-8539-4ab5-a80c-a7e3d02406e9": "What does the method `EagerTFPolicyV2.get_host()` return?",
        "28f5cd29-330a-4d39-8b0a-ff176a523cce": "Under what circumstances would the method `EagerTFPolicyV2.get_host()` return an empty string?",
        "e037b2fd-e811-4986-8717-bb944b812493": "What is the purpose of using exception handling in generator functions?",
        "5af11d51-9306-4665-bb80-985803e5d7a1": "How can you access the values stored in a generator function if it raises an exception before yielding all its values?",
        "715ac410-0cb6-43e0-b00f-c66275ec8a92": "Explain the difference between static and dynamic num_returns in generator functions.",
        "d82a99bf-a9f0-4c07-9fd4-5ad21eef5623": "In the given code, what will be the output of the following line: `assert ray.get([ref1, ref2]) == [0, 1]`?",
        "14138c32-cd52-49f9-9fa1-dbd48bf3081c": "What will happen if you try to retrieve the values of `ref3` and `ref4` using `ray.get()` after the exception is raised in the generator function?",
        "fdc1af2f-653d-4837-a87f-95fc68a24285": "How does a generator with `num_returns=\"dynamic\"` handle exceptions differently compared to a generator with a static number of returns?",
        "b9c30c10-d346-4c56-a606-cd17868e9270": "What will be the output of the following line: `assert ray.get([ref1, ref2]) == [0, 1]` when using a generator with `num_returns=\"dynamic\"`?",
        "a6e06097-5b67-4fa2-b748-135c28ae430f": "How can you retrieve the exception stored in the final ObjectRef of a generator with `num_returns=\"dynamic\"`?",
        "f5e9ecbf-ebde-47b1-9559-33d873a8d129": "Explain the purpose of the `try-except` block in the given code.",
        "8cc804fc-6961-47b0-9787-4bfb0b13a0f2": "Can you provide an example scenario where exception handling in generator functions would be useful?",
        "7b165dab-72d1-4908-b948-289bbf6c019c": "What is the purpose of using histograms in tracking metrics? How can histograms help calculate aggregate quantiles?",
        "61a8f027-4a28-44a9-a3a5-d3604327269b": "How can you observe and record values in a histogram metric? Explain the difference between the \"observe\" and \"record\" methods in the Histogram class.",
        "ba2d77ba-d202-4e76-8cfe-fd908d0d72d0": "What is the purpose of the `item()` function in the given code?",
        "ff18a957-f7bc-44bc-9606-23c16beabf2c": "How does the `reset()` function work in the given code?",
        "1c172e23-6f69-466f-a92f-4e37f900c68a": "What is the purpose of the `save` method in the given code?",
        "d0077ea7-7133-42e1-b218-e6ed353a5553": "How does the `restore` method in the code work?",
        "935a73af-0730-451d-9ae3-bd2fce66f1cf": "What is the significance of the warning message mentioned in the context information? How does it relate to the usage of NumPy arrays and PyTorch tensors?",
        "66ca3ba8-fc59-4eeb-ae9d-a77aa7e600cb": "How can one address the issue of non-writable NumPy arrays when converting them to PyTorch tensors? What are the potential consequences of not addressing this issue?",
        "7c867aa0-b62a-4df5-b320-08055f5a52cc": "What is the purpose of the `TuneReportCheckpointCallback.after_training` method in the `ray.tune.integration.xgboost` module?",
        "b1b38f67-653f-4867-969b-82d09e8b5709": "Can you explain the functionality of the `TuneReportCheckpointCallback.after_training` method and when it is executed?",
        "6a98c84e-e41e-458b-9f9a-057682f3d510": "What is the purpose of setting `n_samples=1` in the given context information?",
        "dd7375df-d571-47d1-8716-7c2804424a0b": "How does the presence or absence of a config parameter affect the training process in the given context?",
        "ec60d7d2-d308-47fb-a596-21ed4e1d30d9": "What is the purpose of the BayesOptSearch.on_trial_complete method in the Ray Tune library?",
        "020ccdfe-2a34-47c7-98a6-3898163019e4": "How does the BayesOptSearch.on_trial_complete method handle errors and what is the expected behavior when an error occurs?",
        "94fa8b26-aead-4847-8860-d9cb9581ef9f": "What is the purpose of the \"train_func\" function in the given code?",
        "2f516a15-8e2b-43c7-b28b-bab5980044a7": "How does the code save a checkpoint during training?",
        "574137cf-837f-4389-b5e1-6781ba63f54b": "What is the purpose of the `_check_result` method in the `Learner` class?",
        "8b201023-b666-46c0-a5a5-474795ded87f": "What exception is raised if the result passed to the `_check_result` method is not in the correct format?",
        "8f8557e1-76ae-4332-b090-da1e7ec77146": "What is the purpose of the `get_dataset` function in the given code? How does it contribute to the overall setup of the dataset and model?",
        "0dd95013-a367-4586-aaf3-cedfda865ed0": "Explain the structure of the `NeuralNetwork` class. What are the different layers and activation functions used in this model?",
        "2f4b71d2-9d52-4fa2-bbd6-51d19ad6ffb9": "What are the default values for the `clip_param` and `lr` parameters in the `DreamerConfig` class?",
        "4fa121bf-eee1-42c4-876b-963a3e9374c8": "How can the `config` object be updated to set the `env` to \"CartPole-v1\" and the `clip_param` to 0.2?",
        "304f8644-80d8-4961-a3ab-d69a3e043187": "Explain the process of restoring a multi-agent Algorithm with a subset of the original policies. Provide step-by-step instructions.",
        "5b3c2f37-536b-4b37-8d8a-a2385601ebb8": "How can the Algorithm.from_checkpoint() utility be used to efficiently restore and continue training a multi-agent Algorithm with a subset of policies?",
        "f812dc87-5925-4e2e-afbc-6cd912c8b4a8": "What is the purpose of the \"if len(self.trials) == 1\" condition in the code?",
        "262e38fa-3673-4558-8d9b-9bf3a89b0a80": "How does the code handle cases where the scope parameter is not within the specified options?",
        "93c56c30-640a-40e0-a34f-17d037863c4b": "What is the purpose of the `SentimentAnalysisDeployment` class in the given code?",
        "e9cd81d6-cbb1-4ff3-8bcf-4c0e39eff2cd": "How does the `SentimentAnalysisDeployment` class use the pretrained sentiment analysis model?",
        "7568e425-2391-47bd-a2b1-4c6ba48d792b": "What is the purpose of the \"task_state_counts\" dictionary in the given code snippet?",
        "8d8b1dee-2665-4df1-ba42-33015630f1c1": "How does the code snippet calculate the total size of objects in megabytes?",
        "2533e519-07ff-4d2b-b160-a0f27be2cd7c": "What is the purpose of the tf.clip_by_value function in the given context?",
        "36475e7b-dcab-4e0f-8d23-5089b59d5e50": "How are the float indices calculated in the context and why is it necessary to adjust kp1 in certain cases?",
        "6719a255-4a10-41dc-9913-0a3327c57bd6": "What is the purpose of the \"Epoch\" parameter in the given context information? How does it affect the training process?",
        "2071ad15-e962-4afa-9305-97b5b8abdc31": "How does the \"train_loss\" metric change over the course of the training process? What does a higher or lower train_loss value indicate?",
        "fc22982f-5aa1-4bd2-ae38-f475c225ec5e": "What is the purpose of using the SGD optimizer in the given code?",
        "007fec7a-6729-493a-b76c-85323543b8a2": "How does the code ensure consistent initialization across workers?",
        "c64ffe90-b431-4f0f-8e7c-352d0053e7c2": "What is the purpose of the `_print_api_warning` function in the given code? Provide a brief explanation.",
        "93a443a5-36e9-4e29-b6a7-43b4501f2c22": "In the `_print_api_warning` function, what are the different boolean parameters and what do they represent?",
        "d8be37c8-6778-4c6d-bd10-a919ec5c6e63": "What is the purpose of the command \"ray stack\" in Python? How does it help in troubleshooting or debugging?",
        "9a19f67e-92c8-4b73-bc6f-6028a52e1492": "Explain the syntax and usage of the command \"ray stack\" with an example. How can it be used to obtain a stack dump of all Python workers on the local machine?",
        "ec0085c4-e57f-4caa-acbf-f787eb5abbf9": "Based on the context information provided, create a question that tests the understanding of the dataset used for fine-tuning.",
        "ba89af3b-afef-4a20-bc0b-1d7f2aaa6f22": "Design a question that assesses the ability to apply the pre-processing logic from the GPT-J-6B Fine-Tuning with Ray Train and DeepSpeed demo to a different dataset.",
        "df13734f-05a5-43a1-b5a1-df890487f903": "What is the purpose of the `shuffle_sequences` parameter in the `training` function?",
        "e23e5875-acd3-44aa-9eb5-b700973eff05": "How does the `num_sgd_iter` parameter affect the training process in the `training` function?",
        "9137745d-6401-470e-a97c-cda0a0b078fd": "What is the purpose of the \"convert_image_dtype\" function in the given code snippet? How does it affect the image data?",
        "a6ed7a60-bc05-4bf1-81c1-84a435fbeb1a": "Explain the role of the \"draw_bounding_boxes\" function in the code. How does it contribute to the visualization of the inference results?",
        "52c730e7-8c0d-49ba-9926-93b501d3a199": "How does Ray enable seamless scaling of workloads from a laptop to a large cluster?",
        "e0b6f6b1-c251-4813-9fd5-8f0f4ca61e34": "What is the difference between a fixed-size Ray cluster and an autoscaling Ray cluster?",
        "45b5c0d3-26bb-4397-ab4d-abcfa549d55a": "What is the purpose of the `iter_torch_batches` function in the given context?",
        "a5cbd804-23e0-4c8e-a493-837f84ed7461": "How does the `train.report` function utilize the `LegacyTorchCheckpoint` class in the given code snippet?",
        "8649a740-cc76-4299-8e1d-0d53ece1ecc4": "What is the purpose of the `on_trial_complete` method in the given context?",
        "1f97b736-3ee2-433e-948c-3d69fc6fd511": "How does the `searcher` object handle suggestions for live trials in the given context?",
        "f57d161a-9ea0-4644-aa64-9a44694200d9": "What is the purpose of the `optimizer` variable in the given code? How is it initialized and what parameters does it optimize?",
        "453bedf7-81ba-4c58-a7c9-fe2dd06c3c32": "Explain the significance of the line `latents = vae.encode(batch[\"images\"]).latent_dist.sample() * 0.` in the code. What does it do and why is the multiplication by 0 performed?",
        "628a4bd0-d849-45b3-b603-a3d61c5a9aed": "What is the purpose of the \"_tf_policy_handles_more_than_one_loss\" parameter in the \"AlgorithmConfig.experimental\" function?",
        "82db0b9d-0ea0-4a26-9add-57626f5b090c": "How does setting the \"_disable_action_flattening\" parameter to True in the \"AlgorithmConfig.experimental\" function affect RLlib's behavior?",
        "eb13dcc1-9542-4cd8-a9fb-31b32f334258": "What does the `stats()` method in `ExperimentAnalysis` return? How is the returned dictionary formatted when the `experiment_checkpoint_path` points to a directory of experiments?",
        "8c96de78-8641-48e1-8a90-8fb8968cb847": "As a teacher, how would you explain the purpose and significance of the `stats()` method in the `ExperimentAnalysis` class to your students?",
        "33de451f-82c7-464f-965e-b056a4cfdc97": "What is the purpose of the `ray_worker_node_extra_envs` dictionary in the given code?",
        "4252b63b-eaa3-45d5-b005-52023a72a984": "How does the code handle the scenario when the number of GPUs on the worker node is greater than zero?",
        "5e00d2a2-8bba-400a-9505-43aa1ec89381": "What is the purpose of the property \"RayFSDPStrategy.root_device\" in the RayFSDPStrategy class?",
        "9215ed44-5cd4-4399-afb3-7c75b8cc2489": "Can you explain the significance of the root device in the context of the RayFSDPStrategy class?",
        "9c36d1c1-9fe9-4774-94b7-26f972a42054": "What is the purpose of the Exploration class in the given source code? How does it contribute to the agent's decision-making process?",
        "425265e0-9249-42c2-b775-312230153ce5": "Explain the role of the Exploration class in the reinforcement learning framework. How does it interact with the model outputs and the agent's actions?",
        "571788ff-7ebd-4297-9056-a5a203ca03b9": "What is the purpose of using the `restore` method in the `XGBoostTrainer` class?",
        "490de506-c61c-4299-ab9f-28e859ea38db": "How can the `restore` method in the `XGBoostTrainer` class be helpful in ensuring fault tolerance during a training experiment?",
        "5ee5ccd0-34a6-4753-a005-1c819f81430c": "What is the purpose of the `logger.info` statement in the given code?",
        "0a40da81-32fd-4ab8-8c15-1e8623dcf6f6": "How does the `torch.distributed.init_process_group` function work and what parameters does it take?",
        "514fbfa9-9fc7-408a-b9ac-113f8bd71426": "What is the purpose of the train_one_step() function in the ray.rllib.execution.train_ops module? How does it relate to the Trainer class?",
        "25437565-8e2a-4772-a53e-23906f8f34a0": "Can you explain the difference between the train_test_split() method in the ray.data.Dataset module and the training() method in the ray.rllib.algorithms.a2c.a2c.A2CConfig class?",
        "51556f67-17cc-408f-a354-f35810cfb0b9": "What is the purpose of the TransformersTrainer class in the HuggingFace library?",
        "1aac6d33-9bf9-473e-bd1b-562574c9e845": "How does the TransformersTrainer class enable distributed training of HuggingFace Transformers models using Ray Actors?",
        "2b26ee56-376a-4efe-b61b-3cd0c20b7e75": "How does the property \"Trainable.uses_cloud_checkpointing#\" relate to the Ray Tune framework?",
        "64953893-8fd1-4698-ba10-fbc3507ae398": "Can you explain the significance of cloud checkpointing in the context of the Ray Tune framework?",
        "12c21964-a400-48e9-8d67-19f9ce11760a": "What is the purpose of the \"load_state\" function in the MultiAgentRLModule class?",
        "daf318ac-be3c-4887-826f-8f8caac80a69": "How can you specify which modules to load when using the \"load_state\" function in the MultiAgentRLModule class?",
        "a0c7ecd2-2ce5-4fb2-b45a-5639d0f917d6": "What are the possible values for \"episode_reward_max\" and \"episode_reward_min\" in the \"evaluation\" section?",
        "90819f73-5bac-40d2-be6f-d5f3d094a36e": "How is the \"episode_reward_mean\" calculated in the \"evaluation\" section?",
        "324be9dd-e84e-4308-b1af-becc2ed4bcdd": "What is the purpose of the \"sampler_results\" section in the context information?",
        "664e9ee0-8686-4d9e-85a9-b96c0b945394": "Can you explain the significance of the \"np.nan\" values in the context information?",
        "8cec7f86-8e67-4683-9a38-c4c6866b9835": "How does the \"training_iteration\" property relate to the \"algos logic\" mentioned in the context information?",
        "b178c0be-52ce-400f-8bf6-1769795f63d8": "What is the value of the \"loss\" in the local context information?",
        "662983b7-e5a8-40ba-9d6b-780e14b2241c": "How many iterations have been completed in the \"multi_objective_5d51f2d2\" trial?",
        "0fe7dd13-cb5d-4cd6-8ff4-514c60b7a0dc": "What is the purpose of the \"if len(self._inferred_metrics) >= limit\" condition in the code?",
        "1519e291-529f-4284-8c64-fb0d664087b4": "How does the \"_current_best_trial\" function determine the metric and mode to use for evaluation?",
        "3b29d0af-bbae-427f-89be-53de89368561": "How does the Repeater.on_trial_result() method in the Ray Tune library handle NaN values in the result dictionary?",
        "59e4c112-557c-4269-82b0-c1422a2d3774": "What is the purpose of the trial_id parameter in the Repeater.on_trial_result() method?",
        "3908e90b-6878-42a6-8fd0-84554f03d5b0": "What is the purpose of the \"GroupedData\" class in the given code? How is it different from the \"GroupBy\" method in the \"Dataset\" class?",
        "a25b64e5-1071-425e-b803-619e5de19a5f": "Explain the conditions under which the \"prune_columns\" flag is used in the code. How does it affect the behavior of the \"select\" method in the \"TableBlockAccessor\" class?",
        "c70c4cd5-f58d-4832-bcc7-035cd39e5ac9": "What are some methods available in the ray.data.preprocessors module for data preprocessing? Provide brief explanations for any two of them.",
        "e71382c1-1f85-415d-a596-cf0d0207c86b": "Compare and contrast the ray.train.huggingface.AccelerateTrainer and ray.train.lightning.LightningTrainer methods. What are their main differences and similarities?",
        "91dcb736-cfe8-415b-835e-0bff7d594392": "What is the purpose of the \"import_path\" field in the context information? How is it used in deploying Serve config to a Ray cluster?",
        "fc40a7f4-a747-4f2b-9f43-13af3a8b9f5f": "Explain the significance of the \"host\" field in the context information. Why is it important to choose the appropriate host for HTTP servers in a Serve application?",
        "229850a9-d834-42cb-9313-0cdbbc65ee50": "What is the purpose of the `submit_job` method in the `JobSubmissionClient` class?",
        "42475650-95c2-4533-b2aa-c65369708b74": "What is the difference between the `submission_id` and `job_id` parameters in the `submit_job` method?",
        "e052deca-81c8-4e0b-bf51-8938cbef8833": "What is the purpose of the `from_state` method in the `Policy` class?",
        "fa604c72-e048-4b48-aade-e7fda055670e": "How can the `from_state` method be used to recover a Policy instance?",
        "fc46e252-1d84-46c6-9c74-74dd10cfb689": "What is the purpose of the RLModuleConfig class in the given context?",
        "c0e90c68-a1d9-4145-b70b-1d7a97531300": "How can the RLModuleConfig class be used to construct RLModules more easily?",
        "60f79f9b-782f-4933-b6c2-eb10356bb8dd": "What is the purpose of the make_rl_module() method in the Policy class?",
        "5f2b7b2f-3b01-4b1e-a9af-aaf3d02240c6": "How does the make_rl_module() method relate to the RLModule API in RLlib?",
        "35ce165e-44d2-4b44-8e3a-fa8d830030f4": "What is the purpose of the \".pdbrc\" file mentioned in the context information? How can it be used to customize the debugger?",
        "611fddef-f517-4773-a8af-fc69f13e623e": "How can the debugger be extended or customized according to the context information?",
        "1cba3f92-9a1f-49c5-b060-612ad22e5217": "What is the purpose of the `make_multi_agent` function in the given code? How does it convert a single-agent environment into a multi-agent environment?",
        "577ca9d2-6e17-4f7a-aa2e-94cfb3811601": "Explain the conditions that need to be satisfied for the `_check_if_action_space_maps_agent_id_to_sub_space` method to return `True`.",
        "47b6b58e-bb5e-4191-908b-1782f1d3b3e9": "What is the purpose of the \"CheckpointConfig.num_to_keep\" parameter in the given context information?",
        "fc71e979-1ab9-43ee-a4f4-847110c29d64": "How does the \"CheckpointConfig.num_to_keep\" parameter affect the checkpoint saving process in the given context information?",
        "d33c8d88-d0a4-4510-95df-3b857269ef4e": "What is the purpose of the property \"RayDDPStrategy.launcher\" in the given context?",
        "81f277e7-c6df-483c-9882-0ddf9d71c06c": "Can you explain the role of the RayDDPStrategy.launcher in the overall functionality of the ray.train.lightning module?",
        "677582a2-bbe0-48d5-8e8b-cff0766d03be": "What is the purpose of the `super().__init__()` method in the given code?",
        "82b192fd-883d-42f4-bfb3-ac69b3b1bc5c": "How does the `get_base_struct_from_space()` function contribute to the code?",
        "a6a24e8a-7ce9-4a28-94a3-325884351e52": "Can you explain the role of the `get_exploration_action()` method in the code?",
        "1b10a544-612c-48af-9c29-1f993423c82d": "What is the significance of the `explore` parameter in the `get_exploration_action()` method?",
        "d51ecfa7-e5de-4568-b108-c279380fdac8": "How does the `ActionDistribution` object relate to the `get_exploration_action()` method?",
        "77ab704d-5520-40b0-84c8-44d694e2ab6b": "What is the expected input type for the `timestep` parameter in the `get_exploration_action()` method?",
        "8ea8c86b-4c87-4c58-a116-10d0eb435072": "How does the `framework` parameter affect the initialization of the object in the `super().__init__()` method?",
        "c8a20c48-7040-4551-9d8d-392e7aff2f71": "Can you explain the purpose of the `**kwargs` parameter in the `super().__init__()` method?",
        "205f0c5e-17ef-459c-801f-42996b04c47d": "How does the `model` parameter contribute to the initialization of the object in the `super().__init__()` method?",
        "8ee1a529-8fa1-4060-aedd-25b535dacbf6": "What is the role of the `@override(Exploration)` decorator in the code?",
        "b737a5ab-b3c8-46bd-bfe4-88135e7e9cd6": "What is the purpose of the TorchTrainer class in the ray.train.torch module?",
        "82afda33-440b-47a7-9429-1b4886aa36a5": "Can you explain the structure of the NeuralNetwork class and its forward method?",
        "26166a2e-e411-48db-bb28-c1519ef05f8e": "What is the purpose of the \"merge_siblings_for_task_group\" function in the given code?",
        "264f9e7f-1d09-4315-8333-d3ebeb95b2f1": "How does the \"merge_siblings_for_task_group\" function handle the case when the \"siblings\" list is empty?",
        "f51f142b-6158-4b3f-af12-297e6e40d20f": "How does Ray handle data transfer between workers and nodes in a distributed computing environment?",
        "16bfa376-b7e5-4ee6-beb3-c28ccb324322": "What is the role of the Plasma object store in Ray's serialization process and how does it facilitate efficient object transfer?",
        "81e6ddbf-0137-4db3-81d9-42249cf34471": "What is the purpose of the \"exit-handler\" template in the given Argo workflow?",
        "d8592020-e4ee-4b23-9233-026499a3d8ec": "Explain the functionality of the \"intentional-fail\" template in the Argo workflow.",
        "f63f0d9f-337e-4e00-a341-1c9cb18aea72": "What is the purpose of the \"experiment_tag\" field in the context information?",
        "d1f88c12-4b7a-42b2-9dfc-59dca26ee05f": "How can the \"time_this_iter_s\" field be used to analyze the performance of the TorchTrainer experiment?",
        "acd80c3e-1213-40cd-a3f7-ed3823449ddb": "What is the purpose of the BayesOptSearch.optimizer in the context of Ray Tune search?",
        "69c89685-f93c-4e50-a043-3df6e800bc8e": "How does the BayesOptSearch.optimizer parameter affect the optimization process in Ray Tune search?",
        "548e0df7-665c-4c7f-b732-d78864cfb4e3": "What is the purpose of the code snippet provided in the context information?",
        "ee85494a-4fb3-4245-8827-5baf9c6c1b68": "How does the code snippet ensure that only the policies that were updated are synchronized?",
        "cb1b7cfd-aafb-431e-923b-db310fd65d8b": "What is the purpose of using Hugging Face Accelerate and Ray Train in the given code example?",
        "333183e1-bf47-4d2b-89fc-7528eeb80c49": "How can the BERT model be fine-tuned using the provided code?",
        "704fff1b-4542-4f96-9ebb-a558325b4e9d": "What is the purpose of the `RayTrainReportCallback` class in the given code?",
        "b2f21ab5-bfea-4789-9cfc-42e0a24bea39": "How does the `RayTrainReportCallback` override the `TrainerCallback.on_save()` method?",
        "dae95beb-5b26-44c4-bcb5-cbea25b272c5": "What is the purpose of the `fit()` method in the `DataParallelTrainer` class?",
        "3c4af451-a851-49d7-900f-7a71d4bd614f": "What exception is raised if there are any failures during the execution of `self.as_trainable()` or during the Tune execution loop?",
        "0213544e-ee3e-471a-b059-76c8af33281b": "What are the possible configuration options that can be specified for a runtime environment using the `RuntimeEnvConfig` class?",
        "d9e61b9d-0bef-42d3-b5fb-6e5e65ee0333": "How can the `RuntimeEnv` class be used to define a runtime environment for a job, task, or actor?",
        "23ec397f-66da-492a-bae9-91dcb6a5e8ba": "How is the training iteration value in the `Trainable` class incremented?",
        "dacb271d-0cd6-412b-83cf-d54daabfbe69": "What is the purpose of the `training_iteration#` property in the `Trainable` class?",
        "bef28f95-fdca-43bc-9b51-e2b29c68abc4": "What is the purpose of the \"actions\" variable in the given code snippet?",
        "9045fafc-2c23-42d0-96cb-aef22589f8ac": "How does the code handle recurrent models in the else statement?",
        "949a365c-c0e1-4629-8dc2-3163eefc041e": "How does the Tune Scikit-Learn API (tune.sklearn) enhance the functionality of the Scikit-Learn library?",
        "d9d08a64-ce52-415e-9648-e602b1ebabaa": "Can you explain the purpose and benefits of using the Tune Scikit-Learn API (tune.sklearn) in machine learning tasks?",
        "b8f33451-a3a2-44d1-ab93-5d2deeb25056": "Explain the purpose and significance of the variables \"initial_p,\" \"final_p,\" \"t,\" \"schedule_timesteps,\" and \"power\" in the given equation. How do these variables contribute to the overall calculation?",
        "36867603-080b-4cdc-9220-b05e764c59a5": "How does the formula in the given context information calculate the final value? Explain the step-by-step process and the mathematical operations involved.",
        "fd7ee43d-d706-421a-9965-e9a49fd29942": "How can you connect to a remote Ray cluster? Provide an example of a concrete address and explain how it can be used to connect to a remote cluster.",
        "23cd85c7-3d03-40bd-bc83-974f295d29ff": "What are the different ways to specify the address parameter when connecting to a Ray cluster? Explain the process followed in each case.",
        "05854491-66cf-4645-8cc6-86340d547760": "What is the purpose of the `environment()` method in the `AlgorithmConfig` class?",
        "5a1dddea-87d4-44a6-834d-b8faa8e6dbdd": "How does the `EpsilonGreedy` class contribute to exploration in reinforcement learning algorithms?",
        "aa2d91de-908a-4db1-845e-298d99b10f33": "What is the purpose of the `wait()` function in the `ray` module? How is it different from the `wait_for_gpu()` function in the `ray.tune.utils` module?",
        "c3e5f214-5d09-48bd-9c8d-375792662a71": "Explain the role of the `WorkerState` class in the `ray.util.state.common` module. How does it relate to the `WorkerSet` class in the `ray.rllib.evaluation.worker_set` module?",
        "b7f5462e-7f9b-411d-9b2e-ac22bfa527c9": "What is the purpose of installing Ray before starting it on your machine or cluster of machines?",
        "e1c73c36-0509-4b0a-b1bb-4e7fabbb08ed": "How can you ensure that Ray is properly installed before following the instructions on this page?",
        "f965d9fa-64c7-49e6-9299-c1000cb971db": "What is the purpose of the FIFOScheduler in the given context?",
        "df73bce3-2a00-4701-bb75-461848b6b36a": "How does the FIFOScheduler determine the order in which trials are run?",
        "d3f1b539-0c95-4886-9c32-396b67474939": "What is the purpose of the \"Node Id\" field in the context information?",
        "ac4ed70d-7207-49aa-9efe-484fedf3432b": "How does the \"Node Ip\" field in the context information contribute to the functioning of the actor?",
        "80bbef58-6430-4fa7-9693-be8b91067ea3": "Explain the purpose of the MinMaxScaler preprocessor in the given code example. How does it transform the data?",
        "abd3fa7f-c709-478d-b247-0eb1bcc6b762": "In the given code example, what happens to the columns that are not specified in the MinMaxScaler? How are they affected by the transformation?",
        "37fdd5e9-62cf-4d8e-a6e3-e006fbe241c9": "What is the purpose of the `set_training` method in the `SampleBatch` class?",
        "0dc93cdd-38eb-44cb-9d92-4fa2795902a2": "How does the `set_training` method in the `SampleBatch` class differ from other methods in the same class?",
        "f8252e71-0e22-45fa-992c-16be241c4488": "What is the purpose of the `get_local_world_size` function in the given code?",
        "5c805a4c-09c7-4489-8690-e59544a23be5": "How is the `get_local_world_size` function used in the `train_loop_per_worker` function?",
        "217ee6de-2bae-4278-9e12-d5dc2acf7ca3": "True or False: If the RolloutWorkers parameter is set to True, will the number of collected batches within the same sample() call be limited based on the number of sub-environments within the worker? Explain your answer.",
        "1eb800d8-82f0-43b0-b898-e282c4965dc6": "How does setting the RolloutWorkers parameter to True affect the behavior of the AlgorithmConfig object? Provide a brief explanation.",
        "da7d920d-3093-42ef-9c15-fa2cd1cbe1e8": "How can performance tips be beneficial for individuals in various fields, such as students, athletes, and professionals?",
        "5d916972-955c-4409-a84d-3942390870f9": "What are some key factors to consider when implementing performance tips to improve overall productivity and efficiency?",
        "b42e84f9-02e2-4616-b071-69e7e06ca49b": "What is the purpose of the `to_tf` method in the given code?",
        "b1a4825c-eb1b-4336-9748-5e9b8c75376d": "How does the `to_tf` method convert the data into a TensorFlow Dataset?",
        "0bb3c257-4d28-4ad4-919f-1f8a4ae84dec": "What is the purpose of the first \"if\" statement in the code snippet?",
        "ed072997-79b5-41c2-9496-7c1b77d52b1e": "What are the possible values for the variable \"max_object_store_memory_fraction\" and what are the corresponding conditions that raise a ValueError?",
        "253aa79e-791f-4b29-a355-be767412dbf0": "What is the purpose of the `synchronous_parallel_sample` function in the given code?",
        "f5db71cf-946e-4c51-b8e2-2171b75bf056": "How does the `multi_gpu_train_one_step` function update the counters and timers in the Algorithm instance?",
        "59792dda-7154-496a-a7a1-25bcc9b1817e": "What is the purpose of the evaluation set in the context information?",
        "c5433b93-2d4d-4f5e-9957-257972639b09": "How does the evaluation loss value compare to the learning rate in the context information?",
        "39b432fb-4f8c-4453-9c6c-74e4022332f9": "What is the purpose of the `sync_up` method in the given code? How does it relate to the `sync_period` variable?",
        "b8d98ba1-1dc3-457a-83b7-b03f0626832f": "Explain the arguments of the `sync_down_if_needed` method and how they are used in the code.",
        "0697dbd9-cbb7-4455-b1a4-07e7c34cb7bf": "What is the purpose of the `get_best_trial` method in the given code?",
        "106da036-259d-4504-a580-f9ab43c6353d": "How does the `get_best_config` method determine the best trial in the experiment?",
        "d393d960-557d-4303-9e80-fa75cf32b932": "What is the value of the mean loss for the trial with the trial_id \"4d4ed536\"?",
        "9e43c702-f398-420a-a845-f21c21aa708a": "How many iterations have been completed for the trial with the trial_id \"4d51b38c\"?",
        "721ed848-f357-4f6c-9dd3-fceecf0fe84e": "What is the purpose of the `PlacementGroup.bundle_count` property in the Ray library?",
        "61bc49d6-83fe-401f-ae29-6d9f4dd25449": "How can the `PlacementGroup.bundle_count` property be used to optimize resource allocation in a distributed computing environment?",
        "50a9fe96-fa0e-41bd-86c5-9adb2f1e0307": "What is the purpose of the \"timeout\" parameter in the given function? How does it affect the behavior of the function?",
        "08647d13-9f01-4179-88b0-d26c14210308": "Why does the code block recommend using `await` on object ref with `asyncio.gather` instead of using blocking `ray.get` inside an async actor? What potential issue does blocking `ray.get` pose in this scenario?",
        "5f006562-326a-43a7-b2dc-67b99c3fc42c": "What is the purpose of the `output_specs_exploration` method in the given code?",
        "39245bf6-570c-421c-a435-83db05564779": "How does the `input_specs_train` method differ from the `input_specs_inference` method in terms of their return values?",
        "b924d8ec-18f5-4b69-82e7-cce6f4289727": "What is the purpose of the `join()` method in the `AsyncSampler` class of the `ray.rllib.evaluation.sampler` module?",
        "f63f89cc-2ce0-4b6b-8dae-d1d6d611be54": "How does the `JsonLoggerCallback` class in the `ray.tune.logger` module differ from the `JupyterNotebookReporter` class in the `ray.tune` module?",
        "1c1a9360-6bf5-464b-90bc-9d9de2232431": "What is the purpose of the `serialize_lineage()` function in the given code?",
        "b6f5b263-9e5f-43d7-b6d7-7e0c417963c2": "Can you explain the structure and properties of the `Dataset` object that is being printed in the `serialize_lineage()` function?",
        "d2a9e8da-07ad-4ad6-9e1a-28bf5b17acb3": "What is the purpose of the `before_compute_actions` method in the RE3 initialization process? How does it contribute to the overall functioning of the policy?",
        "8da7ea71-7b2f-4998-bbd8-c87d0089534b": "Explain the role of the `postprocess_trajectory` method in the RE3 policy. How does it contribute to the calculation of states' latent representations?",
        "d13c6769-991a-4718-b27c-b2bec143e0a8": "What are the advantages of using the ASHA scheduler over the standard HyperBand scheduler?",
        "5f88d2f5-b88c-4b67-95cf-ef9dfb9dcbe5": "Can you explain the key features and parameters of the ASHA scheduler?",
        "fb75f2e3-c4a5-4139-ba9a-22c4faaed420": "How does Ray interact with SLURM in a typical deployment?",
        "957f3e04-aea9-4b1e-8481-e91154d61b98": "Can you explain the steps involved in launching a Ray job with sbatch and SLURM?",
        "0e5c0e49-2292-423d-80e4-49d0dd020bca": "What is the purpose of using Ray tasks in the code snippet provided? How does it contribute to the overall functionality of the program?",
        "f17efd7f-657b-4ce5-ba0d-2d0a487aad2d": "Can you explain the difference between the error patterns raised in Arrow 10+ and Arrow < 10? How does the program handle these errors?",
        "91b1595a-1593-493a-a3ff-80ff56c8cb3d": "How can you enable Ray profiling for timeline generation?",
        "35497de1-2c2c-4507-bcf5-3967305b34eb": "What is the purpose of setting the RAY_task_events_report_interval_ms variable to a positive value?",
        "d45e1b96-98ab-4144-9eeb-4309618eb047": "What is the purpose of the `TorchWorkerProfiler` class in the given context?",
        "1c93d89a-f936-479d-bb8a-509581d9dbe3": "What is the purpose of the `_TorchAccelerator` class in the given context?",
        "b0626909-6a76-4ffb-9423-66a0ea76dcc9": "How can the grid_search function in ray.tune be used to specify a grid of values to search over? Provide an example.",
        "247cbd27-76d5-405e-932e-b70d372bbe9f": "How does the grid_search function in ray.tune handle multiple grid search variables? Explain with an example.",
        "cf9528c8-4019-4dc4-bcf0-294f73160940": "What is the purpose of the \"evaluation_workers\" variable in the given code snippet? How does it affect the evaluation process?",
        "d1aa45bc-5364-49bf-b9cc-08b207e5fb71": "Explain the difference in the evaluation process when the \"unit\" parameter is set to \"episodes\" compared to when it is set to \"ts\".",
        "96e972fe-a165-4884-94f5-95ad1ba79341": "What information does the Overview Metrics page provide in the Ray Cluster Overview view? How can it be useful for monitoring the cluster's performance?",
        "32c0fa3c-1069-4bd3-8831-daa29fecab3e": "What are the two types of events available in the Events view? How are they different from each other and what information do they provide?",
        "aef0f80d-1c1b-4e35-b0d1-894c2e0335eb": "What is the purpose of the \"post_process_metrics\" function in the given code?",
        "672040e0-5199-498c-8e11-237c2f8915e7": "How does the \"inner_adaptation\" function contribute to the overall process described in the code?",
        "58b5b53e-6622-46cb-9b8f-55f39a4fb832": "What is the purpose of the `WorkerSet` constructor in the given context?",
        "48a57197-a425-4777-b720-3a07f6ee8736": "How does the `reset` method in the `WorkerSet` class differ from the `stop` method?",
        "a1bd51ed-d418-4b3e-8d96-001dda090967": "What is the purpose of using the map_batches() API in the given context?",
        "befe1252-e0bd-4aa6-8ef7-f79d37c3083b": "How can the batch_size parameter be optimized to maximize GPU memory usage while avoiding memory overflow?",
        "2e295f3e-d631-464b-bbfc-db85b313d4db": "How does Ray's distributed compute framework help in scaling large language models and generative AI?",
        "bf3d0bd0-fbd0-4c90-bdf8-bd167b650887": "Can you explain the different specialized libraries provided by Ray for data streaming, training, fine-tuning, hyperparameter tuning, and serving in the context of developing and deploying large-scale AI models?",
        "f9731797-6320-46ae-862e-36e52d3502f1": "What is the purpose of the \"if pa is not None and isinstance(schema, pa.Schema)\" condition in the code?",
        "7ffdbe15-7ee3-45d1-b90d-0fece77c0f1d": "How does the code handle the case when the schema contains an instance of ArrowTensorType?",
        "b092b36b-32b0-40e8-925f-5c7850498289": "What is the value of the mean loss for the \"objective_two_101e702a\" trial?",
        "bc4b2882-4887-492c-b040-7eb14ebc7405": "How many iterations have been completed for the \"objective_two_1022212a\" trial?",
        "f58971f0-a1c4-478a-a37e-1794d2a1f89c": "How does the compute_actions_from_input_dict method in the Policy class handle input data that requires a more complex pattern, such as the last n observations or the last m actions/rewards?",
        "710d8c13-1a0d-41d0-a1dc-18295dfeeb66": "What is the purpose of the \"explore\" parameter in the compute_actions_from_input_dict method? How does it affect the selection of actions?",
        "d78d9a5b-89f5-4694-aed4-ed7e69403d1d": "What is the purpose of the \"log_trial_start\" function in the given code?",
        "f0d828be-4be5-4b21-92ca-630f42d64e3f": "How does the \"log_trial_result\" function handle the \"TIMESTEPS_TOTAL\" and \"TRAINING_ITERATION\" keys in the \"result\" dictionary?",
        "f8c78a9d-5fcc-4697-9910-24ccfd1e6545": "What is the purpose of the `get_nowait_batch` method in the given context?",
        "bc9f6c09-6d29-4dd8-a049-b8e3673f4e44": "Explain the difference between forcefully killing the actor and attempting graceful termination before forceful kill in the `shutdown` method.",
        "0dd99c93-a07b-4786-b934-f46515ad311d": "What is the purpose of the Learner class in the RLlib library? How does it contribute to training RLModules?",
        "a574605a-33a1-431b-9963-d75e388c4b3a": "Can you explain the difference between a single agent module and a multi-agent module in the context of RLlib's Learner class? How does the Learner handle the conversion between these two types of modules?",
        "f77d2cf6-82b7-426c-b339-081a3e1e571c": "Explain the purpose and functionality of the \"fold_mapping\" function in the given code.",
        "0283010e-978d-40b1-aa5f-57547718c38c": "How does the \"fold_mapping\" function reshape the input tensor?",
        "8c5eb60a-2393-4482-88b5-ca078c6c8cdf": "What is the purpose of the \"if\" statement in the given code?",
        "bc0fe842-af68-4363-99b2-b477d1be9e27": "How does the \"read_datasource\" function handle the \"meta_provider\" parameter if it is not None?",
        "f7cc3912-8ec5-4bc0-bd01-8fec4a2e6def": "What is the recommended value for the max_batch_size parameter when fine-tuning batching parameters? Why is this value preferred?",
        "727ee0c6-c101-4776-801e-34a470d1b4e6": "How does the relationship between upstream and downstream nodes in a Serve Deployment Graph affect the performance of batching? Provide an example scenario to illustrate this.",
        "6d20f0ec-eec3-4ff5-a322-f945d863db86": "How does the `generate_text` function in the given code snippet use the `streamer` parameter?",
        "ebde839a-5f85-4750-accd-4e07b1ee0d55": "What exception does the code handle in the `consume_streamer` function and how is it handled?",
        "542cf206-050e-40ef-af7a-aca0484b6a50": "What is the purpose of the \"successive_halving\" method in the given code?",
        "24981b66-ba3f-4472-857a-138c6d6fd3bc": "How does the \"successive_halving\" method select the trials to be returned as \"good\" and \"bad\"?",
        "15cc5148-b3d9-4210-970b-e2b74074a161": "What is the value of the mean loss in the local context information?",
        "c65391ec-ed33-4802-adbc-0f63c6d320ef": "How many iterations have been completed in the training process according to the result for objective_a0c11456?",
        "bb650006-0556-4d29-b1c2-fb12799b69fc": "What is the purpose of the property \"RayDDPStrategy.local_rank\" in the Ray training lightning framework?",
        "957f1151-4a3a-4ae0-b72a-cb8ef73cf25e": "How does the \"RayDDPStrategy.local_rank\" property contribute to the distributed training process in the Ray training lightning framework?",
        "055c87dd-5f2f-4d9f-8fe8-2425c77c20bf": "What are the compiler types and standard libraries used in the given context information?",
        "206c39fd-e28c-42c7-83a3-0840af6237b3": "What is the purpose of the \"flatten_unflatten.cpp\" file in the given context information?",
        "3123d6a9-53e7-4b5a-abdd-b15b96489b0c": "What is the purpose of converting Paths to strings in the given code?",
        "9310963b-7ce2-457e-8fed-469a5e706cd5": "Why is the legacy stuff mentioned in the context information marked for removal?",
        "d20b615d-dea9-4c02-8d0c-b2bb5ba55bfe": "How does the retry policy handle tasks that are killed by the memory monitor? Does it retry them indefinitely or is there a limit?",
        "ff83596f-d274-40b2-ae74-b9275721a894": "What is the maximum delay for retrying a task or actor that is killed by the memory monitor?",
        "2788f64b-5811-4360-8566-ae9692144f8a": "What is the purpose of the \"sync_config\" parameter in the code snippet?",
        "a03fda4b-cf0f-4334-b9ed-0c927f9073bf": "Why is the \"keep_checkpoints_num\" parameter deprecated and what should be used instead?",
        "62ffc323-59fa-450e-b9f8-62e533d98730": "What is the purpose of the `get_empty_schema_dict()` method in the code snippet?",
        "ffc115f8-f91f-41f7-b3c9-eec66f772da5": "How does the `_get_status()` method in the code snippet retrieve the status of the Serve instance?",
        "3f11e2dd-19cb-47f2-8e32-465f50a109d2": "What was the total run time for the tuning loop?",
        "d4a226f6-760a-4387-a3b9-39ce47662abd": "How much memory is currently being used out of the total available memory?",
        "3117904f-b383-42b0-9a1c-943ecc965da7": "What is the purpose of the \"set_search_properties\" function in the given code snippet?",
        "1cec2a6b-8cb6-4fa5-a3ed-7f3b889bf43f": "How does the \"_set_search_properties_backwards_compatible\" function ensure backward compatibility in the code?",
        "6d387310-949e-471c-bd9e-ec3e6fa94149": "What is the purpose of the code block starting with \"if (sys.platform == \"win32\" and not netloc...\"? Explain the conditions and the actions taken if those conditions are met.",
        "4efa7739-9a79-4f8d-b7d6-bac1414952fe": "Why is the \"_wrap_s3_serialization_workaround\" function necessary in the given code? Explain its purpose and how it is used.",
        "07dc306d-1582-496a-a2f5-3f0757374695": "What is the purpose of the GCS server in a Ray cluster and where does it exist?",
        "1cfb02fb-0329-4177-b886-ad9373dcfd6d": "Explain the role of the log monitor in a Ray cluster and what type of information can be found in its log files?",
        "99052771-9074-4d69-9392-43375e9f34d6": "What is the main purpose of adopting the RLModule API in RLlib from version 2.6.0 onwards?",
        "383f33fb-0533-4052-a32e-ec510006d031": "How does the RLModule API in RLlib differ from the ModelV2 API and the Policy API?",
        "b835bea3-d7f0-479b-8e26-59ded90b8c64": "How does the XGBoost Dynamic Resources Example ensure that all resources are being used at all times?",
        "7a246cbf-7960-428a-94a6-e9e1af118e81": "What is the purpose of using a ResourceChangingScheduler in the XGBoost Dynamic Resources Example?",
        "7fac1424-6e86-418d-8e4b-2b089f8af685": "How does Ray limit the concurrency of tasks and actors?",
        "e41ca7be-5891-4732-808f-a607813bc5fa": "What issues can arise if tasks or actors use more memory than their proportionate share?",
        "497edf46-1e8b-4cc0-8487-a7c5127aa068": "What is the purpose of the function \"update_priorities_in_replay_buffer\" in the given context?",
        "212d5044-1438-494a-820a-6f1424f0771a": "How does the code snippet ensure that the target network is updated at regular intervals?",
        "18090af4-2197-4b51-a15f-3d25621caf82": "How does the \"DEFAULT\" strategy in Ray handle task scheduling and load balancing?",
        "238e977d-86e1-4f69-8c06-2653f1e369ed": "What factors does Ray consider when selecting the best node for scheduling tasks or actors in the \"DEFAULT\" strategy?",
        "8a72dedc-9ba6-44cb-8794-a0520433a169": "What is the purpose of the \"grad_clip\" parameter in the AlgorithmConfig object?",
        "0b3d0c18-ddc8-46a2-ada2-ee967bab68cf": "How does the \"grad_clip\" parameter affect the gradients during the training process?",
        "6f073bfd-0c8d-4bc0-a171-fe1e93e79d44": "What is the purpose of the \"_inspect_serializability\" function in the given code? Explain its role in checking serializability.",
        "cabe5174-2c8d-4518-ba60-23762a296af8": "In the \"_inspect_generic_serialization\" function, why is it important to assert that the \"base_obj\" is not a function? How does this assertion contribute to the overall functionality of the code?",
        "9266e556-7c50-46f8-b84a-42d27f2975a4": "What is the purpose of making the subclass serializable in the given context?",
        "af4633fd-d012-4a09-adc1-b5332713a822": "How does Ray Train utilize the configure method in the Trainer group to create data iterators for each worker?",
        "254005e8-d8f9-4ec9-bfe0-fc18767b6512": "What is the potential error that may occur if the entrypoint command is wrapped in quotes when using the CLI?",
        "55b993bf-1017-4b76-b555-32cff099c33d": "How should the entrypoint command be provided when using the ray job submit command?",
        "988f61f9-7af4-4637-b23b-9b447305c14d": "What are the parameters required to construct a Learner actor according to the LearnerSpec class?",
        "69dfc80a-412c-482e-a3c0-8e16c2bb42c9": "How can the RLModule instance be passed to the LearnerSpec class if the Learner is not an actor?",
        "9ef49628-5755-41fa-a235-62b91bc070d0": "What is the value of the mean loss for the trial with the trial_id \"c385528e\"?",
        "07abc708-529b-492d-a9c4-0f7de3c099ec": "How many iterations have been completed for the trial with the trial_id \"c387a7c8\"?",
        "4591bd16-5f22-456d-88e8-949f68dc4645": "What are the main functionalities provided by the Learner class in RLModules?",
        "a9a2f015-bc4a-4d72-bc92-dbef43721828": "How does the LearnerGroup API support data-distributed parallel training?",
        "d98706b2-07e2-4ca5-9d4a-f3a17a77fe05": "What is the purpose of the \"pre_backward\" function in the context of the given document?",
        "fc9e3456-e446-42ac-8b52-71df5baf0379": "How does the \"reduce\" function work in the context of distributed processes?",
        "27a0a25d-25da-40e6-9837-8c24e7a43fb1": "What is the default location where Ray writes logs?",
        "c58ad9dd-0b9e-46de-a4e3-723045488dae": "Why is redirecting logs to stderr not recommended?",
        "99a8d56f-dbc1-4169-b3b3-81d2e46e0d24": "How can transforms be optimized in a given context?",
        "0b883284-b0f4-445a-84b1-4ef392e6159c": "What are the key considerations for diversifying the nature of transforms in a document?",
        "f5e58c47-63b1-460d-978e-045e26793322": "What is the purpose of the \"export_checkpoint\" method in the given code?",
        "1dd57ddc-ca86-49f1-bc66-79062e2e8a9a": "How does the code handle the global time step in different frameworks?",
        "8972eff2-3efa-4f4b-9a07-a73d726d6af0": "What is the purpose of the `remote_workers` list in the given code?",
        "95e37cf3-6f3d-44a3-a0a8-f99b04fd79e4": "Why is it important to check the data type and shape of `theta` in the `step` function?",
        "e1ff34fb-3109-4ad2-8c55-bd8385741be6": "How does the LessSampledReplayBuffer class differ from the base ReplayBuffer class?",
        "c94b7654-19da-476b-81fd-0779ac9f208d": "What is the purpose of the sample() method in the LessSampledReplayBuffer class?",
        "e9761bd3-1b76-41f4-9785-7c1302c4e36e": "What is the purpose of shuffling the dataset before feeding it into the model trainers? How does it help in the training process?",
        "7412669e-ffb8-479f-8e83-74923232d68a": "Explain the role of the Trainer actor in the model training workflow. How does it consume the dataset and simulate model training?",
        "34c45532-2392-4087-ba05-1241adcc9b0d": "What is the purpose of the `LegacyTensorflowCheckpoint` class in the given code? How does it differ from the `Checkpoint` class?",
        "fa212297-48a2-4235-ada6-6f22b31d4d5a": "Can you explain the significance of the `Flavor` enum within the `LegacyTensorflowCheckpoint` class? How does it affect the loading of a model from a checkpoint?",
        "1a5af197-3225-4de8-94e3-c993b7df9e37": "How can you add arbitrary stateful components to a policy in order to override methods or define extra methods and attributes?",
        "67f4d4d1-c8bb-453b-beef-2232cb01571c": "What is the purpose of the setup_mixins function in the given context?",
        "70d3bc96-0cf6-48e2-8470-6d7e52120878": "How does Ray distribute users' code to multiple processes across many machines?",
        "8dc3fc66-a5fa-4011-94db-7edc8eb471c3": "Can you explain how Ray provides a debugging experience that is similar to debugging a single-process Python program?",
        "12518d2f-a529-4d82-9b9c-7e0776a455f8": "What is the purpose of the \"LearnerGroup.shutdown()\" method in the Ray RLlib library?",
        "c8d23dbc-c72c-4771-808c-fa1b4a74d055": "How does the \"LearnerGroup.shutdown()\" method contribute to the overall functionality of the Ray RLlib library?",
        "905449d1-b46b-4dd6-a0f2-01fa5086b9f2": "What is the purpose of the `handle_options` parameter in the `_DeploymentHandleBase` class constructor?",
        "14f46b75-bff1-49f2-bfdf-bce2ff570eda": "How is the `request_counter` attribute initialized in the `_DeploymentHandleBase` class?",
        "84fa7aff-b5c0-49dd-ae5e-a7cb92798e24": "What is the purpose of the `add_policy` method in the given code?",
        "94737cf2-7b96-4ce1-955b-1b6330ced78f": "How does the `add_policy` method differ from the `set_weights` method in terms of functionality?",
        "10bee57b-45ec-484a-9641-3fd5cb901524": "What are some common reasons for debugging failures in software development?",
        "bddac138-f1ec-4c9d-b4d9-5430fd8fa850": "How can a teacher or professor effectively help students overcome debugging failures in their programming assignments?",
        "5f65b323-f06e-44c0-bd07-2a664f3174d7": "Explain the purpose of the function \"_prepare_for_ray_worker_node_startup\" and how it addresses the issue of ray port conflicts during concurrent startup of ray worker processes.",
        "b134ba42-60d3-4d1c-8875-d5084fb0d4d8": "Describe the format and content of the \"/tmp/ray_on_spark_worker_port_allocation.txt\" file created by the function. How does this file ensure non-overlapping worker port ranges for multiple ray worker nodes running on the same machine?",
        "4ed55967-a537-4590-af4e-aeae9f0b9426": "What is the purpose of the `RayTrainReportCallback.on_init_end` event in the training process of the `Trainer`?",
        "63e09c78-e508-466a-86e0-905cd17483bc": "How does the `RayTrainReportCallback.on_init_end` event contribute to the overall initialization of the `Trainer` in the training process?",
        "deb10552-08b1-4d58-9484-1f73d7890527": "What is the purpose of the `offline_data()` function in the given context?",
        "5f7ffba8-229b-45cb-85bf-2768aeb0331b": "How does the `evaluation_interval` parameter affect the evaluation process in the given context?",
        "4aeacf9a-9a81-4150-bff1-1a34db09e573": "What is the difference between the methods `num_healthy_remote_workers()` and `num_healthy_workers()` in the given context?",
        "8d726c6a-5a5f-4e6a-b5d9-ed78cde75067": "How does the method `num_in_flight_async_reqs()` contribute to the functionality of the worker manager in the given context?",
        "b161040c-b0fd-4f19-a3ac-cdc9488cbceb": "What is the value of the mean loss found in the context information?",
        "1eb368d5-0c4b-476b-9505-3fe2121a1046": "What are the best hyperparameters found to minimize the mean loss?",
        "5f951074-a90b-417f-8db4-24a2cb600758": "What is the purpose of the `trials` argument in the function?",
        "fbc5e238-5615-45c2-b682-22e8baebafec": "How is the memory consumption information displayed in the progress update?",
        "52cb307a-2411-45ac-be40-7a4f3fa2c1ef": "What is the purpose of the \"datasets\" parameter in the LightningTrainer class? How does it relate to the datamodule and dataloaders specified in the LightningConfigBuilder.fit_params?",
        "3fe1ca0f-ca33-46e6-bc52-43defaebc2a4": "How can the datasets_iter_config be used to configure the iteration process over input ray datasets? What are some of the valid arguments that can be passed to it?",
        "0e001863-ff93-407f-8db3-2bd79eb43cbe": "What is the purpose of the \"trialdir\" in the given context information?",
        "3ad0b35c-1ecb-4ce3-ab5e-f367f7f8bf8f": "How can the output streams, stdout and stderr, be written to different files using the provided context information?",
        "82f01afb-9b13-41f1-b056-ab2a90afeabf": "What is the purpose of Step 3.1 in the given context?",
        "d99016d1-7aed-4229-970f-68f500f27454": "How can you create a RayJob in Step 3.2?",
        "21227383-588d-4d35-bde6-2f498e35d146": "What is the significance of downloading the `ray_v1alpha1_rayjob.yaml` file in Step 3.1?",
        "130b65da-abac-4e63-b5e4-e0ca6d554522": "Can you explain the role of the `ray-operator` in the context?",
        "7b20c082-a760-45e0-8f7f-63ea0636d8e0": "How does Step 3 relate to the overall process of setting up a RayJob?",
        "ee26228e-efe4-4370-a2f6-70b259afff6b": "What is the purpose of the `_determine_transform_to_use` method in the given code?",
        "17f4668e-e2d2-4d6c-bada-8d2871a3be37": "How does the `preferred_batch_format` method in the code determine the preferred batch format?",
        "002fae7f-90b5-4224-977c-e8f6a7e65789": "What is the data type of the \"target\" column in the dataset?",
        "4f78b3f0-537e-463a-9c41-73a15c19ea50": "How many rows are there in the dataset?",
        "bfe7ef1a-d4be-4f01-a8d9-10975f575452": "What is the purpose of the repeated download status messages in the context information? How do they contribute to the overall process?",
        "1b9aceeb-fad0-46e1-9002-c6e7cdfd19b5": "How does the download progress of the file mentioned in the context information impact the performance of the RayTrainWorker processes?",
        "96f45658-8bd4-400a-aaad-9b3937c0998e": "What is the difference between TD3 and DDPG algorithms? How does TD3 improve upon DDPG?",
        "d9060b00-7d6f-4e90-8341-4f156e5ab517": "Can you provide examples of environments in which TD3 has been tuned and implemented successfully?",
        "bb981231-6e9b-4ca8-a6ae-bb6140d01e7e": "What are the resource limits specified in the execution configuration for the XGBoostTrainer?",
        "e6449ed6-ed94-40fd-9cc5-c4169b4c61b4": "How can you enable detailed progress reporting for the XGBoostTrainer?",
        "13cf5871-3c03-4b46-91ef-ccab71ea58c4": "What is the purpose of the \"flax\" library mentioned in the context information?",
        "bc6db71c-edfd-4cf4-a7fa-a0b9b2ea569f": "How does the \"google-auth\" library contribute to the functionality of the Google API Python client?",
        "c3c73920-1a1e-4f0c-b274-9aa0ba13f131": "What is the purpose of the `_configure_placement_group_based_on_context` function?",
        "61dd4774-4451-46d0-ae02-7f020389ad5b": "What are the parameters of the `_configure_placement_group_based_on_context` function and what do they represent?",
        "69200a91-0d4e-4321-90dc-faaab7452af7": "What is the purpose of Optuna in the context of running Tune experiments?",
        "64490ead-3ce4-41a6-be51-a2a6c8905919": "How does Optuna differ from Ray Tune in terms of its approach to hyperparameter optimization?",
        "aef24a02-b5b9-4844-86ee-367c0fe158bf": "What is the purpose of the \"if any(not subcolumns for subcolumns in feature_columns)\" condition in the code?",
        "cf9e90f2-66a9-4839-bcee-0621c6dfab03": "How does the \"make_generator\" function contribute to the overall functionality of the code?",
        "b02201c2-ec04-4954-914b-3b46c2eae3b2": "What is the purpose of the JobType enumeration in the ray.job_submission module?",
        "75133eac-c804-40e2-9632-0a45f4924739": "How does the JobType enumeration differ from the JobType attribute in the ray.job_submission module?",
        "528c47a3-eb8c-4b09-8c3c-6d3db34a10e2": "What is the purpose of the \"view_requirements\" dictionary in the given code snippet? How is it used?",
        "84388d8f-0fe9-4f2e-b996-872f33bcc198": "Can you explain the role of the \"extra_outs\" dictionary in the code? How does it affect the \"self._dummy_batch\" and \"self.view_requirements\" variables?",
        "9673d8db-317a-41b3-b5fa-0ec91e47020a": "What is the purpose of the `try-except` block in the code?",
        "3047b54f-fc08-4edf-b873-842ae1df9cfe": "How does the code handle the case when `pgf` is not an instance of `PlacementGroupFactory` or a callable function?",
        "b606fe6f-7cb0-46f6-b932-1b901712797a": "What files are being downloaded in the first part of the context information?",
        "d419cf83-0f8d-4596-92ab-2bce69b64d86": "How much data is being downloaded in the second part of the context information?",
        "97564cb2-4c8a-4b82-b51f-73773aae8f09": "How can you restore the state of a searcher using the DragonflySearch class?",
        "e456b9e5-a6d2-462b-9908-59a399032bea": "What is the purpose of the restore_from_dir() function in the DragonflySearch class?",
        "52e5967a-fed4-414e-981a-4f0f4df46840": "How does setting the property \"RayDeepSpeedStrategy.restore_checkpoint_after_setup\" to true affect the restoration of checkpoints in the RayDeepSpeedStrategy?",
        "f848c257-1a6f-46e0-aba2-f3224a0cd60f": "In what scenario would it be beneficial to delay restoring from a checkpoint until after pre-dispatch in the RayDeepSpeedStrategy?",
        "076ad76f-80e0-4356-bcdf-d5797dd13193": "How can you enable the Ray debugger to set breakpoints inside tasks and actors running on a Ray cluster?",
        "bad3ae63-143c-45fc-93ff-312aa9c857a0": "What precaution should be taken when using the --ray-debugger-external flag to enable the Ray debugger on a cluster?",
        "5c519ead-1a5b-4329-9a9e-b1824bc9c26a": "What is the purpose of the `D4RLReader` class in the given code?",
        "da168b28-6b5d-465c-9a32-0d18a2f5dac5": "How does the `next` method in the `D4RLReader` class work?",
        "9cee3d64-151f-4586-aac9-e0ca4a435756": "What is the purpose of the `warnings.warn` statement in the given code?",
        "b861f256-0c97-4b8e-a91f-2adb4fbe03ce": "How does the `load_torch_model` function contribute to the overall functionality of the code?",
        "95cdf832-d4ee-4c66-b86d-cccb3619c3ed": "What is the significance of the \"training_iteration\" column in the context information? How does it relate to the termination of trials?",
        "2427c8f6-1678-41c9-b618-129ed073ca05": "Based on the context information, what were the hyperparameters used in the best performing trial?",
        "bc14467d-8ce3-4b6d-9b2a-73b01da66e02": "How does Ray Serve enable the deployment of the StrategyOnRayServe class as a scalable distributed computing service?",
        "015ff135-e49c-4914-bac6-53092bf21b4d": "What is the purpose of the calcIndicator method in the StrategyOnRayServe class?",
        "79026bbf-7dcc-4f0c-8bcf-10a9ff732e4c": "What is the purpose of creating an Amazon EKS cluster with GPU nodes specifically for KubeRay?",
        "6326709b-08b8-44e5-9721-862a01914794": "Can the configuration outlined in the document be applied to all KubeRay examples found in the documentation? Why or why not?",
        "62938856-20ca-445b-bf0b-76bf39460d6f": "What is the purpose of the preferred_batch_format() method in the Normalizer class?",
        "6058daa3-6d99-4180-a24c-ee4ea4ffca97": "How can the preferred batch format be overridden by Preprocessor classes?",
        "b49aca44-69ee-4383-b186-2c5ce5bd6cc0": "Explain the purpose of the \"initial_num_blocks()\" function in the given code. How does it contribute to the overall functionality of the program?",
        "4a0b13a5-1814-4337-ad39-51c91e9abb38": "Compare and contrast the two classes \"PushBasedGroupbyOp\" and \"SimpleShuffleGroupbyOp\" in terms of their functionality and usage in the given code.",
        "6418d7e8-066e-4a9c-b270-90201a90f8f4": "What is the purpose of adjusting the upscaling and downscaling speed in a Ray cluster? How does it benefit applications with many short-lived tasks?",
        "5bd904cb-3bcc-433f-a94c-3f20fb32f5fd": "Explain the three different modes available for upscaling in the RayCluster CR's autoscalerOptions field. How does the \"Conservative\" mode differ from the \"Default\" and \"Aggressive\" modes?",
        "acb33a89-38da-4f9a-8777-f637d4252e02": "What are the commands used to start Ray on the head node and worker nodes?",
        "c0d76b57-a095-4c9a-90be-264b5d42ed9f": "What is the purpose of the \"upscaling_speed\" parameter in the Azure configuration?",
        "c4c76516-2d69-45bf-a537-e13aeede324e": "How can exporting metrics into Arize benefit users of Ray Serve?",
        "9ec26588-9d5f-415f-95fb-33d37b582906": "What are some key features of Arize that make it a valuable tool for monitoring model performance and data quality in machine learning?",
        "08de43f9-3f4e-4fae-85d0-2ea1df4e1cf6": "What is the purpose of the `self.evaluation_workers.foreach_worker_async` function in the given code?",
        "bcdf2136-eee2-4dd9-a052-ebe33fd72c69": "How does the code determine whether to ignore a result in the `eval_results` loop?",
        "c9d53a6e-aaad-4619-a781-58e6af68d2f3": "How does py-spy help in profiling Python programs? Explain its key features and benefits.",
        "4bacd123-c254-4c20-884c-a6099bdc600f": "Describe the process of configuring the RayCluster YAML file to enable py-spy and visualize the Stack Trace and CPU Flame Graph via Ray Dashboard.",
        "43b2b72c-1809-45bd-a851-e66fe8b9233b": "What is the purpose of the \"debug_string\" method in the given code? How does it provide progress notification for the algorithm?",
        "f2e5d290-2757-4a26-bc44-913bde9971d3": "Explain the process of selecting a trial to return in the given code. How does the status of the trial affect its selection?",
        "bdbea4cb-ef4d-40c3-8c3e-126dfbeef355": "What are the key components of the configuration for the PPO algorithm in the given context?",
        "d39ed950-564c-47c8-a669-ac54a9c9cf38": "How does the \"CustomPPOLearner\" class extend the functionality of the \"PPOTorchLearner\" class in the given context?",
        "b66bd5ba-1c1d-404b-acf0-5666b9d71b83": "What is the purpose of the `_block_num_rows` method in the given code? How does it achieve its purpose?",
        "858fc68a-a8f8-409f-9485-f5ce09c45940": "Explain the significance of the `_synchronize_progress_bar` method in the context of the code. How does it ensure proper execution of the streaming executor?",
        "1f024e27-b711-471d-98e5-715502536b0d": "What is the purpose of the link provided in the context information? How can someone opt-out using that link?",
        "c4e4853b-cc02-4c71-9a7e-0b7cc0f76517": "How does the presence of comet_ml and the absence of COMET_API_KEY affect the functionality of the system?",
        "d372bf95-5e32-43d6-9abc-487c058a633f": "What is the purpose of the `else` statement in the given code snippet?",
        "d09ea20a-3a39-4c10-ad92-1cd8027f5a7e": "How does the code construct the `MultiAgentRLModuleSpec` based on the `current_rl_module_spec`?",
        "57472ee6-0532-46fc-a500-1f20d76e62cd": "What is the purpose of the refit parameter in GridSearchCV? How does it affect the best_estimator_ attribute?",
        "72a362c6-f48a-4477-af65-d9cc2d6c37dd": "How does the cv parameter determine the cross-validation splitting strategy? What are the possible inputs for cv and their corresponding behaviors?",
        "ff0704f2-2e8a-4cc2-9b6c-969e77c3736b": "How can we interact with an actor in Python? Provide an example.",
        "4de950f2-7e4e-4f60-82b3-b33bd67cc21a": "Explain the difference between calling methods on different actors and calling methods on the same actor in terms of execution order and state sharing.",
        "65311a5e-087b-4680-b051-86d44b09b160": "What are the three methods mentioned for connecting to GCP in the context information?",
        "f51c19d2-00c1-40d7-a076-862293a795ff": "How can you set up port-forwarding in the Ray cluster?",
        "c1b252b6-7089-44a1-ad5a-9ec8a0831bbc": "What is the purpose of the `learn_on_batch()` function in the given context?",
        "bd3caf1d-05d2-4514-8eee-a2655366ae74": "How does the `sample_and_learn()` function work in combination with distributed allreduce?",
        "c83fc8ad-1085-49f7-a9ac-a64dd429e08d": "What is the purpose of the HyperBandScheduler.CONTINUE status in trial execution?",
        "733eaf84-ffa3-410b-b7c5-c958905da22c": "As a teacher, how would you explain the role of the HyperBandScheduler.CONTINUE status in the context of the document?",
        "c8bc3e3e-95d2-4b61-9844-e5f2cedb89bb": "What is the purpose of the ValueError exception being raised in the code?",
        "c8f93afc-e437-4993-ac82-aebd61f3f61e": "How are the concatenated sequence lengths converted to tensors in the code?",
        "0a610d61-c3eb-4e79-9998-352e8dce1243": "How does the use of Github benefit the tracking of issues, feature requests, and bugs in a project?",
        "f4601d69-8f99-4d87-9804-70d6d5dd8ed4": "What is the significance of labeling certain issues as \"good first issue\" on Github?",
        "6bf3f38c-5035-41db-acfc-be355686f122": "How does Ray execute remote tasks asynchronously, even on a local cluster?",
        "83795c52-2889-4848-b6b1-4bfff29968ba": "What is the purpose of using the .remote() call when executing a Ray task remotely?",
        "44718ce0-532e-4177-87c7-eb13c175dbac": "What is the purpose of the \"if\" statement in the given code snippet?",
        "4e532210-4429-499d-905c-25a25cdb5bf7": "How does the code determine the number of learner bundles to create?",
        "6ecc286a-e3ec-4446-a067-841ea4760d06": "What are the three possible values for the \"storage_unit\" parameter in the initialization of the MultiAgentPrioritizedReplayBuffer class?",
        "33c51ae6-0d18-4c7f-a614-1a75f28566d0": "Explain the difference between the \"independent\" and \"lockstep\" modes in the \"replay_mode\" parameter of the MultiAgentPrioritizedReplayBuffer class.",
        "50e8341f-2185-4b17-814c-34697f2a6a3b": "Based on the context information provided, what is the average value of the second column?",
        "b781fdfc-66e3-4dd0-8d1f-3cd3bcc04bfc": "In the context information, what is the maximum value in the third column and at which row does it occur?",
        "4033192a-a712-4431-bc5d-519a084c64ac": "What is the purpose of resuming from a checkpoint in the training loop? How does it relate to the PBT scheduler?",
        "4979b8d8-2d30-45d4-acbc-99b7b39e149e": "How are the hyperparameters h0 and h1 used in the train_func() function?",
        "3212284f-1970-42b5-ae3b-cde2ea1ba92e": "What is the purpose of the `compress` method in the `MultiAgentBatch` class?",
        "20e50a48-9083-410c-a608-3d7123f69287": "How does the `compress` method in the `MultiAgentBatch` class differ when the `bulk` parameter is set to True versus False?",
        "c071d9a5-4cc7-44a0-844a-3b0977c3a75c": "What is the purpose of the \"LightningConfigBuilder\" class in the given source code?",
        "8cf7b988-6699-4996-9a99-881b58eac301": "Can you explain the role of the \"RayLightningEnvironment\" class in the code?",
        "f8db3b76-b245-4344-ae15-5865921b1b04": "What is the total number of models trained in the given context?",
        "91ce6a45-4764-4e69-9d31-3bfa8572191a": "Which model has the highest error rate and what is the corresponding location ID?",
        "dfd11724-dba7-46f7-813f-557298b23505": "What is the purpose of the \"Partitioning.base_dir\" parameter in the given context information?",
        "2627109e-c064-4039-97a4-e4fa189493cf": "How does specifying a base directory for partitioned paths affect the file paths considered as unpartitioned?",
        "05a8b384-f67e-477b-97d2-577a2c85d7df": "What is the purpose of the `forward` method in the `DummyModel` class?",
        "f2cbca7e-586b-42e5-8f50-fd08d34f4492": "How is the loss calculated in the `training_step` method of the `DummyModel` class?",
        "4902d4b1-c377-4100-b738-0adf275750bc": "What is the purpose of using the `force_list` function in the given code snippet?",
        "a9765b1d-c2d7-4e6c-9818-311c3d2e2f60": "How does iterating over `keys()` instead of `items()` in the `return` statement improve performance in the given code snippet?",
        "8d9a5fd5-d2dc-41ce-9d9c-cf26820567a3": "What is the purpose of the `extract()` function in the given code?",
        "31c77949-9d42-463d-bcf0-c34872abf958": "How does the `transform()` function calculate the total order value?",
        "c5829924-7da1-49d6-a1d9-8d8c0f81c9fa": "What is the purpose of the `load()` function in the given code?",
        "0837229c-ea75-4620-a9a6-8eb490bcba2a": "How is the `order_data` variable used in the workflow?",
        "f2ddf1f5-f0d2-4363-b7dc-3caea6ab38d6": "Can you explain the purpose of the `multiple_outputs=True` parameter in the `transform()` task?",
        "f42b9402-bb7d-4a8c-9079-e22b4865d17e": "How does the `load()` function display the total order value?",
        "dfd7d488-edae-417c-b9a9-4957c7f004e5": "What is the data type of the `order_data_dict` parameter in the `transform()` function?",
        "643d6143-92f1-471c-9900-0e1cdb1192e5": "How does the `json.loads()` function work in the given code?",
        "d3321424-8c86-4110-897e-7c6941dc15c7": "What is the expected output of the workflow when it is executed?",
        "53c33a5c-69d4-410b-9230-ee90dca843b7": "How would you modify the code to save the total order value to a file instead of printing it out?",
        "88086299-cd29-4b46-be2f-cc3f109a137b": "What is the purpose of the \"save_checkpoint\" function in the given code?",
        "58ef5825-34f2-4a9e-9a74-a3b5a0783988": "How does the code handle the scenario when the checkpoint is empty?",
        "09cdfd22-c4ae-43f8-8b1a-644df42d938b": "What is the purpose of the `tail_job_logs` function in the `JobSubmissionClient` class?",
        "d844b962-5cc3-4a83-a9cc-855ec167e46e": "How can the `tail_job_logs` function be used to retrieve and display the logs of a job?"
    },
    "corpus": {
        "afafd081-e18a-4ae9-9218-64b163416609": "ray.tune.ExperimentAnalysis.get_best_checkpoint#\n\n\nExperimentAnalysis.get_best_checkpoint(trial: ray.tune.experiment.trial.Trial, metric: Optional[str] = None, mode: Optional[str] = None, return_path: bool = False) \u2192 Optional[Union[ray.train._checkpoint.Checkpoint, str]][source]#\nGets best persistent checkpoint path of provided trial.\nAny checkpoints with an associated metric value of nan will be filtered out.\n\nParameters\n\ntrial \u2013 The log directory of a trial, or a trial instance.\nmetric \u2013 key of trial info to return, e.g. \u201cmean_accuracy\u201d.\n\u201ctraining_iteration\u201d is used by default if no value was\npassed to self.default_metric.\nmode \u2013 One of [min, max]. Defaults to self.default_mode.\nreturn_path \u2013 If True, only returns the path (and not the\nCheckpoint object). If using Ray client, it is not\nguaranteed that this path is available on the local\n(client) node. Can also contain a cloud URI.\n\n\nReturns\nCheckpoint object or string\nif return_path=True.",
        "07ff7c94-dee6-486e-bcaf-87aa2c8b8120": "def _best_trial_str(\n    trial: Trial,\n    metric: str,\n    parameter_columns: Optional[Union[List[str], Dict[str, str]]] = None,\n):\n    \"\"\"Returns a readable message stating the current best trial.\"\"\"\n    val = unflattened_lookup(metric, trial.last_result, default=None)\n    config = trial.last_result.get(\"config\", {})\n    parameter_columns = parameter_columns or list(config.keys())\n    if isinstance(parameter_columns, Mapping):\n        parameter_columns = parameter_columns.keys()\n    params = {p: unflattened_lookup(p, config) for p in parameter_columns}\n    return (\n        f\"Current best trial: {trial.trial_id} with {metric}={val} and \"\n        f\"parameters={params}\"\n    )\n\n\ndef _fair_filter_trials(\n    trials_by_state: Dict[str, List[Trial]],\n    max_trials: int,\n    sort_by_metric: bool = False,\n):\n    \"\"\"Filters trials such that each state is represented fairly.The oldest trials are truncated if necessary.Args:\n        trials_by_state: Maximum number of trials to return.Returns:\n        Dict mapping state to List of fairly represented trials.\n    \"\"\"num_trials_by_state = collections.defaultdict(int)\n    no_change = False\n    # Determine number of trials to keep per state.",
        "70b4df69-6aa3-493f-b8d1-93dc9e20850f": "Define the Deployment#\nOpen a new Python file called tutorial_batch.py. First, let\u2019s import Ray Serve and some other helpers.\nfrom typing import List\n\nfrom starlette.requests import Request\nfrom transformers import pipeline\n\nfrom ray import serve\n\n\nYou can use the @serve.batch decorator to annotate a function or a method.\nThis annotation will automatically cause calls to the function to be batched together.\nThe function must handle a list of objects and will be called with a single object.\nThis function must also be async def so that you can handle multiple queries concurrently:\n@serve.batch\nasync def my_batch_handler(self, requests: List):\n    pass\n\n\nThis batch handler can then be called from another async def method in your deployment.\nThese calls will be batched and executed together, but return an individual result as if\nthey were a normal function call:\nclass MyBackend:\n    @serve.batch\n    async def my_batch_handler(self, requests: List):\n        results = []\n        for request in requests:\n            results.append(request.json())\n        return results\n\n    async def __call__(self, request):\n        await self.my_batch_handler(request)",
        "94db4119-710b-400f-8f6c-5980d8aaac44": "Decentralized Distributed Proximal Policy Optimization (DD-PPO)#\n\n[paper]\n[implementation]\nUnlike APPO or PPO, with DD-PPO policy improvement is no longer done centralized in the algorithm process. Instead, gradients are computed remotely on each rollout worker and all-reduced at each mini-batch using torch distributed. This allows each worker\u2019s GPU to be used both for sampling and for training.\n\nTip\nDD-PPO is best for envs that require GPUs to function, or if you need to scale out SGD to multiple nodes. If you don\u2019t meet these requirements, standard PPO will be more efficient.\n\n\n\nDD-PPO architecture (both sampling and learning are done on worker GPUs)#\n\n\nTuned examples: CartPole-v1, BreakoutNoFrameskip-v4\nDDPPO-specific configs (see also common configs):\n\n\nclass ray.rllib.algorithms.ddppo.ddppo.DDPPOConfig(algo_class=None)[source]#\nDefines a configuration class from which a DDPPO Algorithm can be built.\nNote(jungong) : despite best efforts, DDPPO does not use fault tolerant and\nelastic features of WorkerSet, because of the way Torch DDP is set up.\nExample\n>>> from ray.rllib.algorithms.ddppo import DDPPOConfig\n>>> config = DDPPOConfig().training(lr=0.003, keep_local_weights_in_sync=True)\n>>> config = config.resources(num_gpus=1)\n>>> config = config.rollouts(num_rollout_workers=10)\n>>> print(config.to_dict())   \n>>> # Build a Algorithm object from the config and run 1 training iteration.\n>>> algo = config.build(env=\"CartPole-v1\")  \n>>> algo.train()",
        "3b56ca61-c572-4508-832b-612ec152db85": "**kwargs\n        ) -> None:\n            for callback in self._callback_list:\n                callback.on_learn_on_batch(\n                    policy=policy, train_batch=train_batch, result=result, **kwargs\n                )\n\n        @override(DefaultCallbacks)\n        def on_train_result(self, *, algorithm=None, result: dict, **kwargs) -> None:\n            for callback in self._callback_list:\n                callback.on_train_result(algorithm=algorithm, result=result, **kwargs)\n\n    return _MultiCallbacks\n\n\n# This Callback is used by the RE3 exploration strategy.# See rllib/examples/re3_exploration.py for details.class RE3UpdateCallbacks(DefaultCallbacks):\n    \"\"\"Update input callbacks to mutate batch with states entropy rewards.\"\"\"_step = 0\n\n    def __init__(\n        self,\n        *args,\n        embeds_dim: int = 128,\n        k_nn: int = 50,\n        beta: float = 0.1,\n        rho: float = 0.0001,\n        beta_schedule: str = \"constant\",\n        **kwargs,\n    ):\n        self.",
        "55dcedf8-3f5e-43ba-8ecb-ae7bab95f663": "theta = [theta0, theta1]\nThe model parameters that we will update in our training loop.\nNeural network parameters\n\nh = [h0, h1]\nThe hyperparameters that PBT will optimize.\nLearning rate, batch size, etc.\n\nQ(theta)\nThe quadratic function we are trying to maximize.\nGeneralization capability over all inputs\n\nQhat(theta | h)\nThe estimator we are given as our training objective, depends (|) on h.\nEmpirical loss/reward\n\n\n\nBelow are the implementations in code.\n\n\ndef Q(theta):\n    return 1.2 - (3/4 * theta[0] ** 2 + theta[1] ** 2)\n\ndef Qhat(theta, h):\n    return 1.2 - (h[0] * theta[0] ** 2 + h[1] * theta[1] ** 2)\n\ndef grad_Qhat(theta, h):\n    theta_grad = -2 * h * theta\n    theta_grad[0] *= 3/4\n    h_grad = -np.square(theta)\n    h_grad[0] *= 3/4\n    return {\"theta\": theta_grad, \"h\": h_grad}\n\ntheta_0 = get_init_theta()\nprint(\"Initial parameter values: theta = \", theta_0)\n\n\n\n\nInitial parameter values: theta =  [0.9 0.9]",
        "2466d669-55cb-40ad-9d99-cb55d8433a4c": "ray.rllib.utils.framework.try_import_tf#\n\n\nray.rllib.utils.framework.try_import_tf(error: bool = False)[source]#\nTries importing tf and returns the module (or None).\n\nParameters\nerror \u2013 Whether to raise an error if tf cannot be imported.\n\nReturns\nTuple containing\n1) tf1.x module (either from tf2.x.compat.v1 OR as tf1.x).\n2) tf module (resulting from import tensorflow). Either tf1.x or\n2.x. 3) The actually installed tf version as int: 1 or 2.\n\nRaises\nImportError \u2013 If error=True and tf is not installed.",
        "19592be9-6bd0-4ed2-8146-209428cbdd8f": "worker_launched_time_ms: Optional[int] = None#\nThe time worker is succesfully launched\n-1 if the value doesn\u2019t exist.\n\n\n\nstart_time_ms: Optional[int] = None#\nThe time when the worker is started and initialized.\n0 if the value doesn\u2019t exist.\n\n\n\nend_time_ms: Optional[int] = None#\nThe time when the worker exits. The timestamp could be delayed\nif the worker is dead unexpectedly.\n0 if the value doesn\u2019t exist.",
        "4e009c04-54f1-430e-a2aa-b420f46b4d0b": "Simplist: Setting up Grafana with Ray-provided configurations#\nGrafana is a tool that supports advanced visualizations of Prometheus metrics and allows you to create custom dashboards with your favorite metrics.\n\n\n\nCreating a new Grafana server\n\nNote\nThe instructions below describe one way of starting a Grafana server on a macOS machine. Refer to the Grafana documentation for how to start Grafana servers in different systems.\nFor KubeRay users, follow these instructions to set up Grafana.\n\nFirst, download Grafana. Follow the instructions on the download page to download the right binary for your operating system.\nGo to the location of the binary and run Grafana using the built-in configuration found in the /tmp/ray/session_latest/metrics/grafana folder.\n./bin/grafana-server --config /tmp/ray/session_latest/metrics/grafana/grafana.ini web\n\n\nAccess Grafana using the default grafana URL, http://localhost:3000.\nSee the default dashboard by going to dashboards -> manage -> Ray -> Default Dashboard. The same metric graphs are accessible in Ray Dashboard after you integrate Grafana with Ray Dashboard.\n\nNote\nIf this is your first time using Grafana, login with the username: admin and password admin.",
        "4b60bf0d-f007-4edd-b8f7-fcb861a46fb7": "MNIST PyTorch Trainable Example#\n# Original Code here:\n# https://github.com/pytorch/examples/blob/master/mnist/main.py\nfrom __future__ import print_function\n\nimport argparse\nimport os\nimport torch\nimport torch.optim as optim\n\nimport ray\nfrom ray import train, tune\nfrom ray.tune.schedulers import ASHAScheduler\nfrom ray.tune.examples.mnist_pytorch import (\n    train_func,\n    test_func,\n    get_data_loaders,\n    ConvNet,\n)\n\n# Change these values if you want the training to run quicker or slower.\nEPOCH_SIZE = 512\nTEST_SIZE = 256\n\n# Training settings\nparser = argparse.ArgumentParser(description=\"PyTorch MNIST Example\")\nparser.add_argument(\n    \"--use-gpu\", action=\"store_true\", default=False, help=\"enables CUDA training\"\n)\nparser.add_argument(\"--ray-address\", type=str, help=\"The Redis address of the cluster.\")\nparser.add_argument(\n    \"--smoke-test\", action=\"store_true\", help=\"Finish quickly for testing\"\n)\n\n\n# Below comments are for documentation purposes only.# fmt: off\n# __trainable_example_begin__\nclass TrainMNIST(tune.Trainable):\n    def setup(self, config):\n        use_cuda = config.get(\"use_gpu\") and torch.cuda.is_available()\n        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n        self.train_loader, self.test_loader = get_data_loaders()\n        self.",
        "43d7a6ba-3856-4d1d-aeec-e3af78a021fa": "Agent grouping is required to leverage algorithms such as Q-Mix.Args:\n            groups: Mapping from group id to a list of the agent ids\n                of group members.If an agent id is not present in any group\n                value, it will be left ungrouped.The group id becomes a new agent ID\n                in the final environment.obs_space: Optional observation space for the grouped\n                env.Must be a tuple space.If not provided, will infer this to be a\n                Tuple of n individual agents spaces (n=num agents in a group).act_space: Optional action space for the grouped env.Must be a tuple space.If not provided, will infer this to be a Tuple\n                of n individual agents spaces (n=num agents in a group).Examples:\n            >>> from ray.rllib.env.multi_agent_env import MultiAgentEnv\n            >>> class MyMultiAgentEnv(MultiAgentEnv): # doctest: +SKIP\n            .     # define your env here\n            .     . # doctest: +SKIP\n            >>> env = MyMultiAgentEnv(.) # doctest: +SKIP\n            >>> grouped_env = env.with_agent_groups(env, { # doctest: +SKIP\n            .",
        "418a8185-c50e-4544-8baf-d81870f10038": "ray.rllib.policy.torch_policy_v2.TorchPolicyV2.from_checkpoint#\n\n\nstatic TorchPolicyV2.from_checkpoint(checkpoint: Union[str, ray.air.checkpoint.Checkpoint], policy_ids: Optional[Container[str]] = None) \u2192 Union[ray.rllib.policy.policy.Policy, Dict[str, ray.rllib.policy.policy.Policy]]#\nCreates new Policy instance(s) from a given Policy or Algorithm checkpoint.\nNote: This method must remain backward compatible from 2.1.0 on, wrt.\ncheckpoints created with Ray 2.0.0 or later.\n\nParameters\n\ncheckpoint \u2013 The path (str) to a Policy or Algorithm checkpoint directory\nor an AIR Checkpoint (Policy or Algorithm) instance to restore\nfrom.\nIf checkpoint is a Policy checkpoint, policy_ids must be None\nand only the Policy in that checkpoint is restored and returned.\nIf checkpoint is an Algorithm checkpoint and policy_ids is None,\nwill return a list of all Policy objects found in\nthe checkpoint, otherwise a list of those policies in policy_ids.\npolicy_ids \u2013 List of policy IDs to extract from a given Algorithm checkpoint.\nIf None and an Algorithm checkpoint is provided, will restore all\npolicies found in that checkpoint. If a Policy checkpoint is given,\nthis arg must be None.\n\n\nReturns\nAn instantiated Policy, if checkpoint is a Policy checkpoint. A dict\nmapping PolicyID to Policies, if checkpoint is an Algorithm checkpoint.\nIn the latter case, returns all policies within the Algorithm if\npolicy_ids is None, else a dict of only those Policies that are in\npolicy_ids.",
        "064bc078-aae6-4ac3-a834-cbf4d2be3145": "ray.tune.schedulers.HyperBandScheduler.on_trial_result#\n\n\nHyperBandScheduler.on_trial_result(tune_controller: TuneController, trial: ray.tune.experiment.trial.Trial, result: Dict)[source]#\nIf bracket is finished, all trials will be stopped.\nIf a given trial finishes and bracket iteration is not done,\nthe trial will be paused and resources will be given up.\nThis scheduler will not start trials but will stop trials.\nThe current running trial will not be handled,\nas the trialrunner will be given control to handle it.",
        "5b508ede-3a92-41d4-9132-acc64f2bf716": "self._enable_record_actor_task_log = (\n            ray_constants.RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING\n        )\n        self._out_file = None\n        self._err_file = None\n        # Create the lock here because the serializer will use it before\n        # initializing Ray.self.lock = threading.RLock()\n        # By default, don't show logs from other drivers.This is set to true by Serve\n        # in order to stream logs from the controller and replica actors across\n        # different drivers that connect to the same Serve instance.# See https://github.com/ray-project/ray/pull/35070.self._filter_logs_by_job = True\n\n    @property\n    def connected(self):\n        \"\"\"bool: True if Ray has been started and False otherwise.\"\"\"return self.node is not None\n\n    @property\n    def node_ip_address(self):\n        self.check_connected()\n        return self.node.node_ip_address\n\n    @property\n    def load_code_from_local(self):\n        self.check_connected()\n        return self._load_code_from_local\n\n    @property\n    def current_job_id(self):\n        if hasattr(self, \"core_worker\"):\n            return self.core_worker.get_current_job_id()\n        return JobID.",
        "26221784-4e63-428f-a8d2-bf141b735daa": "Tensorflow/Keras Training Loop Utilities#\n\n\n\n\n\n\nprepare_dataset_shard(tf_dataset_shard)\nA utility function that overrides default config for Tensorflow Dataset.\n\n\n\n\n\n\n\n\n\nReportCheckpointCallback([checkpoint_on,\u00a0...])\nKeras callback for Ray AIR reporting and checkpointing.",
        "78c6f1f2-399e-42eb-a6dc-6513ff8a2fe0": "from_dict(\n            dict(epoch=epoch, model_weights=model.get_weights())\n        )\n        train.report({}, checkpoint=checkpoint)\n\ntrainer = TensorflowTrainer(\n    train_func,\n    train_loop_config={\"num_epochs\": 5},\n    scaling_config=ScalingConfig(num_workers=2),\n)\nresult = trainer.fit()\n\nprint(result.checkpoint.to_dict())\n# {'epoch': 4, 'model_weights': [array([[-0.31858477],\n#    [ 0.03747174],\n#    [ 0.28266194],\n#    [ 0.8626015 ]], dtype=float32), array([0.02230084], dtype=float32)], '_timestamp': 1656107383, '_preprocessor': None, '_current_checkpoint_id': 4}\n\n\nBy default, checkpoints will be persisted to local disk in the log\ndirectory of each run.",
        "27e5fc4a-aff7-4b08-8e18-af68f8facc8a": "ray.rllib.policy.sample_batch.SampleBatch.keys#\n\n\nSampleBatch.keys() \u2192 a set-like object providing a view on D's keys#",
        "74e6c400-210a-4681-973a-07929b2f8d80": "if hasattr(method, \"__ray_num_returns__\"):\n                self.num_returns[method_name] = method.__ray_num_returns__\n            else:\n                self.num_returns[\n                    method_name\n                ] = ray_constants.DEFAULT_ACTOR_METHOD_NUM_RETURN_VALS\n\n            if hasattr(method, \"__ray_invocation_decorator__\"):\n                self.decorators[method_name] = method.__ray_invocation_decorator__\n\n            if hasattr(method, \"__ray_concurrency_group__\"):\n                self.concurrency_group_for_methods[\n                    method_name\n                ] = method.__ray_concurrency_group__\n\n        # Update cache.cls._cache[actor_creation_function_descriptor] = self\n        return self\n\n\nclass _ActorClassMetadata:\n    \"\"\"Metadata for an actor class.Attributes:\n        language: The actor language, e.g.Python, Java.modified_class: The original class that was decorated (with some\n            additional methods added like __ray_terminate__).actor_creation_function_descriptor: The function descriptor for\n            the actor creation task.",
        "164c9798-7825-46ef-9845-b6eb36e62bd6": "config: Optional[Union[List[Dict], Dict]] = None,\n        size: int = 1,\n        random_state: \"RandomState\" = None,\n    ):\n        if not isinstance(random_state, _BackwardsCompatibleNumpyRng):\n            random_state = _BackwardsCompatibleNumpyRng(random_state)\n\n        if self.q == 1:\n            return self.sampler.sample(domain, config, size, random_state=random_state)\n\n        quantized_domain = copy(domain)\n        quantized_domain.lower = np.ceil(domain.lower / self.q) * self.q\n        quantized_domain.upper = np.floor(domain.upper / self.q) * self.q\n        values = self.sampler.sample(\n            quantized_domain, config, size, random_state=random_state\n        )\n        quantized = np.round(np.divide(values, self.q)) * self.q\n\n        if not isinstance(quantized, np.ndarray):\n            return domain.cast(quantized)\n        return list(quantized)\n\n\n[docs]@PublicAPI\ndef sample_from(func: Callable[[Dict], Any]):\n    \"\"\"Specify that tune should sample configuration values from this function.\n\n    Arguments:\n        func: An callable function to draw a sample from.\n    \"\"\"\n    return Function(func)",
        "c63e0fd1-30a6-4206-a1da-092878027fae": "ray.rllib.core.rl_module.marl_module.MultiAgentRLModule.remove_module#\n\n\nMultiAgentRLModule.remove_module(module_id: str, *, raise_err_if_not_found: bool = True) \u2192 None[source]#\nRemoves a module at run time from the multi-agent module.\n\nParameters\n\nmodule_id \u2013 The module ID to remove.\nraise_err_if_not_found \u2013 Whether to raise an error if the module ID is not\nfound.\n\n\nRaises\nValueError \u2013 If the module ID does not exist and raise_err_if_not_found is\n    True.",
        "c4145c2d-808f-45e4-9fb9-9e1bb856cc1d": "scheduling_strategy_large_args=(\n                        DEFAULT_SCHEDULING_STRATEGY_LARGE_ARGS\n                    ),\n                    large_args_threshold=DEFAULT_LARGE_ARGS_THRESHOLD,\n                    use_polars=DEFAULT_USE_POLARS,\n                    new_execution_backend=DEFAULT_NEW_EXECUTION_BACKEND,\n                    use_streaming_executor=DEFAULT_USE_STREAMING_EXECUTOR,\n                    eager_free=DEFAULT_EAGER_FREE,\n                    decoding_size_estimation=DEFAULT_DECODING_SIZE_ESTIMATION_ENABLED,\n                    min_parallelism=DEFAULT_MIN_PARALLELISM,\n                    enable_tensor_extension_casting=(\n                        DEFAULT_ENABLE_TENSOR_EXTENSION_CASTING\n                    ),",
        "3d421d77-eda3-4a13-a527-10afafacd667": "ray.data.datasource.Partitioning.normalized_base_dir#\n\n\nproperty Partitioning.normalized_base_dir: str#\nReturns the base directory normalized for compatibility with a filesystem.",
        "7f818411-0907-4a6a-ba56-d06285725bcb": "clip_actions=self.config.clip_actions,\n                observation_fn=self.config.observation_fn,\n                sample_collector_class=self.config.sample_collector,\n                render=render,\n            )\n\n        self.input_reader: InputReader = self._get_input_creator_from_config()(\n            self.io_context\n        )\n        self.output_writer: OutputWriter = self._get_output_creator_from_config()(\n            self.io_context\n        )\n\n        # The current weights sequence number (version).May remain None for when\n        # not tracking weights versions.",
        "2b6d1a36-e1d6-4b7d-81e0-8faade7a77b2": "Note that if a column is in both include and exclude, the column is\nexcluded.\n>>> concatenator = Concatenator(include=[\"X0\", \"X1\", \"Y\"], exclude=[\"Y\"])\n>>> concatenator.fit_transform(ds).to_pandas()  \n        Y  concat_out\n0    blue  [0.0, 0.5]\n1  orange  [3.0, 0.2]\n2    blue  [1.0, 0.9]\n\n\nBy default, the concatenated tensor is a dtype common to the input columns.\nHowever, you can also explicitly set the dtype with the dtype\nparameter.\n>>> concatenator = Concatenator(include=[\"X0\", \"X1\"], dtype=np.float32)\n>>> concatenator.fit_transform(ds)  \nDataset(num_blocks=1, num_rows=3, schema={Y: object, concat_out: TensorDtype(shape=(2,), dtype=float32)})\n\n\n\nParameters\n\noutput_column_name \u2013 The desired name for the new column.\nDefaults to \"concat_out\".\ninclude \u2013 A list of columns to concatenate. If None, all columns are\nconcatenated.\nexclude \u2013 A list of column to exclude from concatenation.\nIf a column is in both include and exclude, the column is excluded\nfrom concatenation.\ndtype \u2013 The dtype to convert the output tensors to. If unspecified,\nthe dtype is determined by standard coercion rules.\nraise_if_missing \u2013 If True, an error is raised if any\nof the columns in include or exclude don\u2019t exist.\nDefaults to False.\n\n\nRaises\nValueError \u2013 if raise_if_missing is True and a column in include or\n    exclude doesn\u2019t exist in the dataset.",
        "a0db1f91-70d7-47e3-95b2-bd274b810e1a": "\" Policy IDs that are already in your policy map: \"\n                f\"{list(self.local_worker().policy_map.keys())}\"\n            )\n\n        if workers is not DEPRECATED_VALUE:\n            deprecation_warning(\n                old=\"WorkerSet.add_policy(.., workers=..)\",\n                help=(\n                    \"The `workers` argument to `WorkerSet.add_policy()` is deprecated! \"\"Please do not use it anymore.\"),\n                error=True,\n            )\n\n        if (policy_cls is None) == (policy is None):\n            raise ValueError(\n                \"Only one of `policy_cls` or `policy` must be provided to \"\n                \"staticmethod: `WorkerSet.add_policy()`!\")\n        validate_policy_id(policy_id, error=False)\n\n        # Policy instance not provided: Use the information given here.",
        "61500051-fda4-4c34-9e56-e29f8d1eec40": "ray.data.preprocessors.UniformKBinsDiscretizer.serialize#\n\n\nUniformKBinsDiscretizer.serialize() \u2192 str#\nReturn this preprocessor serialized as a string.\nNote: this is not a stable serialization format as it uses pickle.\nDeveloperAPI: This API may change across minor Ray releases.",
        "b7cfc9b5-cf6c-4cba-a730-de2cd2e6c35b": "ray.tune.schedulers.HyperBandScheduler.on_trial_complete#\n\n\nHyperBandScheduler.on_trial_complete(tune_controller: TuneController, trial: ray.tune.experiment.trial.Trial, result: Dict)[source]#\nCleans up trial info from bracket if trial completed early.",
        "336cd42f-f859-438e-ac28-df3c4e4a0a0d": ")\n                else:\n                    policy_spec = (\n                        PolicySpec.deserialize(spec)\n                        if connector_enabled or isinstance(spec, dict)\n                        else spec\n                    )\n                    self.add_policy(\n                        policy_id=pid,\n                        policy_cls=policy_spec.policy_class,\n                        observation_space=policy_spec.observation_space,\n                        action_space=policy_spec.action_space,\n                        config=policy_spec.config,\n                    )\n            if pid in self.policy_map:\n                self.policy_map[pid].set_state(policy_state)\n\n        # Also restore mapping fn and which policies to train.",
        "459025f0-345e-4b7b-98f0-f70b394659e5": "Full configuration#\n\n\n\nAWS\n# An unique identifier for the head node and workers of this cluster.cluster_name: default\n\n# The maximum number of workers nodes to launch in addition to the head\n# node.max_workers: 2\n\n# The autoscaler will scale up the cluster faster with higher upscaling speed.# E.g., if the task requires adding more nodes then autoscaler will gradually\n# scale up the cluster in chunks of upscaling_speed*currently_running_nodes.# This number should be > 0.\nupscaling_speed: 1.0\n\n# This executes all commands on all nodes in the docker container,\n# and opens all the necessary ports to support the Ray cluster.# Empty string means disabled.docker:\n    image: \"rayproject/ray-ml:latest-gpu\" # You can change this to latest-cpu if you don't need GPU support and want a faster startup\n    # image: rayproject/ray:latest-cpu   # use this one if you don't need ML dependencies, it's faster to pull\n    container_name: \"ray_container\"\n    # If true, pulls latest version of image.Otherwise, `docker run` will only pull the image\n    # if no cached version is present.pull_before_run: True\n    run_options:   # Extra options to pass into \"docker run\"\n        - --ulimit nofile=65536:65536\n\n    # Example of running a GPU head with CPU workers\n    # head_image: \"rayproject/ray-ml:latest-gpu\"\n    # Allow Ray to automatically detect GPUs\n\n    # worker_image: \"rayproject/ray-ml:latest-cpu\"\n    # worker_run_options: []\n\n# If a node is idle for this many minutes, it will be removed.idle_timeout_minutes: 5\n\n# Cloud-provider specific configuration.",
        "390a0173-2b51-4b67-9b85-6b98f487f73d": "_filename = filename\n        self._frequency = frequency\n        self._results_postprocessing_fn = results_postprocessing_fn\n\n    def _get_report_dict(self, evals_log):\n        if isinstance(evals_log, OrderedDict):\n            # xgboost>=1.3\n            result_dict = flatten_dict(evals_log, delimiter=\"-\")\n            for k in list(result_dict):\n                result_dict[k] = result_dict[k][-1]\n        else:\n            # xgboost<1.3\n            result_dict = dict(evals_log)\n        if not self._metrics:\n            report_dict = result_dict\n        else:\n            report_dict = {}\n            for key in self._metrics:\n                if isinstance(self._metrics, dict):\n                    metric = self.",
        "b5fbde7b-13c2-41c5-953b-83ed0093dd52": "loss)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        labels = batch[\"label\"]\n        logits = self.forward(batch)\n        preds = torch.argmax(logits, dim=1)\n        self.predictions.append(preds)\n        self.references.append(labels)\n\n    def on_validation_epoch_end(self):\n        predictions = torch.concat(self.predictions).view(-1)\n        references = torch.concat(self.references).view(-1)\n        matthews_correlation = self.metric.compute(\n            predictions=predictions, references=references\n        )\n\n        # self.metric.compute() returns a dictionary:\n        # e.g.{\"matthews_correlation\": 0.53}\n        self.log_dict(matthews_correlation, sync_dist=True)\n        self.predictions.clear()\n        self.references.clear()\n\n    def configure_optimizers(self):\n        return torch.optim.AdamW(self.parameters(), lr=self.lr, eps=self.eps)",
        "5c186583-ccf7-405d-9489-fa83f23cd437": "PrioritizedReplayBuffer method)\n\n(ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer method)\n\n(ray.rllib.utils.replay_buffers.reservoir_replay_buffer.ReservoirReplayBuffer method)\n\n(ray.rllib.utils.schedules.constant_schedule.ConstantSchedule method)\n\n(ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule method)\n\n(ray.rllib.utils.schedules.linear_schedule.LinearSchedule method)\n\n(ray.rllib.utils.schedules.piecewise_schedule.PiecewiseSchedule method)\n\n(ray.rllib.utils.schedules.polynomial_schedule.PolynomialSchedule method)\n\n(ray.train.Checkpoint method)\n\n(ray.train.context.TrainContext method)\n\n(ray.train.DataConfig method)\n\n(ray.train.huggingface.transformers.RayTrainReportCallback method)\n\n(ray.train.huggingface.TransformersCheckpoint method)\n\n(ray.train.lightgbm.LightGBMCheckpoint method)\n\n(ray.train.lightning.LightningCheckpoint method)\n\n(ray.train.lightning.LightningConfigBuilder method)\n\n(ray.train.lightning.RayDeepSpeedStrategy method)\n\n(ray.train.lightning.RayFSDPStrategy method)\n\n(ray.train.tensorflow.TensorflowCheckpoint method)\n\n(ray.train.torch.TorchCheckpoint method)\n\n(ray.train.xgboost.XGBoostCheckpoint method)\n\n(ray.tune.Callback method)\n\n(ray.tune.logger.aim.AimLoggerCallback method)\n\n(ray.tune.logger.LoggerCallback method)\n\n(ray.tune.",
        "d3758d36-9db3-4f62-a3d8-5f5a549e3072": "[docs]@Deprecated\nclass TuneReportCallback(TuneReportCheckpointCallback):\n    def __init__(\n        self,\n        metrics: Optional[Union[str, List[str], Dict[str, str]]] = None,\n        results_postprocessing_fn: Optional[\n            Callable[[Dict[str, Union[float, List[float]]]], Dict[str, float]]\n        ] = None,\n    ):\n        if log_once(\"tune_lightgbm_report_deprecated\"):\n            warnings.warn(\n                \"`ray.tune.integration.lightgbm.TuneReportCallback` is deprecated. \"\n                \"Use `ray.tune.integration.lightgbm.TuneCheckpointReportCallback` \"\n                \"instead.\"\n            )\n        super().__init__(\n            metrics=metrics,\n            results_postprocessing_fn=results_postprocessing_fn,\n            frequency=0,\n        )",
        "3a0dae48-f8e9-437b-af84-43523171541b": "Source code for ray.serve.http_adapters\nfrom io import BytesIO\nfrom typing import Any, Dict, List, Optional, Union\n\nfrom fastapi import File, Request\nfrom pydantic import BaseModel, Field\nimport numpy as np\nimport starlette.requests\n\nfrom ray.util.annotations import PublicAPI\nfrom ray.serve._private.utils import require_packages\n\n\n_1DArray = List[float]\n_2DArray = List[List[float]]\n_3DArray = List[List[List[float]]]\n_4DArray = List[List[List[List[float]]]]",
        "f6bd0ee7-968c-430f-8d21-e18a82f0143b": "tower_outputs = self._multi_gpu_parallel_grad_calc([postprocessed_batch])\n\n        all_grads, grad_info = tower_outputs[0]\n\n        grad_info[\"allreduce_latency\"] /= len(self._optimizers)\n        grad_info.update(self.stats_fn(postprocessed_batch))\n\n        fetches = self.extra_compute_grad_fetches()\n\n        return all_grads, dict(fetches, **{LEARNER_STATS_KEY: grad_info})\n\n    @override(Policy)\n    @DeveloperAPI\n    def apply_gradients(self, gradients: ModelGradients) -> None:\n        if gradients == _directStepOptimizerSingleton:\n            for i, opt in enumerate(self._optimizers):\n                opt.step()\n        else:\n            # TODO(sven): Not supported for multiple optimizers yet.",
        "a4ce8f16-04ce-416c-8c1d-439f6c81114e": "Synchronizing tasks are usually asynchronous and can be awaited using ``wait()``.The base class implements a ``wait_or_retry()`` API that will retry a failed\n    sync command.The base class also exposes an API to only kick off syncs every ``sync_period``\n    seconds.Args:\n        sync_period: The minimum time in seconds between sync operations, as\n            used by ``sync_up/down_if_needed``.sync_timeout: The maximum time to wait for a sync process to finish before\n            issuing a new sync operation.Ex: should be used by ``wait`` if launching\n            asynchronous sync tasks.\n    \"\"\"def __init__(\n        self,\n        sync_period: float = DEFAULT_SYNC_PERIOD,\n        sync_timeout: float = DEFAULT_SYNC_TIMEOUT,\n    ):\n        self.sync_period = sync_period\n        self.sync_timeout = sync_timeout\n        self.last_sync_up_time = float(\"-inf\")\n        self.last_sync_down_time = float(\"-inf\")\n\n    @abc.abstractmethod\n    def sync_up(\n        self, local_dir: str, remote_dir: str, exclude: Optional[List] = None\n    ) -> bool:\n        \"\"\"Synchronize local directory to remote directory.This function can spawn an asynchronous process that can be awaited in\n        ``wait()``.Args:\n            local_dir: Local directory to sync from.remote_dir: Remote directory to sync up to.",
        "e5cfa1d0-2906-4d4f-9a75-f02b64bf13ce": "(see https://github.com/ray-project/ray/pull/32477#discussion_r1106776101)\n    \"\"\"\n\n[docs]    def __init__(\n        self,\n        capacity: int = 10000,\n        storage_unit: Union[str, StorageUnit] = \"timesteps\",\n        **kwargs,\n    ):\n        \"\"\"Initializes a (FIFO) ReplayBuffer instance.Args:\n            capacity: Max number of timesteps to store in this FIFO\n                buffer.After reaching this number, older samples will be\n                dropped to make space for new ones.storage_unit: If not a StorageUnit, either 'timesteps', 'sequences' or\n                'episodes'.Specifies how experiences are stored.``**kwargs``: Forward compatibility kwargs.\n        \"\"\"",
        "b2fa9cd8-c3b8-4cee-8d90-a4a9f4a8298c": "Deploying a Serve application#\nWhen the RayService is created, the KubeRay controller first creates a Ray cluster using the provided configuration.\nThen, once the cluster is running, it deploys the Serve application to the cluster using the REST API.\nThe controller also creates a Kubernetes Service that can be used to route traffic to the Serve application.\nLet\u2019s see this in action by deploying the FruitStand example.\nThe Serve config for the example is embedded into this example RayService CR.\nTo follow along, save this CR locally in a file named ray_v1alpha1_rayservice.yaml:\n\nNote\n\nThe example RayService uses very low numCpus values for demonstration purposes. In production, provide more resources to the Serve application.\nLearn more about how to configure KubeRay clusters here.\nIf you have dependencies that must be installed during deployment, you can add them to the runtime_env in the Deployment code. Learn more here\n\n\n$ curl -o ray_v1alpha1_rayservice.yaml https://raw.githubusercontent.com/ray-project/kuberay/release-0.5/ray-operator/config/samples/ray_v1alpha1_rayservice.yaml\n\n\nTo deploy the example, we simply kubectl apply the CR.This creates the underlying Ray cluster, consisting of a head and worker node pod (see Ray Clusters Key Concepts for more details on Ray clusters), as well as the service that can be used to query our application:\n$ kubectl apply -f ray_v1alpha1_rayservice.",
        "aafc0c54-4287-406a-957d-c9c87790ca6d": ">>> ds = ray.data.read_json(\"s3://anonymous@ray-example-data/train.jsonl\")\n        >>> ds.schema()\n        Column  Type\n        ------  ----\n        input   string\n\n        Read multiple local files.>>> ray.data.read_json( # doctest: +SKIP\n        ...    [\"local:///path/to/file1\", \"local:///path/to/file2\"])\n\n        Read multiple directories.>>> ray.data.read_json( # doctest: +SKIP\n        ...     [\"s3://bucket/path1\", \"s3://bucket/path2\"])\n\n        By default, :meth:`~ray.data.read_json` parses\n        `Hive-style partitions <https://athena.guide/articles/\\\n        hive-style-partitioning/>`_\n        from file paths.If your data adheres to a different partitioning scheme, set\n        the ``partitioning`` parameter.>>> ds = ray.data.read_json(\"s3://anonymous@ray-example-data/year=2022/month=09/sales.json\")\n        >>> ds.take(1)\n        [{'order_number': 10107, 'quantity': 30, 'year': '2022', 'month': '09'}]\n\n    Args:\n        paths: A single file or directory, or a list of file or directory paths.A list of paths can contain both files and directories.filesystem: The PyArrow filesystem\n            implementation to read from.",
        "f9549c15-e758-4114-a0e6-8503a21f329a": "Fault Tolerance#\nBy default, Ray actors won\u2019t be restarted and\nactor tasks won\u2019t be retried when actors crash unexpectedly.\nYou can change this behavior by setting\nmax_restarts and max_task_retries options\nin ray.remote() and .options().\nSee Ray fault tolerance for more details.",
        "333e0551-340e-40fa-8d47-415910e7dc69": "67109203338623\n  time_this_iter_s: 0.1058969497680664\n  time_total_s: 10.67109203338623\n  timestamp: 1658499825\n  timesteps_since_restore: 0\n  training_iteration: 100\n  trial_id: dd4b4e94\n  warmup_time: 0.003142118453979492\n  \nResult for objective_dd487b56:\n  date: 2022-07-22_15-23-45\n  done: true\n  experiment_id: 75e118a5733e454fab54f4a20c036852\n  experiment_tag: 6_activation=relu,height=-25.9818,steps=100,width=0.7585\n  hostname: Kais-MacBook-Pro.local\n  iterations: 99\n  iterations_since_restore: 100\n  mean_loss: 8.577028987245935\n  neg_mean_loss: -8.577028987245935\n  node_ip: 127.0.0.1\n  pid: 46322\n  time_since_restore: 10.691627979278564\n  time_this_iter_s: 0.10821914672851562\n  time_total_s: 10.691627979278564\n  timestamp: 1658499825\n  timesteps_since_restore: 0\n  training_iteration: 100\n  trial_id: dd487b56\n  warmup_time: 0.0028679370880126953\n  \nResult for objective_dd5a8bca:\n  date: 2022-07-22_15-23-45\n  done: true\n  experiment_id: 775683e6d95a4705846a37e809b474d7\n  experiment_tag: 8_activation=tanh,height=5.2213,",
        "abd6134f-bc09-4374-a567-da8c9fc526cd": "self.model._curiosity_feature_net = self._curiosity_feature_net.to(\n                self.device\n            )\n            self.model._curiosity_inverse_fcnet = self._curiosity_inverse_fcnet.to(\n                self.device\n            )\n            self.model._curiosity_forward_fcnet = self._curiosity_forward_fcnet.to(\n                self.device\n            )\n            self._optimizer = torch.optim.Adam(\n                forward_params + inverse_params + feature_params, lr=self.lr\n            )\n        else:\n            self.model._curiosity_feature_net = self._curiosity_feature_net\n            self.model._curiosity_inverse_fcnet = self._curiosity_inverse_fcnet\n            self.model._curiosity_forward_fcnet = self._curiosity_forward_fcnet\n            # Feature net is a RLlib ModelV2, the other 2 are keras Models.",
        "be43b656-9c5e-4731-b550-07a5ea39026a": "PUT \"/api/serve/deployments/\"#\nDeclaratively deploys the Serve application. Starts Serve on the Ray cluster if it\u2019s not already running. See single-app config schema for the request\u2019s JSON schema.\nExample Request:\nPUT /api/serve/deployments/ HTTP/1.1\nHost: http://localhost:52365/\nAccept: application/json\nContent-Type: application/json\n\n{\n    \"import_path\": \"fruit.deployment_graph\",\n    \"runtime_env\": {\n        \"working_dir\": \"https://github.com/ray-project/serve_config_examples/archive/HEAD.zip\"\n    },\n    \"deployments\": [\n        {\"name\": \"MangoStand\", \"user_config\": {\"price\": 1}},\n        {\"name\": \"OrangeStand\", \"user_config\": {\"price\": 2}},\n        {\"name\": \"PearStand\", \"user_config\": {\"price\": 3}}\n    ]\n}\n\n\nExample Response\nHTTP/1.1 200 OK\nContent-Type: application/json",
        "4e2b5a79-f462-405b-9184-6130f2dc0cd9": "Making models#",
        "058a937d-dc64-4577-b95a-57650694db95": "Source code for ray.train.tensorflow.config\nimport json\nimport logging\nimport os\nfrom dataclasses import dataclass\nfrom typing import List\n\nimport ray\nfrom ray.air.checkpoint import Checkpoint\nfrom ray.train.backend import BackendConfig, Backend, _warn_about_bad_checkpoint_type\nfrom ray.train._internal.storage import _use_storage_context\nfrom ray.train._internal.utils import get_address_and_port\nfrom ray.train._internal.worker_group import WorkerGroup\nfrom ray.train.tensorflow.tensorflow_checkpoint import LegacyTensorflowCheckpoint\nfrom ray.util import PublicAPI\n\n\nlogger = logging.getLogger(__name__)\n\n\n[docs]@PublicAPI(stability=\"beta\")\n@dataclass\nclass TensorflowConfig(BackendConfig):\n    @property\n    def backend_cls(self):\n        return _TensorflowBackend\n\n\ndef _setup_tensorflow_environment(worker_addresses: List[str], index: int):\n    \"\"\"Set up distributed Tensorflow training information.\n\n    This function should be called on each worker.\n\n    Args:\n        worker_addresses: Addresses of all the workers.\n        index: Index (i.e. world rank) of the current worker.\n    \"\"\"\n    tf_config = {\n        \"cluster\": {\"worker\": worker_addresses},\n        \"task\": {\"type\": \"worker\", \"index\": index},\n    }\n    os.environ[\"TF_CONFIG\"] = json.dumps(tf_config)\n\n\nclass _TensorflowBackend(Backend):\n    def on_start(self, worker_group: WorkerGroup, backend_config: TensorflowConfig):\n        # Compute URL for initializing distributed setup.",
        "bdfe4035-f413-444f-bfe7-bd4f723a0f21": "BaseEnv API#",
        "0cfb4e15-8a0c-4a4c-bc3d-d695fa73f732": "ray.train.huggingface.transformers.prepare_trainer#\n\n\nray.train.huggingface.transformers.prepare_trainer(trainer: transformers.trainer.Trainer) \u2192 transformers.trainer.Trainer[source]#\nPrepare your HuggingFace Transformer Trainer for Ray Train.\nThis utility function enable the trainer integrates with Ray Data Integration.\nInternally, it overrides the get_train_dataloader and get_eval_dataloader\nmethods and inject the data integration logics if the train_dataset and\neval_dataset are Ray Data Iterables.\nPublicAPI (alpha): This API is in alpha and may change before becoming stable.",
        "0293545e-8a78-431e-9529-ca62ab2f1d44": "[docs]class Catalog:\n    \"\"\"Describes the sub-module-architectures to be used in RLModules.\n\n    RLlib's native RLModules get their Models from a Catalog object.\n    By default, that Catalog builds the configs it has as attributes.\n    This component was build to be hackable and extensible. You can inject custom\n    components into RL Modules by overriding the `build_xxx` methods of this class.\n    Note that it is recommended to write a custom RL Module for a single use-case.\n    Modifications to Catalogs mostly make sense if you want to reuse the same\n    Catalog for different RL Modules. For example if you have written a custom\n    encoder and want to inject it into different RL Modules (e.g. for PPO, DQN, etc.).\n    You can influence the decision tree that determines the sub-components by modifying\n    `Catalog._determine_components_hook`.\n\n    Usage example:\n\n    # Define a custom catalog\n\n    .. testcode::\n\n        import torch\n        import gymnasium as gym\n        from ray.rllib.core.models.configs import MLPHeadConfig\n        from ray.rllib.core.models.catalog import Catalog\n\n\n        class MyCatalog(Catalog):\n            def __init__(\n                self,\n                observation_space: gym.Space,\n                action_space: gym.Space,\n                model_config_dict: dict,",
        "948789f1-851b-4114-928e-f286c3a649cd": "ray monitor#\nTails the autoscaler logs of a Ray cluster.\nray monitor [OPTIONS] CLUSTER_CONFIG_FILE\n\n\nOptions\n\n\n--lines <lines>#\nNumber of lines to tail.\n\n\n\n-n, --cluster-name <cluster_name>#\nOverride the configured cluster name.\n\n\n\n--log-style <log_style>#\nIf \u2018pretty\u2019, outputs with formatting and color. If \u2018record\u2019, outputs record-style without formatting. \u2018auto\u2019 defaults to \u2018pretty\u2019, and disables pretty logging if stdin is not a TTY.\n\nOptions\nauto | record | pretty\n\n\n\n\n\n--log-color <log_color>#\nUse color logging. Auto enables color logging if stdout is a TTY.\n\nOptions\nauto | false | true\n\n\n\n\n\n-v, --verbose#\n\nArguments\n\n\nCLUSTER_CONFIG_FILE#\nRequired argument",
        "e7a3ef39-d32c-4449-9d46-f66ca83892a6": "num-gpus#\nThis field specifies the number of GPUs available to the Ray container.\nIn future KubeRay versions, the number of GPUs will be auto-detected from Ray container resource limits.\nNote that the values of all Ray start parameters, including num-gpus,\nmust be supplied as strings.",
        "a98d61b7-3bd8-4eb4-aeeb-5bfb8cd66cc4": "Population Based Bandits (PB2) (tune.schedulers.pb2.PB2)#\nTune includes a distributed implementation of Population Based Bandits (PB2).\nThis algorithm builds upon PBT, with the main difference being that instead of using random perturbations,\nPB2 selects new hyperparameter configurations using a Gaussian Process model.\nThe Tune implementation of PB2 requires GPy and sklearn to be installed:\npip install GPy sklearn\n\n\nPB2 can be enabled by setting the scheduler parameter of tune.TuneConfig which is taken in by Tuner, e.g.:\nfrom ray.tune.schedulers.pb2 import PB2\n\npb2_scheduler = PB2(\n    time_attr='time_total_s',\n    metric='mean_accuracy',\n    mode='max',\n    perturbation_interval=600.0,\n    hyperparam_bounds={\n        \"lr\": [1e-3, 1e-5],\n        \"alpha\": [0.0, 1.0],\n    ...\n    }\n)\ntuner = tune.Tuner( ... , tune_config=tune.TuneConfig(scheduler=pb2_scheduler))\nresults = tuner.fit()",
        "73896d27-c596-4a2a-b254-4bc12fa07afd": "Deploy Multiple Applications#\nIn Ray 2.4+, deploying multiple independent Serve applications is supported. This user guide walks through how to generate a multi-application config file and deploy it using the Serve CLI, and monitor your applications using the CLI and the Ray Serve dashboard.",
        "7ed0ad0d-0a25-4d74-8d80-32e1a4c7725c": "view_reqs = self._get_default_view_requirements()\n        if not hasattr(self, \"view_requirements\"):\n            self.view_requirements = view_reqs\n        else:\n            for k, v in view_reqs.items():\n                if k not in self.view_requirements:\n                    self.view_requirements[k] = v\n\n[docs]    def get_connector_metrics(self) -> Dict:\n        \"\"\"Get metrics on timing from connectors.\"\"\"return {\n            \"agent_connectors\": {\n                name + \"_ms\": 1000 * timer.mean\n                for name, timer in self.agent_connectors.timers.items()\n            },\n            \"action_connectors\": {\n                name + \"_ms\": 1000 * timer.mean\n                for name, timer in self.agent_connectors.timers.items()\n            },\n        }\n\n[docs]    def reset_connectors(self, env_id) -> None:\n        \"\"\"Reset action- and agent-connectors for this policy.\"\"\"",
        "83de2df4-012f-4fd0-afe7-c7d4c7a3d9d6": "self.obs_space: Space = obs_space\n        self.action_space: Space = action_space\n        self.num_outputs: int = num_outputs\n        self.model_config: ModelConfigDict = model_config\n        self.name: str = name or \"default_model\"\n        self.framework: str = framework\n        self._last_output = None\n        self.time_major = self.model_config.get(\"_time_major\")\n        # Basic view requirement for all models: Use the observation as input.self.view_requirements = {\n            SampleBatch.OBS: ViewRequirement(shift=0, space=self.obs_space),\n        }\n\n    # TODO: (sven): Get rid of `get_initial_state` once Trajectory\n    #  View API is supported across all of RLlib.[docs]    @PublicAPI\n    def get_initial_state(self) -> List[TensorType]:\n        \"\"\"Get the initial recurrent state values for the model.Returns:\n            List of np.array (for tf) or Tensor (for torch) objects containing the\n            initial hidden state of an RNN, if applicable.",
        "5516e3a2-5397-4f66-a6cb-082f819abd1c": "ray.rllib.utils.exploration.exploration.Exploration#\n\n\nclass ray.rllib.utils.exploration.exploration.Exploration(action_space: <MagicMock name='mock.Space' id='140123239748224'>, *, framework: str, policy_config: dict, model: ray.rllib.models.modelv2.ModelV2, num_workers: int, worker_index: int)[source]#\nBases: object\nImplements an exploration strategy for Policies.\nAn Exploration takes model outputs, a distribution, and a timestep from\nthe agent and computes an action to apply to the environment using an\nimplemented exploration schema.\nMethods\n\n\n\n\n\n\n__init__(action_space,\u00a0*,\u00a0framework,\u00a0...)\n\nparam action_space\nThe action space in which to explore.\n\n\n\n\nbefore_compute_actions(*[,\u00a0timestep,\u00a0...])\nHook for preparations before policy.compute_actions() is called.\n\nget_exploration_action(*,\u00a0...[,\u00a0explore])\nReturns a (possibly) exploratory action and its log-likelihood.\n\nget_exploration_optimizer(optimizers)\nMay add optimizer(s) to the Policy's own optimizers.\n\nget_state([sess])\nReturns the current exploration state.\n\non_episode_end(policy,\u00a0*[,\u00a0environment,\u00a0...])\nHandles necessary exploration logic at the end of an episode.\n\non_episode_start(policy,\u00a0*[,\u00a0environment,\u00a0...])\nHandles necessary exploration logic at the beginning of an episode.\n\npostprocess_trajectory(policy,\u00a0sample_batch)\nHandles post-processing of done episode trajectories.\n\nset_state(state[,\u00a0sess])\nSets the Exploration object's state to the given values.",
        "d3e95b1c-da2c-47c2-83e1-0d306465791f": "Start Ray with the Ray cluster launcher#\nOnce Boto3 is configured to manage resources in your AWS account, you should be ready to launch your cluster using the cluster launcher. The provided cluster config file will create a small cluster with an m5.large head node (on-demand) configured to autoscale to up to two m5.large spot-instance workers.\nTest that it works by running the following commands from your local machine:\n# Download the example-full.yaml\nwget https://raw.githubusercontent.com/ray-project/ray/master/python/ray/autoscaler/aws/example-full.yaml\n\n# Create or update the cluster. When the command finishes, it will print\n# out the command that can be used to SSH into the cluster head node.\nray up example-full.yaml\n\n# Get a remote shell on the head node.\nray attach example-full.yaml\n\n# Try running a Ray program.\npython -c 'import ray; ray.init()'\nexit\n\n# Tear down the cluster.\nray down example-full.yaml\n\n\nCongrats, you have started a Ray cluster on AWS!\nIf you want to learn more about the Ray cluster launcher, see this blog post for a step by step guide.",
        "b6a6f5cf-cba3-4648-94a7-a0a91c6eb817": "More about Ray Scheduling#\n\n\nResources\nGPU Support\nPlacement Groups\nMemory Management\nOut-Of-Memory Prevention",
        "5b364331-5587-41f1-8da1-138426ad1069": "raise NotImplementedError\n\n[docs]    def on_trial_error(self, tune_controller: \"TuneController\", trial: Trial):\n        \"\"\"Notification for the error of trial.This will only be called when the trial is in the RUNNING state.\"\"\"raise NotImplementedError\n\n[docs]    def on_trial_result(\n        self, tune_controller: \"TuneController\", trial: Trial, result: Dict\n    ) -> str:\n        \"\"\"Called on each intermediate result returned by a trial.At this point, the trial scheduler can make a decision by returning\n        one of CONTINUE, PAUSE, and STOP.This will only be called when the\n        trial is in the RUNNING state.\"\"\"raise NotImplementedError\n\n[docs]    def on_trial_complete(\n        self, tune_controller: \"TuneController\", trial: Trial, result: Dict\n    ):\n        \"\"\"Notification for the completion of trial.This will only be called when the trial is in the RUNNING state and\n        either completes naturally or by manual termination.\"\"\"raise NotImplementedError\n\n[docs]    def on_trial_remove(self, tune_controller: \"TuneController\", trial: Trial):\n        \"\"\"Called to remove trial.This is called when the trial is in PAUSED or PENDING state.Otherwise,\n        call `on_trial_complete`.\"\"\"raise NotImplementedError\n\n[docs]    def choose_trial_to_run(self, tune_controller: \"TuneController\") -> Optional[Trial]:\n        \"\"\"Called to choose a new trial to run.",
        "1dd9b303-7b60-4afc-9606-27c6ba56caea": "Blendsearch Example#\n\"\"\"This example demonstrates the usage of BlendSearch with Ray Tune.\n\nIt also checks that it is usable with a separate scheduler.\n\nRequires the FLAML library to be installed (`pip install flaml`).\n\"\"\"\nimport time\n\nimport ray\nfrom ray import train, tune\nfrom ray.tune.search import ConcurrencyLimiter\nfrom ray.tune.schedulers import AsyncHyperBandScheduler\nfrom ray.tune.search.flaml import BlendSearch\n\n\ndef evaluation_fn(step, width, height):\n    return (0.1 + width * step / 100) ** (-1) + height * 0.1\n\n\ndef easy_objective(config):\n    # Hyperparameters\n    width, height = config[\"width\"], config[\"height\"]\n\n    for step in range(config[\"steps\"]):\n        # Iterative training function - can be any arbitrary training procedure\n        intermediate_score = evaluation_fn(step, width, height)\n        # Feed the score back to Tune.\n        train.report({\"iterations\": step, \"mean_loss\": intermediate_score})\n        time.sleep(0.1)",
        "4f7fe93e-657e-45b1-add3-742e478c9754": "ray.rllib.evaluation.sampler.AsyncSampler.join#\n\n\nAsyncSampler.join(timeout=None)#\nWait until the thread terminates.\nThis blocks the calling thread until the thread whose join() method is\ncalled terminates \u2013 either normally or through an unhandled exception\nor until the optional timeout occurs.\nWhen the timeout argument is present and not None, it should be a\nfloating point number specifying a timeout for the operation in seconds\n(or fractions thereof). As join() always returns None, you must call\nis_alive() after join() to decide whether a timeout happened \u2013 if the\nthread is still alive, the join() call timed out.\nWhen the timeout argument is not present or None, the operation will\nblock until the thread terminates.\nA thread can be join()ed many times.\njoin() raises a RuntimeError if an attempt is made to join the current\nthread as that would cause a deadlock. It is also an error to join() a\nthread before it has been started and attempts to do so raises the same\nexception.",
        "73eb5280-1ada-4e01-9dec-cab4d906d60f": "FINISHED\n            else:\n                return None\n\n        if _solution:\n            self.solution_dict[str(trial_id)] = _solution\n            _x = _solution.get_x()\n            new_trial = dict(zip(self._dim_keys, _x))\n            self._live_trial_mapping[trial_id] = new_trial\n            return unflatten_dict(new_trial)\n\n[docs]    def on_trial_complete(\n        self, trial_id: str, result: Optional[Dict] = None, error: bool = False\n    ):\n        \"\"\"Notification for the completion of trial.\"\"\"if result:\n            _solution = self.solution_dict[str(trial_id)]\n            _best_solution_so_far = self.optimizer.complete(\n                _solution, self._metric_op * result[self._metric]\n            )\n            if _best_solution_so_far:\n                self.best_solution_list.append(_best_solution_so_far)\n\n        del self._live_trial_mapping[trial_id]\n\n    def save(self,",
        "94d2c6db-2321-4379-9798-b5d3fa3ff6b1": "ray.rllib.models.torch.torch_modelv2.TorchModelV2.forward#\n\n\nTorchModelV2.forward(input_dict: Dict[str, Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor]], state: List[Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor]], seq_lens: Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor]) -> (typing.Union[<built-in function array>, ForwardRef('jnp.ndarray'), ForwardRef('tf.Tensor'), ForwardRef('torch.Tensor')], typing.List[typing.Union[<built-in function array>, ForwardRef('jnp.ndarray'), ForwardRef('tf.Tensor'), ForwardRef('torch.Tensor')]])#\nCall the model with the given input tensors and state.Any complex observations (dicts, tuples, etc.)will be unpacked by\n__call__ before being passed to forward().To access the flattened\nobservation tensor, refer to input_dict[\u201cobs_flat\u201d].This method can be called any number of times.In eager execution,\neach call to forward() will eagerly evaluate the model.In symbolic\nexecution, each call to forward creates a computation graph that\noperates over the variables of this model (i.e., shares weights).Custom models should override this instead of __call__.Parameters\n\ninput_dict \u2013 dictionary of input tensors, including \u201cobs\u201d,\n\u201cobs_flat\u201d, \u201cprev_action\u201d, \u201cprev_reward\u201d, \u201cis_training\u201d,\n\u201ceps_id\u201d, \u201cagent_id\u201d, \u201cinfos\u201d, and \u201ct\u201d.",
        "3b4943ac-2b4b-46a8-8024-9154787872f1": "local_shuffle_buffer_size: If non-None, the data will be randomly shuffled\n                using a local in-memory shuffle buffer, and this value will serve as the\n                minimum number of rows that must be in the local in-memory shuffle\n                buffer in order to yield a batch.When there are no more rows to add to\n                the buffer, the remaining rows in the buffer will be drained.local_shuffle_seed: The seed to use for the local random shuffle.Returns:\n            An iterator over record batches.\n        \"\"\"context = DataContext.get_current()\n        if not context.use_streaming_executor:\n            # Always use legacy iter_batches for bulk executor.use_legacy = True\n        else:\n            use_legacy = context.use_legacy_iter_batches\n\n        if prefetch_blocks > 0 and not use_legacy:\n            raise DeprecationWarning(\n                \"`prefetch_blocks` arg is deprecated in Ray 2.4.Use \"\n                \"the `prefetch_batches` arg instead to specify the amount of \"\n                \"prefetching in terms of batches instead of blocks.",
        "7c3141f5-e811-48d8-8661-a9b2ef23d646": "from_checkpoint(checkpoint[,\u00a0policy_ids])\nCreates new Policy instance(s) from a given Policy or Algorithm checkpoint.from_state(state)\nRecovers a Policy from a state object.get_batch_divisibility_req()\nGet batch divisibility request.get_connector_metrics()\nGet metrics on timing from connectors.get_exploration_state()\nReturns the state of this Policy's exploration component.get_host()\nReturns the computer's network name.get_session()\nReturns tf.Session object to use for computing actions or None.get_tower_stats(stats_name)\nReturns list of per-tower stats, copied to this Policy's device.import_model_from_h5(import_file)\nImports weights into torch model.init_view_requirements()\nMaximal view requirements dict for learn_on_batch() and compute_actions calls.learn_on_batch_from_replay_buffer(...)\nSamples a batch from given replay actor and performs an update.loss(model,\u00a0dist_class,\u00a0train_batch)\nConstructs the loss function.make_model()\nCreate model.make_model_and_action_dist()\nCreate model and action distribution function.make_rl_module()\nReturns the RL Module (only for when RLModule API is enabled.)maybe_add_time_dimension(input_dict,\u00a0seq_lens)\nAdds a time dimension for recurrent RLModules.on_global_var_update(global_vars)\nCalled on an update to global vars.optimizer()\nCustom the local PyTorch optimizer(s) to use.postprocess_trajectory(sample_batch[,\u00a0...])\nPostprocesses a trajectory and returns the processed trajectory.reset_connectors(env_id)\nReset action- and agent-connectors for this policy.restore_connectors(state)\nRestore agent and action connectors if configs available.",
        "1d3286a3-a210-4bc7-913a-78827917c363": "Memory Aware Scheduling#\nBy default, Ray does not take into account the potential memory usage of a task or actor when scheduling. This is simply because it cannot estimate ahead of time how much memory is required. However, if you know how much memory a task or actor requires, you can specify it in the resource requirements of its ray.remote decorator to enable memory-aware scheduling:\n\nImportant\nSpecifying a memory requirement does NOT impose any limits on memory usage. The requirements are used for admission control during scheduling only (similar to how CPU scheduling works in Ray). It is up to the task itself to not use more memory than it requested.\n\nTo tell the Ray scheduler a task or actor requires a certain amount of available memory to run, set the memory argument. The Ray scheduler will then reserve the specified amount of available memory during scheduling, similar to how it handles CPU and GPU resources:\n# reserve 500MiB of available memory to place this task\n@ray.remote(memory=500 * 1024 * 1024)\ndef some_function(x):\n    pass\n\n# reserve 2.5GiB of available memory to place this actor\n@ray.remote(memory=2500 * 1024 * 1024)\nclass SomeActor:\n    def __init__(self, a, b):\n        pass\n\n\nIn the above example, the memory quota is specified statically by the decorator, but you can also set them dynamically at runtime using .options() as follows:\n# override the memory quota to 100MiB when submitting the task\nsome_function.options(memory=100 * 1024 * 1024).remote(x=1)\n\n# override the memory quota to 1GiB when creating the actor\nSomeActor.options(memory=1000 * 1024 * 1024).remote(a=1, b=2)",
        "2140c854-da29-4176-8a2d-acbd87f15fb7": "head_node_options \u2013 A dict representing Ray head node extra options, these\noptions will be passed to ray start script.Note you need to convert\nray start options key from --foo-bar format to foo_bar format.For flag options (e.g.\u2018\u2013disable-usage-stats\u2019), you should set the value\nto None in the option dict, like {\"disable_usage_stats\": None}.Note: Short name options (e.g.\u2018-v\u2019) are not supported.worker_node_options \u2013 A dict representing Ray worker node extra options,\nthese options will be passed to ray start script.Note you need to\nconvert ray start options key from --foo-bar format to foo_bar\nformat.For flag options (e.g.\u2018\u2013disable-usage-stats\u2019), you should set the value\nto None in the option dict, like {\"disable_usage_stats\": None}.Note: Short name options (e.g.\u2018-v\u2019) are not supported.ray_temp_root_dir \u2013 A local disk path to store the ray temporary data.The\ncreated cluster will create a subdirectory\n\u201cray-{head_port}-{random_suffix}\u201d beneath this path.strict_mode \u2013 Boolean flag to fast-fail initialization of the ray cluster if\nthe available spark cluster does not have sufficient resources to fulfill\nthe resource allocation for memory, cpu and gpu.When set to true, if the\nrequested resources are not available for recommended minimum recommended\nfunctionality, an exception will be raised that details the inadequate\nspark cluster configuration settings.If overridden as False,\na warning is raised.collect_log_to_path \u2013 If specified, after ray head / worker nodes terminated,\ncollect their logs to the specified path.On Databricks Runtime, we\nrecommend you to specify a local path starts with \u2018/dbfs/\u2019, because the\npath mounts with a centralized storage device and stored data is persisted\nafter Databricks spark cluster terminated.\n\n\nReturns\nThe address of the initiated Ray cluster on spark.",
        "90d18c07-e608-41a0-b8b0-fa66f6435ca5": "if len(init_args) == 0 and self._replica_config.init_args is not None:\n            init_args = self._replica_config.init_args\n        if len(init_kwargs) == 0 and self._replica_config.init_kwargs is not None:\n            init_kwargs = self._replica_config.init_kwargs\n\n        replica_config = ReplicaConfig.create(\n            self._replica_config.deployment_def,\n            init_args=init_args,\n            init_kwargs=init_kwargs,\n            ray_actor_options=self._replica_config.ray_actor_options,\n            placement_group_bundles=self._replica_config.placement_group_bundles,\n            placement_group_strategy=self._replica_config.placement_group_strategy,\n            max_replicas_per_node=self._replica_config.max_replicas_per_node,\n        )\n\n        return get_global_client().deploy(\n            self._name,\n            replica_config=replica_config,\n            deployment_config=self._deployment_config,\n            version=self._version,",
        "705c4311-82f2-4c33-9f56-31ec73cc8914": "Single Agent\nimport gymnasium as gym\nfrom ray.rllib.core.rl_module.rl_module import SingleAgentRLModuleSpec\nfrom ray.rllib.core.testing.torch.bc_module import DiscreteBCTorchModule\nfrom ray.rllib.core.testing.bc_algorithm import BCConfigTest\n\n\nconfig = (\n    BCConfigTest()\n    .environment(\"CartPole-v1\")\n    .rl_module(\n        _enable_rl_module_api=True,\n        rl_module_spec=SingleAgentRLModuleSpec(module_class=DiscreteBCTorchModule),\n    )\n    .training(\n        model={\"fcnet_hiddens\": [32, 32]},\n        _enable_learner_api=True,\n    )\n)\n\nalgo = config.build()\n\n\n\nNote\nFor passing RL Module specs, all fields do not have to be filled as they are filled based on the described environment or other algorithm configuration parameters (i.e. ,``observation_space``, action_space, model_config_dict are not required fields when passing a custom RL Module spec to the algorithm config.)\n\n\n\n\nMulti Agent\nimport gymnasium as gym\nfrom ray.rllib.core.rl_module.rl_module import SingleAgentRLModuleSpec\nfrom ray.rllib.core.rl_module.marl_module import MultiAgentRLModuleSpec\nfrom ray.rllib.core.testing.torch.bc_module import DiscreteBCTorchModule\nfrom ray.rllib.core.testing.bc_algorithm import BCConfigTest\nfrom ray.rllib.examples.env.multi_agent import MultiAgentCartPole",
        "ccbd38e0-fd60-46a3-a733-f0087d72b464": "003498077392578125\n  \nResult for objective_f59fe9d6:\n  date: 2022-07-22_15-31-30\n  done: false\n  experiment_id: efbda212c15c4bd38cfc5f39dfae8b73\n  hostname: Kais-MacBook-Pro.local\n  iterations: 47\n  iterations_since_restore: 48\n  mean_loss: -2.3825537636804834\n  neg_mean_loss: 2.3825537636804834\n  node_ip: 127.0.0.1\n  pid: 47185\n  time_since_restore: 5.170727014541626\n  time_this_iter_s: 0.10740494728088379\n  time_total_s: 5.170727014541626\n  timestamp: 1658500290\n  timesteps_since_restore: 0\n  training_iteration: 48\n  trial_id: f59fe9d6\n  warmup_time: 0.003314971923828125\n  \nResult for objective_f5b1ec08:\n  date: 2022-07-22_15-31-30\n  done: false\n  experiment_id: dadb542868ba4b10adf1ef161c75ea17\n  hostname: Kais-MacBook-Pro.local\n  iterations: 47\n  iterations_since_restore: 48\n  mean_loss: 0.5431509247331814\n  neg_mean_loss: -0.5431509247331814\n  node_ip: 127.0.0.1\n  pid: 47189\n  time_since_restore: 5.153015613555908\n  time_this_iter_s: 0.10737276077270508\n  time_total_s: 5.",
        "68291fa2-cb7f-4bc5-ba58-41206f55fecc": "# If you have `SyncConfig` configured, the content should also\n# show up in the corresponding cloud storage path.\n\n\n\nParameters\n\nmetrics \u2013 The metrics you want to report.\ncheckpoint \u2013 The optional checkpoint you want to report.\n\n\n\nPublicAPI (beta): This API is in beta and may change before becoming stable.",
        "8c2ae503-4af6-4afe-b007-782311b10bbe": "ray.rllib.core.learner.learner.Learner._check_registered_optimizer#\n\n\nLearner._check_registered_optimizer(optimizer: Union[torch.optim.optimizer.Optimizer, keras.optimizers.optimizer_experimental.optimizer.Optimizer], params: Sequence[Union[torch.Tensor, tensorflow.python.ops.variables.Variable]]) \u2192 None[source]#\nChecks that the given optimizer and parameters are valid for the framework.\n\nParameters\n\noptimizer \u2013 The optimizer object to check.\nparams \u2013 The list of parameters to check.",
        "4b3e5f87-1fdd-453d-8b1e-8bc10d79d808": "ray.train.tensorflow.TensorflowCheckpoint.get_preprocessor#\n\n\nTensorflowCheckpoint.get_preprocessor() \u2192 Optional[ray.data.preprocessor.Preprocessor]#\nReturn the preprocessor stored in the checkpoint.\n\nReturns\nThe preprocessor stored in the checkpoint, or None if no\npreprocessor was stored.",
        "3b184b7c-78aa-423b-a6ea-5157291ea193": "Migrating a single deployment to the new deployment API#\nIn the 1.x deployment API, we usually have the following code for deployment.\n@serve.deployment\nclass Model:\n    def __call__(self, input: int):\n        # some inference work\n        return\n\n\nModel.deploy()\nhandle = Model.get_handle()\nhandle.remote(1)\n\n\nWith the 2.0 deployment API, you can use the following code to update the above one.\n@serve.deployment\nclass Model:\n    def __call__(self, input: int):\n        # some inference work\n        return\n\n\nhandle = serve.run(Model.bind())\nhandle.remote(1)",
        "35a63870-5208-420b-804c-93a9823e1c04": "or worker_state[\"is_policy_to_train\"] == NOT_SERIALIZABLE\n            ):\n                worker_state[\"is_policy_to_train\"] = policies_to_train\n\n        return state\n\n    @DeveloperAPI\n    def _create_local_replay_buffer_if_necessary(\n        self, config: PartialAlgorithmConfigDict\n    ) -> Optional[MultiAgentReplayBuffer]:\n        \"\"\"Create a MultiAgentReplayBuffer instance if necessary.Args:\n            config: Algorithm-specific configuration data.Returns:\n            MultiAgentReplayBuffer instance based on algorithm config.None, if local replay buffer is not needed.\n        \"\"\"if not config.get(\"replay_buffer_config\") or config[\"replay_buffer_config\"].get(\n            \"no_local_replay_buffer\"\n        ):\n            return\n\n        return from_config(ReplayBuffer, config[\"replay_buffer_config\"])\n\n    @DeveloperAPI\n    def _kwargs_for_execution_plan(self):\n        kwargs = {}\n        if self.local_replay_buffer is not None:\n            kwargs[\"local_replay_buffer\"] = self.local_replay_buffer\n        return kwargs\n\n    def _run_one_training_iteration(self) -> Tuple[ResultDict, \"TrainIterCtx\"]:\n        \"\"\"Runs one training iteration (self.iteration will be +1 after this).",
        "5a9143a6-3c2b-4673-b9c7-9c92cd63d34f": "1\n  pid: 45918\n  time_since_restore: 5.103626012802124\n  time_this_iter_s: 0.10568881034851074\n  time_total_s: 5.103626012802124\n  timestamp: 1658499559\n  timesteps_since_restore: 0\n  training_iteration: 47\n  trial_id: 421d81ee\n  warmup_time: 0.002989053726196289\n  \nResult for objective_402f9534:\n  date: 2022-07-22_15-19-21\n  done: false\n  experiment_id: 66af4092dc134e049ed47a56532133ce\n  hostname: Kais-MacBook-Pro.local\n  iterations: 94\n  iterations_since_restore: 95\n  mean_loss: 15.983470378488619\n  neg_mean_loss: -15.983470378488619\n  node_ip: 127.0.0.1\n  pid: 45909\n  time_since_restore: 10.194732666015625\n  time_this_iter_s: 0.11167168617248535\n  time_total_s: 10.194732666015625\n  timestamp: 1658499561\n  timesteps_since_restore: 0\n  training_iteration: 95\n  trial_id: 402f9534\n  warmup_time: 0.0026721954345703125\n  \nResult for objective_402f9534:\n  date: 2022-07-22_15-19-22\n  done: true\n  experiment_id: 66af4092dc134e049ed47a56532133ce\n  experiment_tag: 5_activation=relu,height=2.4385,steps=100,",
        "d218de8a-19c3-45a3-8504-bd98ace16f34": "Return:\n             True if the placement group is created.False otherwise.\n        \"\"\"return _call_placement_group_ready(self.id, timeout_seconds)\n\n    @property\n    def bundle_specs(self) -> List[Dict]:\n        \"\"\"List[Dict]: Return bundles belonging to this placement group.\"\"\"self._fill_bundle_cache_if_needed()\n        return self.bundle_cache\n\n    @property\n    def bundle_count(self) -> int:\n        self._fill_bundle_cache_if_needed()\n        return len(self.bundle_cache)\n\n    def _fill_bundle_cache_if_needed(self) -> None:\n        if not self.bundle_cache:\n            self.bundle_cache = _get_bundle_cache(self.id)\n\n    def __eq__(self, other):\n        if not isinstance(other, PlacementGroup):\n            return False\n        return self.id == other.id\n\n    def __hash__(self):\n        return hash(self.id)\n\n\n@client_mode_wrap\ndef _call_placement_group_ready(pg_id: PlacementGroupID, timeout_seconds: int) -> bool:\n    worker = ray._private.worker.global_worker\n    worker.check_connected()\n\n    return worker.core_worker.wait_placement_group_ready(pg_id, timeout_seconds)",
        "1bb2ae16-8da7-44e9-b955-38ab88ca5d63": "),\n        gt=0,\n    )\n    user_config: Optional[Dict] = Field(\n        default=DEFAULT.VALUE,\n        description=(\n            \"Config to pass into this deployment's \"\n            \"reconfigure method.This can be updated dynamically \"\n            \"without restarting replicas\"\n        ),\n    )\n    autoscaling_config: Optional[Dict] = Field(\n        default=DEFAULT.VALUE,\n        description=(\n            \"Config specifying autoscaling \"\n            \"parameters for the deployment's number of replicas. \"\"If null, the deployment won't autoscale its number of \"\n            \"replicas; the number of replicas will be fixed at \"\n            \"num_replicas.\"),\n    )\n    graceful_shutdown_wait_loop_s: float = Field(\n        default=DEFAULT.VALUE,\n        description=(\n            \"Duration that deployment replicas will wait until there \"\n            \"is no more work to be done before shutting down.Uses a \"\n            \"default if null.\"",
        "afdf18c6-4fd2-40bd-8063-4943608993f7": "restore_from_object() (ray.rllib.algorithms.algorithm.Algorithm method)\n\nrestore_workers() (ray.rllib.algorithms.algorithm.Algorithm method)\n\nResult (class in ray.train)\n\nResultGrid (class in ray.tune)\n\nresults (ray.tune.ExperimentAnalysis property)\n\nresults_df (ray.tune.ExperimentAnalysis property)\n\nresume() (in module ray.workflow)\n\nresume_all() (in module ray.workflow)\n\nresume_async() (in module ray.workflow)\n\nRETURNS_TO_GO (ray.rllib.policy.sample_batch.SampleBatch attribute)\n\nreuse_actors (ray.tune.TuneConfig attribute)\n\nReward\n\nREWARDS (ray.rllib.policy.sample_batch.SampleBatch attribute)\n\nright_zero_pad() (ray.rllib.policy.sample_batch.SampleBatch method)\n\nrl_module() (ray.rllib.algorithms.algorithm_config.AlgorithmConfig method)\n\nRLModule (class in ray.rllib.core.rl_module.rl_module)\n\nRLModuleConfig (class in ray.rllib.core.rl_module.rl_module)\n\nRobustScaler (class in ray.data.preprocessors)\n\nRollout\n\nRollout Worker\n\nrollouts() (ray.rllib.algorithms.algorithm_config.AlgorithmConfig method)\n\nRolloutWorker (class in ray.rllib.evaluation.rollout_worker)\n\nroot_device (ray.train.lightning.RayDDPStrategy property)\n\n(ray.train.lightning.RayDeepSpeedStrategy property)\n\n(ray.train.lightning.RayFSDPStrategy property)",
        "df7b07e1-42a7-4f4c-af95-ff0ec8b14c2d": "Stats#\nWhen spilling is happening, the following INFO level messages will be printed to the raylet logs (e.g., /tmp/ray/session_latest/logs/raylet.out):\nlocal_object_manager.cc:166: Spilled 50 MiB, 1 objects, write throughput 230 MiB/s\nlocal_object_manager.cc:334: Restored 50 MiB, 1 objects, read throughput 505 MiB/s\n\n\nYou can also view cluster-wide spill stats by using the ray memory command:\n--- Aggregate object store stats across all nodes ---\nPlasma memory usage 50 MiB, 1 objects, 50.0% full\nSpilled 200 MiB, 4 objects, avg write throughput 570 MiB/s\nRestored 150 MiB, 3 objects, avg read throughput 1361 MiB/s\n\n\nIf you only want to display cluster-wide spill stats, use ray memory --stats-only.",
        "4e72355e-3255-4fd1-84c2-7e5d233a229a": "__init__()\n\n        runtime_env = kwargs\n        if py_modules is not None:\n            runtime_env[\"py_modules\"] = py_modules\n        if working_dir is not None:\n            runtime_env[\"working_dir\"] = working_dir\n        if pip is not None:\n            runtime_env[\"pip\"] = pip\n        if conda is not None:\n            runtime_env[\"conda\"] = conda\n        if container is not None:\n            runtime_env[\"container\"] = container\n        if env_vars is not None:\n            runtime_env[\"env_vars\"] = env_vars\n        if config is not None:\n            runtime_env[\"config\"] = config\n        if worker_process_setup_hook is not None:\n            runtime_env[\"worker_process_setup_hook\"] = worker_process_setup_hook\n\n        if runtime_env.get(\"java_jars\"):\n            runtime_env[\"java_jars\"] = runtime_env.get(\"java_jars\")\n\n        self.update(runtime_env)\n\n        # Blindly trust that the runtime_env has already been validated.# This is dangerous and should only be used internally (e.g., on the\n        # deserialization codepath.",
        "8b2c7c31-d145-4fad-863e-e9bcfee0d795": "Note that already ongoing episodes will\n                not change their mapping but will use the old mapping till\n                the end of the episode.policies_to_train: An optional container of policy IDs to be\n                trained or a callable taking PolicyID and - optionally -\n                SampleBatchType and returning a bool (trainable or not?).If None, will keep the existing setup in place.Policies, whose IDs are not in the list (or for which the\n                callable returns False) will not be updated.\n        \"\"\"if policy_id not in self.policy_map:\n            raise ValueError(f\"Policy ID '{policy_id}' not in policy map!\")del self.policy_map[policy_id]\n        del self.preprocessors[policy_id]\n        self.set_policy_mapping_fn(policy_mapping_fn)\n        if policies_to_train is not None:\n            self.set_is_policy_to_train(policies_to_train)\n\n[docs]    def set_policy_mapping_fn(\n        self,\n        policy_mapping_fn: Optional[Callable[[AgentID, \"Episode\"], PolicyID]] = None,\n    ) -> None:\n        \"\"\"Sets `self.policy_mapping_fn` to a new callable (if provided).Args:\n            policy_mapping_fn: The new mapping function to use.",
        "78871974-2b66-4f0e-b3b3-a6b12b5cf607": "serve#\nCLI for managing Serve applications on a Ray cluster.\nserve [OPTIONS] COMMAND [ARGS]...",
        "84dd30ba-6405-4b1f-83b2-4535a495a903": "Catching application-level failures#\nRay surfaces application-level failures as Python-level exceptions. When a task\non a remote worker or actor fails due to a Python-level exception, Ray wraps\nthe original exception in a RayTaskError and stores this as the task\u2019s\nreturn value. This wrapped exception will be thrown to any worker that tries\nto get the result, either by calling ray.get or if the worker is executing\nanother task that depends on the object.\n\nimport ray\n\n@ray.remote\ndef f():\n    raise Exception(\"the real error\")\n\n@ray.remote\ndef g(x):\n    return\n\n\ntry:\n    ray.get(f.remote())\nexcept ray.exceptions.RayTaskError as e:\n    print(e)\n    # ray::f() (pid=71867, ip=XXX.XX.XXX.XX)\n    #   File \"errors.py\", line 5, in f\n    #     raise Exception(\"the real error\")\n    # Exception: the real error\n\ntry:\n    ray.get(g.remote(f.remote()))\nexcept ray.exceptions.RayTaskError as e:\n    print(e)\n    # ray::g() (pid=73085, ip=128.32.132.47)\n    #   At least one of the input arguments for this task could not be computed:\n    # ray.exceptions.RayTaskError: ray::f() (pid=73085, ip=XXX.XX.XXX.XX)\n    #   File \"errors.py\", line 5, in f\n    #     raise Exception(\"the real error\")\n    # Exception: the real error\n\n\n\nUse ray list tasks from State API CLI to query task exit details:\n# This API is only available when you download Ray via `pip install \"ray[default]\"`\nray list tasks",
        "4ac5062c-26ae-4483-a734-429972d4d8b4": "class FitStatus(str, Enum):\n        \"\"\"The fit status of preprocessor.\"\"\"NOT_FITTABLE = \"NOT_FITTABLE\"\n        NOT_FITTED = \"NOT_FITTED\"\n        # Only meaningful for Chain preprocessors.# At least one contained preprocessor in the chain preprocessor\n        # is fitted and at least one that can be fitted is not fitted yet.# This is a state that show up if caller only interacts\n        # with the chain preprocessor through intended Preprocessor APIs.PARTIALLY_FITTED = \"PARTIALLY_FITTED\"\n        FITTED = \"FITTED\"\n\n    # Preprocessors that do not need to be fitted must override this._is_fittable = True\n\n    def fit_status(self) -> \"Preprocessor.FitStatus\":\n        if not self._is_fittable:\n            return Preprocessor.FitStatus.NOT_FITTABLE\n        elif hasattr(self, \"_fitted\") and self._fitted:\n            return Preprocessor.FitStatus.FITTED\n        else:\n            return Preprocessor.FitStatus.NOT_FITTED\n\n[docs]    @Deprecated\n    def transform_stats(self) -> Optional[str]:\n        \"\"\"Return Dataset stats for the most recent transform call, if any.\"\"\"raise DeprecationWarning(\n            \"`preprocessor.transform_stats()` is no longer supported in Ray 2.4. \"\"With Dataset now lazy by default, the stats are only populated \"\n            \"after execution.",
        "929692f3-451e-4520-8ee7-856d6fcfe989": "def train_func(config):\n\n    # Data\n    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n    train_data = FashionMNIST(root='./data', train=True, download=True, transform=transform)\n    train_dataloader = DataLoader(train_data, batch_size=128, shuffle=True)\n\n    # Training\n    model = ImageClassifier()\n    # [1] Configure PyTorch Lightning Trainer.\n    trainer = pl.Trainer(\n        max_epochs=10,\n        devices=\"auto\",\n        accelerator=\"auto\",\n        strategy=ray.train.lightning.RayDDPStrategy(),\n        plugins=[ray.train.lightning.RayLightningEnvironment()],\n        callbacks=[ray.train.lightning.RayTrainReportCallback()],\n    )\n    trainer = ray.train.lightning.prepare_trainer(trainer)\n    trainer.fit(model, train_dataloaders=train_dataloader)\n\n# [2] Configure scaling and resource requirements.\nscaling_config = ScalingConfig(num_workers=2, use_gpu=True)\n\n# [3] Launch distributed training job.\ntrainer = TorchTrainer(train_func, scaling_config=scaling_config)\nresult = trainer.fit()",
        "bbac7849-29b2-4f52-9610-fc35a8f66583": "Source code for ray.tune.tune_config\nimport datetime\nfrom dataclasses import dataclass\nfrom typing import Callable, Optional, Union\n\nfrom ray.tune.experiment.trial import Trial\nfrom ray.tune.schedulers import TrialScheduler\nfrom ray.tune.search import SearchAlgorithm, Searcher\nfrom ray.util import PublicAPI\n\n\n[docs]@dataclass\n@PublicAPI(stability=\"beta\")\nclass TuneConfig:\n    \"\"\"Tune specific configs.Args:\n        metric: Metric to optimize.This metric should be reported\n            with `tune.report()`.If set, will be passed to the search\n            algorithm and scheduler.mode: Must be one of [min, max].Determines whether objective is\n            minimizing or maximizing the metric attribute.If set, will be\n            passed to the search algorithm and scheduler.search_alg: Search algorithm for optimization.Default to\n            random search.scheduler: Scheduler for executing the experiment.Choose among FIFO (default), MedianStopping,\n            AsyncHyperBand, HyperBand and PopulationBasedTraining.Refer to\n            ray.tune.schedulers for more options.num_samples: Number of times to sample from the\n            hyperparameter space.Defaults to 1.If `grid_search` is\n            provided as an argument, the grid will be repeated\n            `num_samples` of times.If this is -1, (virtually) infinite\n            samples are generated until a stopping condition is met.",
        "0fe856d9-be17-4d34-8776-7c4e34bb7e36": "ray.rllib.policy.torch_policy_v2.TorchPolicyV2.action_sampler_fn#\n\n\nTorchPolicyV2.action_sampler_fn(model: ray.rllib.models.modelv2.ModelV2, *, obs_batch: Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor], state_batches: Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor], **kwargs) \u2192 Tuple[Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor], Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor], Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor], List[Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor]]][source]#\nCustom function for sampling new actions given policy.\n\nParameters\n\nmodel \u2013 Underlying model.\nobs_batch \u2013 Observation tensor batch.\nstate_batches \u2013 Action sampling state batch.\n\n\nReturns\nSampled action\nLog-likelihood\nAction distribution inputs\nUpdated state",
        "a51e6a38-a016-48e1-93e0-649d1b0cd232": "Parameters\n\nfeature_columns \u2013 Columns that correspond to model inputs. If this is a\nstring, the input data is a tensor. If this is a list, the input data\nis a dict that maps column names to their tensor representation.\nlabel_column \u2013 Columns that correspond to model targets. If this is a\nstring, the target data is a tensor. If this is a list, the target data\nis a dict that maps column names to their tensor representation.\nprefetch_batches \u2013 The number of batches to fetch ahead of the current batch\nto fetch. If set to greater than 0, a separate threadpool will be used\nto fetch the objects to the local node, format the batches, and apply\nthe collate_fn. Defaults to 1. You can revert back to the old\nprefetching behavior that uses prefetch_blocks by setting\nuse_legacy_iter_batches to True in the DataContext.\nbatch_size \u2013 Record batch size. Defaults to 1.\ndrop_last \u2013 Set to True to drop the last incomplete batch,\nif the dataset size is not divisible by the batch size. If\nFalse and the size of dataset is not divisible by the batch\nsize, then the last batch will be smaller. Defaults to False.\nlocal_shuffle_buffer_size \u2013 If non-None, the data will be randomly shuffled\nusing a local in-memory shuffle buffer, and this value will serve as the\nminimum number of rows that must be in the local in-memory shuffle\nbuffer in order to yield a batch. When there are no more rows to add to\nthe buffer, the remaining rows in the buffer will be drained. This\nbuffer size must be greater than or equal to batch_size, and\ntherefore batch_size must also be specified when using local\nshuffling.\nlocal_shuffle_seed \u2013 The seed to use for the local random shuffle.\n\n\nReturns\nA tf.data.Dataset that yields inputs and targets.",
        "51f1e266-0d58-49a1-a90a-7fac2fb27bac": "Example:\n        >>> from ray.rllib.examples.env.two_step_game import TwoStepGame\n        >>> from ray.rllib.algorithms.qmix import QMixConfig\n        >>> config = QMixConfig()  # doctest: +SKIP\n        >>> config = config.training(gamma=0.9, lr=0.01, kl_coeff=0.3)  # doctest: +SKIP\n        >>> config = config.resources(num_gpus=0)  # doctest: +SKIP\n        >>> config = config.rollouts(num_rollout_workers=4)  # doctest: +SKIP\n        >>> print(config.to_dict())  # doctest: +SKIP\n        >>> # Build an Algorithm object from the config and run 1 training iteration.>>> algo = config.build(env=TwoStepGame)  # doctest: +SKIP\n        >>> algo.train()  # doctest: +SKIP\n\n    Example:\n        >>> from ray.rllib.examples.env.two_step_game import TwoStepGame\n        >>> from ray.rllib.algorithms.qmix import QMixConfig\n        >>> from ray import air\n        >>> from ray import tune\n        >>> config = QMixConfig()\n        >>> # Print out some default values.>>> print(config.optim_alpha)  # doctest: +SKIP\n        >>> # Update the config object.",
        "1df50a2b-9065-41a0-bbbf-45525d07beb7": "(RayTrainWorker pid=1789, ip=172.31.90.137) ***** Running training *****\n(RayTrainWorker pid=1789, ip=172.31.90.137)   Num examples = 8551\n(RayTrainWorker pid=1789, ip=172.31.90.137)   Num Epochs = 4\n(RayTrainWorker pid=1789, ip=172.31.90.137)   Instantaneous batch size per device = 16\n(RayTrainWorker pid=1789, ip=172.31.90.137)   Total train batch size (w. parallel, distributed & accumulation) = 64\n(RayTrainWorker pid=1789, ip=172.31.90.137)   Gradient Accumulation steps = 1\n(RayTrainWorker pid=1789, ip=172.31.90.137)   Total optimization steps = 2140\n\n\n(RayTrainWorker pid=1483, ip=172.31.85.32) Is CUDA available: True\n(RayTrainWorker pid=1485, ip=172.31.85.32) Is CUDA available: True\n(RayTrainWorker pid=1486, ip=172.31.85.32) Is CUDA available: True\n(RayTrainWorker pid=1484, ip=172.31.85.32) Is CUDA available: True\n(RayTrainWorker pid=1977, ip=172.31.76.237) Starting training\n(RayTrainWorker pid=1976, ip=172.31.76.237) Starting training\n(RayTrainWorker pid=1975, ip=172.31.76.237) Starting training\n(RayTrainWorker pid=1974, ip=172.31.76.237) Starting training",
        "85e15933-0a24-4a3b-a06f-8df1bd40688f": "ray.rllib.core.rl_module.rl_module.SingleAgentRLModuleSpec.update#\n\n\nSingleAgentRLModuleSpec.update(other) \u2192 None[source]#\nUpdates this spec with the given other spec. Works like dict.update().",
        "899587e4-9814-41bf-a87c-14ee1eab16b6": "self.view_requirements = self.model.update_default_view_requirements(\n                self.view_requirements\n            )\n        else:\n            # Auto-update model's inference view requirements, if recurrent.self._update_model_view_requirements_from_init_state()\n            # Combine view_requirements for Model and Policy.self.view_requirements.update(self.model.view_requirements)\n\n        if self.config.get(\"_enable_rl_module_api\", False):\n            # We don't need an exploration object with RLModules\n            self.exploration = None\n        else:\n            self.exploration = self._create_exploration()\n\n        if not self.config.get(\"_enable_learner_api\", False):\n            self._optimizers = force_list(self.optimizer())\n\n            # Backward compatibility workaround so Policy will call self.loss()\n            # directly.# TODO (jungong): clean up after all policies are migrated to new sub-class\n            #  implementation.self._loss = None\n\n            # Store, which params (by index within the model's list of\n            # parameters) should be updated per optimizer.# Maps optimizer idx to set or param indices.",
        "9a019f9f-637f-402e-9290-4e73df2ef157": "Time complexity: O(1)\n\n        Args:\n            label_column: The name of the column used as the\n                label (second element of the output list).Can be None for\n                prediction, in which case the second element of returned\n                tuple will also be None.feature_columns: The names of the columns\n                to use as the features.Can be a list of lists or\n                a dict of string-list pairs for multi-tensor output.If ``None``, then use all columns except the label column as\n                the features.label_column_dtype: The torch dtype to\n                use for the label column.If ``None``, then automatically infer\n                the dtype.feature_column_dtypes: The dtypes to use for the feature\n                tensors.This should match the format of ``feature_columns``,\n                or be a single dtype, in which case it is applied to\n                all tensors.If ``None``, then automatically infer the dtype.batch_size: How many samples per batch to yield at a time.Defaults to 1.\n            prefetch_batches: The number of batches to fetch ahead of the current batch\n                to fetch.",
        "464db224-7a20-4ae6-8b0a-2516d9a031a8": "Note that when num_envs_per_worker > 1, episode steps will be buffered\nuntil the episode completes, and hence batches may contain\nsignificant amounts of off-policy data.remote_worker_envs \u2013 If using num_envs_per_worker > 1, whether to create\nthose new envs in remote processes instead of in the same worker.This adds overheads, but can make sense if your envs can take much\ntime to step / reset (e.g., for StarCraft).Use this cautiously;\noverheads are significant.remote_env_batch_wait_ms \u2013 Timeout that remote workers are waiting when\npolling environments.0 (continue when at least one env is ready) is\na reasonable default, but optimal value could be obtained by measuring\nyour environment step / reset and model inference perf.validate_workers_after_construction \u2013 Whether to validate that each created\nremote worker is healthy after its construction process.preprocessor_pref \u2013 Whether to use \u201crllib\u201d or \u201cdeepmind\u201d preprocessors by\ndefault.Set to None for using no preprocessor.In this case, the\nmodel will have to handle possibly complex observations from the\nenvironment.observation_filter \u2013 Element-wise observation filter, either \u201cNoFilter\u201d\nor \u201cMeanStdFilter\u201d.compress_observations \u2013 Whether to LZ4 compress individual observations\nin the SampleBatches collected during rollouts.enable_tf1_exec_eagerly \u2013 Explicitly tells the rollout worker to enable\nTF eager execution.This is useful for example when framework is\n\u201ctorch\u201d, but a TF2 policy needs to be restored for evaluation or\nleague-based purposes.sampler_perf_stats_ema_coef \u2013 If specified, perf stats are in EMAs.This\nis the coeff of how much new data points contribute to the averages.Default is None, which uses simple global average instead.",
        "d09b8151-46ab-46a5-b390-2f374ee29d2b": "CheckpointConfig(\n                checkpoint_score_attribute=\"mean_accuracy\",\n                num_to_keep=4,\n            ),\n        ),\n        tune_config=tune.TuneConfig(\n            scheduler=scheduler,\n            metric=\"mean_accuracy\",\n            mode=\"max\",\n            num_samples=4,\n        ),\n        param_space={\n            \"lr\": tune.uniform(0.001, 1),\n            \"momentum\": tune.uniform(0.001, 1),\n        },\n    )\n    results = tuner.fit()\n    # __tune_end__\n\n    eval_best_model(results)",
        "621a5828-cd84-4e44-b02d-673c1b529282": "env_steps: The number of environment steps in the environment\n                this batch contains.This will be less than the number of\n                transitions this batch contains across all policies in total.\n        \"\"\"for v in policy_batches.values():\n            assert isinstance(v, SampleBatch)\n        self.policy_batches = policy_batches\n        # Called \"count\" for uniformity with SampleBatch.# Prefer to access this via the `env_steps()` method when possible\n        # for clarity.self.count = env_steps\n\n[docs]    @PublicAPI\n    def env_steps(self) -> int:\n        \"\"\"The number of env steps (there are >= 1 agent steps per env step).Returns:\n            The number of environment steps contained in this batch.\n        \"\"\"return self.count\n\n    @PublicAPI\n    def __len__(self) -> int:\n        \"\"\"Same as `self.env_steps()`.\"\"\"return self.count\n\n[docs]    @PublicAPI\n    def agent_steps(self) -> int:\n        \"\"\"The number of agent steps (there are >= 1 agent steps per env step).Returns:\n            The number of agent steps total in this batch.\n        \"\"\"",
        "0013e4f0-5ccb-4506-8ef7-6d0d8f1cf312": "If set to greater than 0, a separate threadpool is used\n                to fetch the objects to the local node, format the batches, and apply\n                the collate_fn.Defaults to 1.You can revert back to the old\n                prefetching behavior that uses `prefetch_blocks` by setting\n                `use_legacy_iter_batches` to True in the datasetContext.drop_last: Set to True to drop the last incomplete batch,\n                if the dataset size is not divisible by the batch size.If\n                False and the size of the stream is not divisible by the batch\n                size, then the last batch is smaller.Defaults to False.local_shuffle_buffer_size: If non-None, the data is randomly shuffled\n                using a local in-memory shuffle buffer, and this value will serve as the\n                minimum number of rows that must be in the local in-memory shuffle\n                buffer in order to yield a batch.When there are no more rows to add to\n                the buffer, the remaining rows in the buffer is drained.This\n                buffer size must be greater than or equal to ``batch_size``, and\n                therefore ``batch_size`` must also be specified when using local\n                shuffling.",
        "5be5d41a-9dd6-4b7c-a8ab-cf10652314f5": "Source code for ray.rllib.algorithms.callbacks\nimport gc\nimport os\nimport platform\nimport tracemalloc\nfrom typing import TYPE_CHECKING, Dict, List, Optional, Tuple, Type, Union\n\nimport numpy as np\n\nfrom ray.rllib.env.base_env import BaseEnv\nfrom ray.rllib.env.env_context import EnvContext\nfrom ray.rllib.evaluation.episode import Episode\nfrom ray.rllib.evaluation.episode_v2 import EpisodeV2\nfrom ray.rllib.evaluation.postprocessing import Postprocessing\nfrom ray.rllib.policy import Policy\nfrom ray.rllib.policy.sample_batch import SampleBatch\nfrom ray.rllib.utils.annotations import (\n    override,\n    OverrideToImplementCustomLogic,\n    PublicAPI,\n)\nfrom ray.rllib.utils.deprecation import Deprecated, deprecation_warning\nfrom ray.rllib.utils.exploration.random_encoder import (\n    _MovingMeanStd,\n    compute_states_entropy,\n    update_beta,\n)\nfrom ray.rllib.utils.typing import AgentID, EnvType, PolicyID\nfrom ray.tune.callback import _CallbackMeta\n\n# Import psutil after ray so the packaged version is used.\nimport psutil\n\nif TYPE_CHECKING:\n    from ray.rllib.algorithms.algorithm import Algorithm\n    from ray.rllib.evaluation import RolloutWorker\n\n\n[docs]@PublicAPI\nclass DefaultCallbacks(metaclass=_CallbackMeta):\n    \"\"\"Abstract base class for RLlib callbacks (similar to Keras callbacks).These callbacks can be used for custom metrics and custom postprocessing.By default, all of these callbacks are no-ops.",
        "b6678ac7-e167-4996-a90c-05baeb92ec70": "The latest Ray Java snapshot can be found in sonatype repository. To use the latest Ray Java snapshot in your application, add the following entries in your pom.xml:\n<!-- only needed for snapshot version of ray -->\n<repositories>\n  <repository>\n    <id>sonatype</id>\n    <url>https://oss.sonatype.org/content/repositories/snapshots/</url>\n    <releases>\n      <enabled>false</enabled>\n    </releases>\n    <snapshots>\n      <enabled>true</enabled>\n    </snapshots>\n  </repository>\n</repositories>\n\n<dependencies>\n  <dependency>\n    <groupId>io.ray</groupId>\n    <artifactId>ray-api</artifactId>\n    <version>${ray.version}</version>\n  </dependency>\n  <dependency>\n    <groupId>io.ray</groupId>\n    <artifactId>ray-runtime</artifactId>\n    <version>${ray.version}</version>\n  </dependency>\n</dependencies>\n\n\n\nNote\nWhen you run pip install to install Ray, Java jars are installed as well. The above dependencies are only used to build your Java code and to run your code in local mode.\nIf you want to run your Java code in a multi-node Ray cluster, it\u2019s better to exclude Ray jars when packaging your code to avoid jar conficts if the versions (installed Ray with pip install and maven dependencies) don\u2019t match.",
        "9e55dfe0-bc07-4c2c-8492-86863a489372": "Define the Training Loop#\nHere we define a training loop for each worker. Compare with the original PyTorch Lightning code, there are 3 main differences:\n\nDistributed strategy: Use RayDDPStrategy.\nCluster environment: Use RayLightningEnvironment.\nParallel devices: Always sets to devices=\"auto\" to use all available devices configured by TorchTrainer.\n\nPlease refer to Getting Started with PyTorch Lightning.\nFor checkpoint reportining, Ray Train provides a minimal RayTrainReportCallback that reports metrics and checkpoint on each train epoch end. For more complex checkpoint logic, please implement custom callbacks as described in Saving and Loading Checkpoint user guide.\n\n\nuse_gpu = True # Set it to False if you want to run without GPUs\nnum_workers = 4",
        "2c756da0-ff54-44b9-979e-2768c3288a27": "@PublicAPI\ndef copy_torch_tensors(x: TensorStructType, device: Optional[str] = None):\n    \"\"\"Creates a copy of `x` and makes deep copies torch.Tensors in x.\n\n    Also moves the copied tensors to the specified device (if not None).\n\n    Note if an object in x is not a torch.Tensor, it will be shallow-copied.\n\n    Args:\n        x : Any (possibly nested) struct possibly containing torch.Tensors.\n        device : The device to move the tensors to.\n\n    Returns:\n        Any: A new struct with the same structure as `x`, but with all\n            torch.Tensors deep-copied and moved to the specified device.\n\n    \"\"\"\n\n    def mapping(item):\n        if isinstance(item, torch.Tensor):\n            return (\n                torch.clone(item.detach())\n                if device is None\n                else item.detach().to(device)\n            )\n        else:\n            return item\n\n    return tree.map_structure(mapping, x)",
        "10579eeb-9098-4750-a93a-4e5851e08733": "CSV#\n\n\n\n\n\n\nread_csv(paths,\u00a0*[,\u00a0filesystem,\u00a0...])\nCreates a Dataset from CSV files.\n\nDataset.write_csv(path,\u00a0*[,\u00a0filesystem,\u00a0...])\nWrites the Dataset to CSV files.",
        "2cfb6ada-7bf7-41a8-a43e-2fff1d9f0683": "attempt_number: The attempt number of the task if getting logs generated by a task._interval: The interval in secs to print new logs when `follow=True`.Return:\n        A Generator of log line, None for SendType and ReturnType.Raises:\n        Exceptions: :class:`RayStateApiException <ray.util.state.exception.RayStateApiException>` if the CLI\n            failed to query the data.\n    \"\"\"",
        "b0b9528b-a6a0-4ed6-a4a6-06431482a27f": "ray.data.Dataset.sum#\n\n\nDataset.sum(on: Optional[Union[str, List[str]]] = None, ignore_nulls: bool = True) \u2192 Union[Any, Dict[str, Any]][source]#\nCompute the sum of one or more columns.\n\nNote\nThis operation will trigger execution of the lazy transformations performed on this dataset.\n\nExamples\n>>> import ray\n>>> ray.data.range(100).sum(\"id\")\n4950\n>>> ray.data.from_items([\n...     {\"A\": i, \"B\": i**2}\n...     for i in range(100)\n... ]).sum([\"A\", \"B\"])\n{'sum(A)': 4950, 'sum(B)': 328350}\n\n\n\nParameters\n\non \u2013 a column name or a list of column names to aggregate.\nignore_nulls \u2013 Whether to ignore null values. If True, null\nvalues are ignored when computing the sum. If False,\nwhen a null value is encountered, the output is None.\nRay Data considers np.nan, None, and pd.NaT to be null\nvalues. Default is True.\n\n\nReturns\nThe sum result.\nFor different values of on, the return varies:\n\non=None: a dict containing the column-wise sum of all\ncolumns,\non=\"col\": a scalar representing the sum of all items in\ncolumn \"col\",\non=[\"col_1\", ..., \"col_n\"]: an n-column dict\ncontaining the column-wise sum of the provided columns.\n\nIf the dataset is empty, all values are null. If ignore_nulls is\nFalse and any value is null, then the output is None.",
        "fb3b5325-b896-476f-8b2c-a577f08fdab5": "Using the Memory Monitor#",
        "99204f19-2c5c-4127-8f3d-a010f81722c7": "# `unsquash_actions` is None: Use value of config['normalize_actions'].if unsquash_actions is None:\n            unsquash_actions = self.config.normalize_actions\n        # `clip_actions` is None: Use value of config['clip_actions'].elif clip_actions is None:\n            clip_actions = self.config.clip_actions\n\n        # Preprocess obs and states.",
        "cb1cc4dc-96ab-438a-9871-86a6ddc882fc": "Step 4: Verify TLS authentication#\n# Log in to the worker Pod\nkubectl exec -it ${WORKER_POD} -- bash\n\n# Since the head Pod has the certificate of the full qualified DNS resolution for the Ray head service, the connection to the worker Pods\n# is established successfully\nray health-check --address service-ray-head.default.svc.cluster.local:6379\n\n# Since service-ray-head hasn't added to the alt_names section in the certificate, the connection fails and an error\n# message similar to the following is displayed: \"Peer name service-ray-head is not in peer certificate\".\nray health-check --address service-ray-head:6379\n\n# After you add `DNS.3 = service-ray-head` to the alt_names sections and deploy the YAML again, the connection is able to work.\n\n\nEnabling TLS causes a performance hit due to the extra overhead of mutual\nauthentication and encryption.\nTesting has shown that this overhead is large for small workloads and becomes\nrelatively smaller for large workloads.\nThe exact overhead depends on the nature of your workload.",
        "f3d01534-038f-4360-a669-d281788ec33e": "Start with the one from the config, which\n        # might be None in older checkpoints (nowadays AlgorithmConfig has a proper\n        # default for this); Need to cover this situation via the backup lambda here.self.policy_mapping_fn = (\n            lambda agent_id, episode, worker, **kw: DEFAULT_POLICY_ID\n        )\n        self.set_policy_mapping_fn(self.config.policy_mapping_fn)\n\n        self.env_creator: EnvCreator = env_creator\n        # Resolve possible auto-fragment length.configured_rollout_fragment_length = self.config.get_rollout_fragment_length(\n            worker_index=self.worker_index\n        )\n        self.total_rollout_fragment_length: int = (\n            configured_rollout_fragment_length * self.config.num_envs_per_worker\n        )\n        self.preprocessing_enabled: bool = not config._disable_preprocessor_api\n        self.last_batch: Optional[SampleBatchType] = None\n        self.global_vars: dict = {\n            # TODO(sven): Make this per-policy!\"timestep\": 0,\n            # Counter for performed gradient updates per policy in `self.policy_map`.",
        "651e6388-5664-45a2-a733-673396de7753": "param_indices = self.multi_gpu_param_groups[opt_idx]\n                        for param_idx, param in enumerate(parameters):\n                            if param_idx in param_indices and param.grad is not None:\n                                param.grad.data.zero_()\n                        # Recompute gradients of loss over all variables.loss_out[opt_idx].backward(retain_graph=True)\n                        grad_info.update(\n                            self.extra_grad_process(opt, loss_out[opt_idx])\n                        )\n\n                        grads = []\n                        # Note that return values are just references;\n                        # Calling zero_grad would modify the values.",
        "91ee936c-a55a-4ebc-904f-8cb45c03669d": "try:\n                i.record_stream(curr_stream)\n            except AttributeError:\n                pass\n\n    def __len__(self):\n        return len(self._dataloader)\n\n    def _prefetch_next_batch(self):\n        next_batch = next(self.dataloader_iter, None)\n        self.next_batch = self._move_to_device(next_batch)\n\n    def __iter__(self):\n        self.dataloader_iter = iter(self._dataloader)\n        self._prefetch_next_batch()\n        return self\n\n    def __next__(self):\n        next_batch = self.next_batch\n        if next_batch is None:\n            raise StopIteration\n        self._wait_for_batch(next_batch)\n        self._prefetch_next_batch()\n        return next_batch\n\n\nclass _WrappedOptimizer(Optimizer):\n    def __init__(self, optimizer: Optimizer, scaler: Optional[GradScaler] = None):\n        self.optimizer = optimizer\n        self.scaler = scaler\n\n    @property\n    def state(self):\n        return self.optimizer.state\n\n    @state.setter\n    def state(self,",
        "ef88c71a-20ff-43aa-adf8-94405c21010c": "GCS Fault Tolerance#\nIn addition to the application-level fault-tolerance provided by the RayService controller,\nRay now supports infrastructure-level fault tolerance for the Ray head pod.\nYou can set up an external Redis instance as a data store for the Ray head. If the Ray head crashes,\na new head will be created without restarting the Ray cluster.\nThe Ray head\u2019s GCS will recover its state from the external Redis instance.\nSee the Ray Serve documentation for more information and\nthe KubeRay docs on GCS Fault Tolerance for a detailed guide.",
        "bda71e34-4101-4ba4-9286-ad4bf3b77e6c": ")\n        blocks = self.get_internal_block_refs()\n        output = DelegatingBlockBuilder()\n        for block in blocks:\n            output.add_block(ray.get(block))\n        block = output.build()\n        return _block_to_df(block)\n\n[docs]    @ConsumptionAPI(pattern=\"Time complexity:\")\n    @DeveloperAPI\n    def to_pandas_refs(self) -> List[ObjectRef[\"pandas.DataFrame\"]]:\n        \"\"\"Converts this :class:`~ray.data.Dataset` into a distributed set of Pandas\n        dataframes.One DataFrame is created for each block in this Dataset.This function induces a copy of the data.For zero-copy access to the\n        underlying data, consider using :meth:`Dataset.to_arrow` or\n        :meth:`Dataset.get_internal_block_refs`.Examples:\n            >>> import ray\n            >>> ds = ray.data.range(10, parallelism=2)\n            >>> refs = ds.to_pandas_refs()\n            >>> len(refs)\n            2\n\n        Time complexity: O(dataset size / parallelism)\n\n        Returns:\n            A list of remote pandas DataFrames created from this dataset.\n        \"\"\"",
        "07ac20f9-e0d4-4b1e-a320-37147db3f5d2": "59) Auto configuring locality_with_output=['6002ded0aaa53ce9a0351d22a72b344ef411a422919132f41d9f937a', 'd3bbd390b6fe73f26202f96d75998946cf3e8b457528d426db0c6e07', 'fe6aaf54317ee630a02d23e0d49581b57b5cd51316eaf769e28bb045', 'f7de4694a4f764c05a9c51a6a4bd40ac33f3fced3b25127b25cd4ac3', '42866a2fba4ce2ab4b6645c4d731d486b762e2b23ac24cafccba7096', '8a7272830662c7e756a656de0a9b433a3a1f9b990768f692b6fe11a7', 'bba62e8b57552509c62a6b6b7fd67c1a2280b9d81b3d9c41eb4d1b9b', 'b40764f303538c24bc439106f2e7b2144d382bfed6c9fdec15ab828e', 'd1de4d4b6d44eff93857026df4ef0f70e24e3dc91e15d87015f2ed32', '4d6a9dc1aa7bfc80cb73d9f66f4e28041807f12769391f5643bce143', '8bcc7235f459b61be21fe158d0bae4fef2ec6de013ec60e7aaf7897a',",
        "e02b28af-bb3a-4bf1-82e4-94b8dcf3bcfe": "Configuring the autoscaler#\nFor large, long running clusters, there are a few parameters that can be tuned.\n\nEnsure your quotas for node types are set correctly.\nFor long running clusters, set the AUTOSCALER_MAX_NUM_FAILURES environment\nvariable to a large number (or inf) to avoid unexpected autoscaler\ncrashes. The variable can be set by prepending export AUTOSCALER_MAX_NUM_FAILURES=inf;\nto the head node\u2019s Ray start command.\n(Note: you may want a separate mechanism to detect if the autoscaler\nerrors too often).\nFor large clusters, consider tuning upscaling_speed for faster\nautoscaling.",
        "3070edc7-5e65-48b4-a29b-98ec52601e43": "tuner = tune.Tuner(\n                train_func,\n                param_space={\n                    \"lr\": tune.grid_search([0.001, 0.01, 0.1, 1.0]),\n                    \"epochs\": 10,\n                },\n                run_config=RunConfig(\n                    callbacks=[WandbLoggerCallback(project=\"Optimization_Project\")]\n                ),\n            )\n            results = tuner.fit()\n\n        .. testoutput::\n            :hide:\n\n            ...\n\n    Args:\n        project: Name of the Wandb project.Mandatory.group: Name of the Wandb group.Defaults to the trainable\n            name.api_key_file: Path to file containing the Wandb API KEY.This\n            file only needs to be present on the node running the Tune script\n            if using the WandbLogger.api_key: Wandb API Key.Alternative to setting ``api_key_file``.excludes: List of metrics and config that should be excluded from\n            the log.",
        "8d8f1dbd-648f-44c6-a554-93beec1ddd73": "Quickstart#\nInstall Ray Serve and its dependencies:\npip install \"ray[serve]\"\n\n\nDefine a simple \u201chello world\u201d application, run it locally, and query it over HTTP.\nimport requests\nfrom starlette.requests import Request\nfrom typing import Dict\n\nfrom ray import serve\n\n\n# 1: Define a Ray Serve application.\n@serve.deployment(route_prefix=\"/\")\nclass MyModelDeployment:\n    def __init__(self, msg: str):\n        # Initialize model state: could be very large neural net weights.\n        self._msg = msg\n\n    def __call__(self, request: Request) -> Dict:\n        return {\"result\": self._msg}\n\n\napp = MyModelDeployment.bind(msg=\"Hello world!\")\n\n# 2: Deploy the application locally.\nserve.run(app)\n\n# 3: Query the application and print the result.\nprint(requests.get(\"http://localhost:8000/\").json())\n# {'result': 'Hello world!'}",
        "49ffb5b3-396b-4eb2-8d5d-bc1457e1a861": "on_evaluate_end(*, algorithm: Algorithm, evaluation_metrics: dict, **kwargs) \u2192 None[source]#\nRuns when the evaluation is done.\nRuns at the end of Algorithm.evaluate().\n\nParameters\n\nalgorithm \u2013 Reference to the algorithm instance.\nevaluation_metrics \u2013 Results dict to be returned from algorithm.evaluate().\nYou can mutate this object to add additional metrics.\nkwargs \u2013 Forward compatibility placeholder.\n\n\n\n\n\n\non_postprocess_trajectory(*, worker: RolloutWorker, episode: ray.rllib.evaluation.episode.Episode, agent_id: Any, policy_id: str, policies: Dict[str, ray.rllib.policy.policy.Policy], postprocessed_batch: ray.rllib.policy.sample_batch.SampleBatch, original_batches: Dict[Any, Tuple[ray.rllib.policy.policy.Policy, ray.rllib.policy.sample_batch.SampleBatch]], **kwargs) \u2192 None[source]#\nCalled immediately after a policy\u2019s postprocess_fn is called.\nYou can use this callback to do additional postprocessing for a policy,\nincluding looking at the trajectory data of other agents in multi-agent\nsettings.\n\nParameters\n\nworker \u2013 Reference to the current rollout worker.\nepisode \u2013 Episode object.\nagent_id \u2013 Id of the current agent.\npolicy_id \u2013 Id of the current policy for the agent.\npolicies \u2013 Mapping of policy id to policy objects. In single\nagent mode there will only be a single \u201cdefault_policy\u201d.\npostprocessed_batch \u2013 The postprocessed sample batch\nfor this agent. You can mutate this object to apply your own\ntrajectory postprocessing.\noriginal_batches \u2013 Mapping of agents to their unpostprocessed\ntrajectory data. You should not mutate this object.\nkwargs \u2013 Forward compatibility placeholder.",
        "e1e7873e-ffb5-4bd7-bf29-cf72884955de": "ray.rllib.models.tf.tf_modelv2.TFModelV2#\n\n\nclass ray.rllib.models.tf.tf_modelv2.TFModelV2(obs_space: <MagicMock name='mock.spaces.Space' id='140124479140000'>, action_space: <MagicMock name='mock.spaces.Space' id='140124479140000'>, num_outputs: int, model_config: dict, name: str)[source]#\nBases: ray.rllib.models.modelv2.ModelV2\nTF version of ModelV2, which should contain a tf keras Model.\nNote that this class by itself is not a valid model unless you\nimplement forward() in a subclass.\nMethods\n\n\n\n\n\n\n__init__(obs_space,\u00a0action_space,\u00a0...)\nInitializes a TFModelV2 instance.\n\ncontext()\nReturns a contextmanager for the current TF graph.\n\ncustom_loss(policy_loss,\u00a0loss_inputs)\nOverride to customize the loss function used to optimize this model.\n\nforward(input_dict,\u00a0state,\u00a0seq_lens)\nCall the model with the given input tensors and state.\n\nget_initial_state()\nGet the initial recurrent state values for the model.\n\nimport_from_h5(h5_file)\nImports weights from an h5 file.\n\nis_time_major()\nIf True, data for calling this ModelV2 must be in time-major format.\n\nlast_output()\nReturns the last output returned from calling the model.\n\nmetrics()\nOverride to return custom metrics from your model.\n\nregister_variables(variables)\nRegister the given list of variables with this model.\n\nupdate_ops()\nReturn the list of update ops for this model.\n\nvalue_function()\nReturns the value function output for the most recent forward pass.",
        "5ea3e811-4056-4992-8520-eaf85d59c2be": "if key == SampleBatch.DONES:\n            raise KeyError(\n                \"Cannot set `DONES` anymore in a SampleBatch! \"\"Instead, set the new TERMINATEDS and TRUNCATEDS keys.The values under\"\n                \" DONES will then be automatically computed using terminated|truncated.\")\n        # Defend against creating SampleBatch via pickle (no property\n        # `added_keys` and first item is already set).elif not hasattr(self, \"added_keys\"):\n            dict.__setitem__(self, key, item)\n            return\n\n        # Backward compatibility for when \"input-dicts\" were used.if key == \"is_training\":\n            if log_once(\"SampleBatch['is_training']\"):\n                deprecation_warning(\n                    old=\"SampleBatch['is_training']\",\n                    new=\"SampleBatch.is_training\",\n                    error=False,\n                )\n            self._is_training = item\n            return\n\n        if key not in self:\n            self.added_keys.",
        "e258aa7a-c142-498a-baa7-c6b7a1c0187c": "iter_torch_batches(*[,\u00a0prefetch_batches,\u00a0...])\nReturn an iterator over batches of data represented as Torch tensors.iterator()\nReturn a DataIterator over this dataset.lazy()\nEnable lazy evaluation.limit(limit)\nTruncate the dataset to the first limit rows.map(fn,\u00a0*[,\u00a0compute,\u00a0fn_constructor_args,\u00a0...])\nApply the given function to each row of this dataset.map_batches(fn,\u00a0*[,\u00a0batch_size,\u00a0compute,\u00a0...])\nApply the given function to batches of data.materialize()\nExecute and materialize this dataset into object store memory.max([on,\u00a0ignore_nulls])\nReturn the maximum of one or more columns.mean([on,\u00a0ignore_nulls])\nCompute the mean of one or more columns.min([on,\u00a0ignore_nulls])\nReturn the minimum of one or more columns.num_blocks()\nReturn the number of blocks of this dataset.random_sample(fraction,\u00a0*[,\u00a0seed])\nReturns a new Dataset containing a random fraction of the rows.random_shuffle(*[,\u00a0seed,\u00a0num_blocks])\nRandomly shuffle the rows of this Dataset.randomize_block_order(*[,\u00a0seed])\nRandomly shuffle the blocks of this Dataset.repartition(num_blocks,\u00a0*[,\u00a0shuffle])\nRepartition the Dataset into exactly this number of blocks.repeat([times])\nConvert this into a DatasetPipeline by looping over this dataset.schema([fetch_if_missing])\nReturn the schema of the dataset.select_columns(cols,\u00a0*[,\u00a0compute])\nSelect one or more columns from the dataset.serialize_lineage()\nSerialize this dataset's lineage, not the actual data or the existing data futures, to bytes that can be stored and later deserialized, possibly on a different cluster.show([limit])\nPrint up to the given number of rows from the Dataset.",
        "019e503c-f173-46b2-9ecb-d07da755c3a4": "def _prepare_progress_reporter_for_ray_client(\n    progress_reporter: ProgressReporter,\n    verbosity: Union[int, Verbosity],\n    string_queue: Optional[Queue] = None,\n) -> Tuple[ProgressReporter, Queue]:\n    \"\"\"Prepares progress reported for Ray Client by setting the string queue.\n\n    The string queue will be created if it's None.\"\"\"\n    set_verbosity(verbosity)\n    progress_reporter = progress_reporter or _detect_reporter()\n\n    # JupyterNotebooks don't work with remote tune runs out of the box\n    # (e.g. via Ray client) as they don't have access to the main\n    # process stdout. So we introduce a queue here that accepts\n    # strings, which will then be displayed on the driver side.\n    if isinstance(progress_reporter, RemoteReporterMixin):\n        if string_queue is None:\n            string_queue = Queue(\n                actor_options={\"num_cpus\": 0, **_force_on_current_node(None)}\n            )\n        progress_reporter.output_queue = string_queue\n\n    return progress_reporter, string_queue",
        "72eadc9e-92ff-4176-851a-44f42bb07428": "Uploads#\nIf a working_dir is specified in the runtime env, when running ray.init() the Ray client will upload the working_dir on the laptop to /tmp/ray/session_latest/runtime_resources/_ray_pkg_<hash of directory contents>.\nRay workers are started in the /tmp/ray/session_latest/runtime_resources/_ray_pkg_<hash of directory contents> directory on the cluster. This means that relative paths in the remote tasks and actors in the code will work on the laptop and on the cluster without any code changes. For example, if the working_dir on the laptop contains data.txt and run.py, inside the remote task definitions in run.py one can just use the relative path \"data.txt\". Then python run.py will work on my laptop, and also on the cluster. As a side note, since relative paths can be used in the code, the absolute path is only useful for debugging purposes.",
        "b960a7eb-5204-4f99-9473-82fe17dfc61e": "ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule.value#\n\n\nExponentialSchedule.value(t: Union[int, numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor]) \u2192 Any#\nGenerates the value given a timestep (based on schedule\u2019s logic).\n\nParameters\nt \u2013 The time step. This could be a tf.Tensor.\n\nReturns\nThe calculated value depending on the schedule and t.",
        "2a48f762-5834-4aed-aad4-d9d6b5db1040": "seq_lens_ = self.get(SampleBatch.SEQ_LENS)\n        if seq_lens_ is None or (isinstance(seq_lens_, list) and len(seq_lens_) == 0):\n            self.pop(SampleBatch.SEQ_LENS, None)\n        # Numpyfy seq_lens if list.",
        "ae55b3a3-ef45-43e2-823f-04d776f09da4": "self._points_to_evaluate,\n                self._evaluated_rewards,\n            )\n            if self._evaluated_rewards:\n                self._opt.observe(\n                    pd.DataFrame(self._points_to_evaluate),\n                    np.array(self._evaluated_rewards) * self._metric_op,\n                )\n            else:\n                self._initial_points = self._points_to_evaluate\n\n    def set_search_properties(\n        self, metric: Optional[str], mode: Optional[str], config: Dict, **spec\n    ) -> bool:\n        if self._opt:\n            return False\n        space = self.convert_search_space(config)\n        self._space = space\n\n        if metric:\n            self._metric = metric\n        if mode:\n            self._mode = mode\n\n        self._setup_optimizer()\n        return True\n\n    def suggest(self,",
        "7229ae73-1db5-4bb3-b204-80daf6c13578": "ray.tune.integration.lightgbm.TuneReportCheckpointCallback#\n\n\nclass ray.tune.integration.lightgbm.TuneReportCheckpointCallback(metrics: Optional[Union[str, List[str], Dict[str, str]]] = None, filename: str = 'checkpoint', frequency: int = 1, results_postprocessing_fn: Optional[Callable[[Dict[str, Union[float, List[float]]]], Dict[str, float]]] = None)[source]#\nBases: ray.tune.integration.lightgbm.TuneCallback\nCreates a callback that reports metrics and checkpoints model.\nSaves checkpoints after each validation step. Also reports metrics to Tune,\nwhich is needed for checkpoint registration.\n\nParameters\n\nmetrics \u2013 Metrics to report to Tune. If this is a list,\neach item describes the metric key reported to LightGBM,\nand it will be reported under the same name to Tune. If this is a\ndict, each key will be the name reported to Tune and the respective\nvalue will be the metric key reported to LightGBM.\nfilename \u2013 Filename of the checkpoint within the checkpoint\ndirectory. Defaults to \u201ccheckpoint\u201d. If this is None,\nall metrics will be reported to Tune under their default names as\nobtained from LightGBM.\nfrequency \u2013 How often to save checkpoints. Defaults to 0 (no checkpoints\nare saved during training). A checkpoint is always saved at the end\nof training.\nresults_postprocessing_fn \u2013 An optional Callable that takes in\nthe dict that will be reported to Tune (after it has been flattened)\nand returns a modified dict that will be reported instead.",
        "5caeceef-e88b-4cf7-aa5c-c0f47f91b628": "ray.data.preprocessor.Preprocessor.transform_batch#\n\n\nPreprocessor.transform_batch(data: DataBatchType) \u2192 DataBatchType[source]#\nTransform a single batch of data.\nThe data will be converted to the format supported by the Preprocessor,\nbased on which _transform_* methods are implemented.\n\nParameters\ndata \u2013 Input data batch.\n\nReturns\nThe transformed data batch. This may differ\nfrom the input type depending on which _transform_* methods\nare implemented.\n\nReturn type\nDataBatchType",
        "711db2c2-8063-4f1e-b8f3-9c93dbaa1b3b": "Reading files#\nRay Data reads files from local disk or cloud storage in a variety of file formats.\nTo view the full list of supported file formats, see the\nInput/Output reference.\n\n\n\nParquet\nTo read Parquet files, call read_parquet().\nimport ray\n\nds = ray.data.read_parquet(\"local:///tmp/iris.parquet\")\n\nprint(ds.schema())\n\n\nColumn        Type\n------        ----\nsepal.length  double\nsepal.width   double\npetal.length  double\npetal.width   double\nvariety       string\n\n\n\n\n\nImages\nTo read raw images, call read_images(). Ray Data represents\nimages as NumPy ndarrays.\nimport ray\n\nds = ray.data.read_images(\"local:///tmp/batoidea/JPEGImages/\")\n\nprint(ds.schema())\n\n\nColumn  Type\n------  ----\nimage   numpy.ndarray(shape=(32, 32, 3), dtype=uint8)\n\n\n\n\n\nText\nTo read lines of text, call read_text().\nimport ray\n\nds = ray.data.read_text(\"local:///tmp/this.txt\")\n\nprint(ds.schema())\n\n\nColumn  Type\n------  ----\ntext    string\n\n\n\n\n\nCSV\nTo read CSV files, call read_csv().\nimport ray\n\nds = ray.data.read_csv(\"local:///tmp/iris.csv\")\n\nprint(ds.schema())\n\n\nColumn             Type\n------             ----\nsepal length (cm)  double\nsepal width (cm)   double\npetal length (cm)  double\npetal width (cm)   double\ntarget             int64",
        "86121a35-cd6b-478e-8e3a-85a9101b3eda": "ray.rllib.policy.sample_batch.SampleBatch.CUR_OBS#\n\n\nSampleBatch.CUR_OBS = 'obs'#",
        "60ad83e8-a4e3-44bc-8847-296f3162ea52": "Java\n// Create ten Counter actors.\nList<ActorHandle<Counter>> counters = new ArrayList<>();\nfor (int i = 0; i < 10; i++) {\n    counters.add(Ray.actor(Counter::new).remote());\n}\n\n// Increment each Counter once and get the results. These tasks all happen in\n// parallel.\nList<ObjectRef<Integer>> objectRefs = new ArrayList<>();\nfor (ActorHandle<Counter> counterActor : counters) {\n    objectRefs.add(counterActor.task(Counter::increment).remote());\n}\n// prints [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nSystem.out.println(Ray.get(objectRefs));\n\n// Increment the first Counter five times. These tasks are executed serially\n// and share state.\nobjectRefs = new ArrayList<>();\nfor (int i = 0; i < 5; i++) {\n    objectRefs.add(counters.get(0).task(Counter::increment).remote());\n}\n// prints [2, 3, 4, 5, 6]\nSystem.out.println(Ray.get(objectRefs));",
        "12a77f5b-be8f-4c0b-af16-0be04d074aa1": "mean_results_per_model = []\n    for model_results in fold_results_per_model:\n        aggregated_results = defaultdict(list)\n        for fold_result in model_results:\n            for metric, value in fold_result.items():\n                aggregated_results[metric].append(value)\n        mean_results = {\n            metric: np.mean(values) for metric, values in aggregated_results.items()\n        }\n        mean_results_per_model.append(mean_results)\n\n    # Join models and their metrics together.mean_results_per_model = {\n        models[i]: mean_results_per_model[i] for i in range(len(mean_results_per_model))\n    }\n    return mean_results_per_model",
        "0b3897e9-9ed6-4b3d-9467-044d4f65b217": "5MB/s]\nDownloading:  24%|\u2588\u2588\u258d       | 99.9M/416M [00:01<00:04, 79.3MB/s]\nDownloading:  26%|\u2588\u2588\u258c       | 108M/416M [00:01<00:04, 80.3MB/s] \nDownloading:  28%|\u2588\u2588\u258a       | 116M/416M [00:01<00:04, 78.3MB/s]\nDownloading:  30%|\u2588\u2588\u2589       | 123M/416M [00:01<00:03, 79.3MB/s]\nDownloading:  31%|\u2588\u2588\u2588\u258f      | 131M/416M [00:01<00:04, 72.6MB/s]\nDownloading:  34%|\u2588\u2588\u2588\u258e      | 139M/416M [00:01<00:03, 76.8MB/s]\nDownloading:  35%|\u2588\u2588\u2588\u258c      | 147M/416M [00:02<00:03, 79.2MB/s]\nDownloading:  37%|\u2588\u2588\u2588\u258b      | 155M/416M [00:02<00:03, 77.9MB/s]\nDownloading:  39%|\u2588\u2588\u2588\u2589      | 163M/416M [00:02<00:03, 67.7MB/s]\nDownloading:  42%|\u2588\u2588\u2588\u2588\u258f     | 173M/416M [00:02<00:03, 79.2MB/s]\nDownloading:  44%|\u2588\u2588\u2588\u2588\u258e     | 182M/416M [00:02<00:02, 81.",
        "62eac653-f08d-40c7-a133-0a4d6f36f7cb": "Example:\n\n        Per default, you can just call ``setup_mlflow`` and continue to use\n        MLflow like you would normally do:\n\n        .. code-block:: python\n\n            from ray.air.integrations.mlflow import setup_mlflow\n\n            def training_loop(config):\n                mlflow = setup_mlflow(config)\n                # ...\n                mlflow.log_metric(key=\"loss\", val=0.123, step=0)\n\n        In distributed data parallel training, you can utilize the return value of\n        ``setup_mlflow``.This will make sure it is only invoked on the first worker\n        in distributed training runs... code-block:: python\n\n            from ray.air.integrations.mlflow import setup_mlflow\n\n            def training_loop(config):\n                mlflow = setup_mlflow(config)\n                # ...\n                mlflow.log_metric(key=\"loss\", val=0.123, step=0)\n\n\n        You can also use MlFlow's autologging feature if using a training\n        framework like Pytorch Lightning, XGBoost, etc.More information can be\n        found here\n        (https://mlflow.org/docs/latest/tracking.html#automatic-logging).",
        "ee6a8cc6-bbf5-4278-87e9-ccc3e9475026": "or \"\n                    \"`ConfigSpace.hyperparameters.Hyperparameter` \"\n                    \"instance when using bohb search\")\n\n\n[docs]class TuneSearchCV(TuneBaseSearchCV):\n    \"\"\"Generic, non-grid search on hyper parameters.Randomized search is invoked with ``search_optimization`` set to\n    ``\"random\"`` and behaves like scikit-learn's ``RandomizedSearchCV``.Bayesian search can be invoked with several values of\n    ``search_optimization``.- ``\"bayesian\"``, using https://scikit-optimize.github.io/stable/\n     - ``\"bohb\"``, using HpBandSter - https://github.com/automl/HpBandSter\n\n    Tree-Parzen Estimators search is invoked with ``search_optimization``\n    set to ``\"hyperopt\"``, using HyperOpt - http://hyperopt.github.io/hyperopt\n\n    All types of search aside from Randomized search require parent\n    libraries to be installed.TuneSearchCV implements a \"fit\" and a \"score\" method.It also implements \"predict\", \"predict_proba\", \"decision_function\",\n    \"transform\" and \"inverse_transform\" if they are implemented in the\n    estimator used.The parameters of the estimator used to apply these methods are optimized\n    by cross-validated search over parameter settings.In contrast to GridSearchCV, not all parameter values are tried out, but\n    rather a fixed number of parameter settings is sampled from the specified\n    distributions.The number of parameter settings that are tried is\n    given by n_trials.Args:\n        estimator (`estimator`): This is assumed to implement the\n            scikit-learn estimator interface.",
        "c1088fa4-765c-4e23-96a7-f7b4658750eb": "# __sphinx_doc_end__\n        # fmt: on\n\n[docs]    @override(AlgorithmConfig)\n    def training(\n        self,\n        *,\n        action_noise_std: Optional[float] = NotProvided,\n        l2_coeff: Optional[float] = NotProvided,\n        noise_stdev: Optional[int] = NotProvided,\n        episodes_per_batch: Optional[int] = NotProvided,\n        eval_prob: Optional[float] = NotProvided,\n        # return_proc_mode: Optional[int] = NotProvided,\n        stepsize: Optional[float] = NotProvided,\n        noise_size: Optional[int] = NotProvided,\n        report_length: Optional[int] = NotProvided,\n        tf_single_threaded: Optional[bool] = NotProvided,\n        **kwargs,\n    ) -> \"ESConfig\":\n        \"\"\"Sets the training related configuration.Args:\n            action_noise_std: Std.deviation to be used when adding (standard normal)\n                noise to computed actions.Action noise is only added, if\n                `compute_actions` is called with the `add_noise` arg set to True.l2_coeff: Coefficient to multiply current weights with inside the globalg\n                optimizer update term.noise_stdev: Std.deviation of parameter noise.",
        "c7103200-e8ff-40d3-ae22-6ab55e4b7178": "ray.train.huggingface.TransformersCheckpoint.get_model#\n\n\nTransformersCheckpoint.get_model(model: Union[Type[transformers.modeling_utils.PreTrainedModel], torch.nn.modules.module.Module], **pretrained_model_kwargs) \u2192 Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module][source]#\nRetrieve the model stored in this checkpoint.",
        "fbf12b71-8ef8-46b7-a5cc-9b1bad0852f1": "Without windowing::\n\n            [preprocessing......]\n                                  [inference.......]\n                                                     [write........]\n            Time ----------------------------------------------------------->\n\n        With windowing::\n\n            [prep1] [prep2] [prep3]\n                    [infer1] [infer2] [infer3]\n                             [write1] [write2] [write3]\n            Time ----------------------------------------------------------->\n\n        Examples:\n            >>> import ray\n            >>> # Create an inference pipeline.>>> ds = ray.data.read_binary_files(dir) # doctest: +SKIP\n            >>> infer = ... # doctest: +SKIP\n            >>> pipe = ds.window(blocks_per_window=10).map(infer) # doctest: +SKIP\n            DatasetPipeline(num_windows=40, num_stages=2)\n            >>> # The higher the stage parallelism, the shorter the pipeline.",
        "170c2e34-c5da-4117-ad6b-de1a602e95a8": "ray.tune.search.dragonfly.DragonflySearch#\n\n\nclass ray.tune.search.dragonfly.DragonflySearch(optimizer: Optional[str] = None, domain: Optional[str] = None, space: Optional[Union[Dict, List[Dict]]] = None, metric: Optional[str] = None, mode: Optional[str] = None, points_to_evaluate: Optional[List[Dict]] = None, evaluated_rewards: Optional[List] = None, random_state_seed: Optional[int] = None, **kwargs)[source]#\nBases: ray.tune.search.searcher.Searcher\nUses Dragonfly to optimize hyperparameters.\nDragonfly provides an array of tools to scale up Bayesian optimisation to\nexpensive large scale problems, including high dimensional optimisation.\nparallel evaluations in synchronous or asynchronous settings,\nmulti-fidelity optimisation (using cheap approximations to speed up the\noptimisation process), and multi-objective optimisation. For more info:\n\nDragonfly Website: https://github.com/dragonfly/dragonfly\nDragonfly Documentation: https://dragonfly-opt.readthedocs.io/\n\nTo use this search algorithm, install Dragonfly:\n$ pip install dragonfly-opt",
        "ace2a4ee-5cff-4261-86a9-4ca603b03026": "ray.runtime_context.RuntimeContext.get_assigned_resources#\n\n\nRuntimeContext.get_assigned_resources()[source]#\nGet the assigned resources to this worker.\nBy default for tasks, this will return {\u201cCPU\u201d: 1}.\nBy default for actors, this will return {}. This is because\nactors do not have CPUs assigned to them by default.\n\nReturns\nA dictionary mapping the name of a resource to a float, where\nthe float represents the amount of that resource reserved\nfor this worker.",
        "ab16e6b4-6fd8-41bb-a03c-da4e25c8fb0c": "_epoch)\n        pipe = DatasetPipeline(it, False, length=len(it._splits))\n        if read_stage:\n            pipe = pipe.foreach_window(\n                lambda ds, read_stage=read_stage: Dataset(\n                    ds._plan.with_stage(read_stage), ds._epoch, True\n                )\n            )\n        return pipe\n\n[docs]    @Deprecated(message=\"Use `Dataset.materialize()` instead.\")def fully_executed(self) -> \"MaterializedDataset\":\n        logger.warning(\n            \"Deprecation warning: use Dataset.materialize() instead of \"\n            \"fully_executed().\")\n        self._plan.execute(force_read=True)\n        return self\n\n[docs]    @Deprecated(message=\"Check `isinstance(Dataset, MaterializedDataset)` instead.\")def is_fully_executed(self) -> bool:\n        logger.warning(\n            \"Deprecation warning: Check \"\n            \"`isinstance(Dataset, MaterializedDataset)` \"\n            \"instead of using is_fully_executed().\")\n        return self._plan.has_computed_output()\n\n[docs]    @ConsumptionAPI(pattern=\"store memory.",
        "bb0da904-ff8d-4f21-b6c6-4f77dca18972": "How to use Tune with PyTorch#\nIn this walkthrough, we will show you how to integrate Tune into your PyTorch\ntraining workflow. We will follow this tutorial from the PyTorch documentation\nfor training a CIFAR10 image classifier.\n\nHyperparameter tuning can make the difference between an average model and a highly\naccurate one. Often simple things like choosing a different learning rate or changing\na network layer size can have a dramatic impact on your model performance. Fortunately,\nTune makes exploring these optimal parameter combinations easy - and works nicely\ntogether with PyTorch.\nAs you will see, we only need to add some slight modifications. In particular, we\nneed to\n\nwrap data loading and training in functions,\nmake some network parameters configurable,\nadd checkpointing (optional),\nand define the search space for the model tuning\n\n\nNote\nTo run this example, you will need to install the following:\n$ pip install ray torch torchvision\n\n\n\n\n\nSetup / Imports\nData loaders\nConfigurable neural network\nThe train function\nTest set accuracy\nConfiguring the search space\nSee More PyTorch Examples",
        "39ab13ac-ed9e-48d0-9c33-51b6d23d3ed1": "ray.rllib.algorithms.algorithm_config.AlgorithmConfig.update_from_dict#\n\n\nAlgorithmConfig.update_from_dict(config_dict: dict) \u2192 ray.rllib.algorithms.algorithm_config.AlgorithmConfig[source]#\nModifies this AlgorithmConfig via the provided python config dict.\nWarns if config_dict contains deprecated keys.\nSilently sets even properties of self that do NOT exist. This way, this method\nmay be used to configure custom Policies which do not have their own specific\nAlgorithmConfig classes, e.g.\nray.rllib.examples.policy.random_policy::RandomPolicy.\n\nParameters\nconfig_dict \u2013 The old-style python config dict (PartialAlgorithmConfigDict)\nto use for overriding some properties defined in there.\n\nReturns\nThis updated AlgorithmConfig object.",
        "4c5acc7c-4398-4515-864f-b4aed9ee9dd9": "ray.rllib.policy.torch_policy_v2.TorchPolicyV2.stats_fn#\n\n\nTorchPolicyV2.stats_fn(train_batch: ray.rllib.policy.sample_batch.SampleBatch) \u2192 Dict[str, Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor]][source]#\nStats function. Returns a dict of statistics.\n\nParameters\ntrain_batch \u2013 The SampleBatch (already) used for training.\n\nReturns\nThe stats dict.",
        "8690e8ca-6675-459b-bdb1-660c49a04890": "In distributed data parallel training, you can utilize the return value of\nsetup_mlflow. This will make sure it is only invoked on the first worker\nin distributed training runs.\nfrom ray.air.integrations.mlflow import setup_mlflow\n\ndef training_loop(config):\n    mlflow = setup_mlflow(config)\n    # ...\n    mlflow.log_metric(key=\"loss\", val=0.123, step=0)\n\n\nYou can also use MlFlow\u2019s autologging feature if using a training\nframework like Pytorch Lightning, XGBoost, etc. More information can be\nfound here\n(https://mlflow.org/docs/latest/tracking.html#automatic-logging).\nfrom ray.air.integrations.mlflow import setup_mlflow\n\ndef train_fn(config):\n    mlflow = setup_mlflow(config)\n    mlflow.autolog()\n    xgboost_results = xgb.train(config, ...)\n\n\nPublicAPI (alpha): This API is in alpha and may change before becoming stable.",
        "e9f100ee-f241-4182-82e7-d384e489717f": "return None\n            sum_ = block_acc.sum(on, ignore_nulls)\n            if sum_ is None:\n                # ignore_nulls=False and at least one null.return None\n            mean = sum_ / count\n            M2 = block_acc.sum_of_squared_diffs_from_mean(on, ignore_nulls, mean)\n            return [M2, mean, count]\n\n        def finalize(a: List[float]):\n            # Compute the final standard deviation from the accumulated\n            # sum of squared differences from current mean and the count.",
        "9f936f2a-daa6-43aa-89a4-186e72d4eb95": "alpha = np.array([1.0, 1.2, 3.0, 3.2])\n    A = np.array(\n        [\n            [10, 3, 17, 3.5, 1.7, 8],\n            [0.05, 10, 17, 0.1, 8, 14],\n            [3, 3.5, 1.7, 10, 17, 8],\n            [17, 8, 0.05, 10, 0.1, 14],\n        ]\n    )\n    P = 10 ** (-4) * np.array(\n        [\n            [1312, 1696, 5569, 124, 8283, 5886],\n            [2329, 4135, 8307, 3736, 1004, 9991],\n            [2348, 1451, 3522, 2883, 3047, 6650],\n            [4047, 8828, 8732, 5743, 1091, 381],\n        ]\n    )\n    y = 0.0\n    for j, alpha_j in enumerate(alpha):\n        t = 0\n        for k in range(6):\n            t += A[j, k] * ((x[k] - P[j, k]) ** 2)\n        y -= alpha_j * np.exp(-t)\n    return y",
        "0e8f0a87-7a57-4659-bf38-fda8bb61cb4c": "535736572413468\n  neg_mean_loss: 6.535736572413468\n  node_ip: 127.0.0.1\n  pid: 46969\n  time_since_restore: 9.71235203742981\n  time_this_iter_s: 0.10665416717529297\n  time_total_s: 9.71235203742981\n  timestamp: 1658500224\n  timesteps_since_restore: 0\n  training_iteration: 91\n  trial_id: cb9d338c\n  warmup_time: 0.003387928009033203\n  \nResult for objective_d229961e:\n  date: 2022-07-22_15-30-25\n  done: false\n  experiment_id: d8bb04569c644d6fabad5064c1828ba3\n  hostname: Kais-MacBook-Pro.local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 12.022300234864176\n  neg_mean_loss: -12.022300234864176\n  node_ip: 127.0.0.1\n  pid: 47009\n  time_since_restore: 0.1041719913482666\n  time_this_iter_s: 0.1041719913482666\n  time_total_s: 0.1041719913482666\n  timestamp: 1658500225\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: d229961e\n  warmup_time: 0.",
        "d8658a00-d2b8-46af-9309-13818813e377": "[docs]def init_collective_group(\n    world_size: int, rank: int, backend=types.Backend.NCCL, group_name: str = \"default\"\n):\n    \"\"\"Initialize a collective group inside an actor process.\n\n    Args:\n        world_size: the total number of processes in the group.\n        rank: the rank of the current process.\n        backend: the CCL backend to use, NCCL or GLOO.\n        group_name: the name of the collective group.\n\n    Returns:\n        None\n    \"\"\"\n    _check_inside_actor()\n    backend = types.Backend(backend)\n    _check_backend_availability(backend)\n    global _group_mgr\n    # TODO(Hao): implement a group auto-counter.\n    if not group_name:\n        raise ValueError(\"group_name '{}' needs to be a string.\".format(group_name))\n\n    if _group_mgr.is_group_exist(group_name):\n        raise RuntimeError(\"Trying to initialize a group twice.\")\n\n    assert world_size > 0\n    assert rank >= 0\n    assert rank < world_size\n    _group_mgr.create_collective_group(backend, world_size, rank, group_name)\n\n\n[docs]def create_collective_group(\n    actors,\n    world_size: int,\n    ranks: List[int],\n    backend=types.Backend.NCCL,\n    group_name: str = \"default\",\n):\n    \"\"\"Declare a list of actors as a collective group.Note: This function should be called in a driver process.",
        "bd7d57fb-ddba-4ab5-b6f2-6e6f0369d74f": "ray.runtime_env.RuntimeEnvConfig.known_fields#\n\n\nRuntimeEnvConfig.known_fields: Set[str] = {'eager_install', 'setup_timeout_seconds'}#",
        "84a3ab73-7bd0-466b-999b-ca716be02494": "- ``on=[\"col_1\", ..., \"col_n\"]``: a dataset of ``n + 1``\n              columns where the first column is the groupby key and the second\n              through ``n + 1`` columns are the results of the aggregations.If groupby key is ``None`` then the key part of return is omitted.\n        \"\"\"return self._aggregate_on(Mean, on, ignore_nulls)\n\n[docs]    def std(\n        self,\n        on: Union[str, List[str]] = None,\n        ddof: int = 1,\n        ignore_nulls: bool = True,\n    ) -> Dataset:\n        \"\"\"Compute grouped standard deviation aggregation.",
        "ad22cbab-593c-404b-9624-73c17396cc33": "263MB/s]\nDownloading (\u2026)l-00001-of-00003.bin:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 9.13G/9.95G [00:34<00:03, 257MB/s]\n(RayTrainWorker pid=74711, ip=10.0.45.211)  [repeated 634x across cluster]\nDownloading (\u2026)l-00001-of-00003.bin:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 8.17G/9.95G [00:35<00:07, 228MB/s] [repeated 628x across cluster]\nDownloading (\u2026)l-00001-of-00003.bin: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.95G/9.95G [00:37<00:00, 262MB/s]\nDownloading shards:  33%|\u2588\u2588\u2588\u258e      | 1/3 [00:38<01:16, 38.09s/it]\nDownloading (\u2026)l-00002-of-00003.bin:   0%|          | 0.00/9.90G [00:00<?, ?B/s]\nDownloading (\u2026)l-00002-of-00003.bin:   1%|\u258f         | 126M/9.90G [00:00<00:35, 273MB/s] \nDownloading (\u2026)l-00001-of-00003.bin:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 9.27G/9.95G [00:39<00:02, 228MB/s] [repeated 394x across cluster]\n(RayTrainWorker pid=75547, ip=10.0.42.158)  [repeated 633x across cluster]\nDownloading (\u2026)l-00002-of-00003.",
        "ed588c9c-d7d9-4433-a920-145c240b7a71": "Using GPUs for inference#\nTo use GPUs for inference, make the following changes to your code:\n\nUpdate the class implementation to move the model and data to and from GPU.Specify num_gpus=1 in the ds.map_batches() call to indicate that each actor should use 1 GPU.Specify a batch_size for inference.For more details on how to configure the batch size, see Configuring Batch Size.The remaining is the same as the Quickstart.HuggingFacePyTorchTensorFlowfrom typing import Dict\nimport numpy as np\n\nimport ray\n\nds = ray.data.from_numpy(np.asarray([\"Complete this\", \"for me\"]))\n\nclass HuggingFacePredictor:\n    def __init__(self):\n        from transformers import pipeline\n        # Set \"cuda:0\" as the device so the Huggingface pipeline uses GPU.self.model = pipeline(\"text-generation\", model=\"gpt2\", device=\"cuda:0\")\n\n    def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, list]:\n        predictions = self.model(list(batch[\"data\"]), max_length=20, num_return_sequences=1)\n        batch[\"output\"] = [sequences[0][\"generated_text\"] for sequences in predictions]\n        return batch\n\n# Use 2 actors, each actor using 1 GPU.2 GPUs total.predictions = ds.map_batches(\n    HuggingFacePredictor,\n    num_gpus=1,\n    # Specify the batch size for inference.# Increase this for larger datasets.batch_size=1,\n    # Set the ActorPool size to the number of GPUs in your cluster.compute=ray.data.ActorPoolStrategy(size=2),\n    )\npredictions.show(limit=1)",
        "5915d0ba-517b-46ca-9140-023e0d445120": "Here the workflow initially just consists of the book_trip task. Once\nexecuted, book_trip generates tasks to book flights and hotels in parallel,\nwhich feeds into a task to decide whether to cancel the trip or finalize it. The\nDAG can be visualized as follows (note the dynamically generated nested\nworkflows within book_trip):\n\nThe execution order here will be:\n1. Run the book_trip task.\n2. Run the two book_flight tasks and the book_hotel  task in parallel.\n3. Once all three booking tasks finish, finalize_or_cancel will be executed and its return will be the output of the workflow.",
        "e4e5ec3b-d43f-4286-990c-823273547552": ")\n\n        if len(fittable) > 1:\n            raise ValueError(\n                f\"More than one dataset was specified to be fit: {fittable}\"\n            )\n        if not has_wildcard:\n            for k, v in datasets.items():\n                if k not in result:\n                    raise ValueError(\n                        f\"An unexpected dataset `{k}` was given.The list of expected \"\n                        f\"datasets is `{list(result)}`.\")\n        return result\n\n    def _merge(self, other: \"DatasetConfig\") -> \"DatasetConfig\":\n        \"\"\"Merge the given DatasetConfig into this one.\"\"\"",
        "797ffd19-75db-4dd4-9342-a1daeae2397b": "@ray.remote\ndef extract() -> dict:\n    data_string = '{\"1001\": 301.27, \"1002\": 433.21, \"1003\": 502.22}'\n    order_data_dict = json.loads(data_string)\n    return order_data_dict\n\n\n@ray.remote\ndef transform(order_data_dict: dict) -> dict:\n    total_order_value = 0\n    for value in order_data_dict.values():\n        total_order_value += value\n    return {\"total_order_value\": ray.put(total_order_value)}\n\n\n@ray.remote\ndef load(data_dict: dict) -> str:\n    total_order_value = ray.get(data_dict[\"total_order_value\"])\n    return f\"Total order value is: {total_order_value:.2f}\"\n\n\nif __name__ == \"__main__\":\n    order_data = extract.bind()\n    order_summary = transform.bind(order_data)\n    etl = load.bind(order_summary)\n    print(workflow.run(etl))",
        "683fcad0-2090-4659-a55c-c86d1cbfa2c4": "GPU Support#\nGPUs are critical for many machine learning applications.\nRay natively supports GPU as a pre-defined resource type and allows tasks and actors to specify their GPU resource requirements.",
        "5f0de405-2959-4a5f-8b70-7c17eb9ece49": "ray.tune.schedulers.HyperBandScheduler.metric#\n\n\nproperty HyperBandScheduler.metric#",
        "5676fd4f-d2cc-443e-ae1b-850d713abe8e": "Autoscaling#\nThe Ray autoscaler is a process that runs on the head node (or as a sidecar container in the head pod if using Kubernetes).\nWhen the resource demands of the Ray workload exceed the\ncurrent capacity of the cluster, the autoscaler will try to increase the number of worker nodes. When worker nodes\nsit idle, the autoscaler will remove worker nodes from the cluster.\nIt is important to understand that the autoscaler only reacts to task and actor resource requests, and not application metrics or physical resource utilization.\nTo learn more about autoscaling, refer to the user guides for Ray clusters on VMs and Kubernetes.",
        "962eea72-9d45-42b7-ab2a-9aaa3b3e8caa": "Step 5: Change the Ray image from rayproject/ray:${RAY_VERSION} to rayproject/ray-ml:${RAY_VERSION}#\n# Uninstall RayCluster\nhelm uninstall raycluster\n\n# Install the RayCluster CR with the Ray image `rayproject/ray-ml:${RAY_VERSION}`\nhelm install raycluster kuberay/ray-cluster --version 0.6.0 --set image.repository=rayproject/ray-ml\n\n\nThe error message in Step 4 indicates that the Ray image rayproject/ray:${RAY_VERSION} does not have the TensorFlow package.\nDue to the significant size of TensorFlow, we have opted to use an image with TensorFlow as the base instead of installing it within Runtime Environments.\nIn this Step, we will change the Ray image from rayproject/ray:${RAY_VERSION} to rayproject/ray-ml:${RAY_VERSION}.",
        "4eb01ca4-95cc-47de-ba1b-708534cee678": "\"`evaluation_strategy` or `save_strategy` may also be set to 'no'.\\n\"\n            f\"Got `logging_strategy`={trainer.args.logging_strategy}\\n\"\n            f\"`evaluation_strategy`={trainer.args.evaluation_strategy}\\n\"\n            f\"`save_strategy`={trainer.args.save_strategy}\"\n        )\n\n    if trainer.args.save_strategy in (\"steps\", IntervalStrategy.STEPS):\n        if (\n            trainer.args.save_steps < trainer.args.logging_steps\n            or trainer.args.save_steps % trainer.args.logging_steps != 0\n        ):\n            raise ValueError(\n                \"When using 'steps' `save_strategy`, `save_steps` must be \"\n                \"equal or bigger to `logging_steps`, and must be divisible \"\n                \"by `logging_steps` (so that saving occurs at the same time \"\n                f\"logging does).Got `save_steps`={trainer.args.save_steps}, \"\n                f\"`logging_steps`={trainer.args.logging_steps}.\"",
        "07385b10-b2c4-46d3-bfec-8e556374efbe": "ray.util.queue.Queue.put_nowait#\n\n\nQueue.put_nowait(item: Any) \u2192 None[source]#\nEquivalent to put(item, block=False).\n\nRaises\nFull \u2013 if the queue is full.",
        "9d50bff6-9daf-426d-8cf1-5c3054a23a1d": "tablefmt=\"html\",\n                showindex=False,\n                headers=\"keys\",\n            ),\n            max_height=\"none\",\n        )\n\n    @property\n    def _tune_legacy_checkpoint_score_attr(self) -> Optional[str]:\n        \"\"\"Same as ``checkpoint_score_attr`` in ``tune.run``.Only used for Legacy API compatibility.\n        \"\"\"if self.checkpoint_score_attribute is None:\n            return self.checkpoint_score_attribute\n        prefix = \"\"\n        if self.checkpoint_score_order == MIN:\n            prefix = \"min-\"\n        return f\"{prefix}{self.checkpoint_score_attribute}\"\n\n\n[docs]@dataclass\n@PublicAPI(stability=\"beta\")\nclass RunConfig:\n    \"\"\"Runtime configuration for training and tuning runs.Upon resuming from a training or tuning run checkpoint,\n    Ray Train/Tune will automatically apply the RunConfig from\n    the previously checkpointed run.Args:\n        name: Name of the trial or experiment.If not provided, will be deduced\n            from the Trainable.storage_path: Path to store results at.Can be a local directory or\n            a destination on cloud storage.If Ray storage is set up,\n            defaults to the storage location.Otherwise, this defaults to\n            the local ``~/ray_results`` directory.",
        "94e7b86f-20a6-4258-b148-315fbbe6829c": "),\n    )\n\n    is_driver_deployment: bool = Field(\n        default=DEFAULT.VALUE,\n        description=\"Indicate Whether the deployment is driver deployment \"\n        \"Driver deployments are spawned one per node.\",\n    )\n\n[docs]    @root_validator\n    def num_replicas_and_autoscaling_config_mutually_exclusive(cls, values):\n        if values.get(\"num_replicas\", None) not in [DEFAULT.VALUE, None] and values.get(\n            \"autoscaling_config\", None\n        ) not in [DEFAULT.VALUE, None]:\n            raise ValueError(\n                \"Manually setting num_replicas is not allowed \"\n                \"when autoscaling_config is provided.\")\n\n        return values\n\n    deployment_schema_route_prefix_format = validator(\"route_prefix\", allow_reuse=True)(\n        _route_prefix_format\n    )\n\n[docs]    def get_user_configured_option_names(self) -> Set[str]:\n        \"\"\"Get set of names for all user-configured options.Any field not set to DEFAULT.VALUE is considered a user-configured option.\n        \"\"\"return {\n            field for field, value in self.dict().items() if value is not DEFAULT.VALUE\n        }",
        "2c0e30b0-4e91-4c54-a074-c05ae91b3a60": "Specifying CPU and GPU resources#\nWe recommend doing heavy computation within Ray tasks, actors, or Ray libraries, not directly in the top level of your entrypoint script.\nNo extra configuration is needed to do this.\nHowever, if you need to do computation directly in the entrypoint script and would like to reserve CPU and GPU resources for the entrypoint script, you may specify the entrypoint_num_cpus, entrypoint_num_gpus and entrypoint_resources arguments to submit_job.  These arguments function\nidentically to the num_cpus, num_gpus, and resources arguments to @ray.remote() decorator for tasks and actors as described in Specifying Task or Actor Resource Requirements.\njob_id = client.submit_job(\n    entrypoint=\"python script.py\",\n    runtime_env={\n        \"working_dir\": \"./\",\n    }\n    # Reserve 1 GPU for the entrypoint script\n    entrypoint_num_gpus=1\n)",
        "d6dd7474-ee7a-4280-8eea-a507b5949a7f": "with self._timers[SAMPLE_TIMER]:\n            new_sample_batches = synchronous_parallel_sample(\n                worker_set=self.workers, concat=False\n            )\n\n        for batch in new_sample_batches:\n            # Update counters.self._counters[NUM_ENV_STEPS_SAMPLED] += batch.env_steps()\n            self._counters[NUM_AGENT_STEPS_SAMPLED] += batch.agent_steps()\n            # Store new samples in the replay buffer.self.local_replay_buffer.add(batch)\n\n        # Update target network every `target_network_update_freq` sample steps.cur_ts = self._counters[\n            NUM_AGENT_STEPS_SAMPLED\n            if self.config.count_steps_by == \"agent_steps\"\n            else NUM_ENV_STEPS_SAMPLED\n        ]\n\n        train_results = {}\n\n        if cur_ts > self.config.num_steps_sampled_before_learning_starts:\n            # Sample n batches from replay buffer until the total number of timesteps\n            # reaches `train_batch_size`.",
        "15ffee5e-49a2-4237-b19a-2b67dd59a61b": "Pod and container lifecyle: preStopHook#\nIt is recommended for every Ray container\u2019s configuration\nto include the following blocking block:\nlifecycle:\n  preStop:\n    exec:\n      command: [\"/bin/sh\",\"-c\",\"ray stop\"]\n\n\nTo ensure graceful termination, ray stop is executed prior to the Ray pod\u2019s termination.",
        "160e725c-38a0-4617-a42d-343f8209a88e": "[docs]@PublicAPI\ndef from_dask(df: \"dask.DataFrame\") -> MaterializedDataset:\n    \"\"\"Create a :class:`~ray.data.Dataset` from a\n    `Dask DataFrame <https://docs.dask.org/en/stable/generated/dask.dataframe.DataFrame.html#dask.dataframe.DataFrame>`_.\n\n    Args:\n        df: A `Dask DataFrame`_.\n\n    Returns:\n        A :class:`~ray.data.MaterializedDataset` holding rows read from the DataFrame.\n    \"\"\"  # noqa: E501\n    import dask\n\n    from ray.util.dask import ray_dask_get\n\n    partitions = df.to_delayed()\n    persisted_partitions = dask.persist(*partitions, scheduler=ray_dask_get)\n\n    import pandas\n\n    def to_ref(df):\n        if isinstance(df, pandas.DataFrame):\n            return ray.put(df)\n        elif isinstance(df, ray.ObjectRef):\n            return df\n        else:\n            raise ValueError(\n                \"Expected a Ray object ref or a Pandas DataFrame, \" f\"got {type(df)}\"\n            )\n\n    ds = from_pandas_refs(\n        [to_ref(next(iter(part.dask.values()))) for part in persisted_partitions],\n    )\n    return ds",
        "c77eb138-7475-4418-ba16-ebf60343fccc": "\",\n         \"type\": \"object\",\n         \"properties\": {\n            \"name\": {\n               \"title\": \"Name\",\n               \"description\": \"Globally-unique name identifying this deployment.\",\n               \"type\": \"string\"\n            },\n            \"num_replicas\": {\n               \"title\": \"Num Replicas\",\n               \"description\": \"The number of processes that handle requests to this deployment.Uses a default if null.\",\n               \"default\": 1,\n               \"exclusiveMinimum\": 0,\n               \"type\": \"integer\"\n            },\n            \"route_prefix\": {\n               \"title\": \"Route Prefix\",\n               \"description\": \"[DEPRECATED] Please use route_prefix under ServeApplicationSchema instead.",
        "335ddbc6-e713-4fd3-b426-1d0978dc4e54": "common_path = os.path.commonpath(paths)\n        # If parent directory (or base directory, if using partitioning) is common to\n        # all paths, fetch all file infos at that prefix and filter the response to the\n        # provided paths.if (\n            partitioning is not None\n            and common_path == _unwrap_protocol(partitioning.base_dir)\n        ) or all(str(pathlib.Path(path).parent) == common_path for path in paths):\n            yield from _get_file_infos_common_path_prefix(\n                paths, common_path, filesystem, ignore_missing_paths\n            )\n        # 3.Parallelization case.else:\n            logger.warning(\n                f\"Expanding {len(paths)} path(s).This may be a HIGH LATENCY \"\n                f\"operation on some cloud storage services.Moving all the \"\n                \"paths to a common parent directory will lead to faster \"\n                \"metadata fetching.\")\n            # Parallelize requests via Ray tasks.yield from _get_file_infos_parallel(paths, filesystem, ignore_missing_paths)",
        "c054f750-f552-4bef-a2c1-dc9fb6d33367": "Workflow Execution API#\n\n\n\n\n\n\nrun(dag,\u00a0*args[,\u00a0workflow_id,\u00a0metadata])\nRun a workflow.\n\nrun_async(dag,\u00a0*args[,\u00a0workflow_id,\u00a0metadata])\nRun a workflow asynchronously.",
        "cfe875dd-fedf-44b3-9efa-e1609b8a1faf": "How can I get started contributing to Tune?#\nWe use Github to track issues, feature requests, and bugs. Take a look at the\nones labeled \u201cgood first issue\u201d and \u201chelp wanted\u201d for a place to start.\nLook for issues with \u201c[tune]\u201d in the title.\n\nNote\nIf raising a new issue or PR related to Tune, be sure to include \u201c[tune]\u201d in the title and add a tune label.\n\nFor project organization, Tune maintains a relatively up-to-date organization of\nissues on the Tune Github Project Board.\nHere, you can track and identify how issues are organized.",
        "d432778e-a36d-40e1-8a6b-ccda85f88db5": "Population Based Training Replay (tune.schedulers.PopulationBasedTrainingReplay)#\nTune includes a utility to replay hyperparameter schedules of Population Based Training runs.\nYou just specify an existing experiment directory and the ID of the trial you would\nlike to replay. The scheduler accepts only one trial, and it will update its\nconfig according to the obtained schedule.\nfrom ray import tune\nfrom ray.tune.schedulers import PopulationBasedTrainingReplay\n\nreplay = PopulationBasedTrainingReplay(\n    experiment_dir=\"~/ray_results/pbt_experiment/\",\n    trial_id=\"XXXXX_00001\"\n)\ntuner = tune.Tuner(\n    train_fn,\n    tune_config=tune.TuneConfig(scheduler=replay)\n)\nresults = tuner.fit()\n\n\nSee here for an example on how to use the\nreplay utility in practice.\n\n\n\n\n\n\nPopulationBasedTrainingReplay(policy_file)\nReplays a Population Based Training run.",
        "c52985d2-6588-48e3-9768-aa26b2627119": "ray.rllib.policy.policy.Policy.get_state#\n\n\nPolicy.get_state() \u2192 Dict[str, Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor, dict, tuple]][source]#\nReturns the entire current state of this Policy.\nNote: Not to be confused with an RNN model\u2019s internal state.\nState includes the Model(s)\u2019 weights, optimizer weights,\nthe exploration component\u2019s state, as well as global variables, such\nas sampling timesteps.\nNote that the state may contain references to the original variables.\nThis means that you may need to deepcopy() the state before mutating it.\n\nReturns\nSerialized local state.",
        "46afc16d-e068-47ed-a8c1-7ade6f0a3307": "for pol in self.policy_map.values():\n            if not pol._model_init_state_automatically_added and not pol.config.get(\n                \"_enable_rl_module_api\", False\n            ):\n                pol._update_model_view_requirements_from_init_state()\n\n        self.multiagent: bool = set(self.policy_map.keys()) != {DEFAULT_POLICY_ID}\n        if self.multiagent and self.env is not None:\n            if not isinstance(\n                self.env,\n                (BaseEnv, ExternalMultiAgentEnv, MultiAgentEnv, ray.actor.ActorHandle),\n            ):\n                raise ValueError(\n                    f\"Have multiple policies {self.policy_map}, but the \"\n                    f\"env {self.env} is not a subclass of BaseEnv, \"\n                    f\"MultiAgentEnv, ActorHandle, or ExternalMultiAgentEnv!\")\n\n        if self.worker_index == 0:\n            logger.info(\"Built filter map: {}\".format(self.filters))\n\n        # This RolloutWorker has no env.",
        "480f6e47-db8c-4099-8e43-100498aee253": "search_optimization):\n    # Tune Domain is always good\n    if isinstance(dist, Domain):\n        return\n\n    search_optimization = available_optimizations.get(\n        type(search_optimization), search_optimization)\n\n    if search_optimization == \"random\":\n        if not (isinstance(dist, list) or hasattr(dist, \"rvs\")):\n            raise ValueError(\"distribution must be a list or scipy \"\n                             \"distribution when using randomized search\")\n    elif not isinstance(dist, tuple) and not isinstance(dist, list):\n        if search_optimization == \"bayesian\":\n            import skopt\n            if not isinstance(dist, skopt.space.Dimension):\n                raise ValueError(\"distribution must be a tuple, list, or \"\n                                 \"`skopt.space.Dimension` instance when using \"\n                                 \"bayesian search\")\n        elif search_optimization == \"hyperopt\":\n            import hyperopt.pyll\n            if not isinstance(dist, hyperopt.pyll.base.",
        "469e0a1d-97b5-4d60-8fcb-e629cf7cd0e9": ")\n\n    if points_to_evaluate and evaluated_rewards:\n        if not isinstance(evaluated_rewards, list):\n            raise TypeError(\n                \"evaluated_rewards expected to be a list, got {}.\".format(\n                    type(evaluated_rewards)\n                )\n            )\n        if not len(evaluated_rewards) == len(points_to_evaluate):\n            raise ValueError(\n                \"Dim of evaluated_rewards {}\".format(evaluated_rewards)\n                + \" and points_to_evaluate {}\".format(points_to_evaluate)\n                + \" do not match.\")",
        "38e8afd7-53cd-409a-bf5e-e9eb438e5b3c": "ray.train.lightning.RayDeepSpeedStrategy.root_device#\n\n\nproperty RayDeepSpeedStrategy.root_device: torch.device#\nReturn the root device.",
        "d98febd6-0870-423a-937d-1eb95deb8a56": "track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1),",
        "51440d6a-b324-425f-94e8-3ae8d4a4c83d": "Large Scale Workload Orchestration#\nThe following highlights feature projects leveraging Ray Core\u2019s distributed APIs to simplify the orchestration of large scale workloads.\n\n[Blog] Highly Available and Scalable Online Applications on Ray at Ant Group\n[Blog] Ray Forward 2022 Conference: Hyper-scale Ray Application Use Cases\n[Blog] A new world record on the CloudSort benchmark using Ray\n[Example] Speed up your web crawler by parallelizing it with Ray",
        "31c59f74-e1e4-49a0-9460-24d31ce05fdf": "ray.train.Checkpoint.to_directory#\n\n\nCheckpoint.to_directory(path: Optional[Union[str, os.PathLike]] = None) \u2192 str[source]#\nWrite checkpoint data to directory.\n\nParameters\npath \u2013 Target directory to restore data in. If not specified,\nwill create a temporary directory.\n\nReturns\nDirectory containing checkpoint data.\n\nReturn type\nstr",
        "1fe4a4df-c48a-4de0-9087-863c88e5c13a": "RunConfig(\n            name=\"ax\",\n            stop={\"timesteps_total\": 100},\n        ),\n        tune_config=tune.TuneConfig(\n            metric=\"hartmann6\",  # provided in the 'easy_objective' function\n            mode=\"min\",\n            search_alg=algo,\n            scheduler=scheduler,\n            num_samples=10 if args.smoke_test else 50,\n        ),\n        param_space={\n            \"iterations\": 100,\n            \"x1\": tune.uniform(0.0, 1.0),\n            \"x2\": tune.uniform(0.0, 1.0),\n            \"x3\": tune.uniform(0.0, 1.0),\n            \"x4\": tune.uniform(0.0, 1.0),\n            \"x5\": tune.uniform(0.0, 1.0),\n            \"x6\": tune.uniform(0.0, 1.0),\n        },\n    )\n    results = tuner.fit()\n    print(\"Best hyperparameters found were: \", results.get_best_result().config)",
        "96005992-b3c6-4a81-a7c6-b79dc643c999": "def tune_with_setup():\n    \"\"\"Example for using the setup_wandb utility with the function API\"\"\"\n    tuner = tune.Tuner(\n        train_function_wandb,\n        tune_config=tune.TuneConfig(\n            metric=\"loss\",\n            mode=\"min\",\n        ),\n        param_space={\n            \"mean\": tune.grid_search([1, 2, 3, 4, 5]),\n            \"sd\": tune.uniform(0.2, 0.8),\n        },\n    )\n    tuner.fit()\n\n\n\n\nFinally, you can also define a class-based Tune Trainable by using the setup_wandb in the setup() method and storing the run object as an attribute. Please note that with the class trainable, you have to pass the trial id, name, and group separately:",
        "1a64be70-8cc4-4d36-b155-543529579151": "beta: Hyperparameter to choose between exploration and\n                exploitation.beta_schedule: Schedule to use for beta decay, one of\n                \"constant\" or \"linear_decay\".rho: Beta decay factor, used for on-policy algorithm.k_nn: Number of neighbours to set for K-NN entropy\n                estimation.random_timesteps: The number of timesteps to act completely\n                randomly (see [1]).sub_exploration: The config dict for the underlying Exploration\n                to use (e.g.epsilon-greedy for DQN).If None, uses the\n                FromSpecDict provided in the Policy's default config.Raises:\n            ValueError: If the input framework is Torch.\n        \"\"\"# TODO(gjoliver): Add supports for Pytorch.if framework == \"torch\":\n            raise ValueError(\"This RE3 implementation does not support Torch.\")",
        "0f20d391-ea2d-43d1-9939-1e3aa94d073b": "ray.data.preprocessors.OneHotEncoder.fit#\n\n\nOneHotEncoder.fit(ds: Dataset) \u2192 Preprocessor#\nFit this Preprocessor to the Dataset.\nFitted state attributes will be directly set in the Preprocessor.\nCalling it more than once will overwrite all previously fitted state:\npreprocessor.fit(A).fit(B) is equivalent to preprocessor.fit(B).\n\nParameters\nds \u2013 Input dataset.\n\nReturns\nThe fitted Preprocessor with state attributes.\n\nReturn type\nPreprocessor",
        "c2c8ace5-136b-46b5-815f-dad7fe9be1fd": "bin:  38%|\u2588\u2588\u2588\u258a      | 97.2M/256M [00:01<00:01, 95.1MB/s]\nDownloading pytorch_model.bin:  42%|\u2588\u2588\u2588\u2588\u258f     | 106M/256M [00:01<00:01, 95.6MB/s] \nDownloading pytorch_model.bin:  45%|\u2588\u2588\u2588\u2588\u258c     | 116M/256M [00:01<00:01, 96.0MB/s]\nDownloading pytorch_model.bin:  49%|\u2588\u2588\u2588\u2588\u2589     | 125M/256M [00:01<00:01, 96.2MB/s]\nDownloading pytorch_model.bin:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 134M/256M [00:01<00:01, 96.0MB/s]\nDownloading pytorch_model.bin:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 143M/256M [00:01<00:01, 96.1MB/s]\nDownloading pytorch_model.bin:  60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 152M/256M [00:01<00:01, 96.0MB/s]\nDownloading pytorch_model.bin:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 162M/256M [00:01<00:01, 96.2MB/s]\nDownloading pytorch_model.bin:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 171M/256M [00:02<00:00, 96.1MB/s]\nDownloading pytorch_model.bin:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 180M/256M [00:02<00:00, 96.",
        "4af4cb8b-4bd3-46e9-82b4-ffe63ff27b23": "ray.serve.schema.ServeDeploySchema#\n\n\npydantic model ray.serve.schema.ServeDeploySchema[source]#\nMulti-application config for deploying a list of Serve applications to the Ray\ncluster.\nThis is the request JSON schema for the v2 REST API\nPUT \"/api/serve/applications/\".\n\nNOTE: This config allows extra parameters to make it forward-compatible (ieolder versions of Serve are able to accept configs from a newer versions,\nsimply ignoring new parameters)\n\n\nPublicAPI (alpha): This API is in alpha and may change before becoming stable.Show JSON schema{\n   \"title\": \"ServeDeploySchema\",\n   \"description\": \"Multi-application config for deploying a list of Serve applications to the Ray\\ncluster.\\n\\nThis is the request JSON schema for the v2 REST API\\n`PUT \\\"/api/serve/applications/\\\"`.\\n\\nNOTE: This config allows extra parameters to make it forward-compatible (ie\\n      older versions of Serve are able to accept configs from a newer versions,\\n      simply ignoring new parameters)\\n\\n**PublicAPI (alpha):** This API is in alpha and may change before becoming stable.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"proxy_location\": {\n         \"description\": \"The location of HTTP servers.\\n- \\\"EveryNode\\\" (default): start one HTTP server per node.\\n- \\\"HeadOnly\\\": start one HTTP server on the head node.\\n- \\\"NoServer\\\": disable HTTP server.",
        "34720444-6bc4-4adc-8726-b496bfcb49c0": "Source code for ray.train.lightning._lightning_utils\nimport os\nimport ray\nfrom ray import train\nfrom ray.air.constants import MODEL_KEY\nfrom ray.data.dataset import DataIterator\nfrom ray.util import PublicAPI\n\nimport logging\nimport shutil\nimport torch\nimport tempfile\nfrom ray.train import Checkpoint\nfrom ray.train._internal.storage import _use_storage_context\nfrom ray.train.lightning.lightning_checkpoint import (\n    LightningCheckpoint,\n    LegacyLightningCheckpoint,\n)\nfrom packaging.version import Version\nfrom typing import Any, Dict, Optional\nfrom torch.utils.data import IterableDataset, DataLoader\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, Callback\nfrom pytorch_lightning.plugins.environments import LightningEnvironment\nfrom pytorch_lightning.strategies import DDPStrategy, DeepSpeedStrategy\n\n_LIGHTNING_GREATER_EQUAL_2_0 = Version(pl.__version__) >= Version(\"2.0.0\")\n_TORCH_GREATER_EQUAL_1_12 = Version(torch.__version__) >= Version(\"1.12.0\")\n_TORCH_FSDP_AVAILABLE = _TORCH_GREATER_EQUAL_1_12 and torch.distributed.is_available()\n\nif _LIGHTNING_GREATER_EQUAL_2_0:\n    from pytorch_lightning.strategies import FSDPStrategy\nelse:\n    from pytorch_lightning.strategies import DDPFullyShardedStrategy as FSDPStrategy\n\nif _TORCH_FSDP_AVAILABLE:\n    from torch.distributed.fsdp import (\n        FullStateDictConfig,",
        "4e3a2c09-0a4b-4bd3-89f7-0c86bc70f4ab": "@Deprecated(\n    old=\"rllib/algorithms/a3c/\",\n    new=\"rllib_contrib/a3c/\",\n    help=ALGO_DEPRECATION_WARNING,\n    error=False,\n)\nclass A3C(Algorithm):\n    @classmethod\n    @override(Algorithm)\n    def get_default_config(cls) -> AlgorithmConfig:\n        return A3CConfig()\n\n    @classmethod\n    @override(Algorithm)\n    def get_default_policy_class(\n        cls, config: AlgorithmConfig\n    ) -> Optional[Type[Policy]]:\n        if config[\"framework\"] == \"torch\":\n            from ray.rllib.algorithms.a3c.a3c_torch_policy import A3CTorchPolicy\n\n            return A3CTorchPolicy\n        elif config[\"framework\"] == \"tf\":\n            from ray.rllib.algorithms.a3c.a3c_tf_policy import A3CTF1Policy\n\n            return A3CTF1Policy\n        else:\n            from ray.rllib.algorithms.a3c.a3c_tf_policy import A3CTF2Policy\n\n            return A3CTF2Policy\n\n    def training_step(self) -> ResultDict:\n        # Shortcut.",
        "b2e42ad0-f37d-467d-a00d-0ca9797c3f56": ")\n\n        if num_replicas == 0:\n            raise ValueError(\"num_replicas is expected to larger than 0\")\n\n        if not _internal and version is not DEFAULT.VALUE:\n            logger.warning(\n                \"DeprecationWarning: `version` in `Deployment.options()` has been \"\n                \"deprecated.Explicitly specifying version will raise an error in the \"\n                \"future!\")\n\n        if not _internal and route_prefix is not DEFAULT.VALUE:\n            logger.warning(\n                \"DeprecationWarning: `route_prefix` in `@serve.deployment` has been \"\n                \"deprecated.To specify a route prefix for an application, pass it \"\n                \"into `serve.run` instead.\")\n\n        if num_replicas not in [DEFAULT.VALUE, None]:\n            new_deployment_config.num_replicas = num_replicas\n        if user_config is not DEFAULT.VALUE:\n            new_deployment_config.user_config = user_config\n        if max_concurrent_queries is not DEFAULT.VALUE:\n            new_deployment_config.",
        "9cd1363b-cfbf-4d45-933e-e2c13d587253": "ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.apply#\n\n\nReplayBuffer.apply(func: Callable[[Any, Optional[Any], Optional[Any]], ray.rllib.utils.typing.T], *args, **kwargs) \u2192 ray.rllib.utils.typing.T#\nCalls the given function with this rollout worker instance.\nA generic interface for applying arbitray member functions on a\nremote actor.\n\nParameters\n\nfunc \u2013 The function to call, with this RolloutWorker as first\nargument, followed by args, and kwargs.\nargs \u2013 Optional additional args to pass to the function call.\nkwargs \u2013 Optional additional kwargs to pass to the function call.\n\n\nReturns\nThe return value of the function call.\n\n\nDeveloperAPI: This API may change across minor Ray releases.",
        "20f90da8-0442-4c2c-b853-cfe40fab4730": "Sub Workflows#\n\nCadence version:#\n// https://github.com/uber/cadence-java-samples/blob/master/src/main/java/com/uber/cadence/samples/hello/HelloChild.java\npublic static class GreetingWorkflowImpl implements GreetingWorkflow {\n\n  @Override\n  public String getGreeting(String name) {\n    // Workflows are stateful.So a new stub must be created for each new child.GreetingChild child = Workflow.newChildWorkflowStub(GreetingChild.class);\n\n    // This is a non blocking call that returns immediately.// Use child.composeGreeting(\"Hello\", name) to call synchronously.Promise<String> greeting = Async.function(child::composeGreeting, \"Hello\", name);\n    // Do something else here.return greeting.get(); // blocks waiting for the child to complete.\n  }// This example shows how parent workflow return right after starting a child workflow,\n  // and let the child run itself.private String demoAsyncChildRun(String name) {\n    GreetingChild child = Workflow.newChildWorkflowStub(GreetingChild.class);\n    // non blocking call that initiated child workflow\n    Async.function(child::composeGreeting, \"Hello\", name);\n    // instead of using greeting.get() to block till child complete,\n    // sometimes we just want to return parent immediately and keep child running\n    Promise<WorkflowExecution> childPromise = Workflow.getWorkflowExecution(child);\n    childPromise.get(); // block until child started,\n    // otherwise child may not start because parent complete first.return \"let child run, parent just return\";\n  }\n\n  public static void main(String[] args) {\n    // Start a worker that hosts both parent and child workflow implementations.",
        "8b829944-ced6-4ffb-8afe-2a6ae314dbf5": "Log files in logging directory#\nBelow are the log files in the logging directory. Broadly speaking, two types of log files exist: system log files and application log files.\nNote that .out logs are from stdout/stderr and .err logs are from stderr. The backward compatibility of log directories is not guaranteed.\n\nNote\nSystem logs may include information about your applications. For example, runtime_env_setup-[job_id].log may include information about your application\u2019s environment and dependency.",
        "35c7b17d-0850-4136-bd47-cb19329c2418": "Head Node#\nEvery Ray cluster has one node which is designated as the head node of the cluster.\nThe head node is identical to other worker nodes, except that it also runs singleton processes responsible for cluster management such as the\nautoscaler, GCS and the Ray driver processes\nwhich run Ray jobs. Ray may schedule\ntasks and actors on the head node just like any other worker node, which is not desired in large-scale clusters.\nSee Configuring the head node for the best practice in large-scale clusters.",
        "6f35bbf5-9a9f-4cc9-9e5c-8efa8312fe46": "Source code for ray.rllib.algorithms.td3.td3\n\"\"\"A more stable successor to TD3.\n\nBy default, this uses a near-identical configuration to that reported in the\nTD3 paper.\n\"\"\"\nfrom ray.rllib.algorithms.algorithm_config import AlgorithmConfig\nfrom ray.rllib.algorithms.ddpg.ddpg import DDPG, DDPGConfig\nfrom ray.rllib.utils.annotations import override\nfrom ray.rllib.utils.deprecation import (\n    DEPRECATED_VALUE,\n    Deprecated,\n    ALGO_DEPRECATION_WARNING,\n)\n\n\n[docs]class TD3Config(DDPGConfig):\n    \"\"\"Defines a configuration class from which a TD3 Algorithm can be built.Example:\n        >>> from ray.rllib.algorithms.td3 import TD3Config\n        >>> config = TD3Config().training(lr=0.01).resources(num_gpus=1)\n        >>> print(config.to_dict())  # doctest: +SKIP\n        >>> # Build a Algorithm object from the config and run one training iteration.>>> algo = config.build(env=\"Pendulum-v1\")  # doctest: +SKIP\n        >>> algo.train()  # doctest: +SKIP\n\n    Example:\n        >>> from ray.rllib.algorithms.td3 import TD3Config\n        >>> from ray import air\n        >>> from ray import tune\n        >>> config = TD3Config()\n        >>> # Print out some default values.>>> print(config.lr)   # doctest: +SKIP\n        >>> # Update the config object.",
        "862ab291-aabf-416f-9f26-9bda4a4849bf": "futures = list(self._trial_logging_futures.values())\n        done, remaining = ray.wait(futures, num_returns=len(futures), timeout=timeout)\n        for ready_future in done:\n            finished_trial = self._logging_future_to_trial.pop(ready_future)\n            self._cleanup_logging_actor(finished_trial)\n\n        if kill_on_timeout:\n            for remaining_future in remaining:\n                trial = self._logging_future_to_trial.pop(remaining_future)\n                self._cleanup_logging_actor(trial)\n\n    def on_experiment_end(self, trials: List[\"Trial\"], **info):\n        \"\"\"Wait for the actors to finish their call to `wandb.finish`.This includes uploading all logs + artifacts to wandb.\"\"\"",
        "e6fa45c9-f2f7-4349-b78b-9b45e5d9e34c": "This\n            guarantees that models are trained for at least a certain amount\n            of time or timesteps before being perturbed.hyperparam_mutations: Hyperparams to mutate.The format is\n            as follows: for each key, either a list, function,\n            or a tune search space object (tune.loguniform, tune.uniform,\n            etc.)can be provided.A list specifies an allowed set of\n            categorical values.A function or tune search space object\n            specifies the distribution of a continuous parameter.You must\n            use tune.choice, tune.uniform, tune.loguniform, etc..Arbitrary\n            tune.sample_from objects are not supported.A key can also hold a dict for nested hyperparameters.You must specify at least one of `hyperparam_mutations` or\n            `custom_explore_fn`.Tune will sample the search space provided by\n            `hyperparam_mutations` for the initial hyperparameter values if the\n            corresponding hyperparameters are not present in a trial's initial `config`.quantile_fraction: Parameters are transferred from the top\n            `quantile_fraction` fraction of trials to the bottom\n            `quantile_fraction` fraction.Needs to be between 0 and 0.5.Setting it to 0 essentially implies doing no exploitation at all.resample_probability: The probability of resampling from the\n            original distribution when applying `hyperparam_mutations`.",
        "7f2e099f-02bd-4072-9c77-6588af614ac0": "Parquet column pruning#\nCurrent Dataset reads all Parquet columns into memory.\nIf you only need a subset of the columns, make sure to specify the list of columns\nexplicitly when calling ray.data.read_parquet() to\navoid loading unnecessary data (projection pushdown).\nFor example, use ray.data.read_parquet(\"s3://anonymous@ray-example-data/iris.parquet\", columns=[\"sepal.length\", \"variety\"]) to read\njust two of the five columns of Iris dataset.",
        "d3ad3ab8-21ad-4753-86ca-38dcb6dfed1d": "results.update(results[\"sampler_results\"])\n\n        results[\"num_healthy_workers\"] = self.workers.num_healthy_remote_workers()\n        results[\"num_in_flight_async_reqs\"] = self.workers.num_in_flight_async_reqs()\n        results[\n            \"num_remote_worker_restarts\"\n        ] = self.workers.num_remote_worker_restarts()\n\n        # Train-steps- and env/agent-steps this iteration.",
        "8e09bc01-b16e-4e9a-aaa4-8e5bd23efd1d": "preprocessor: Optional[\"Preprocessor\"] = None,\n    ):\n\n        if TRANSFORMERS_IMPORT_ERROR is not None:\n            raise TRANSFORMERS_IMPORT_ERROR\n\n        # Functionality required for TransformersTrainer only added in this\n        # version\n        if Version(transformers.__version__) < Version(\"4.19.0\"):\n            raise RuntimeError(\n                \"TransformersTrainer requires transformers>=4.19.0, but you \"\n                f\"have {transformers.__version__} which is incompatible. \"\"Update on all nodes with `pip install -U 'transformers>=4.19.0'`.\")\n\n        self._validate_trainer_init_per_worker(\n            trainer_init_per_worker, \"trainer_init_per_worker\"\n        )\n\n        super().__init__(\n            train_loop_per_worker=_huggingface_train_loop_per_worker,\n            train_loop_config=self._create_trainer_init_config(\n                trainer_init_per_worker, trainer_init_config\n            ),\n            torch_config=torch_config,\n            scaling_config=scaling_config,",
        "cfc9edd9-fbaf-48cd-a11c-7cd50856dc78": "8})\n\n                result_grid = Tuner(\n                    trainable=training_loop_per_worker,\n                    run_config=RunConfig(name=\"my_tune_run\")\n                ).fit()\n\n                # Get last reported results per trial\n                df = result_grid.get_dataframe()\n\n                # Get best ever reported accuracy per trial\n                df = result_grid.get_dataframe(\n                    filter_metric=\"accuracy\", filter_mode=\"max\"\n                )\n\n            . testoutput::\n                :hide:\n\n                .\n\n        Args:\n            filter_metric: Metric to filter best result for.filter_mode: If ``filter_metric`` is given, one of ``[\"min\", \"max\"]``\n                to specify if we should find the minimum or maximum result.Returns:\n            Pandas DataFrame with each trial as a row and their results as columns.\n        \"\"\"",
        "254daae6-8763-47ec-893d-26f8cc1bfc67": "ray.data.preprocessors.OneHotEncoder.transform#\n\n\nOneHotEncoder.transform(ds: Dataset) \u2192 Dataset#\nTransform the given dataset.\n\nParameters\nds \u2013 Input Dataset.\n\nReturns\nThe transformed Dataset.\n\nReturn type\nray.data.Dataset\n\nRaises\nPreprocessorNotFittedException \u2013 if fit is not called yet.",
        "8565c47c-f5fd-4a06-a98f-2b38c448346f": "ray.data.block.BlockMetadata.exec_stats#\n\n\nBlockMetadata.exec_stats: Optional[ray.data.block.BlockExecStats]#\nExecution stats for this block.",
        "9f0acc96-8732-4002-8e3f-3d8550fa967b": "@DeveloperAPI\ndef assign_value(spec: Dict, path: Tuple, value: Any):\n    \"\"\"Assigns a value to a nested dictionary.\n\n    Handles the special case of tuples, in which case the tuples\n    will be re-constructed to accomodate the updated value.\n    \"\"\"\n    parent_spec = None\n    parent_key = None\n    for k in path[:-1]:\n        parent_spec = spec\n        parent_key = k\n        spec = spec[k]\n    key = path[-1]\n    if not isinstance(spec, tuple):\n        # spec is mutable. Just assign the value.\n        spec[key] = value\n    else:\n        if parent_spec is None:\n            raise ValueError(\"Cannot assign value to a tuple.\")\n        assert isinstance(key, int), \"Tuple key must be an int.\"\n        # Special handling since tuples are immutable.\n        parent_spec[parent_key] = spec[:key] + (value,) + spec[key + 1 :]\n\n\ndef _get_value(spec: Dict, path: Tuple) -> Any:\n    for k in path:\n        spec = spec[k]\n    return spec\n\n\ndef _resolve_domain_vars(\n    spec: Dict,\n    domain_vars: List[Tuple[Tuple, Domain]],\n    allow_fail: bool = False,\n    random_state: \"RandomState\" = None,\n) -> Tuple[bool,",
        "acea1daa-9a6e-4792-9fcf-dc6fe8aa73e4": "ray.tune.Trainable.trial_id#\n\n\nproperty Trainable.trial_id#\nTrial ID for the corresponding trial of this Trainable.\nThis is not set if not using Tune.\nfrom ray.tune import Trainable\n\ntrial_id = Trainable().trial_id",
        "2c01de33-31ac-4e11-9204-83b34992db94": "Serve Replica Detail page#\nThis page shows metadata about the Serve replica, high-level metrics about the replica if you configured Grafana and Prometheus, and\na history of completed Tasks of that replica.",
        "fdfd3f34-82a0-4c3a-87d6-81bd4afd9b2f": "action_space=tl_act_space,  # special action space for lights?),\n        },\n        \"policy_mapping_fn\":\n            lambda agent_id, episode, worker, **kwargs:\n                \"traffic_light\"  # Traffic lights are always controlled by this policy\n                if agent_id.startswith(\"traffic_light_\")\n                else random.choice([\"car1\", \"car2\"])  # Randomly choose from car policies\n    },\n})\n\nwhile True:\n    print(algo.train())\n\n\nTo exclude some policies in your multiagent.policies dictionary, you can use the multiagent.policies_to_train setting.For example, you may want to have one or more random (non learning) policies interact with your learning ones:\n# Example for a mapping function that maps agent IDs \"player1\" and \"player2\" to either\n# \"random_policy\" or \"learning_policy\", making sure that in each episode, both policies\n# are always playing each other.def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n    agent_idx = int(agent_id[-1])  # 0 (player1) or 1 (player2)\n    # agent_id = \"player[1|2]\" -> policy depends on episode ID\n    # This way, we make sure that both policies sometimes play player1\n    # (start player) and sometimes player2 (player to move 2nd).",
        "9e23f533-aacc-4551-b3c6-92e95f1261e8": "self._maybe_save_artifacts_to_cloud()\n\n        self._result_logger.flush()\n        self._result_logger.close()\n        if self._monitor.is_alive():\n            self._monitor.stop()\n            self._monitor.join()\n        self.cleanup()\n\n        self._close_logfiles()\n\n    @property\n    def logdir(self):\n        \"\"\"Directory of the results and checkpoints for this Trainable.Tune will automatically sync this folder with the driver if execution\n        is distributed.Note that the current working directory will also be changed to this.\n\n        \"\"\"return os.path.join(self._logdir, \"\")\n\n    @property\n    def trial_name(self):\n        \"\"\"Trial name for the corresponding trial of this Trainable.This is not set if not using Tune... testcode::\n\n            from ray.tune import Trainable\n\n            name = Trainable().trial_name\n        \"\"\"\n        if self._trial_info:\n            return self._trial_info.trial_name\n        else:\n            return \"default\"\n\n    @property\n    def trial_id(self):\n        \"\"\"Trial ID for the corresponding trial of this Trainable.This is not set if not using Tune.",
        "b6ff6a78-4843-4355-8cc4-b38422f9549b": "Result(metrics={'loss': 0.3886, 'learning_rate': 0.0, 'epoch': 2.0, 'step': 1070, 'eval_loss': 0.6215357184410095, 'eval_matthews_correlation': 0.42957017514952434, 'eval_runtime': 0.9956, 'eval_samples_per_second': 273.204, 'eval_steps_per_second': 5.022, 'train_runtime': 174.4696, 'train_samples_per_second': 98.023, 'train_steps_per_second': 6.133, 'train_loss': 0.4661755713346963, '_timestamp': 1661447637, '_time_this_iter_s': 96.96447467803955, '_training_iteration': 2, 'should_checkpoint': True, 'done': True, 'trial_id': 'c1ff5_00000', 'experiment_tag': '0'}, error=None, log_dir=PosixPath('/home/ray/ray_results/TransformersTrainer_2022-08-25_10-10-02/TransformersTrainer_c1ff5_00000_0_2022-08-25_10-10-04'))",
        "370c3667-f0b6-416a-bad6-256178677801": "32628  |       0.0991242 |                    1 |\n  | train_mnist_tune_63ecc_00006 | TERMINATED |       |             64 |            128 | 0.000158761 |          128 | 0.134595 |       0.959766  |                   10 |\n  | train_mnist_tune_63ecc_00007 | TERMINATED |       |             64 |             64 | 0.000672126 |           64 | 0.118182 |       0.972903  |                   10 |\n  | train_mnist_tune_63ecc_00008 | TERMINATED |       |            128 |             64 | 0.000502428 |           32 | 0.11082  |       0.975518  |                   10 |\n  | train_mnist_tune_63ecc_00009 | TERMINATED |       |             64 |            256 | 0.",
        "f6bf6e51-2164-46cc-a719-7a46199d0d25": "Example:\n\n        .. code-block:: python\n\n            search_alg.save(\"./my_favorite_path.pkl\")\n\n            search_alg2 = Searcher(...)\n            search_alg2 = ConcurrencyLimiter(search_alg2, 1)\n            search_alg2.restore(checkpoint_path)\n            tuner = tune.Tuner(\n                cost,\n                tune_config=tune.TuneConfig(\n                    search_alg=search_alg2,\n                    num_samples=5\n                ),\n            )\n            tuner.fit()\n\n        \"\"\"\n        raise NotImplementedError\n\n[docs]    def set_max_concurrency(self, max_concurrent: int) -> bool:\n        \"\"\"Set max concurrent trials this searcher can run.This method will be called on the wrapped searcher by the\n        ``ConcurrencyLimiter``.It is intended to allow for searchers\n        which have custom, internal logic handling max concurrent trials\n        to inherit the value passed to ``ConcurrencyLimiter``.If this method returns False, it signifies that no special\n        logic for handling this case is present in the searcher.",
        "ff4fec03-af1b-41a5-8197-d968d21834d4": "serve.run(StreamingResponder.bind())\n\nr = requests.get(\"http://localhost:8000?max=10\", stream=True)\nstart = time.time()\nr.raise_for_status()\nfor i, chunk in enumerate(r.iter_content(chunk_size=None, decode_unicode=True)):\n    print(f\"Got result {round(time.time()-start, 1)}s after start: '{chunk}'\")\n    if i == 10:\n        print(\"Client disconnecting\")\n        break",
        "1529b91d-6bf3-4301-9018-c97d2f2d3ac4": "== Status ==Current time: 2022-07-22 15:07:54 (running for 00:00:26.41)Memory usage on this node: 9.9/16.0 GiBUsing HyperBand: num_stopped=9 total_brackets=1\nRound #0:\n  Bracket(Max Size (n)=1, Milestone (r)=64, completed=66.8%): {TERMINATED: 10} Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/4.95 GiB heap, 0.0/2.0 GiB objectsCurrent best trial: a0c11456 with mean_loss=-4.53376204004117 and parameters={'steps': 100, 'width': 3.7250202606878258, 'height': -57.97769618290691, 'activation': 'tanh'}Result logdir: /Users/kai/ray_results/bohb_expNumber of trials: 10/10 (10 TERMINATED)\n\nTrial name        status    loc            activation     height   width    loss  iter  total time (s)  ts  iterations  neg_mean_loss\n\n\nobjective_9e8d8b06TERMINATED127.0.0.1:45117tanh         37.6516 12.2188  5.28254    16        2.23943    0          15       -5.28254\nobjective_a052a214TERMINATED127.0.0.1:45150relu         -4.1062717.9931 11.1524      4        0.",
        "ae07332e-a19d-4fdd-a939-5f27291e4e93": "state[\"_optimizer_variables\"] = []\n        if not self.config.get(\"_enable_learner_api\", False):\n            if self._optimizer and len(self._optimizer.variables()) > 0:\n                state[\"_optimizer_variables\"] = self._optimizer.variables()\n\n        # Add exploration state.if self.exploration:\n            # This is not compatible with RLModules, which have a method\n            # `forward_exploration` to specify custom exploration behavior.state[\"_exploration_state\"] = self.exploration.get_state()\n\n        return state\n\n    @override(Policy)\n    @OverrideToImplementCustomLogic_CallToSuperRecommended\n    def set_state(self, state: PolicyState) -> None:\n        # Set optimizer vars.optimizer_vars = state.get(\"_optimizer_variables\", None)\n        if optimizer_vars and self._optimizer.variables():\n            if not type(self).__name__.endswith(\"_traced\") and log_once(\n                \"set_state_optimizer_vars_tf_eager_policy_v2\"\n            ):\n                logger.warning(\n                    \"Cannot restore an optimizer's state for tf eager!",
        "1eb66c8e-643e-4168-832d-2f0cc9d36f9c": "_workers])\n        total_time = sum(s[\"total_time\"] for s in stats)\n        accesses = [s[\"num_accesses\"] for s in stats]\n        blocks = [s[\"num_blocks\"] for s in stats]\n        msg = \"RandomAccessDataset:\\n\"\n        msg += \"- Build time: {}s\\n\".format(round(self._build_time, 2))\n        msg += \"- Num workers: {}\\n\".format(len(stats))\n        msg += \"- Blocks per worker: {} min, {} max, {} mean\\n\".format(\n            min(blocks), max(blocks), int(sum(blocks) / len(blocks))\n        )\n        msg += \"- Accesses per worker: {} min, {} max, {} mean\\n\".format(\n            min(accesses), max(accesses), int(sum(accesses) / len(accesses))\n        )\n        msg += \"- Mean access time: {}us\\n\".format(\n            int(total_time / (1 + sum(accesses)) * 1e6)\n        )\n        return msg\n\n    def _worker_for(self, block_index: int):\n        return random.choice(self._block_to_workers_map[block_index])\n\n    def _find_le(self, x: Any) -> int:\n        i = bisect.bisect_left(self._upper_bounds,",
        "4ac8696d-5571-4d01-a5f7-76c77e4d89ea": "RLlib reports separate training statistics for each policy in the return from train(), along with the combined reward.Here is a simple example training script\nin which you can vary the number of agents and policies in the environment.For how to use multiple training methods at once (here DQN and PPO),\nsee the two-trainer example.",
        "c2fb50aa-2ce4-4019-b291-f161445bea0e": "Preprocessing Data#\nOnce the cluster is started, you can then SSH into the head node using ray attach lm-cluster.yaml and download or preprocess the data on EFS for training. We can run preprocess.sh (code) to do this, which adapts instructions from the RoBERTa tutorial.",
        "08ebb830-a825-4091-aa71-debbdc302b2c": "Source code for ray.rllib.algorithms.alpha_zero.alpha_zero\nimport logging\nfrom typing import List, Optional, Type, Union\n\nfrom ray.rllib.algorithms.callbacks import DefaultCallbacks\nfrom ray.rllib.algorithms.algorithm import Algorithm\nfrom ray.rllib.algorithms.algorithm_config import AlgorithmConfig, NotProvided\nfrom ray.rllib.execution.rollout_ops import (\n    synchronous_parallel_sample,\n)\nfrom ray.rllib.execution.train_ops import (\n    multi_gpu_train_one_step,\n    train_one_step,\n)\nfrom ray.rllib.models.catalog import ModelCatalog\nfrom ray.rllib.models.modelv2 import restore_original_dimensions\nfrom ray.rllib.models.torch.torch_action_dist import TorchCategorical\nfrom ray.rllib.policy.policy import Policy\nfrom ray.rllib.policy.sample_batch import concat_samples\nfrom ray.rllib.utils.annotations import override\nfrom ray.rllib.utils.deprecation import (\n    DEPRECATED_VALUE,\n    Deprecated,\n    ALGO_DEPRECATION_WARNING,\n)\nfrom ray.rllib.utils.framework import try_import_torch\nfrom ray.rllib.utils.metrics import (\n    NUM_AGENT_STEPS_SAMPLED,\n    NUM_ENV_STEPS_SAMPLED,\n    SYNCH_WORKER_WEIGHTS_TIMER,\n    SAMPLE_TIMER,\n)\nfrom ray.rllib.utils.replay_buffers.utils import validate_buffer_config\nfrom ray.rllib.utils.",
        "44cf8606-51b6-45c4-81ff-23367d3d59d8": "Dashboard:\nhttp://session-i8ddtfaxhwypbvnyb9uzg7xs.i.anyscaleuserdata-staging.com/auth/?token=agh0_CkcwRQIhAJXwvxwq31GryaWthvXGCXZebsijbuqi7qL2pCa5uROOAiBGjzsyXAJFHLlaEI9zSlNI8ewtghKg5UV3t8NmlxuMcRJmEiCtvjcKE0VPiU7iQx51P9oPQjfpo5g1RJXccVSS5005cBgCIgNuL2E6DAj9xazjBhDwj4veAUIMCP3ClJgGEPCPi94B-gEeChxzZXNfaThERFRmQVhId1lwYlZueWI5dVpnN3hT&redirect_to=dashboard\n\n\n\n\n\n\nWe can check the resources our cluster is composed of. If you are running this notebook on your local machine or Google Colab, you should see the number of CPU cores and GPUs available on the said machine.\n\n\npprint(ray.cluster_resources())\n\n\n\n\n{'CPU': 208.0,\n 'GPU': 16.0,\n 'accelerator_type:T4': 4.0,\n 'memory': 616693614180.0,\n 'node:172.31.76.237': 1.0,\n 'node:172.31.80.117': 1.0,\n 'node:172.31.85.193': 1.0,\n 'node:172.31.85.32': 1.0,\n 'node:172.31.90.137': 1.0,\n 'object_store_memory': 259318055729.0}",
        "a6b6c807-4ba5-4876-bbba-76b15abd1395": "evaluation_config: Optional[\n            Union[\"AlgorithmConfig\", PartialAlgorithmConfigDict]\n        ] = NotProvided,\n        off_policy_estimation_methods: Optional[Dict] = NotProvided,\n        ope_split_batch_by_episode: Optional[bool] = NotProvided,\n        evaluation_num_workers: Optional[int] = NotProvided,\n        custom_evaluation_function: Optional[Callable] = NotProvided,\n        always_attach_evaluation_results: Optional[bool] = NotProvided,\n        enable_async_evaluation: Optional[bool] = NotProvided,\n        # Deprecated args.evaluation_num_episodes=DEPRECATED_VALUE,\n    ) -> \"AlgorithmConfig\":\n        \"\"\"Sets the config's evaluation settings.Args:\n            evaluation_interval: Evaluate with every `evaluation_interval` training\n                iterations.The evaluation stats will be reported under the \"evaluation\"\n                metric key.Note that for Ape-X metrics are already only reported for\n                the lowest epsilon workers (least random workers).Set to None (or 0) for no evaluation.evaluation_duration: Duration for which to run evaluation each\n                `evaluation_interval`.",
        "1ae39665-bb34-4d3a-8319-6184406178b7": "def _process_observations(\n    *,\n    worker: \"RolloutWorker\",\n    base_env: BaseEnv,\n    active_episodes: Dict[EnvID, Episode],\n    unfiltered_obs: Dict[EnvID, Dict[AgentID, EnvObsType]],\n    rewards: Dict[EnvID, Dict[AgentID, float]],\n    terminateds: Dict[EnvID, Dict[AgentID, bool]],\n    truncateds: Dict[EnvID, Dict[AgentID, bool]],\n    infos: Dict[EnvID, Dict[AgentID, EnvInfoDict]],\n    multiple_episodes_in_batch: bool,\n    callbacks: \"DefaultCallbacks\",\n    observation_fn: \"ObservationFunction\",\n    sample_collector: SampleCollector,\n) -> Tuple[\n    Set[EnvID],\n    Dict[PolicyID, List[_PolicyEvalData]],\n    List[Union[RolloutMetrics, SampleBatchType]],\n]:\n    \"\"\"Record new data from the environment and prepare for policy evaluation.Args:\n        worker: Reference to the current rollout worker.base_env: Env implementing BaseEnv.active_episodes: Mapping from\n            episode ID to currently ongoing Episode object.unfiltered_obs: Doubly keyed dict of env-ids -> agent ids\n            -> unfiltered observation tensor, returned by a `BaseEnv.poll()`\n            call.rewards: Doubly keyed dict of env-ids -> agent ids ->\n            rewards tensor, returned by a `BaseEnv.poll()` call.",
        "452017f7-5110-4ca4-8787-2a9e5d65a9eb": "ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_learner_hyperparameters#\n\n\nAlgorithmConfig.get_learner_hyperparameters() \u2192 ray.rllib.core.learner.learner.LearnerHyperparameters[source]#\nReturns a new LearnerHyperparameters instance for the respective Learner.\nThe LearnerHyperparameters is a dataclass containing only those config settings\nfrom AlgorithmConfig that are used by the algorithm\u2019s specific Learner\nsub-class. They allow distributing only those settings relevant for learning\nacross a set of learner workers (instead of having to distribute the entire\nAlgorithmConfig object).\nNote that LearnerHyperparameters should always be derived directly from a\nAlgorithmConfig object\u2019s own settings and considered frozen/read-only.\n\nReturns\nA LearnerHyperparameters instance for the respective Learner.",
        "b7387b1c-7e00-44f4-8f44-8dc2daf1a137": "Current mode: {self.worker.mode}\"\n        actor_id = self.worker.actor_id\n        return actor_id if not actor_id.is_nil() else None\n\n[docs]    def get_actor_id(self) -> Optional[str]:\n        \"\"\"Get the current actor ID in this worker.ID of the actor of the current process.This shouldn't be used in a driver process.The ID will be in hex format.Returns:\n            The current actor id in hex format in this worker.None if there's no\n            actor id.\n        \"\"\"# only worker mode has actor_id\n        if self.worker.mode != ray._private.worker.WORKER_MODE:\n            logger.warning(\n                \"This method is only available when the process is a \"\n                \"worker.Current mode: {self.worker.mode}\"\n            )\n            return None\n        actor_id = self.worker.actor_id\n        return actor_id.hex() if not actor_id.is_nil() else None\n\n    @property\n    def namespace(self):\n        \"\"\"Get the current namespace of this worker.Returns:\n            The current namespace of this worker.\n        \"\"\"return self.worker.namespace\n\n    @property\n    def was_current_actor_reconstructed(self):\n        \"\"\"Check whether this actor has been restarted.",
        "c95f9f31-e29a-4e7d-af7f-ba7c18be8f95": "Code example#\nAnti-pattern:\nimport ray\nimport numpy as np\n\nray.init()\n\nlarge_object = np.zeros(10 * 1024 * 1024)\n\n\n@ray.remote\ndef f1():\n    return len(large_object)  # large_object is serialized along with f1!\n\n\nray.get(f1.remote())\n\n\nBetter approach #1:\nlarge_object_ref = ray.put(np.zeros(10 * 1024 * 1024))\n\n\n@ray.remote\ndef f2(large_object):\n    return len(large_object)\n\n\n# Large object is passed through object store.\nray.get(f2.remote(large_object_ref))\n\n\nBetter approach #2:\nlarge_object_creator = lambda: np.zeros(10 * 1024 * 1024)  # noqa E731\n\n\n@ray.remote\ndef f3():\n    large_object = (\n        large_object_creator()\n    )  # Lambda is small compared with the large object.\n    return len(large_object)\n\n\nray.get(f3.remote())",
        "038db77a-be9c-4554-ae45-dfcef190f4e8": "Pod templates#\nThe bulk of the configuration for a headGroupSpec or\nworkerGroupSpec goes in the template field. The template is a Kubernetes Pod\ntemplate which determines the configuration for the pods in the group.\nHere are some of the subfields of the pod template to pay attention to:",
        "9689017c-cad3-499d-b519-abd0689b2491": "Ray Cluster#\nA Ray cluster consists of a single head node\nand any number of connected worker nodes:\n\n\n\nA Ray cluster with two worker nodes. Each node runs Ray helper processes to\nfacilitate distributed scheduling and memory management. The head node runs\nadditional control processes (highlighted in blue).#\n\n\nThe number of worker nodes may be autoscaled with application demand as specified\nby your Ray cluster configuration. The head node runs the autoscaler.\n\nNote\nRay nodes are implemented as pods when running on Kubernetes.\n\nUsers can submit jobs for execution on the Ray cluster, or can interactively use the\ncluster by connecting to the head node and running ray.init. See\nRay Jobs for more information.",
        "bd200f05-c0de-48a5-a19e-8f524fb4baaa": "else:\n            new_policy_instance_kwargs = dict(\n                policy_id=policy_id,\n                policy_cls=type(policy),\n                observation_space=policy.observation_space,\n                action_space=policy.action_space,\n                config=policy.config,\n                policy_state=policy.get_state(),\n                policy_mapping_fn=policy_mapping_fn,\n                policies_to_train=list(policies_to_train)\n                if policies_to_train\n                else None,\n                module_spec=module_spec,\n            )\n\n        def _create_new_policy_fn(worker: RolloutWorker):\n            # `foreach_worker` function: Adds the policy the the worker (and\n            # maybe changes its policy_mapping_fn - if provided here).worker.add_policy(**new_policy_instance_kwargs)\n\n        if self.local_worker() is not None:\n            # Add policy directly by (already instantiated) object.",
        "bf15ad7b-1ebe-4e59-a318-c1a6a6c091eb": "Bundles#\nA bundle is a collection of \u201cresources\u201d. It could be a single resource, {\"CPU\": 1}, or a group of resources, {\"CPU\": 1, \"GPU\": 4}.\nA bundle is a unit of reservation for placement groups. \u201cScheduling a bundle\u201d means we find a node that fits the bundle and reserve the resources specified by the bundle.\nA bundle must be able to fit on a single node on the Ray cluster. For example, if you only have an 8 CPU node, and if you have a bundle that requires {\"CPU\": 9}, this bundle cannot be scheduled.",
        "8f4381bd-3d5d-4743-8f18-faf9982b1279": "# TODO (Kourosh) Do this inside the Learner so that we don't have to do\n            #  this back and forth communication between driver and the remote\n            #  learner actors.is_module_trainable = self.workers.local_worker().is_policy_to_train\n            self.learner_group.set_is_module_trainable(is_module_trainable)\n            train_results = self.learner_group.update(\n                train_batch,\n                minibatch_size=self.config.sgd_minibatch_size,\n                num_iters=self.config.num_sgd_iter,\n            )\n\n        elif self.config.simple_optimizer:\n            train_results = train_one_step(self, train_batch)\n        else:\n            train_results = multi_gpu_train_one_step(self, train_batch)\n\n        if self.config._enable_learner_api:\n            # The train results's loss keys are pids to their loss values.But we also\n            # return a total_loss key at the same level as the pid keys.So we need to\n            # subtract that to get the total set of pids to update.",
        "295c183e-9e15-400b-a9d6-c27d10ecea4a": "experiment_spec = Experiment(\n    \"my_experiment_name\",\n    my_func,\n    stop={\"mean_accuracy\": 100},\n    config={\n        \"alpha\": tune.grid_search([0.2, 0.4, 0.6]),\n        \"beta\": tune.grid_search([1, 2]),\n    },\n    resources_per_trial={\n        \"cpu\": 1,\n        \"gpu\": 0\n    },\n    num_samples=10,\n    local_dir=\"~/ray_results\",\n    checkpoint_freq=10,\n    max_failures=2)\n\n\n\nParameters\n\nTODO (xwjiang) \u2013 Add the whole list.\n_experiment_checkpoint_dir \u2013 Internal use only. If present, use this\nas the root directory for experiment checkpoint. If not present,\nthe directory path will be deduced from trainable name instead.\n\n\n\nDeveloperAPI: This API may change across minor Ray releases.\nMethods\n\n\n\n\n\n\nfrom_json(name,\u00a0spec)\nGenerates an Experiment object from JSON.\n\nget_experiment_checkpoint_dir(run_obj[,\u00a0...])\nGet experiment checkpoint dir without setting up an experiment.\n\nget_trainable_name(run_object)\nGet Trainable name.\n\nregister_if_needed(run_object)\nRegisters Trainable or Function at runtime.\n\n\n\nAttributes\n\n\n\n\n\n\nPUBLIC_KEYS\n\n\ncheckpoint_config\n\n\ncheckpoint_dir\n\n\nlocal_dir\n\n\nlocal_path\n\n\npath\n\n\npublic_spec\nReturns the spec dict with only the public-facing keys.\n\nremote_checkpoint_dir\n\n\nremote_path\n\n\nrun_identifier\nReturns a string representing the trainable identifier.\n\nstopper",
        "b4a51bb9-c270-4fb8-bf83-d392ff02a5da": "This environment\nvariable is deprecated, and the chdir_to_trial_dir flag described above should be\nused instead.This class supports checkpointing to and restoring from remote storage.PublicAPI: This API is stable across Ray releases.Methods\n\n\n\n\n\n\n__init__([config,\u00a0logger_creator,\u00a0...])\nInitialize a Trainable.\n\ncleanup()\nSubclasses should override this for any cleanup on stop.\n\ndefault_resource_request(config)\nProvides a static resource requirement for the given configuration.\n\ndelete_checkpoint(checkpoint_path)\nDeletes local copy of checkpoint.\n\nexport_model(export_formats[,\u00a0export_dir])\nExports model based on export_formats.\n\nget_auto_filled_metrics([now,\u00a0...])\nReturn a dict with metrics auto-filled by the trainable.\n\nget_config()\nReturns configuration passed in by Tune.\n\nload_checkpoint(checkpoint)\nSubclasses should override this to implement restore().\n\nlog_result(result)\nSubclasses can optionally override this to customize logging.\n\nreset(new_config[,\u00a0logger_creator,\u00a0...])\nResets trial for use with new config.\n\nreset_config(new_config)\nResets configuration without restarting the trial.\n\nresource_help(config)\nReturns a help string for configuring this trainable's resources.\n\nrestore(checkpoint_path[,\u00a0...])\nRestores training state from a given model checkpoint.\n\nsave([checkpoint_dir,\u00a0prevent_upload])\nSaves the current model state to a checkpoint.\n\nsave_checkpoint(checkpoint_dir)\nSubclasses should override this to implement save().\n\nsetup(config)\nSubclasses should override this for custom initialization.\n\nstep()\nSubclasses should override this to implement train().\n\nstop()\nReleases all resources used by this trainable.\n\ntrain()\nRuns one logical iteration of training.\n\ntrain_buffered(buffer_time_s[,\u00a0...])\nRuns multiple iterations of training.",
        "cf482f2d-1f6f-4e95-8290-11ebb851fe37": "grad_clip: Optional[float] = NotProvided,\n        lambda_: Optional[float] = NotProvided,\n        dreamer_train_iters: Optional[int] = NotProvided,\n        batch_size: Optional[int] = NotProvided,\n        batch_length: Optional[int] = NotProvided,\n        imagine_horizon: Optional[int] = NotProvided,\n        free_nats: Optional[float] = NotProvided,\n        kl_coeff: Optional[float] = NotProvided,\n        prefill_timesteps: Optional[int] = NotProvided,\n        explore_noise: Optional[float] = NotProvided,\n        dreamer_model: Optional[dict] = NotProvided,\n        num_steps_sampled_before_learning_starts: Optional[int] = NotProvided,\n        **kwargs,\n    ) -> \"DreamerConfig\":\n        \"\"\"\n\n        Args:\n            td_model_lr: PlaNET (transition dynamics) model learning rate.actor_lr: Actor model learning rate.critic_lr: Critic model learning rate.grad_clip: If specified, clip the global norm of gradients by this amount.lambda_: The GAE (lambda) parameter.dreamer_train_iters: Training iterations per data collection from real env.batch_size: Number of episodes to sample for loss calculation.batch_length: Length of each episode to sample for loss calculation.imagine_horizon: Imagination horizon for training Actor and Critic.free_nats: Free nats.kl_coeff: KL coefficient for the model Loss.",
        "044ff9f5-6fe2-4b72-aca4-5d6b4bb7808f": "The basics of our build system#\nThe Ray documentation is built using the sphinx build system.\nWe\u2019re using the Sphinx Book Theme from the\nexecutable books project.\nThat means that you can write Ray documentation in either Sphinx\u2019s native\nreStructuredText (rST) or in\nMarkedly Structured Text (MyST).\nThe two formats can be converted to each other, so the choice is up to you.\nHaving said that, it\u2019s important to know that MyST is\ncommon markdown compliant.\nIf you intend to add a new document, we recommend starting from an .md file.\nThe Ray documentation also fully supports executable formats like Jupyter Notebooks.\nMany of our examples are notebooks with MyST markdown cells.\nIn fact, this very document you\u2019re reading is a notebook.\nYou can check this for yourself by either downloading the .ipynb file,\nor directly launching this notebook into either Binder or Google Colab in the top navigation bar.",
        "17473fdd-84e9-4b05-b823-af3c337e214a": "static vectorize_gym_envs(make_env: Optional[Callable[[int], Any]] = None, existing_envs: Optional[List[<MagicMock name='mock.Env' id='140123320868816'>]] = None, num_envs: int = 1, action_space: Optional[<MagicMock name='mock.Space' id='140123320933248'>] = None, observation_space: Optional[<MagicMock name='mock.Space' id='140123320933248'>] = None, restart_failed_sub_environments: bool = False, env_config=None, policy_config=None) \u2192 ray.rllib.env.vector_env._VectorizedGymEnv[source]#\nTranslates any given gym.Env(s) into a VectorizedEnv object.\n\nParameters\n\nmake_env \u2013 Factory that produces a new gym.Env taking the sub-env\u2019s\nvector index as only arg. Must be defined if the\nnumber of existing_envs is less than num_envs.\nexisting_envs \u2013 Optional list of already instantiated sub\nenvironments.\nnum_envs \u2013 Total number of sub environments in this VectorEnv.\naction_space \u2013 The action space. If None, use existing_envs[0]\u2019s\naction space.\nobservation_space \u2013 The observation space. If None, use\nexisting_envs[0]\u2019s observation space.\nrestart_failed_sub_environments \u2013 If True and any sub-environment (within\na vectorized env) throws any error during env stepping, the\nSampler will try to restart the faulty sub-environment. This is done\nwithout disturbing the other (still intact) sub-environment and without\nthe RolloutWorker crashing.\n\n\nReturns\nThe resulting _VectorizedGymEnv object (subclass of VectorEnv).",
        "0b414adb-08d3-458a-847c-ee6ca9262499": "ray.data.datasource.PathPartitionParser.of#\n\n\nstatic PathPartitionParser.of(style: ray.data.datasource.partitioning.PartitionStyle = PartitionStyle.HIVE, base_dir: Optional[str] = None, field_names: Optional[List[str]] = None, filesystem: Optional[pyarrow.fs.FileSystem] = None) \u2192 PathPartitionParser[source]#\nCreates a path-based partition parser using a flattened argument list.\n\nParameters\n\nstyle \u2013 The partition style - may be either HIVE or DIRECTORY.\nbase_dir \u2013 \u201c/\u201d-delimited base directory to start searching for partitions\n(exclusive). File paths outside of this directory will be considered\nunpartitioned. Specify None or an empty string to search for\npartitions in all file path directories.\nfield_names \u2013 The partition key names. Required for DIRECTORY partitioning.\nOptional for HIVE partitioning. When non-empty, the order and length of\npartition key field names must match the order and length of partition\ndirectories discovered. Partition key field names are not required to\nexist in the dataset schema.\nfilesystem \u2013 Filesystem that will be used for partition path file I/O.\n\n\nReturns\nThe new path-based partition parser.",
        "b3680ad9-c0b1-4ba6-874e-483646918d81": ">>> config.training(  # doctest:+SKIP\n        ...     lr=tune.grid_search([0.001, 0.0001]), beta=0.75\n        ... )\n        >>> # Set the config object's data path.>>> # Run this from the ray directory root.>>> config.offline_data(  # doctest:+SKIP\n        ...     input_=\"./rllib/tests/data/cartpole/large.json\"\n        ... )\n        >>> # Set the config object's env, used for evaluation.>>> config.environment(env=\"CartPole-v1\")  # doctest:+SKIP\n        >>> # Use to_dict() to get the old-style python config dict\n        >>> # when running with tune.>>> tune.Tuner(   # doctest:+SKIP\n        ...     \"BC\",\n        ...     param_space=config.to_dict(),\n        ... ).fit()\n    \"\"\"\n\n    def __init__(self, algo_class=None):\n        super().__init__(algo_class=algo_class or BC)\n\n        # fmt: off\n        # __sphinx_doc_begin__\n        # No need to calculate advantages (or do anything else with the rewards).self.beta = 0.0\n        # Advantages (calculated during postprocessing)\n        # not important for behavioral cloning.",
        "a8b60efa-460f-4787-910a-0379cab25920": "Source code for ray.rllib.core.learner.learner_group\nfrom collections import defaultdict, deque\nfrom functools import partial\nimport pathlib\nfrom typing import (\n    Any,\n    Callable,\n    List,\n    Mapping,\n    Optional,\n    Set,\n    Type,\n    TYPE_CHECKING,\n    Union,\n)\nimport uuid\n\nimport ray\nfrom ray.rllib.core.learner.reduce_result_dict_fn import _reduce_mean_results\nfrom ray.rllib.core.rl_module.rl_module import (\n    ModuleID,\n    SingleAgentRLModuleSpec,\n    RLMODULE_STATE_DIR_NAME,\n)\nfrom ray.rllib.core.learner.learner import LearnerSpec\nfrom ray.rllib.policy.sample_batch import MultiAgentBatch\nfrom ray.rllib.utils.actor_manager import FaultTolerantActorManager\nfrom ray.rllib.utils.minibatch_utils import ShardBatchIterator\nfrom ray.rllib.utils.typing import ResultDict\nfrom ray.rllib.utils.numpy import convert_to_numpy\nfrom ray.train._internal.backend_executor import BackendExecutor\nfrom ray.tune.utils.file_transfer import sync_dir_between_nodes\n\n\nif TYPE_CHECKING:\n    from ray.rllib.core.learner.learner import Learner",
        "f722ead5-dba3-42e9-88a4-f18a6b7f9bf1": "if not self._results_queue.empty():\n            logger.warning(\n                (\n                    \"Some results were added after the trial stop condition. \"\"These results won't be logged.\")\n            )\n\n        # Check for any errors that might have been missed.self._report_thread_runner_error()\n        legacy_tune_session._shutdown()\n\n        if self.temp_checkpoint_dir is not None and os.path.exists(\n            self.temp_checkpoint_dir\n        ):\n            shutil.rmtree(self.temp_checkpoint_dir)\n            logger.debug(\"Clearing temporary checkpoint: %s\", self.temp_checkpoint_dir)\n\n    def reset_config(self, new_config):\n        if _use_storage_context():\n            session = get_session()\n\n            # Wait for thread termination so it is save to re-use the same actor.thread_timeout = int(os.environ.get(\"TUNE_FUNCTION_THREAD_TIMEOUT_S\", 2))\n            session.finish(timeout=thread_timeout)\n            if session.training_thread.is_alive():\n                # Did not finish within timeout, reset unsuccessful.return False\n\n            session.",
        "ac846ccb-1d5f-4abc-90d2-137838c752d3": "Code example\nBatch Training and Tuning using Ray Tune\n\n\n\n\n\n\n\nVideo\nScaling Instacart fulfillment ML on Ray\n\n\n\n\n\n\n\nCode example\nUsing Aim with Ray Tune For Experiment Management\n\n\n\n\n\n\n\nCode example\nUsing Comet with Ray Tune For Experiment Management\n\n\n\n\n\n\n\nCode example\nTracking Your Experiment Process Weights & Biases\n\n\n\n\n\n\n\nCode example\nUsing MLflow Tracking & AutoLogging with Tune\n\n\n\n\n\n\n\nCode example\nHow To Use Tune With Ax\n\n\n\n\n\n\n\nCode example\nHow To Use Tune With Dragonfly\n\n\n\n\n\n\n\nCode example\nHow To Use Tune With HyperOpt\n\n\n\n\n\n\n\nCode example\nHow To Use Tune With BayesOpt\n\n\n\n\n\n\n\nCode example\nHow To Use Tune With BlendSearch and CFO\n\n\n\n\n\n\n\nCode example\nHow To Use Tune With TuneBOHB\n\n\n\n\n\n\n\nCode example\nHow To Use Tune With Nevergrad\n\n\n\n\n\n\n\nCode example\nHow To Use Tune With Optuna\n\n\n\n\n\n\n\nCode example\nHow To Use Tune With SigOpt\n\n\n\n\n\n\n\nVideo\nProductionizing ML at Scale with Ray Serve\n\n\n\n\n\n\n\nBlog\nSimplify your MLOps with Ray & Ray Serve\n\n\n\n\n\n\n\nTutorial\nGetting Started with Ray Serve\n\n\n\n\n\n\n\nTutorial\nModel Composition in Serve\n\n\n\n\n\n\n\nTutorial\nGetting Started with Ray Tune\n\n\n\n\n\n\n\nBlog\nHow to distribute hyperparameter tuning with Ray Tune\n\n\n\n\n\n\n\nVideo\nSimple Distributed Hyperparameter Optimization\n\n\n\n\n\n\n\nBlog\nHyperparameter Search with \ud83e\udd17 Transformers\n\n\n\n\n\n\n\nCode example\nHow To Use Tune With Keras & TF Models\n\n\n\n\n\n\n\nCode example\nHow To Use Tune With PyTorch Models\n\n\n\n\n\n\n\nCode example\nHow To Tune PyTorch Lightning Models\n\n\n\n\n\n\n\nCode example\nModel Selection & Serving With Ray Serve\n\n\n\n\n\n\n\nCode example\nTuning RL Experiments With Ray Tune & Ray Serve\n\n\n\n\n\n\n\nCode example\nA Guide To Tuning XGBoost Parameters With Tune",
        "80e280e4-11e8-44a0-847a-e1e07d42db20": "base_model=accelerator.unwrap_model(model)\n                    checkpoint_dir = tempfile.mkdtemp()\n                    torch.save(\n                        {\"model_state_dict\": base_model.state_dict()},\n                        os.path.join(checkpoint_dir, \"model.pt\"),\n                    )\n                    checkpoint = Checkpoint.from_directory(checkpoint_dir)\n\n                    # Report and record metrics, checkpoint model at end of each\n                    # epoch\n                    train.report(\n                        {\"loss\": loss.item(), \"epoch\": epoch},\n                        checkpoint=checkpoint\n                    )",
        "372e8c06-a453-4ab2-ac46-83013f98a9aa": "# run_config is not a tunable hyperparameter so it does not need to be\n                # merged.run_config = base_config.pop(\"run_config\", None)\n                self._merged_config = merge_dicts(base_config, self.config)\n                self._merged_config[\"run_config\"] = run_config\n                merged_scaling_config = self._merged_config.get(\"scaling_config\")\n                if isinstance(merged_scaling_config, dict):\n                    merged_scaling_config = ScalingConfig(**merged_scaling_config)\n                self._merged_config[\n                    \"scaling_config\"\n                ] = self._reconcile_scaling_config_with_trial_resources(\n                    merged_scaling_config\n                )\n                if self.has_base_dataset():\n                    # Set the DataContext on the Trainer actor to the DataContext\n                    # specified on the driver.",
        "afba90d7-2e98-485b-9af6-5a944b694e06": "dumps(\n                        deployment[\"ray_actor_options\"][\"runtime_env\"]\n                    )\n\n                # Convert ray_actor_options' keys\n                deployment[\"ray_actor_options\"] = dict_keys_snake_to_camel_case(\n                    deployment[\"ray_actor_options\"]\n                )\n\n            # JSON-serialize user_config dictionary\n            if isinstance(deployment.get(\"user_config\"), dict):\n                deployment[\"user_config\"] = json.dumps(deployment[\"user_config\"])\n\n            # Convert deployment's keys\n            config[\"deployments\"][idx] = dict_keys_snake_to_camel_case(deployment)\n\n        # Convert top-level runtime_env\n        if isinstance(config.get(\"runtime_env\"), dict):\n            config[\"runtime_env\"] = json.dumps(config[\"runtime_env\"])\n\n        # Convert top-level option's keys\n        config = dict_keys_snake_to_camel_case(config)\n\n        return config",
        "f75480c8-561c-46ac-9a4d-d727f923230f": "else:\n                if isinstance(self.action_space, (Discrete, MultiDiscrete)):\n                    prev_a = one_hot(prev_a, self.action_space)\n                prev_a_r.append(\n                    tf.reshape(tf.cast(prev_a, tf.float32), [-1, self.action_dim])\n                )\n        # Prev rewards.if self.model_config[\"lstm_use_prev_reward\"]:\n            prev_a_r.append(\n                tf.reshape(\n                    tf.cast(input_dict[SampleBatch.PREV_REWARDS], tf.float32), [-1, 1]\n                )\n            )\n\n        # Concat prev.actions + rewards to the \"main\" input.if prev_a_r:\n            wrapped_out = tf.concat([wrapped_out] + prev_a_r, axis=1)\n\n        # Push everything through our LSTM.",
        "6f4e6e02-ebd5-4158-b046-f940b4e06abe": "ray.job_submission.JobInfo.metadata#\n\n\nJobInfo.metadata: Optional[Dict[str, str]] = None#\nArbitrary user-provided metadata for the job.",
        "5995504e-74cb-4714-b147-cec4a7e7a96e": "actor_placement_resources = {}\n        assert actor_method_cpu in [0, 1]\n        if actor_method_cpu == 1:\n            actor_placement_resources = resources.copy()\n            actor_placement_resources[\"CPU\"] += 1\n        if meta.is_cross_language:\n            creation_args = cross_language._format_args(worker, args, kwargs)\n        else:\n            function_signature = meta.method_meta.signatures[\"__init__\"]\n            creation_args = signature.flatten_args(function_signature, args, kwargs)\n\n        if scheduling_strategy is None or isinstance(\n            scheduling_strategy, PlacementGroupSchedulingStrategy\n        ):\n            # TODO(jjyao) Clean this up once the\n            # placement_group option is removed.# We should also consider pushing this logic down to c++\n            # so that it can be reused by all languages.if isinstance(scheduling_strategy, PlacementGroupSchedulingStrategy):\n                placement_group = scheduling_strategy.placement_group\n                placement_group_bundle_index = (\n                    scheduling_strategy.",
        "5da281eb-901d-4980-8664-6bbd35d7ffac": "join(\n            [\n                \"Max Size (n)={}\".format(self._n),\n                \"Milestone (r)={}\".format(self._cumul_r),\n                \"completed={:.1%}\".format(self.completion_percentage()),\n            ]\n        )\n        counts = collections.Counter([t.status for t in self._all_trials])\n        trial_statuses = \", \".join(\n            sorted(\"{}: {}\".format(k, v) for k, v in counts.items())\n        )\n        return \"Bracket({}): {{{}}} \".format(status, trial_statuses)",
        "7c153ea1-8184-4853-b318-94fa9e2b41ee": "\".format(policy_id)\n                    )\n                continue\n\n            #  Try to transform batch_indices to td_error dimensions\n            if len(batch_indices) != len(td_error):\n                T = replay_buffer.replay_sequence_length\n                assert (\n                    len(batch_indices) > len(td_error) and len(batch_indices) % T == 0\n                )\n                batch_indices = batch_indices.reshape([-1, T])[:, 0]\n                assert len(batch_indices) == len(td_error)\n            prio_dict[policy_id] = (batch_indices, td_error)\n\n        # Make the actual buffer API call to update the priority weights on all\n        # policies.replay_buffer.update_priorities(prio_dict)\n\n\n[docs]@DeveloperAPI\ndef sample_min_n_steps_from_buffer(\n    replay_buffer: ReplayBuffer, min_steps: int, count_by_agent_steps: bool\n) -> Optional[SampleBatchType]:\n    \"\"\"Samples a minimum of n timesteps from a given replay buffer.This utility method is primarily used by the QMIX algorithm and helps with\n    sampling a given number of time steps which has stored samples in units\n    of sequences or complete episodes.",
        "b0a4db69-16c8-4e5d-a9a4-f61fcf78e275": "ray.data.datasource.Reader.get_read_tasks#\n\n\nReader.get_read_tasks(parallelism: int) \u2192 List[ray.data.datasource.datasource.ReadTask][source]#\nExecute the read and return read tasks.\n\nParameters\n\nparallelism \u2013 The requested read parallelism. The number of read\ntasks should equal to this value if possible.\nread_args \u2013 Additional kwargs to pass to the datasource impl.\n\n\nReturns\nA list of read tasks that can be executed to read blocks from the\ndatasource in parallel.",
        "f178e299-b3ca-45c1-83c2-4160cbaf87b0": "ray.tune.ResultGrid#\n\n\nclass ray.tune.ResultGrid(experiment_analysis: ray.tune.analysis.experiment_analysis.ExperimentAnalysis)[source]#\nBases: object\nA set of Result objects for interacting with Ray Tune results.\nYou can use it to inspect the trials and obtain the best result.\nThe constructor is a private API. This object can only be created as a result of\nTuner.fit().\nExample:\n.. testcode:\nimport random\nfrom ray import train, tune\ndef random_error_trainable(config):\n    if random.random() < 0.5:\n        return {\"loss\": 0.0}\n    else:\n        raise ValueError(\"This is an error\")\ntuner = tune.Tuner(\n    random_error_trainable,\n    run_config=train.RunConfig(name=\"example-experiment\"),\n    tune_config=tune.TuneConfig(num_samples=10),\n)\ntry:\n    result_grid = tuner.fit()\nexcept ValueError:\n    pass\nfor i in range(len(result_grid)):\n    result = result_grid[i]\n    if not result.error:\n            print(f\"Trial finishes successfully with metrics\"\n               f\"{result.metrics}.\")\n    else:\n            print(f\"Trial failed with error {result.error}.\")",
        "e30917ee-e8ad-4582-bfcc-feeb6ebb156c": "ray.train.lightning.RayFSDPStrategy.checkpoint_io#\n\n\nproperty RayFSDPStrategy.checkpoint_io: pytorch_lightning.plugins.io.checkpoint_plugin.CheckpointIO#",
        "75695de0-e05c-4780-b18a-e2899af4fd67": "ray.rllib.algorithms.algorithm.Algorithm.import_model#\n\n\nAlgorithm.import_model(import_file: str)[source]#\nImports a model from import_file.\nNote: Currently, only h5 files are supported.\n\nParameters\nimport_file \u2013 The file to import the model from.\n\nReturns\nA dict that maps ExportFormats to successfully exported models.",
        "49be9df1-927c-494c-8b45-00fc1f454837": "[docs]    def __init__(\n        self,\n        action_space: Space,\n        *,\n        framework: str,\n        model: ModelV2,\n        feature_dim: int = 288,\n        feature_net_config: Optional[ModelConfigDict] = None,\n        inverse_net_hiddens: Tuple[int] = (256,),\n        inverse_net_activation: str = \"relu\",\n        forward_net_hiddens: Tuple[int] = (256,),\n        forward_net_activation: str = \"relu\",\n        beta: float = 0.2,\n        eta: float = 1.0,\n        lr: float = 1e-3,\n        sub_exploration: Optional[FromConfigSpec] = None,\n        **kwargs\n    ):\n        \"\"\"Initializes a Curiosity object.Uses as defaults the hyperparameters described in [1].Args:\n             feature_dim: The dimensionality of the feature (phi)\n                vectors.feature_net_config: Optional model\n                configuration for the feature network, producing feature\n                vectors (phi) from observations.This can be used to configure\n                fcnet- or conv_net setups to properly process any observation\n                space.",
        "7e6f3263-a00a-4ae6-9004-441765c72e0c": "if __name__ == \"__main__\":\n    deepspeed_config = {\n        \"optimizer\": {\n            \"type\": \"AdamW\",\n            \"params\": {\n                \"lr\": 2e-5,\n            },\n        },\n        \"scheduler\": {\"type\": \"WarmupLR\", \"params\": {\"warmup_num_steps\": 100}},\n        \"fp16\": {\"enabled\": True},\n        \"bf16\": {\"enabled\": False},  # Turn this on if using AMPERE GPUs.\"zero_optimization\": {\n            \"stage\": 3,\n            \"offload_optimizer\": {\n                \"device\": \"none\",\n            },\n            \"offload_param\": {\n                \"device\": \"none\",\n            },\n        },\n        \"gradient_accumulation_steps\": 1,\n        \"gradient_clipping\": True,\n        \"steps_per_print\": 10,\n        \"train_micro_batch_size_per_gpu\": 16,\n        \"wall_clock_breakdown\": False,",
        "e694ad76-0086-43ed-8484-083072534364": "self._check_is_built()\n        # TODO: once we figure out the optimizer format, we can set/get the state\n        return {\n            \"module_state\": self.get_module_state(),\n            \"optimizer_state\": self.get_optimizer_state(),\n        }\n        # return {\"module_state\": self.get_module_state(), \"optimizer_state\": {}}\n\n[docs]    def set_optimizer_state(self, state: Mapping[str, Any]) -> None:\n        \"\"\"Sets the state of all optimizers currently registered in this Learner.Args:\n            state: The state of the optimizers.\n        \"\"\"raise NotImplementedError\n\n[docs]    def get_optimizer_state(self) -> Mapping[str, Any]:\n        \"\"\"Returns the state of all optimizers currently registered in this Learner.Returns:\n            The current state of all optimizers currently registered in this Learner.\n        \"\"\"raise NotImplementedError\n\n    def _set_slicing_by_batch_id(\n        self, batch: MultiAgentBatch, *, value: bool\n    ) -> MultiAgentBatch:\n        \"\"\"Enables slicing by batch id in the given batch.If the input batch contains batches of sequences we need to make sure when\n        slicing happens it is sliced via batch id and not timestamp.Calling this\n        method enables the same flag on each SampleBatch within the input\n        MultiAgentBatch.",
        "0dd26e96-e113-4de5-ab17-6d95c9bb8e27": "train_batch = sample_min_n_steps_from_buffer(\n                replay_buffer=self.local_replay_buffer,\n                min_steps=self.config.train_batch_size,\n                count_by_agent_steps=self.config.count_steps_by == \"agent_steps\",\n            )\n\n            # Learn on the training batch.# Use simple optimizer (only for multi-agent or tf-eager; all other\n            # cases should use the multi-GPU optimizer, even if only using 1 GPU)\n            if self.config.get(\"simple_optimizer\") is True:\n                train_results = train_one_step(self, train_batch)\n            else:\n                train_results = multi_gpu_train_one_step(self, train_batch)\n\n            # Update target network every `target_network_update_freq` sample steps.",
        "4a4ee07e-9852-4615-9adb-dcee39215494": "provider.location#\n\n\n\nAWS\nNot available.\n\n\n\nAzure\nThe location to use for deployment of the Ray cluster.\n\nRequired: Yes\nImportance: High\nType: String\nDefault: westus2\n\n\n\n\nGCP\nNot available.",
        "6f0ce03a-1903-4b43-b44b-95e781cf2699": "Redirecting Worker logs to the Driver#\nBy default, Worker stdout and stderr for Tasks and Actors stream to the Ray Driver (the entrypoint script that calls ray.init). It helps users aggregate the logs for the distributed Ray application in a single place.\nimport ray\n\n# Initiate a driver.\nray.init()\n\n\n@ray.remote\ndef task():\n    print(\"task\")\n\n\nray.get(task.remote())\n\n\n@ray.remote\nclass Actor:\n    def ready(self):\n        print(\"actor\")\n\n\nactor = Actor.remote()\nray.get(actor.ready.remote())\n\n\nAll stdout emitted from the print method are printed to the driver with a (Task or Actor repr, process ID, IP address) prefix.\n(pid=45601) task\n(Actor pid=480956) actor",
        "aabc8e72-b147-4676-8ca4-3591a5e7b15b": "ray.job_submission.JobStatus.STOPPED#\n\n\nJobStatus.STOPPED = 'STOPPED'#\nThe job was intentionally stopped by the user.",
        "6a71b2bd-16fe-45bf-837e-7e4ce2b1331a": "ray.rllib.core.rl_module.rl_module.RLModule#\n\n\nclass ray.rllib.core.rl_module.rl_module.RLModule(config: ray.rllib.core.rl_module.rl_module.RLModuleConfig)[source]#\nBases: abc.ABC\nBase class for RLlib modules.Subclasses should call super().__init__(config) in their __init__ method.Here is the pseudocode for how the forward methods are called:\nExample for creating a sampling loop:\nfrom ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module import (\n    PPOTorchRLModule\n)\nfrom ray.rllib.algorithms.ppo.ppo_catalog import PPOCatalog\nimport gymnasium as gym\nimport torch\n\nenv = gym.make(\"CartPole-v1\")\n\n# Create a single agent RL module spec.",
        "9d2f2b0b-b724-4a87-b77f-fb0fd080f1a6": "[Advanced] Detached Placement Group#\nBy default, the lifetimes of placement groups belong to the driver and actor.\n\nIf the placement group is created from a driver, it is destroyed when the driver is terminated.\nIf it is created from a detached actor, it is killed when the detached actor is killed.\n\nTo keep the placement group alive regardless of its job or detached actor, specify\nlifetime=\"detached\". For example:\n\n\n\nPython\n# driver_1.py\n# Create a detached placement group that survives even after\n# the job terminates.\npg = placement_group([{\"CPU\": 1}], lifetime=\"detached\", name=\"global_name\")\nray.get(pg.ready())\n\n\n\n\n\nJava\nThe lifetime argument is not implemented for Java APIs yet.\n\n\nLet\u2019s terminate the current script and start a new Python script. Call ray list placement-groups, and you can see the placement group is not removed.\nNote that the lifetime option is decoupled from the name. If we only specified\nthe name without specifying lifetime=\"detached\", then the placement group can\nonly be retrieved as long as the original driver is still running.\nIt is recommended to always specify the name when creating the detached placement group.",
        "30a97f86-c31f-4c51-9320-835401cd8bae": "935801029205322\n  time_this_iter_s: 0.10489487648010254\n  time_total_s: 11.531881093978882\n  timestamp: 1658499100\n  timesteps_since_restore: 0\n  timesteps_total: 0\n  training_iteration: 100\n  trial_id: 25b64488\n  warmup_time: 0.006460905075073242\n  \n\n\n\n\nHere again are the hyperparameters found to minimize the mean loss of the\ndefined objective.\n\n\nprint(\"Best hyperparameters found were: \", results.get_best_result().config)\n\n\n\n\nBest hyperparameters found were:  {'activation': 'tanh', 'height': -48.451797714080236, 'steps': 100, 'width': 10.119125894538891}",
        "1769ef33-b7e8-4c29-a63f-a1161fadf08a": "ray.train.lightning.RayDeepSpeedStrategy.world_size#\n\n\nproperty RayDeepSpeedStrategy.world_size: int#",
        "f94e24ab-5f53-48d1-bac5-f360121870f7": "Application logs#\n\njob-driver-[submission_id].log: The stdout of a job submitted with the Ray Jobs API.\nworker-[worker_id]-[job_id]-[pid].[out|err]: Python or Java part of Ray drivers and workers. All stdout and stderr from Tasks or Actors are streamed to these files. Note that job_id is the ID of the driver.",
        "1b28d587-84e7-4066-a1f3-975b948b66e7": "DesignSpace):\n            raise ValueError(\n                f\"Invalid search space: {type(self._space)}.Either pass a \"\n                f\"valid search space to the `HEBOSearch` class or pass \"\n                f\"a `param_space` parameter to `tune.Tuner()`\"\n            )\n\n        if self._space.num_paras <= 0:\n            raise ValueError(\n                \"Got empty search space.Please make sure to pass \"\n                \"a valid search space with at least one parameter to \"\n                \"`HEBOSearch`\"\n            )\n\n        if self._random_state_seed is not None:\n            np.random.seed(self._random_state_seed)\n            torch.random.manual_seed(self._random_state_seed)\n\n        self._opt = hebo.optimizers.hebo.HEBO(space=self._space, **self._hebo_config)\n\n        if self._points_to_evaluate:\n            validate_warmstart(\n                self._space.para_names,",
        "b47d567d-3127-4fdd-9226-84c17aee3356": "ray.util.queue.Queue.put#\n\n\nQueue.put(item: Any, block: bool = True, timeout: Optional[float] = None) \u2192 None[source]#\nAdds an item to the queue.\nIf block is True and the queue is full, blocks until the queue is no\nlonger full or until timeout.\nThere is no guarantee of order if multiple producers put to the same\nfull queue.\n\nRaises\n\nFull \u2013 if the queue is full and blocking is False.\nFull \u2013 if the queue is full, blocking is True, and it timed out.\nValueError \u2013 if timeout is negative.",
        "be0a9e07-0cd4-44ec-bb4d-de397b9a624c": "if not error and not pruned:\n            self._opt.observe(\n                pd.DataFrame(\n                    [\n                        {\n                            k: v\n                            for k, v in parameters.items()\n                            if k in self._opt.space.para_names\n                        }\n                    ]\n                ),\n                np.array([value]) * self._metric_op,\n            )\n        else:\n            logger.warning(\n                \"Only non errored and non pruned points can be added to HEBO.\")\n\n[docs]    def save(self, checkpoint_path: str):\n        \"\"\"Storing current optimizer state.\"\"\"",
        "ccd3ebe7-2e1e-4eb2-ac3f-fd07788b6ab5": "0034351348876953125\n  \nResult for objective_ed2322be:\n  date: 2022-07-22_15-31-16\n  done: false\n  experiment_id: e95895ab00b54841933d324c3de8f58e\n  hostname: Kais-MacBook-Pro.local\n  iterations: 47\n  iterations_since_restore: 48\n  mean_loss: 2.1909053484385796\n  neg_mean_loss: -2.1909053484385796\n  node_ip: 127.0.0.1\n  pid: 47163\n  time_since_restore: 5.168597936630249\n  time_this_iter_s: 0.10674691200256348\n  time_total_s: 5.168597936630249\n  timestamp: 1658500276\n  timesteps_since_restore: 0\n  training_iteration: 48\n  trial_id: ed2322be\n  warmup_time: 0.0032410621643066406\n  \nResult for objective_ed217cf2:\n  date: 2022-07-22_15-31-16\n  done: false\n  experiment_id: 52186ede891e429aac44318036e7a7bb\n  hostname: Kais-MacBook-Pro.local\n  iterations: 47\n  iterations_since_restore: 48\n  mean_loss: -1.9004596703789314\n  neg_mean_loss: 1.9004596703789314\n  node_ip: 127.0.0.1\n  pid: 47162\n  time_since_restore: 5.14047384262085\n  time_this_iter_s: 0.10724306106567383\n  time_total_s: 5.",
        "0a7ace9a-1281-41ed-87ba-dd9173f5b33e": "Starting the Ray worker nodes#\nBelow, we do the same thing, but for each worker. Make sure the Ray head and Ray worker processes are not started on the same node.\n# optional, though may be useful in certain versions of Ray < 1.0.\nsleep 10\n\n# number of nodes other than the head node\nworker_num=$((SLURM_JOB_NUM_NODES - 1))\n\nfor ((i = 1; i <= worker_num; i++)); do\n    node_i=${nodes_array[$i]}\n    echo \"Starting WORKER $i at $node_i\"\n    srun --nodes=1 --ntasks=1 -w \"$node_i\" \\\n        ray start --address \"$ip_head\" \\\n        --num-cpus \"${SLURM_CPUS_PER_TASK}\" --num-gpus \"${SLURM_GPUS_PER_TASK}\" --block &\n    sleep 5\ndone",
        "eaf9f90d-6101-493c-b073-cadb166c7511": "Loading your environment#\nFirst, you\u2019ll often want to Load modules or your own conda environment at the beginning of the script.\nNote that this is an optional step, but it is often required for enabling the right set of dependencies.\n# Example: module load pytorch/v1.4.0-gpu\n# Example: conda activate my-env\n\nconda activate my-env",
        "2f8e0ae1-4fc3-430e-b9cb-72c885641c80": "py:\n                                                                                                                  :<module>:18\n\n192.168.0.15  6465   Driver  ffffffffffffffffffffffffffffffffffffffff0100000002000000  18 MiB  CAPTURED_IN_OBJECT  (put object)  |\n                                                                                                                   test.py:\n                                                                                                                  <module>:19\n\n192.168.0.",
        "576d03e2-7b09-47b5-acf1-6d0edf73255b": "If ``fn`` mutates its input, this needs to be ``False`` in order to\n                avoid \"assignment destination is read-only\" or \"buffer source array is\n                read-only\" errors.Default is ``False``.fn_args: Positional arguments to pass to ``fn`` after the first argument.These arguments are top-level arguments to the underlying Ray task.fn_kwargs: Keyword arguments to pass to ``fn``.These arguments are\n                top-level arguments to the underlying Ray task.fn_constructor_args: Positional arguments to pass to ``fn``'s constructor.You can only provide this if ``fn`` is a callable class.These arguments\n                are top-level arguments in the underlying Ray actor construction task.fn_constructor_kwargs: Keyword arguments to pass to ``fn``'s constructor.This can only be provided if ``fn`` is a callable class.These arguments\n                are top-level arguments in the underlying Ray actor construction task.num_cpus: The number of CPUs to reserve for each parallel map worker.num_gpus: The number of GPUs to reserve for each parallel map worker.For\n                example, specify `num_gpus=1` to request 1 GPU for each parallel map worker.ray_remote_args: Additional resource requirements to request from\n                ray for each map worker... note::\n\n            The size of the batches provided to ``fn`` might be smaller than the\n            specified ``batch_size`` if ``batch_size`` doesn't evenly divide the\n            block(s) sent to a given map task.",
        "9266ceae-e24a-4db7-95aa-2a6caf7ecda2": "[docs]@dataclass(init=not is_pydantic_2)\nclass ObjectSummaryPerKey:\n    #: Total number of objects of the type.\n    total_objects: int\n    #: Total size in mb.\n    total_size_mb: float\n    #: Total number of workers that reference the type of objects.\n    total_num_workers: int\n    #: Total number of nodes that reference the type of objects.\n    total_num_nodes: int\n    #: State name to the count dict. State name is equivalent to\n    #: ObjectState.\n    task_state_counts: Dict[TypeTaskStatus, int] = field(default_factory=dict)\n    #: Ref count type to the count dict. State name is equivalent to\n    #: ObjectState.\n    ref_type_counts: Dict[TypeReferenceType, int] = field(default_factory=dict)\n\n\n[docs]@dataclass\nclass ObjectSummaries:\n    #: Group key (actor class name) -> summary\n    summary: Dict[str, ObjectSummaryPerKey]\n    #: Total number of referenced objects in the cluster.total_objects: int\n    #: Total size of referenced objects in the cluster in MB.total_size_mb: float\n    #: Whether or not the callsite collection is enabled.callsite_enabled: bool\n    summary_by: str = \"callsite\"\n\n    @classmethod\n    def to_summary(cls, *, objects: List[Dict]):\n        # NOTE: The argument tasks contains a list of dictionary\n        # that have the same k/v as ObjectState.",
        "8643bc8c-0d77-45e0-b6cb-0fcaa972e8d7": "1\n  pid: 54416\n  time_since_restore: 0.22218012809753418\n  time_this_iter_s: 0.007044076919555664\n  time_total_s: 0.22218012809753418\n  timestamp: 1658505356\n  timesteps_since_restore: 0\n  training_iteration: 10\n  trial_id: c28a3_00000\n  warmup_time: 0.0035409927368164062\n  \nResult for train_breast_cancer_c28a3_00003:\n  date: 2022-07-22_16-56-01\n  done: false\n  eval-error: 0.08391608391608392\n  eval-logloss: 0.6472820101918041\n  experiment_id: 7ff6133237404b4ea4755b9f8cd114f2\n  hostname: Kais-MacBook-Pro.local\n  iterations_since_restore: 1\n  node_ip: 127.0.0.1\n  pid: 54442\n  time_since_restore: 0.023206233978271484\n  time_this_iter_s: 0.023206233978271484\n  time_total_s: 0.023206233978271484\n  timestamp: 1658505361\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: c28a3_00003\n  warmup_time: 0.006722211837768555\n  \nResult for train_breast_cancer_c28a3_00005:\n  date: 2022-07-22_16-56-01\n  done: true\n  eval-error: 0.08391608391608392\n  eval-logloss: 0.",
        "fd32ad23-9f8c-41d8-9d4b-7d4f709138ab": "ray.train.lightning.RayFSDPStrategy.on_train_end#\n\n\nRayFSDPStrategy.on_train_end() \u2192 None#\nCalled when train ends.",
        "f1ea3cc9-a715-4603-915d-5b7752f820b0": "model = ConvNet().to(self.device)\n        self.optimizer = optim.SGD(\n            self.model.parameters(),\n            lr=config.get(\"lr\", 0.01),\n            momentum=config.get(\"momentum\", 0.9))\n\n    def step(self):\n        train_func(\n            self.model, self.optimizer, self.train_loader, device=self.device)\n        acc = test_func(self.model, self.test_loader, self.device)\n        return {\"mean_accuracy\": acc}\n\n    def save_checkpoint(self, checkpoint_dir):\n        checkpoint_path = os.path.join(checkpoint_dir, \"model.pth\")\n        torch.save(self.model.state_dict(), checkpoint_path)\n\n    def load_checkpoint(self, checkpoint_dir):\n        checkpoint_path = os.path.join(checkpoint_dir, \"model.pth\")\n        self.model.load_state_dict(torch.load(checkpoint_path))\n\n\n# __trainable_example_end__\n# fmt: on\n\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    ray.init(address=args.ray_address, num_cpus=6 if args.smoke_test else None)\n    sched = ASHAScheduler()\n\n    tuner = tune.Tuner(\n        tune.",
        "373e2b8b-8e7b-4b7c-9ea2-7e9211f9d779": "ray.train.lightning.RayTrainReportCallback.on_configure_sharded_model#\n\n\nRayTrainReportCallback.on_configure_sharded_model(trainer: pytorch_lightning.trainer.trainer.Trainer, pl_module: pytorch_lightning.core.lightning.LightningModule) \u2192 None#\n\nDeprecated since version v1.6: This callback hook was deprecated in v1.6 and will be removed in v1.8. Use setup() instead.\n\nCalled before configure sharded model.",
        "4ce5e4e9-59fe-4dbd-9d37-49a0b090e725": "Returns:\n        :class:`~ray.data.Dataset` producing rows read from the specified paths.\n    \"\"\"output_arrow_format = True\n    if meta_provider is None:\n        meta_provider = get_generic_metadata_provider(BinaryDatasource._FILE_EXTENSION)\n    return read_datasource(\n        BinaryDatasource(),\n        parallelism=parallelism,\n        paths=paths,\n        include_paths=include_paths,\n        filesystem=filesystem,\n        ray_remote_args=ray_remote_args,\n        open_stream_args=arrow_open_stream_args,\n        meta_provider=meta_provider,\n        partition_filter=partition_filter,\n        partitioning=partitioning,\n        ignore_missing_paths=ignore_missing_paths,\n        output_arrow_format=output_arrow_format,\n    )\n\n\n[docs]@PublicAPI(stability=\"alpha\")\ndef read_sql(\n    sql: str,\n    connection_factory: Callable[[], Connection],\n    *,\n    parallelism: int = -1,\n    ray_remote_args: Optional[Dict[str, Any]] = None,\n) -> Dataset:\n    \"\"\"Read from a database that provides a\n    `Python DB API2-compliant <https://peps.python.org/pep-0249/>`_ connector.",
        "7da9d501-b09f-4514-a9a6-e56586b0848f": "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\nimport numpy as np\nimport torch\n\nnum_labels = 3 if task.startswith(\"mnli\") else 1 if task==\"stsb\" else 2\nmetric_name = \"pearson\" if task == \"stsb\" else \"matthews_correlation\" if task == \"cola\" else \"accuracy\"\nmodel_name = model_checkpoint.split(\"/\")[-1]\nvalidation_key = \"validation_mismatched\" if task == \"mnli-mm\" else \"validation_matched\" if task == \"mnli\" else \"validation\"\nname = f\"{model_name}-finetuned-{task}\"\n\n# Calculate the maximum steps per epoch based on the number of rows in the training\n# dataset.# Make sure to scale by the total number of training workers and the per device batch\n# size.max_steps_per_epoch = ray_datasets[\"train\"].count() // (num_workers * batch_size)\n\ndef trainer_init_per_worker(train_dataset, eval_dataset = None, **config):\n    print(f\"Is CUDA available: {torch.cuda.is_available()}\")\n    metric = load_metric_fn()\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n    args = TrainingArguments(\n        name,\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",",
        "bbdf7b97-1a09-4772-b0d5-c9e1887ef93e": "ray.train.tensorflow.TensorflowCheckpoint#\n\n\nclass ray.train.tensorflow.TensorflowCheckpoint(path: Union[str, os.PathLike], filesystem: Optional[pyarrow._fs.FileSystem] = None)[source]#\nBases: ray.train._internal.framework_checkpoint.FrameworkCheckpoint\nA Checkpoint with TensorFlow-specific functionality.\nPublicAPI (beta): This API is in beta and may change before becoming stable.\nMethods\n\n\n\n\n\n\n__init__(path[,\u00a0filesystem])\nConstruct a Checkpoint.\n\nas_directory()\nReturn checkpoint directory path in a context.\n\nfrom_directory(path)\nCreate checkpoint object from a local directory.\n\nfrom_h5(file_path,\u00a0*[,\u00a0preprocessor])\nCreate a Checkpoint that stores a Keras model from H5 format.\n\nfrom_model(model,\u00a0*[,\u00a0preprocessor])\nCreate a Checkpoint that stores a Keras model.\n\nfrom_saved_model(dir_path,\u00a0*[,\u00a0preprocessor])\nCreate a Checkpoint that stores a Keras model from SavedModel format.\n\nget_metadata()\nReturn the metadata dict stored with the checkpoint.\n\nget_model()\nRetrieve the model stored in this checkpoint.\n\nget_preprocessor()\nReturn the preprocessor stored in the checkpoint.\n\nset_metadata(metadata)\nSet the metadata stored with this checkpoint.\n\nset_preprocessor(preprocessor)\nStore a preprocessor with the checkpoint.\n\nto_directory([path])\nWrite checkpoint data to directory.\n\nupdate_metadata(metadata)\nUpdate the metadata stored with this checkpoint.\n\n\n\nAttributes\n\n\n\n\n\n\nMODEL_FILENAME_KEY",
        "16c52537-bdbd-4729-a531-53d85816a0d9": "Launch Ray in Docker#\nStart out by launching the deployment container.\ndocker run --shm-size=<shm-size> -t -i rayproject/ray\n\n\nReplace <shm-size> with a limit appropriate for your system, for example\n512M or 2G. A good estimate for this is to use roughly 30% of your available memory (this is\nwhat Ray uses internally for its Object Store). The -t and -i options here are required to support\ninteractive use of the container.\nIf you use a GPU version Docker image, remember to add --gpus all option. Replace <ray-version> with your target ray version in the following command:\ndocker run --shm-size=<shm-size> -t -i --gpus all rayproject/ray:<ray-version>-gpu\n\n\nNote: Ray requires a large amount of shared memory because each object\nstore keeps all of its objects in shared memory, so the amount of shared memory\nwill limit the size of the object store.\nYou should now see a prompt that looks something like:\nroot@ebc78f68d100:/ray#",
        "435de8cb-68c2-49cc-a9e1-4cc6860b488f": "Convert existing PyTorch code to Ray AIR#\nIf you already have working PyTorch code, you don\u2019t have to start from scratch to utilize the benefits of Ray AIR. Instead, you can continue to use your existing code and incrementally add Ray AIR components as needed.\nSome of the benefits you\u2019ll get by using Ray AIR with your existing PyTorch training code:\n\nEasy distributed data-parallel training on a cluster\nAutomatic checkpointing/fault tolerance and result tracking\nParallel data preprocessing\nSeamless integration with hyperparameter tuning\nScalable model serving\n\nThis tutorial will show you how to start with Ray AIR from your existing PyTorch training code and learn how to distribute your training.",
        "509e0adb-6360-4ac5-b224-41983d25e341": "_to_config):\n                config_update[k] = v\n            elif not _is_allowed_type(v):\n                continue\n            else:\n                log[k] = v\n\n        config_update.pop(\"callbacks\", None)  # Remove callbacks\n        return log, config_update\n\n\nclass WandbLoggerCallback(LoggerCallback):\n    \"\"\"WandbLoggerCallback\n\n    Weights and biases (https://www.wandb.ai/) is a tool for experiment\n    tracking, model optimization, and dataset versioning. This Ray Tune\n    ``LoggerCallback`` sends metrics to Wandb for automatic tracking and\n    visualization.\n\n    Example:\n\n        .. testcode::\n\n            import random\n\n            from ray import train, tune\n            from ray.train import RunConfig\n            from ray.air.integrations.wandb import WandbLoggerCallback",
        "13cf9286-d472-4747-b5b3-5da53bf77d57": "[docs]@PublicAPI\nclass ObjectStoreFullError(RayError):\n    \"\"\"Indicates that the object store is full.\n\n    This is raised if the attempt to store the object fails\n    because the object store is full even after multiple retries.\n    \"\"\"\n\n    def __str__(self):\n        return super(ObjectStoreFullError, self).__str__() + (\n            \"\\n\"\n            \"The local object store is full of objects that are still in \"\n            \"scope and cannot be evicted. Tip: Use the `ray memory` command \"\n            \"to list active objects in the cluster.\"\n        )\n\n\n[docs]@PublicAPI\nclass OutOfDiskError(RayError):\n    \"\"\"Indicates that the local disk is full.\n\n    This is raised if the attempt to store the object fails\n    because both the object store and disk are full.\n    \"\"\"\n\n    def __str__(self):\n        # TODO(scv119): expose more disk usage information and link to a doc.\n        return super(OutOfDiskError, self).__str__() + (\n            \"\\n\"\n            \"The object cannot be created because the local object store\"\n            \" is full and the local disk's utilization is over capacity\"\n            \" (95% by default).\"\n            \"Tip: Use `df` on this node to check disk usage and \"\n            \"`ray memory` to check object store memory usage.\"\n        )",
        "ee739339-074c-4cf8-ae94-59f4752bdd5f": "Fields\n\nautoscaling_config (Optional[Dict])\ngraceful_shutdown_timeout_s (float)\ngraceful_shutdown_wait_loop_s (float)\nhealth_check_period_s (float)\nhealth_check_timeout_s (float)\nis_driver_deployment (bool)\nmax_concurrent_queries (int)\nmax_replicas_per_node (int)\nname (str)\nnum_replicas (Optional[int])\nplacement_group_bundles (List[Dict[str, float]])\nplacement_group_strategy (str)\nray_actor_options (ray.serve.schema.RayActorOptionsSchema)\nroute_prefix (Optional[str])\nuser_config (Optional[Dict])\n\n\nValidators\n\nnum_replicas_and_autoscaling_config_mutually_exclusive \u00bb all fields\n\n\n\n\n\nfield autoscaling_config: Optional[Dict] = DEFAULT.VALUE#\nConfig specifying autoscaling parameters for the deployment\u2019s number of replicas. If null, the deployment won\u2019t autoscale its number of replicas; the number of replicas will be fixed at num_replicas.\n\nValidated by\n\nnum_replicas_and_autoscaling_config_mutually_exclusive\n\n\n\n\n\n\nfield graceful_shutdown_timeout_s: float = DEFAULT.VALUE#\nServe controller waits for this duration before forcefully killing the replica for shutdown. Uses a default if null.\n\nConstraints\n\nminimum = 0\n\n\nValidated by\n\nnum_replicas_and_autoscaling_config_mutually_exclusive\n\n\n\n\n\n\nfield graceful_shutdown_wait_loop_s: float = DEFAULT.VALUE#\nDuration that deployment replicas will wait until there is no more work to be done before shutting down. Uses a default if null.\n\nConstraints\n\nminimum = 0",
        "a33f7220-3f5d-42f8-927c-7528bebc97b5": "def object_transfer_timeline(filename=None):\n    \"\"\"Return a list of transfer events that can viewed as a timeline.\n\n    To view this information as a timeline, simply dump it as a json file by\n    passing in \"filename\" or using using json.dump, and then load go to\n    chrome://tracing in the Chrome web browser and load the dumped file. Make\n    sure to enable \"Flow events\" in the \"View Options\" menu.\n\n    Args:\n        filename: If a filename is provided, the timeline is dumped to that\n            file.\n\n    Returns:\n        If filename is not provided, this returns a list of profiling events.\n            Each profile event is a dictionary.\n    \"\"\"\n    return state.chrome_tracing_object_transfer_dump(filename=filename)\n\n\n[docs]@DeveloperAPI\n@client_mode_hook\ndef cluster_resources():\n    \"\"\"Get the current total cluster resources.\n\n    Note that this information can grow stale as nodes are added to or removed\n    from the cluster.\n\n    Returns:\n        A dictionary mapping resource name to the total quantity of that\n            resource in the cluster.\n    \"\"\"\n    return state.cluster_resources()\n\n\n[docs]@DeveloperAPI\n@client_mode_hook\ndef available_resources():\n    \"\"\"Get the current available cluster resources.\n\n    This is different from `cluster_resources` in that this will return idle\n    (available) resources rather than total resources.\n\n    Note that this information can grow stale as tasks start and finish.\n\n    Returns:\n        A dictionary mapping resource name to the total quantity of that\n            resource in the cluster.\n    \"\"\"\n    return state.available_resources()",
        "46200a7e-d6c4-4770-89d1-3ecb2be1df41": "on_train_batch_end() (ray.train.lightning.RayTrainReportCallback method)\n\non_train_batch_start() (ray.train.lightning.RayDDPStrategy method)\n\n(ray.train.lightning.RayDeepSpeedStrategy method)\n\n(ray.train.lightning.RayFSDPStrategy method)\n\n(ray.train.lightning.RayTrainReportCallback method)\n\n\non_train_begin() (ray.train.huggingface.transformers.RayTrainReportCallback method)\n\non_train_end() (ray.train.huggingface.transformers.RayTrainReportCallback method)\n\n(ray.train.lightning.RayDDPStrategy method)\n\n(ray.train.lightning.RayDeepSpeedStrategy method)\n\n(ray.train.lightning.RayFSDPStrategy method)\n\n(ray.train.lightning.RayTrainReportCallback method)\n\n\non_train_epoch_start() (ray.train.lightning.RayTrainReportCallback method)\n\non_train_result() (ray.rllib.algorithms.callbacks.DefaultCallbacks method)\n\non_train_start() (ray.train.lightning.RayDDPStrategy method)\n\n(ray.train.lightning.RayDeepSpeedStrategy method)\n\n(ray.train.lightning.RayFSDPStrategy method)\n\n(ray.train.lightning.RayTrainReportCallback method)\n\n\non_training_start() (ray.train.backend.Backend method)\n\non_trial_add() (ray.tune.schedulers.AsyncHyperBandScheduler method)\n\n(ray.tune.schedulers.HyperBandForBOHB method)\n\n(ray.tune.schedulers.HyperBandScheduler method)\n\n(ray.tune.schedulers.TrialScheduler method)",
        "d8e709a9-2b01-4deb-a65d-11b267cb6151": "[docs]@PublicAPI\ndef range(n: int, *, parallelism: int = -1) -> Dataset:\n    \"\"\"Creates a :class:`~ray.data.Dataset` from a range of integers [0..n).This function allows for easy creation of synthetic datasets for testing or\n    benchmarking :ref:`Ray Data <data>`.Examples:\n\n        >>> import ray\n        >>> ds = ray.data.range(10000)\n        >>> ds\n        Dataset(num_blocks=..., num_rows=10000, schema={id: int64})\n        >>> ds.map(lambda row: {\"id\": row[\"id\"] * 2}).take(4)\n        [{'id': 0}, {'id': 2}, {'id': 4}, {'id': 6}]\n\n    Args:\n        n: The upper bound of the range of integers.parallelism: The amount of parallelism to use for the dataset.Defaults to -1,\n            which automatically determines the optimal parallelism for your\n            configuration.You should not need to manually set this value in most cases.For details on how the parallelism is automatically determined and guidance\n            on how to tune it, see\n            :ref:`Tuning read parallelism <read_parallelism>`.",
        "4675f32f-6d24-4523-aef2-dd898e1b50d2": "(RayTrainWorker pid=1789, ip=172.31.90.137) ***** Running Evaluation *****\n(RayTrainWorker pid=1789, ip=172.31.90.137)   Num examples = 1043\n(RayTrainWorker pid=1789, ip=172.31.90.137)   Batch size = 16\n(RayTrainWorker pid=1789, ip=172.31.90.137) The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n\n(RayTrainWorker pid=1789, ip=172.31.90.137) {'loss': 0.2687, 'learning_rate': 5e-06, 'epoch': 3.0}\n(RayTrainWorker pid=1789, ip=172.31.90.137) {'eval_loss': 0.6935313940048218, 'eval_matthews_correlation': 0.5300538425561, 'eval_runtime': 1.0176, 'eval_samples_per_second': 267.305, 'eval_steps_per_second': 4.914, 'epoch': 3.0}",
        "1a99d330-62d4-4ddf-b22a-b6bdfe06fddb": "add_hyperparameter(\n            CS.CategoricalHyperparameter(\n                name=\"activation\", choices=[\"relu\", \"tanh\"]))\n\n        algo = TuneBOHB(\n            config_space, metric=\"mean_loss\", mode=\"min\")\n        bohb = HyperBandForBOHB(\n            time_attr=\"training_iteration\",\n            metric=\"mean_loss\",\n            mode=\"min\",\n            max_t=100)\n        run(my_trainable, scheduler=bohb, search_alg=algo)\n\n    \"\"\"\n\n    def __init__(\n        self,\n        space: Optional[Union[Dict, \"ConfigSpace.ConfigurationSpace\"]] = None,\n        bohb_config: Optional[Dict] = None,\n        metric: Optional[str] = None,\n        mode: Optional[str] = None,\n        points_to_evaluate: Optional[List[Dict]] = None,\n        seed: Optional[int] = None,\n        max_concurrent: int = 0,\n    ):\n        assert (\n            BOHB is not None\n        ), \"\"\"HpBandSter must be installed!You can install HpBandSter with the command:\n            `pip install hpbandster ConfigSpace`.\"\"\"",
        "e34acd89-6a74-4abe-a072-31adbc218707": "self.num_rollout_workers = 2\n        self.rollout_fragment_length = 50\n        self.train_batch_size = 500\n        self.min_time_s_per_iteration = 10\n        self.num_gpus = 0\n        self.num_multi_gpu_tower_stacks = 1\n        self.minibatch_buffer_size = 1\n        self.num_sgd_iter = 1\n        self.target_update_frequency = 1\n        self.replay_proportion = 0.0\n        self.replay_buffer_num_slots = 100\n        self.learner_queue_size = 16\n        self.learner_queue_timeout = 300\n        self.max_sample_requests_in_flight_per_worker = 2\n        self.broadcast_interval = 1\n\n        self.grad_clip = 40.0\n        # Note: Only when using _enable_learner_api=True can the clipping mode be\n        # configured by the user.On the old API stack, RLlib will always clip by\n        # global_norm, no matter the value of `grad_clip_by`.",
        "42f7c036-0c04-403a-870b-1d1ef7749ee5": "ray.tune.search.optuna.OptunaSearch.FINISHED#\n\n\nOptunaSearch.FINISHED = 'FINISHED'#",
        "6cdf542c-8e01-4cef-8b89-076c32962ece": "1:46323relu         54.6085     100 1.2361  16.2163     100         10.6711          99     -16.2163  \nobjective_dd5a8bcaTERMINATED127.0.0.1:46328tanh          5.22131    10017.0952   0.580871   100         10.7017          99      -0.580871\nobjective_e3482178TERMINATED127.0.0.1:46341tanh         78.844      10015.5079   7.94912    100         12.6417          99      -7.94912 \nobjective_e532d6e0TERMINATED127.0.0.1:46353tanh        -66.9988     100 7.15087 -6.56059    100         10.7486          99       6.56059 \n\nResult for objective_d363eed6:\n  date: 2022-07-22_15-23-18\n  done: false\n  experiment_id: af8f846e60254bc794827e76909df4f0\n  hostname: Kais-MacBook-Pro.local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 29.698044266420816\n  neg_mean_loss: -29.",
        "96ce8bc2-2978-47d7-814b-717b33f8a30a": "key = cls._translate_special_keys(key, warn_deprecated=True)\n            config_overrides[key] = value\n\n        return config_overrides\n\n    def __init__(self, algo_class=None):\n        # Define all settings and their default values.# Define the default RLlib Algorithm class that this AlgorithmConfig will be\n        # applied to.self.algo_class = algo_class\n\n        # `self.python_environment()`\n        self.extra_python_environs_for_driver = {}\n        self.extra_python_environs_for_worker = {}\n\n        # `self.resources()`\n        self.num_gpus = 0\n        self.num_cpus_per_worker = 1\n        self.num_gpus_per_worker = 0\n        self._fake_gpus = False\n        self.num_cpus_for_local_worker = 1\n        self.num_learner_workers = 0\n        self.num_gpus_per_learner_worker = 0\n        self.num_cpus_per_learner_worker = 1\n        self.local_gpu_idx = 0\n        self.custom_resources_per_worker = {}\n        self.placement_strategy = \"PACK\"\n\n        # `self.framework()`\n        self.",
        "097fcf03-a573-42bd-a411-542c4bf2a4aa": "PyTorch+Optuna\nTo tune your PyTorch models with Optuna, you wrap your model in an objective function whose config you\ncan access for selecting hyperparameters.\nIn the example below we only tune the momentum and learning rate (lr) parameters of the model\u2019s optimizer,\nbut you can tune any other model parameter you want.\nAfter defining the search space, you can simply initialize the OptunaSearch object and pass it to run.\nIt\u2019s important to tell Ray Tune which metric you want to optimize and whether you want to maximize or minimize it.\nWe stop tuning this training run after 5 iterations, but you can easily define other stopping rules as well.\nimport torch\nfrom ray import train, tune\nfrom ray.tune.search.optuna import OptunaSearch\n\n\ndef objective(config):  # \u2460\n    train_loader, test_loader = load_data()  # Load some data\n    model = ConvNet().to(\"cpu\")  # Create a PyTorch conv net\n    optimizer = torch.optim.SGD(  # Tune the optimizer\n        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"]\n    )\n\n    while True:\n        train(model, optimizer, train_loader)  # Train the model\n        acc = test(model, test_loader)  # Compute test accuracy\n        train.report({\"mean_accuracy\": acc})  # Report to Tune",
        "f33fb97d-69d4-4e03-81ae-a5262c416883": "if any(\n                    [\n                        self.entrypoint_num_cpus is not None\n                        and self.entrypoint_num_cpus > 0,\n                        self.entrypoint_num_gpus is not None\n                        and self.entrypoint_num_gpus > 0,\n                        self.entrypoint_resources not in [None, {}],\n                    ]\n                ):\n                    self.message += (\n                        \" It may be waiting for resources \"\n                        \"(CPUs, GPUs, custom resources) to become available.\")\n                if self.runtime_env not in [None, {}]:\n                    self.message += (\n                        \" It may be waiting for the runtime environment to be set up.\")\n            elif self.status == JobStatus.RUNNING:\n                self.message = \"Job is currently running.\"",
        "b2bed103-d4d6-4510-8b82-3cb5882b2be1": "ray.rllib.models.modelv2.ModelV2.forward#",
        "4057cd71-e8b0-4231-9404-5dfcccc078fe": ">>> config.environment(env=\"CartPole-v1\")   # doctest: +SKIP\n        >>> # Use to_dict() to get the old-style python config dict\n        >>> # when running with tune.>>> tune.Tuner( # doctest: +SKIP\n        ...     \"AlphaZero\",\n        ...     run_config=air.RunConfig(stop={\"episode_reward_mean\": 200}),\n        ...     param_space=config.to_dict(),\n        ... ).fit()\n    \"\"\"\n\n    def __init__(self, algo_class=None):\n        \"\"\"Initializes a PPOConfig instance.\"\"\"super().__init__(algo_class=algo_class or AlphaZero)\n\n        # fmt: off\n        # __sphinx_doc_begin__\n        # AlphaZero specific config settings:\n        self.sgd_minibatch_size = 128\n        self.shuffle_sequences = True\n        self.num_sgd_iter = 30\n        self.replay_buffer_config = {\n            \"type\": \"ReplayBuffer\",\n            # Size of the replay buffer in batches (not timesteps!).\"capacity\": 1000,\n            # Choosing `fragments` here makes it so that the buffer stores entire\n            # batches, instead of sequences, episodes or timesteps.",
        "a26a0911-2a90-43d4-a599-346eabe28ca0": "Models, Preprocessors, and Action Distributions#\nThe following diagram provides a conceptual overview of data flow between different components in RLlib.\nWe start with an Environment, which - given an action - produces an observation.\nThe observation is preprocessed by a Preprocessor and Filter (e.g. for running mean normalization)\nbefore being sent to a neural network Model. The model output is in turn\ninterpreted by an ActionDistribution to determine the next action.\nThe components highlighted in green can be replaced with custom user-defined\nimplementations, as described in the next sections. The purple components are\nRLlib internal, which means they can only be modified by changing the algorithm\nsource code.",
        "6f324b29-469d-4882-9f61-5089620fe271": "7032668590545654\n  timestamp: 1658498675\n  timesteps_since_restore: 0\n  timesteps_total: 99\n  training_iteration: 100\n  trial_id: 34adf04a\n  warmup_time: 0.0027239322662353516\n  \nResult for objective_34b7abda:\n  date: 2022-07-22_15-04-35\n  done: true\n  experiment_id: f135a2c40f5644ba9d2ae096a9dd10e0\n  experiment_tag: 10_iterations=100,x1=0.2653,x2=0.9249,x3=0.1517,x4=0.4360,x5=0.8573,x6=0.0898\n  hostname: Kais-MacBook-Pro.local\n  iterations_since_restore: 100\n  l2norm: 1.3718451333547932\n  landscape: -1.6624439263544026\n  node_ip: 127.0.0.1\n  pid: 44771\n  time_since_restore: 2.6852078437805176\n  time_this_iter_s: 0.029579877853393555\n  time_total_s: 2.6852078437805176\n  timestamp: 1658498675\n  timesteps_since_restore: 0\n  timesteps_total: 99\n  training_iteration: 100\n  trial_id: 34b7abda\n  warmup_time: 0.002721071243286133\n  \n\n\n\n\nAnd now we have the hyperparameters found to minimize the mean loss.\n\n\nprint(\"Best hyperparameters found were: \", results.get_best_result().config)",
        "eee179f0-cc31-4582-8091-72fdce983a0f": "# Initialize workers with Horovod environment variables\n        setup_futures = []\n        for rank in range(len(worker_group)):\n            worker_node_id = worker_group.workers[rank].metadata.node_id\n            setup_futures.append(\n                worker_group.execute_single_async(\n                    rank,\n                    _init_env_vars,\n                    rank,\n                    len(worker_group),\n                    worker_node_id,\n                )\n            )\n        ray.get(setup_futures)\n\n        # Use Horovod Ray Coordinator\n        # backend_config as settings\n        self.coordinator = Coordinator(backend_config)\n\n        # Get all the hostnames of all workers\n        node_ids = [w.metadata.node_id for w in worker_group.workers]\n        hostnames = [w.metadata.hostname for w in worker_group.workers]\n        # Register each hostname to the coordinator.assumes the hostname\n        # ordering is the same.",
        "3ab88eae-5f4f-4377-b392-de77d2d9c588": "use_gpu = True\n\n            model_checkpoint = \"gpt2\"\n            tokenizer_checkpoint = \"sgugger/gpt2-like-tokenizer\"\n            block_size = 128\n\n            datasets = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n            tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint)\n\n            def tokenize_function(examples):\n                return tokenizer(examples[\"text\"])\n\n            tokenized_datasets = datasets.map(\n                tokenize_function, batched=True, num_proc=1, remove_columns=[\"text\"]\n            )\n\n            def group_texts(examples):\n                # Concatenate all texts.concatenated_examples = {\n                    k: sum(examples[k], []) for k in examples.keys()\n                }\n                total_length = len(concatenated_examples[list(examples.keys())[0]])\n                # We drop the small remainder, we could add padding if the model\n                # supported it.",
        "c835ea07-933b-4eb6-bc88-69c5086752a0": "Source code for ray.util.collective.collective\n\"\"\"APIs exposed under the namespace ray.util.collective.\"\"\"\nimport logging\nimport os\nfrom typing import List\n\nimport numpy as np\n\nimport ray\nfrom ray.util.collective import types\n\n_NCCL_AVAILABLE = True\n_GLOO_AVAILABLE = True\n\nlogger = logging.getLogger(__name__)\n\ntry:\n    from ray.util.collective.collective_group.nccl_collective_group import NCCLGroup\nexcept ImportError:\n    _NCCL_AVAILABLE = False\n    logger.warning(\n        \"NCCL seems unavailable. Please install Cupy \"\n        \"following the guide at: \"\n        \"https://docs.cupy.dev/en/stable/install.html.\"\n    )\n\ntry:\n    from ray.util.collective.collective_group.gloo_collective_group import GLOOGroup\nexcept ImportError:\n    _GLOO_AVAILABLE = False\n\n\ndef nccl_available():\n    return _NCCL_AVAILABLE\n\n\ndef gloo_available():\n    return _GLOO_AVAILABLE\n\n\n[docs]class GroupManager(object):\n    \"\"\"Use this class to manage the collective groups we created so far.Each process will have an instance of `GroupManager`.Each process\n    could belong to multiple collective groups.The membership information\n    and other metadata are stored in the global `_group_mgr` object.\n    \"\"\"",
        "035a7c98-1392-4cee-b844-90ac6302da6b": "ray.data.block.BlockExecStats#\n\n\nclass ray.data.block.BlockExecStats[source]#\nBases: object\nExecution stats for this block.\n\n\nwall_time_s#\nThe wall-clock time it took to compute this block.\n\n\n\ncpu_time_s#\nThe CPU time it took to compute this block.\n\n\n\nnode_id#\nA unique id for the node that computed this block.\n\nDeveloperAPI: This API may change across minor Ray releases.\nMethods",
        "7ae5ccc9-67f7-4a1f-b0f2-6957b0095db8": ">>> algo = config.build(env=\"CartPole-v1\")  # doctest: +SKIP\n        >>> algo.train()  # doctest: +SKIP\n\n    Example:\n        >>> from ray.rllib.algorithms.ppo import PPOConfig\n        >>> from ray import air\n        >>> from ray import tune\n        >>> config = PPOConfig()\n        >>> # Print out some default values.>>> print(config.clip_param)  # doctest: +SKIP\n        >>> # Update the config object.>>> config.training(  # doctest: +SKIP\n        ... lr=tune.grid_search([0.001, 0.0001]), clip_param=0.2\n        ... )\n        >>> # Set the config object's env.>>> config = config.environment(env=\"CartPole-v1\")   # doctest: +SKIP\n        >>> # Use to_dict() to get the old-style python config dict\n        >>> # when running with tune.>>> tune.Tuner(  # doctest: +SKIP\n        ...     \"PPO\",\n        ...     run_config=air.RunConfig(stop={\"episode_reward_mean\": 200}),\n        ...     param_space=config.to_dict(),\n        ... ).fit()\n    \"\"\"\n\n    def __init__(self, algo_class=None):\n        \"\"\"Initializes a PPOConfig instance.\"\"\"",
        "9093458b-1ac6-485f-8643-2fe46c753d08": "Use it to read small datasets or prototype... warning::\n        If your dataset is large, this function may execute slowly or raise an\n        out-of-memory error.To avoid issues, read the underyling data with a function\n        like :meth:`~ray.data.read_images`... note::\n        This function isn't parallelized.It loads the entire dataset into the local\n        node's memory before moving the data to the distributed object store.Examples:\n        >>> import ray\n        >>> import tensorflow_datasets as tfds\n        >>> dataset, _ = tfds.load('cifar10', split=[\"train\", \"test\"])  # doctest: +SKIP\n        >>> ds = ray.data.from_tf(dataset)  # doctest: +SKIP\n        >>> ds  # doctest: +SKIP\n        MaterializedDataset(\n            num_blocks=.\n            num_rows=50000,\n            schema={\n                id: binary,\n                image: numpy.ndarray(shape=(32, 32, 3), dtype=uint8),\n                label: int64\n            }\n        )\n        >>> ds.take(1)  # doctest: +SKIP\n        [{'id': b'train_16399',",
        "d0fdc4c8-70d8-4d58-905e-55bba327cd02": "ray.runtime_env.RuntimeEnv.clear#\n\n\nRuntimeEnv.clear() \u2192 None.\u00a0 Remove all items from D.#",
        "ed79501a-01e5-4fc6-aa00-e9a1b543fb30": "10711097717285156\n  time_total_s: 5.172597885131836\n  timestamp: 1658499908\n  timesteps_since_restore: 0\n  training_iteration: 48\n  trial_id: '12342770'\n  warmup_time: 0.0032460689544677734\n  \nResult for objective_12374d7e:\n  date: 2022-07-22_15-25-08\n  done: false\n  experiment_id: 5788d010ee194eeeabfc3592d37fb2cc\n  hostname: Kais-MacBook-Pro.local\n  iterations: 47\n  iterations_since_restore: 48\n  mean_loss: 9.955526689542863\n  neg_mean_loss: -9.955526689542863\n  node_ip: 127.0.0.1\n  pid: 46551\n  time_since_restore: 5.162422180175781\n  time_this_iter_s: 0.10872411727905273\n  time_total_s: 5.162422180175781\n  timestamp: 1658499908\n  timesteps_since_restore: 0\n  training_iteration: 48\n  trial_id: 12374d7e\n  warmup_time: 0.002891063690185547\n  \nResult for objective_1045958e:\n  date: 2022-07-22_15-25-10\n  done: false\n  experiment_id: 3579bfc2b346424b833f82f23d459807\n  hostname: Kais-MacBook-Pro.local\n  iterations: 94\n  iterations_since_restore: 95\n  mean_loss: 2.852294770731789\n  neg_mean_loss: -2.",
        "eaf08b3b-1898-47cd-a020-3067913c792c": "Raises:\n        Exceptions: :class:`RayStateApiException <ray.util.state.exception.RayStateApiException>` if the CLI\n            failed to query the data.\n    \"\"\"# noqa: E501\n    return StateApiClient(address=address).list(\n        StateResource.OBJECTS,\n        options=ListApiOptions(\n            limit=limit, timeout=timeout, filters=filters, detail=detail\n        ),\n        raise_on_missing_output=raise_on_missing_output,\n        _explain=_explain,\n    )\n\n\n[docs]@DeveloperAPI\ndef list_runtime_envs(\n    address: Optional[str] = None,\n    filters: Optional[List[Tuple[str, PredicateType, SupportedFilterType]]] = None,\n    limit: int = DEFAULT_LIMIT,\n    timeout: int = DEFAULT_RPC_TIMEOUT,\n    detail: bool = False,\n    raise_on_missing_output: bool = True,\n    _explain: bool = False,\n) -> List[RuntimeEnvState]:\n    \"\"\"List runtime environments in the cluster.Args:\n        address: Ray bootstrap address, could be `auto`, `localhost:6379`.If None, it will be resolved automatically from an initialized ray.filters: List of tuples of filter key, predicate (=, or !=), and\n            the filter value.E.g., `(\"node_id\", \"=\", \"abcdef\")`\n        limit: Max number of entries returned by the state backend.timeout: Max timeout value for the state APIs requests made.",
        "98aa1543-6a82-4d4b-bf8b-28e77ba01edd": "Raylet failure#\nWhen a raylet process fails, the corresponding node will be marked as dead and is treated the same as node failure.\nEach raylet is associated with a unique id, so even if the raylet restarts on the same physical machine,\nit\u2019ll be treated as a new raylet/node to the Ray cluster.",
        "f0b4d50a-ba08-488b-b088-2bbbbacc492b": "Args:\n            sample_batch: sample_batch: batch of experiences for the policy,\n                which will contain at most one episode trajectory.other_agent_batches: In a multi-agent env, this contains a\n                mapping of agent ids to (policy, agent_batch) tuples\n                containing the policy and experiences of the other agents.episode: An optional multi-agent episode object to provide\n                access to all of the internal episode state, which may\n                be useful for model-based or multi-agent algorithms.Returns:\n            The postprocessed sample batch.\n        \"\"\"assert tf.executing_eagerly()\n        return Policy.postprocess_trajectory(self, sample_batch)\n\n[docs]    @OverrideToImplementCustomLogic\n    def optimizer(\n        self,\n    ) -> Union[\"tf.keras.optimizers.Optimizer\", List[\"tf.keras.optimizers.Optimizer\"]]:\n        \"\"\"TF optimizer to use for policy optimization.Returns:\n            A local optimizer or a list of local optimizers to use for this\n                Policy's Model.\n        \"\"\"",
        "fe3c5034-630d-4a36-9a43-a20219a1ee29": "Overview#\nThis tutorial will cover:\n\nCreating a Dataset that represents the images in the dataset\nRunning the computationally expensive OCR process on each image in the dataset in parallel\nFiltering the dataset by keeping only images that contain text\nPerforming various NLP operations on the text",
        "cc61bbd5-1914-4428-a09a-b5bc5aa86d31": "Serving tuned models with Ray Serve#\nLet\u2019s now turn to the model serving part with Ray Serve. Serve allows\nyou to deploy your models as multiple deployments. Broadly speaking,\na deployment handles incoming requests and replies with a result. For\ninstance, our MNIST deployment takes an image as input and outputs the\ndigit it recognized from it. This deployment can be exposed over HTTP.\nFirst, we will define our deployment. This loads our PyTorch\nMNIST model from a checkpoint, takes an image as an input and\noutputs our digit prediction according to our trained model:",
        "74e19511-18c4-4e74-b255-bac75f517c5d": "import gymnasium as gym\nfrom ray.rllib.algorithms.ppo import PPOConfig\n\n\n# Define your problem using python and Farama-Foundation's gymnasium API:\nclass SimpleCorridor(gym.Env):\n    \"\"\"Corridor in which an agent must learn to move right to reach the exit.---------------------\n    | S | 1 | 2 | 3 | G |   S=start; G=goal; corridor_length=5\n    ---------------------\n\n    Possible actions to chose from are: 0=left; 1=right\n    Observations are floats indicating the current field index, e.g.0.0 for\n    starting position, 1.0 for the field next to the starting position, etc..Rewards are -0.1 for all steps, except when reaching the goal (+1.0).\n    \"\"\"def __init__(self, config):\n        self.end_pos = config[\"corridor_length\"]\n        self.cur_pos = 0\n        self.action_space = gym.spaces.Discrete(2)  # left and right\n        self.observation_space = gym.spaces.Box(0.0, self.end_pos, shape=(1,))\n\n    def reset(self, *, seed=None, options=None):\n        \"\"\"Resets the episode.Returns:\n           Initial observation of the new episode and an info dict.\n        \"\"\"self.cur_pos = 0\n        # Return initial observation.return [self.cur_pos], {}\n\n    def step(self, action):\n        \"\"\"Takes a single step in the episode given `action`.",
        "e49b51c3-f991-4664-8041-f8ecb7804d11": "JobSubmissionClient#\n\n\n\n\n\n\nJobSubmissionClient([address,\u00a0...])\nA local client for submitting and interacting with jobs on a remote cluster.\n\n\n\n\n\n\n\n\n\nJobSubmissionClient.submit_job(*,\u00a0entrypoint)\nSubmit and execute a job asynchronously.\n\nJobSubmissionClient.stop_job(job_id)\nRequest a job to exit asynchronously.\n\nJobSubmissionClient.get_job_status(job_id)\nGet the most recent status of a job.\n\nJobSubmissionClient.get_job_info(job_id)\nGet the latest status and other information associated with a job.\n\nJobSubmissionClient.list_jobs()\nList all jobs along with their status and other information.\n\nJobSubmissionClient.get_job_logs(job_id)\nGet all logs produced by a job.\n\nJobSubmissionClient.tail_job_logs(job_id)\nGet an iterator that follows the logs of a job.",
        "e1f92f9c-b8dc-4a5e-8847-bd645d11bec5": "algo = HyperOptSearch(space=conditional_space, metric=\"mean_loss\", mode=\"min\")\nalgo = ConcurrencyLimiter(algo, max_concurrent=4)\n\n\n\n\nNow we run the experiment, this time with an empty config because we instead provided space to the HyperOptSearch search_alg.\n\n\ntuner = tune.Tuner(\n    objective_two,\n    tune_config=tune.TuneConfig(\n        metric=\"mean_loss\",\n        mode=\"min\",\n        search_alg=algo,\n        num_samples=num_samples,\n    ),\n)\nresults = tuner.fit()\n\n\n\n\n== Status ==Current time: 2022-07-22 15:32:33 (running for 00:00:44.21)Memory usage on this node: 10.7/16.0 GiBUsing FIFO scheduling algorithm.Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/5.29 GiB heap, 0.0/2.0 GiB objectsCurrent best trial: 0de7d38c with mean_loss=-9.200364093875208 and parameters={'activation': {'activation': 'relu', 'mult': 1.3982639549501585}, 'height': -66.3136247260571, 'steps': 100, 'width': 13.922128223483856}Result logdir: /Users/kai/ray_results/objective_two_2022-07-22_15-31-49Number of trials: 10/10 (10 TERMINATED)\n\nTrial name            status    loc            activation/activa...    activation/mult   height  steps    width    loss  iter  total time (s)  iterations  neg_mean_loss",
        "d1206441-e701-4ee4-84b7-555bd26f3509": "ray.tune.search.Searcher.FINISHED#\n\n\nSearcher.FINISHED = 'FINISHED'#",
        "1026f648-a7e8-42ee-af28-50595f00b56c": "Step 3: Configure environment variables for Ray TLS authentication#\nTo enable TLS authentication in your Ray cluster, set the following environment variables:\n\nRAY_USE_TLS: Either 1 or 0 to use/not-use TLS. If this is set to 1 then all of the environment variables below must be set. Default: 0.\nRAY_TLS_SERVER_CERT: Location of a certificate file which is presented to other endpoints so as to achieve mutual authentication (i.e. tls.crt).\nRAY_TLS_SERVER_KEY: Location of a private key file which is the cryptographic means to prove to other endpoints that you are the authorized user of a given certificate (i.e. tls.key).\nRAY_TLS_CA_CERT: Location of a CA certificate file which allows TLS to decide whether an endpoint\u2019s certificate has been signed by the correct authority (i.e. ca.crt).\n\nFor more information on how to configure Ray with TLS authentication, please refer to Ray\u2019s document.",
        "06ea0883-f926-4527-b5e7-9ef7afb5fddd": "stop_experiment() (ray.tune.web_server.TuneClient method)\n\nstop_job() (ray.job_submission.JobSubmissionClient method)\n\nstop_trial() (ray.tune.web_server.TuneClient method)\n\nSTOPPED (ray.job_submission.JobStatus attribute)\n\nStopper (class in ray.tune.stopper)\n\nstopper (ray.tune.Experiment property)\n\nstorage_filesystem (ray.train.RunConfig attribute)\n\nstorage_path (ray.train.RunConfig attribute)\n\nStorageUnit (class in ray.rllib.utils.replay_buffers.replay_buffer)\n\nstrategy (ray.tune.execution.placement_groups.PlacementGroupFactory property)\n\nstrategy() (ray.train.lightning.LightningConfigBuilder method)\n\nstrategy_name (ray.train.lightning.RayDDPStrategy attribute)\n\n(ray.train.lightning.RayDeepSpeedStrategy attribute)\n\n(ray.train.lightning.RayFSDPStrategy attribute)\n\n\nstreaming_split() (ray.data.Dataset method)\n\nstyle (ray.data.datasource.Partitioning attribute)\n\nSUBMISSION (ray.job_submission.JobType attribute)\n\nsubmission_id (ray.job_submission.JobDetails attribute)\n\nsubmit() (ray.util.ActorPool method)\n\nsubmit_job() (ray.job_submission.JobSubmissionClient method)\n\nSUCCEEDED (ray.job_submission.JobStatus attribute)\n\nsuccess (ray.util.state.common.RuntimeEnvState attribute)\n\nsuggest() (ray.tune.search.bayesopt.BayesOptSearch method)\n\n(ray.tune.search.Searcher method)\n\n\nSum (class in ray.data.aggregate)\n\nsum() (ray.data.Dataset method)\n\n(ray.data.grouped_data.GroupedData method)",
        "5b58c850-3bed-4dec-80a9-669b7c14ea24": "ray.rllib.core.models.catalog.Catalog.latent_dims#\n\n\nproperty Catalog.latent_dims#\nReturns the latent dimensions of the encoder.\nThis establishes an agreement between encoder and heads about the latent\ndimensions. Encoders can be built to output a latent tensor with\nlatent_dims dimensions, and heads can be built with tensors of\nlatent_dims dimensions as inputs. This can be safely ignored if this\nagreement is not needed in case of modifications to the Catalog.\n\nReturns\nThe latent dimensions of the encoder.",
        "ee0d1faa-16fa-4eca-8224-671f17953d02": "action_dist = None\n                if SampleBatch.ACTION_DIST_INPUTS in fwd_out:\n                    dist_inputs = fwd_out[SampleBatch.ACTION_DIST_INPUTS]\n                    action_dist_class = self.model.get_inference_action_dist_cls()\n                    action_dist = action_dist_class.from_logits(dist_inputs)\n                    action_dist = action_dist.to_deterministic()\n\n                # If `forward_inference()` returned actions, use them here as-is.if SampleBatch.ACTIONS in fwd_out:\n                    actions = fwd_out[SampleBatch.ACTIONS]\n                # Otherwise, sample actions from the distribution.",
        "07c9da02-70ab-405c-bcd2-917735199933": "[docs]@PublicAPI\nclass LocalRayletDiedError(RayError):\n    \"\"\"Indicates that the task's local raylet died.\"\"\"\n\n    def __str__(self):\n        return \"The task's local raylet died. Check raylet.out for more information.\"\n\n\n[docs]@PublicAPI\nclass WorkerCrashedError(RayError):\n    \"\"\"Indicates that the worker died unexpectedly while executing a task.\"\"\"\n\n    def __str__(self):\n        return (\n            \"The worker died unexpectedly while executing this task. \"\n            \"Check python-core-worker-*.log files for more information.\"\n        )\n\n\n[docs]@PublicAPI\nclass RayActorError(RayError):\n    \"\"\"Indicates that the actor died unexpectedly before finishing a task.This exception could happen either because the actor process dies while\n    executing a task, or because a task is submitted to a dead actor.If the actor is dead because of an exception thrown in its creation tasks,\n    RayActorError will contain the creation_task_error, which is used to\n    reconstruct the exception on the caller side.Args:\n        cause: The cause of the actor error.`RayTaskError` type means\n            the actor has died because of an exception within `__init__`.`ActorDiedErrorContext` means the actor has died because of\n            unexepected system error.None means the cause is not known.Theoretically, this should not happen,\n            but it is there as a safety check.\n    \"\"\"def __init__(self, cause: Union[RayTaskError, ActorDiedErrorContext] = None):\n        # -- If the actor has failed in the middle of __init__, this is set.",
        "3e9afc61-80e7-4872-927b-fe54fa405bc9": "m1 = Model.bind(1)\nm2 = Model.bind(2)\n\nwith InputNode() as user_input:\n    m1_output = m1.forward.bind(user_input[0])\n    m2_output = m2.forward.bind(user_input[1])\n    combine_output = combine.bind(m1_output, m2_output, kwargs_output=user_input[2])\n\n# m1_output visualization\ngraph = _dag_to_dot(m1_output)\nto_string = graph.to_string()\nprint(to_string)\n\n# Full graph visualization\ngraph = _dag_to_dot(combine_output)\nto_string = graph.to_string()\nprint(to_string)\n\n\nThe ray.dag.vis_utils._dag_to_dot method takes in a DeploymentNode and produces a graph visualization. You can see the string form of the visualization by running the script:\n$ python deployment_graph_viz.py\n\ndigraph G {\nrankdir=LR;\nINPUT_ATTRIBUTE_NODE -> forward;\nINPUT_NODE -> INPUT_ATTRIBUTE_NODE;\nModel -> forward;\n}\n\ndigraph G {\nrankdir=LR;\nforward -> combine;\nINPUT_ATTRIBUTE_NODE -> forward;\nINPUT_NODE -> INPUT_ATTRIBUTE_NODE;\nModel -> forward;\nforward_1 -> combine;\nINPUT_ATTRIBUTE_NODE_1 -> forward_1;\nINPUT_NODE -> INPUT_ATTRIBUTE_NODE_1;\nModel_1 -> forward_1;\nINPUT_ATTRIBUTE_NODE_2 -> combine;\nINPUT_NODE -> INPUT_ATTRIBUTE_NODE_2;\n}",
        "0e76fa2c-19fd-4d12-9222-9e2f59dbe2e4": "Example:\n\n            .. testcode::\n\n                import ray\n\n                @ray.remote\n                class Actor:\n                    def ready(self):\n                        return True\n\n                @ray.remote\n                def f():\n                    return True\n\n                # All the below code generates different task ids.# Task ids are available for actor creation.a = Actor.remote()\n                # Task ids are available for actor tasks.a.ready.remote()\n                # Task ids are available for normal tasks.f.remote()\n\n        Returns:\n            The current worker's task id.None if there's no task id.\n        \"\"\"# only worker mode has actor_id\n        assert (\n            self.worker.mode == ray._private.worker.WORKER_MODE\n        ), f\"This method is only available when the process is a\\\n                 worker.",
        "c0343a57-6fff-47cf-bb90-58ec46aba93d": "default_options.pop(\"concurrency_groups\", None)\n        updated_options = ray_option_utils.update_options(\n            default_options, actor_options\n        )\n        ray_option_utils.validate_actor_options(updated_options, in_options=True)\n\n        # only update runtime_env when \".options()\" specifies new runtime_env\n        if \"runtime_env\" in actor_options:\n            updated_options[\"runtime_env\"] = parse_runtime_env(\n                updated_options[\"runtime_env\"]\n            )\n\n        class ActorOptionWrapper:\n            def remote(self, *args, **kwargs):\n                return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n\n            @DeveloperAPI\n            def bind(self, *args, **kwargs):\n                \"\"\"\n                For Ray DAG building that creates static graph from decorated\n                class or functions.\n                \"\"\"",
        "53222acf-4a00-4cce-a2af-555159425782": "- \"DriverPid\" (process ID of the driver for this job),\n            - \"StartTime\" (UNIX timestamp of the start time of this job),\n            - \"StopTime\" (UNIX timestamp of the stop time of this job, if any)\n        \"\"\"\n        self._check_connected()\n\n        job_table = self.global_state_accessor.get_job_table()\n\n        results = []\n        for i in range(len(job_table)):\n            entry = gcs_pb2.JobTableData.FromString(job_table[i])\n            job_info = {}\n            job_info[\"JobID\"] = entry.job_id.hex()\n            job_info[\"DriverIPAddress\"] = entry.driver_address.ip_address\n            job_info[\"DriverPid\"] = entry.driver_pid\n            job_info[\"Timestamp\"] = entry.timestamp\n            job_info[\"StartTime\"] = entry.start_time\n            job_info[\"EndTime\"] = entry.end_time\n            job_info[\"IsDead\"] = entry.is_dead\n            job_info[\"Entrypoint\"] = entry.entrypoint\n            results.",
        "60746287-20bd-4e2a-ba17-8d45e83aca57": "More Resources#\nThe following links provide helpful resources on how to efficiently leverage the ray.util.collective library.\n\nMore running examples under ray.util.collective.examples.\nScaling up the Spacy Name Entity Recognition (NER) pipeline using Ray collective library.\nImplementing the AllReduce strategy for data-parallel distributed ML training.",
        "53f00b51-dd69-4aba-a21c-1a58c2213ab1": "ray.tune.Callback.setup#\n\n\nCallback.setup(stop: Optional[Stopper] = None, num_samples: Optional[int] = None, total_num_samples: Optional[int] = None, **info)[source]#\nCalled once at the very beginning of training.\nAny Callback setup should be added here (setting environment\nvariables, etc.)\n\nParameters\n\nstop \u2013 Stopping criteria.\nIf time_budget_s was passed to train.RunConfig, a\nTimeoutStopper will be passed here, either by itself\nor as a part of a CombinedStopper.\nnum_samples \u2013 Number of times to sample from the\nhyperparameter space. Defaults to 1. If grid_search is\nprovided as an argument, the grid will be repeated\nnum_samples of times. If this is -1, (virtually) infinite\nsamples are generated until a stopping condition is met.\ntotal_num_samples \u2013 Total number of samples factoring\nin grid search samplers.\n**info \u2013 Kwargs dict for forward compatibility.",
        "48295f23-f910-4f50-9c3b-ed0dad67d8e7": "ray.train.ScalingConfig.num_workers#\n\n\nScalingConfig.num_workers: Optional[Union[int, Domain, Dict[str, List]]] = None#",
        "de171646-188a-437d-9dff-e234c33b58d4": "ray.tune.Trainable.get_config#\n\n\nTrainable.get_config()[source]#\nReturns configuration passed in by Tune.",
        "084e7c19-6be6-4d2c-b201-07319d0487b3": "ray.train.ScalingConfig.total_resources#\n\n\nproperty ScalingConfig.total_resources#\nMap of total resources required for the trainer.",
        "312aa466-f8cc-41c5-b834-7eab1db944a2": "Note that the execution order is not\n                guaranteed when max_concurrency > 1.\n            name: The globally unique name for the actor, which can be used\n                to retrieve the actor via ray.get_actor(name) as long as the\n                actor is still alive.namespace: Override the namespace to use for the actor.By default,\n                actors are created in an anonymous namespace.The actor can\n                be retrieved via ray.get_actor(name=name, namespace=namespace).lifetime: Either `None`, which defaults to the actor will fate\n                share with its creator and will be deleted once its refcount\n                drops to zero, or \"detached\", which means the actor will live\n                as a global object independent of the creator.placement_group: (This has been deprecated, please use\n                `PlacementGroupSchedulingStrategy` scheduling_strategy)\n                the placement group this actor belongs to,\n                or None if it doesn't belong to any group.Setting to \"default\"\n                autodetects the placement group based on the current setting of\n                placement_group_capture_child_tasks.",
        "86c26df3-8c8c-423d-8056-30cbcfcdcf3c": "Function Trainable API#\nUse the Function API to define a custom training function that Tune runs in Ray actor processes. Each trial is placed\ninto a Ray actor process and runs in parallel.\nThe config argument in the function is a dictionary populated automatically by Ray Tune and corresponding to\nthe hyperparameters selected for the trial from the search space.\nWith the Function API, you can report intermediate metrics by simply calling session.report within the function.\nfrom ray import train, tune\n\n\ndef trainable(config: dict):\n    intermediate_score = 0\n    for x in range(20):\n        intermediate_score = objective(x, config[\"a\"], config[\"b\"])\n        train.report({\"score\": intermediate_score})  # This sends the score to Tune.\n\n\ntuner = tune.Tuner(trainable, param_space={\"a\": 2, \"b\": 4})\nresults = tuner.fit()\n\n\n\nTip\nDo not use session.report within a Trainable class.\n\nIn the previous example, we reported on every step, but this metric reporting frequency\nis configurable. For example, we could also report only a single time at the end with the final score:\nfrom ray import train, tune\n\n\ndef trainable(config: dict):\n    final_score = 0\n    for x in range(20):\n        final_score = objective(x, config[\"a\"], config[\"b\"])\n\n    train.report({\"score\": final_score})  # This sends the score to Tune.\n\n\ntuner = tune.Tuner(trainable, param_space={\"a\": 2, \"b\": 4})\nresults = tuner.fit()",
        "9e62d724-9e94-4233-9627-ebbf458717b1": "Fine-tune dolly-v2-7b with Ray AIR LightningTrainer and FSDP#\nIn this example, we demonstrate how to use Ray AIR to fine-tune a dolly-v2-7b model. dolly-v2-12b is a 12 billion parameter causal language model created by Databricks, derived from EleutherAI\u2019s Pythia-12b, and fine-tuned on a ~15K record instruction corpus.\nWe load the pre-trained model from the HuggingFace model hub into a LightningModule and launch an FSDP fine-tuning job across 16 T4 GPUs with the help of Ray LightningTrainer. It is also straightforward to fine-tune other similar large language models in a similar manner as shown in this example.\nBefore starting this example, we highly recommend reading Ray Train Key Concepts and Ray Data Key Concepts.",
        "ad09a9ac-4407-43c7-8b08-e61cc8f1e3f3": "2]),\n        .                                 \"b\": np.array([10, 11])\n        .                                 }}, env_steps=2)\n        >>> c2 = SampleBatch({\"a\": np.array([3]), # doctest: +SKIP\n        .                   \"b\": np.array([12])})\n        >>> print(concat_samples([b1, b2])) # doctest: +SKIP\n        MultiAgentBatch = {'default_policy': {\"a\": np.array([1, 2, 3]),\n                                              \"b\": np.array([10, 11, 12])}}\n    \"\"\"\n\n    if any(isinstance(s, MultiAgentBatch) for s in samples):\n        return concat_samples_into_ma_batch(samples)\n\n    # the output is a SampleBatch type\n    concatd_seq_lens = []\n    concatd_num_grad_updates = [0, 0.0]  # [0]=count; [1]=weighted sum values\n    concated_samples = []\n    # Make sure these settings are consistent amongst all batches.",
        "bebdf575-bf60-4892-9c70-e6042f703acd": "This can be any arbitrary function\n                that takes a list of dictionaries and returns a single dictionary.For\n                example you can either take an average (default) or concatenate the\n                results (for example for metrics) or be more selective about you want to\n                report back to the algorithm's training_step.If None is passed, the\n                results will not get reduced.Returns:\n            A list of list of dictionaries of results, where the outer list\n            corresponds to separate calls to `async_update`, and the inner\n            list corresponds to the results from each Learner(s).Or if the results\n            are reduced, a list of dictionaries of the reduced results from each\n            call to async_update that is ready.\n        \"\"\"if self.is_local:\n            raise ValueError(\n                \"Cannot call `async_update` when running in local mode with \"\n                \"num_workers=0.\"",
        "8fea3508-d598-42ba-b2a6-0012d0db9c19": "need_unwrap_path_protocol = False\n\n        filesystem = PyFileSystem(FSSpecHandler(filesystem))\n\n    resolved_paths = []\n    for path in paths:\n        path = _resolve_custom_scheme(path)\n        try:\n            resolved_filesystem, resolved_path = _resolve_filesystem_and_path(\n                path, filesystem\n            )\n        except pa.lib.ArrowInvalid as e:\n            if \"Cannot parse URI\" in str(e):\n                resolved_filesystem, resolved_path = _resolve_filesystem_and_path(\n                    _encode_url(path), filesystem\n                )\n                resolved_path = _decode_url(resolved_path)\n            elif \"Unrecognized filesystem type in URI\" in str(e):\n                scheme = urllib.parse.urlparse(path, allow_fragments=False).scheme\n                if scheme in [\"http\", \"https\"]:\n                    # If scheme of path is HTTP and filesystem is not resolved,\n                    # try to use fsspec HTTPFileSystem.",
        "95dc5861-fbb8-47d5-83dd-40151492d28c": "Example: Running Tune with cloud storage#\nLet\u2019s assume that you\u2019re running this example script from your Ray cluster\u2019s head node.In the example below, my_trainable is a Tune trainable\nthat implements saving and loading checkpoints.import os\nimport ray\nfrom ray import air, tune\nfrom your_module import my_trainable\n\n# Look for the existing cluster and connect to it\nray.init()\n\n# Set the local caching directory.Results will be stored here\n# before they are synced to remote storage.This env variable is ignored\n# if `storage_path` below is set to a local directory.os.environ[\"RAY_AIR_LOCAL_CACHE_DIR\"] = \"/tmp/mypath\"\n\ntuner = tune.Tuner(\n    my_trainable,\n    run_config=air.RunConfig(\n        # Name of your experiment\n        name=\"my-tune-exp\",\n        # Configure how experiment data and checkpoints are persisted.# We recommend cloud storage checkpointing as it survives the cluster when\n        # instances are terminated and has better performance.storage_path=\"s3://my-checkpoints-bucket/path/\",\n        checkpoint_config=air.CheckpointConfig(\n            # We'll keep the best five checkpoints at all times\n            # (with the highest AUC scores, a metric reported by the trainable)\n            checkpoint_score_attribute=\"max-auc\",\n            checkpoint_score_order=\"max\",\n            num_to_keep=5,\n        ),\n    ),\n)\n# This starts the run!results = tuner.fit()",
        "7592cf3b-37db-4bfd-b89f-1ccd71258df1": "\",\n               \"default\": 1,\n               \"type\": \"integer\"\n            },\n            \"is_driver_deployment\": {\n               \"title\": \"Is Driver Deployment\",\n               \"description\": \"Indicate Whether the deployment is driver deployment Driver deployments are spawned one per node.\",\n               \"default\": 1,\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"name\"\n         ]\n      },\n      \"ServeApplicationSchema\": {\n         \"title\": \"ServeApplicationSchema\",\n         \"description\": \"Describes one Serve application, and currently can also be used as a standalone\\nconfig to deploy a single application to a Ray cluster.\\n\\n\\nThis is the request JSON schema for the v1 REST API `PUT \\\"/api/serve/deployments/\\\"`.\\n\\n**PublicAPI (beta):** This API is in beta and may change before becoming stable.",
        "48576780-c641-41e0-8d40-ee756235300d": ")\n        future = self._index_to_future[self._next_return_index]\n        timeout_msg = \"Timed out waiting for result\"\n        raise_timeout_after_ignore = False\n        if timeout is not None:\n            res, _ = ray.wait([future], timeout=timeout)\n            if not res:\n                if not ignore_if_timedout:\n                    raise TimeoutError(timeout_msg)\n                else:\n                    raise_timeout_after_ignore = True\n        del self._index_to_future[self._next_return_index]\n        self._next_return_index += 1\n\n        future_key = tuple(future) if isinstance(future, list) else future\n        i, a = self._future_to_actor.pop(future_key)\n\n        self._return_actor(a)\n        if raise_timeout_after_ignore:\n            raise TimeoutError(\n                timeout_msg + \".The task {} has been ignored.\".format(future)\n            )\n        return ray.get(future)\n\n[docs]    def get_next_unordered(self, timeout=None, ignore_if_timedout=False):\n        \"\"\"Returns any of the next pending results.",
        "5273a768-1be6-4c63-852d-792f689abf87": "You can use the Ray State API to check the controller\u2019s status:\n$ ray list actors --filter \"class_name=ServeController\"\n\n======== List: 2022-10-04 21:36:37.157754 ========\nStats:\n------------------------------\nTotal: 2\n\nTable:\n------------------------------\n    ACTOR_ID                          CLASS_NAME       STATE    NAME                      PID\n 0  3281133ee86534e3b707190b01000000  ServeController  ALIVE    SERVE_CONTROLLER_ACTOR  49914\n 1  70a718c973c2ce9471d318f701000000  ServeController  DEAD     SERVE_CONTROLLER_ACTOR  48570\n\n\nYou should still be able to query your deployments while the controller is recovering:\n# If you're running KubeRay, you\n# can do this from inside the pod:\n\n$ python\n\n>>> import requests\n>>> requests.get(\"http://localhost:8000\").json()\n347\n\n\n\nNote\nWhile the controller is dead, replica health-checking and deployment autoscaling will not work. They\u2019ll continue working once the controller recovers.",
        "e56d37f1-14b6-4359-8157-6325e19dc820": "Serve a text summarizer on Kubernetes#\n\nNote: The Python files for the Ray Serve application and its client are in the ray-project/serve_config_examples repo.",
        "cae6a7c4-7971-46ef-af86-1377ba42cba8": "ray.rllib.policy.policy.Policy.get_num_samples_loaded_into_buffer#\n\n\nPolicy.get_num_samples_loaded_into_buffer(buffer_index: int = 0) \u2192 int[source]#\nReturns the number of currently loaded samples in the given buffer.\n\nParameters\nbuffer_index \u2013 The index of the buffer (a MultiGPUTowerStack)\nto use on the devices. The number of buffers on each device\ndepends on the value of the num_multi_gpu_tower_stacks config\nkey.\n\nReturns\nThe number of tuples loaded per device.",
        "8d1c2848-6310-4f55-9342-5a1da16bc251": "ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rollouts#\n\n\nAlgorithmConfig.rollouts(*, env_runner_cls: Optional[type] = <ray.rllib.utils.from_config._NotProvided object>, num_rollout_workers: Optional[int] = <ray.rllib.utils.from_config._NotProvided object>, num_envs_per_worker: Optional[int] = <ray.rllib.utils.from_config._NotProvided object>, create_env_on_local_worker: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>, sample_collector: Optional[Type[ray.rllib.evaluation.collectors.sample_collector.SampleCollector]] = <ray.rllib.utils.from_config._NotProvided object>, sample_async: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>, enable_connectors: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>, use_worker_filter_stats: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>, update_worker_filter_stats: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>, rollout_fragment_length: Optional[Union[int, str]] = <ray.rllib.utils.from_config._NotProvided object>, batch_mode: Optional[str] = <ray.rllib.utils.from_config._NotProvided object>, remote_worker_envs: Optional[bool] = <ray.rllib.utils.from_config.",
        "d5b9e33f-d362-4fdf-8215-027d04725d18": "@ray.remote\nclass RolloutWorker(object):\n    def __init__(self):\n        self.env = gym.make(\"ALE/Pong-v5\")\n\n    def compute_gradient(self, model):\n        # Compute a simulation episode.\n        xs, hs, dlogps, drs = rollout(model, self.env)\n        reward_sum = sum(drs)\n        # Vectorize the arrays.\n        epx = np.vstack(xs)\n        eph = np.vstack(hs)\n        epdlogp = np.vstack(dlogps)\n        epr = np.vstack(drs)\n\n        # Compute the discounted reward backward through time.\n        discounted_epr = process_rewards(epr)\n        # Standardize the rewards to be unit normal (helps control the gradient\n        # estimator variance).\n        discounted_epr -= np.mean(discounted_epr)\n        discounted_epr /= np.std(discounted_epr)\n        # Modulate the gradient with advantage (the policy gradient magic\n        # happens right here).\n        epdlogp *= discounted_epr\n        return model.policy_backward(eph, epx, epdlogp), reward_sum",
        "cf3bd0fc-b0ad-4b06-885d-a58cfd457a10": "mode=mode,\n        )\n\n        self._ax = ax_client\n        self._ax_kwargs = ax_kwargs or {}\n\n        if isinstance(space, dict) and space:\n            resolved_vars, domain_vars, grid_vars = parse_spec_vars(space)\n            if domain_vars or grid_vars:\n                logger.warning(\n                    UNRESOLVED_SEARCH_SPACE.format(par=\"space\", cls=type(self))\n                )\n                space = self.convert_search_space(space)\n\n        self._space = space\n        self._parameter_constraints = parameter_constraints\n        self._outcome_constraints = outcome_constraints\n\n        self._points_to_evaluate = copy.deepcopy(points_to_evaluate)\n\n        self._parameters = []\n        self._live_trial_mapping = {}\n\n        if self._ax or self._space:\n            self._setup_experiment()\n\n    def _setup_experiment(self):\n        if self._metric is None and self.",
        "0a3e5e8d-d0e3-4570-9b76-4ca9e98f31b4": "Code example#\nAnti-pattern:\nimport ray\n\nray.init()\n\noutputs = []\nfor i in range(10):\n\n    @ray.remote\n    def double(i):\n        return i * 2\n\n    outputs.append(double.remote(i))\noutputs = ray.get(outputs)\n# The double remote function is pickled and uploaded 10 times.\n\n\nBetter approach:\n@ray.remote\ndef double(i):\n    return i * 2\n\n\noutputs = []\nfor i in range(10):\n    outputs.append(double.remote(i))\noutputs = ray.get(outputs)\n# The double remote function is pickled and uploaded 1 time.\n\n\nWe should define the same remote function or class outside of the loop instead of multiple times inside a loop so that it\u2019s pickled and uploaded only once.",
        "abbe1b15-b395-4e22-86de-2ac7b064811a": "# Return a sub-dict only containing those param_ref keys (and their values)\n        # that belong to the `optimizer`.return {\n            ref: param_dict[ref]\n            for ref in self._optimizer_parameters[optimizer]\n            if ref in param_dict and param_dict[ref] is not None\n        }\n\n[docs]    def get_module_state(\n        self, module_ids: Optional[Set[str]] = None\n    ) -> Mapping[str, Any]:\n        \"\"\"Returns the state of the underlying MultiAgentRLModule.The output should be numpy-friendly for easy serialization, not framework\n        specific tensors.Args:\n            module_ids: The ids of the modules to get the weights for.If None, all\n                modules will be returned.Returns:\n            A dictionary that holds the state of the modules in a numpy-friendly\n            format.\n        \"\"\"",
        "174094f0-270b-48c2-aaf2-11623d008268": "At the end of the episode, the noise is undone and an action\n    diff (pi-delta) is calculated, from which we determine the changes in the\n    noise's stddev for the next episode.\n    \"\"\"[docs]    def __init__(\n        self,\n        action_space,\n        *,\n        framework: str,\n        policy_config: dict,\n        model: ModelV2,\n        initial_stddev: float = 1.0,\n        random_timesteps: int = 10000,\n        sub_exploration: Optional[dict] = None,\n        **kwargs\n    ):\n        \"\"\"Initializes a ParameterNoise Exploration object.Args:\n            initial_stddev: The initial stddev to use for the noise.random_timesteps: The number of timesteps to act completely\n                randomly (see [1]).sub_exploration: Optional sub-exploration config.None for auto-detection/setup.\n        \"\"\"",
        "8e39a8dc-389a-4257-8867-db2370c00d1b": "Ray Clusters Overview#\nRay enables seamless scaling of workloads from a laptop to a large cluster. While Ray\nworks out of the box on single machines with just a call to ray.init, to run Ray\napplications on multiple nodes you must first deploy a Ray cluster.\nA Ray cluster is a set of worker nodes connected to a common Ray head node.\nRay clusters can be fixed-size, or they may autoscale up and down according\nto the resources requested by applications running on the cluster.",
        "3a79d506-b5c2-40cd-a8fd-cdbbee935c75": "view_requirements: The view requirements to use if anything else than\n                observation_space is to be encoded.This signifies an advanced use case.\n        \"\"\"return cls._get_encoder_config(\n            observation_space=observation_space,\n            # Use model_config_dict without flags that would end up in complex models\n            model_config_dict={\n                **model_config_dict,\n                **{\"use_lstm\": False, \"use_attention\": False},\n            },\n            view_requirements=view_requirements,\n        )\n\n[docs]    @classmethod\n    def _get_dist_cls_from_action_space(\n        cls,\n        action_space: gym.Space,\n        *,\n        framework: Optional[str] = None,\n    ) -> Distribution:\n        \"\"\"Returns a distribution class for the given action space.You can get the required input dimension for the distribution by calling\n        `action_dict_cls.required_input_dim(action_space)`\n        on the retrieved class.This is useful, because the Catalog needs to find out\n        about the required input dimension for the distribution before the model that\n        outputs these inputs is configured.Args:\n            action_space: Action space of the target gym env.framework: The framework to use.",
        "ea4eaadb-50c9-40a0-b705-c0179a6e6214": "Fault Tolerant Config\napiVersion: ray.io/v1alpha1\nkind: RayService\nmetadata:\n    ...\nspec:\n    ...\n    rayClusterConfig:\n        headGroupSpec:\n            ...\n            template:\n                ...\n                spec:\n                    ...\n                    env:\n                        ...\n                        - name: RAY_REDIS_ADDRESS\n                          value: redis:6379\n\n\n\n\nRAY_REDIS_ADDRESS\u2019s value should be your Redis database\u2019s redis:// address. It should contain your Redis database\u2019s host and port. An example Redis address is redis://user:secret@localhost:6379/0?foo=bar&qux=baz.\nIn the example above, the Redis deployment name (redis) is the host within the Kubernetes cluster, and the Redis port is 6379. The example is compatible with the previous section\u2019s example config.\nAfter you apply the Redis objects along with your updated RayService, your Ray cluster can recover from head node crashes without restarting all the workers!\n\nSee also\nCheck out the KubeRay guide on GCS fault tolerance to learn more about how Serve leverages the external Redis cluster to provide head node fault tolerance.",
        "52567013-aa58-4a18-be47-abc55021e7b4": ")\n\n    @override(AlgorithmConfig)\n    def get_rollout_fragment_length(self, worker_index: int = 0) -> int:\n        if self.rollout_fragment_length == \"auto\":\n            # Example:\n            # 2 workers (ignored as learning happens on workers),\n            # 2 envs per worker, 100 train batch size:\n            # -> 100 / 2 -> 50\n            # 4 workers (ignored), 3 envs per worker, 1500 train batch size:\n            # -> 1500 / 3 -> 500\n            rollout_fragment_length = self.train_batch_size // (\n                self.num_envs_per_worker\n            )\n            return rollout_fragment_length\n        else:\n            return self.rollout_fragment_length",
        "25a2580c-784d-4b2a-840f-09a58bc2f693": "ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.get_host#\n\n\nEagerTFPolicyV2.get_host() \u2192 str#\nReturns the computer\u2019s network name.\n\nReturns\nThe computer\u2019s networks name or an empty string, if the network\nname could not be determined.",
        "5688abf8-c3ff-4918-80a5-c4b4651f66ba": "Exception handling#\nIf a generator function raises an exception before yielding all its values, the values that it already stored will still be accessible through their ObjectRefs.\nThe remaining ObjectRefs will contain the raised exception.\nThis is true for both static and dynamic num_returns.\nIf the task was called with num_returns=\"dynamic\", the exception will be stored as an additional final ObjectRef in the ObjectRefGenerator.\n@ray.remote\ndef generator():\n    for i in range(2):\n        yield i\n    raise Exception(\"error\")\n\n\nref1, ref2, ref3, ref4 = generator.options(num_returns=4).remote()\nassert ray.get([ref1, ref2]) == [0, 1]\n# All remaining ObjectRefs will contain the error.\ntry:\n    ray.get([ref3, ref4])\nexcept Exception as error:\n    print(error)\n\ndynamic_ref = generator.options(num_returns=\"dynamic\").remote()\nref_generator = ray.get(dynamic_ref)\nref1, ref2, ref3 = ref_generator\nassert ray.get([ref1, ref2]) == [0, 1]\n# Generators with num_returns=\"dynamic\" will store the exception in the final\n# ObjectRef.\ntry:\n    ray.get(ref3)\nexcept Exception as error:\n    print(error)",
        "5fb5244e-eebe-4715-bf19-a08a337cb8dd": "ray.util.metrics.Histogram#\n\n\nclass ray.util.metrics.Histogram(name: str, description: str = '', boundaries: Optional[List[float]] = None, tag_keys: Optional[Tuple[str, ...]] = None)[source]#\nBases: ray.util.metrics.Metric\nTracks the size and number of events in buckets.\nHistograms allow you to calculate aggregate quantiles\nsuch as 25, 50, 95, 99 percentile latency for an RPC.\nThis corresponds to Prometheus\u2019 histogram metric:\nhttps://prometheus.io/docs/concepts/metric_types/#histogram\n\nParameters\n\nname \u2013 Name of the metric.\ndescription \u2013 Description of the metric.\nboundaries \u2013 Boundaries of histogram buckets.\ntag_keys \u2013 Tag keys of the metric.\n\n\n\nDeveloperAPI: This API may change across minor Ray releases.\nMethods\n\n\n\n\n\n\nobserve(value[,\u00a0tags])\nObserve a given value and add it to the appropriate bucket.\n\nrecord(value[,\u00a0tags,\u00a0_internal])\nRecord the metric point of the metric.\n\nset_default_tags(default_tags)\nSet default tags of metrics.\n\n\n\nAttributes\n\n\n\n\n\n\ninfo\nReturn information about histogram metric.",
        "e5bcaa91-2e61-4663-9db1-f0ef05538216": "item()\n\n        train.report(\n            {\n                \"mape_collected\": mape_collected,\n                \"valid_loss\": valid_loss,\n                \"mean_valid_loss_collected\": mean_valid_loss_collected,\n            }\n        )\n\n        # reset for next epoch\n        mape.reset()\n        mean_valid_loss.reset()\n\n\ntrainer = TorchTrainer(\n    train_func,\n    train_loop_config={\"num_epochs\": 5},\n    scaling_config=ScalingConfig(num_workers=2),\n)\nresult = trainer.fit()\nprint(result.metrics[\"valid_loss\"], result.metrics[\"mean_valid_loss_collected\"])\n# 0.5109779238700867 0.5512474775314331",
        "ac61f87d-eced-4962-996a-408f4dc70f5f": "__name__\n                )\n            )\n\n        cs = ConfigSpace.ConfigurationSpace()\n        for path, domain in domain_vars:\n            par = \"/\".join(str(p) for p in path)\n            value = resolve_value(par, domain)\n            cs.add_hyperparameter(value)\n\n        return cs\n\n    def save(self, checkpoint_path: str):\n        save_object = self.__dict__\n        with open(checkpoint_path, \"wb\") as outputFile:\n            cloudpickle.dump(save_object, outputFile)\n\n    def restore(self, checkpoint_path: str):\n        with open(checkpoint_path, \"rb\") as inputFile:\n            save_object = cloudpickle.load(inputFile)\n        self.__dict__.update(save_object)",
        "bf1d9818-f2c4-4724-ab97-94c8d31f4164": "This type of warning will be suppressed for the rest of this program.(Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)(RayTrainWorker pid=175614) /tmp/ipykernel_160001/3839218723.py:26: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors.This means writing to this tensor will result in undefined behavior.You may want to copy the array to protect its data or make it writable before converting it to a tensor.This type of warning will be suppressed for the rest of this program.(Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)(RayTrainWorker pid=175611) /tmp/ipykernel_160001/3839218723.py:26: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors.This means writing to this tensor will result in undefined behavior.You may want to copy the array to protect its data or make it writable before converting it to a tensor.This type of warning will be suppressed for the rest of this program.(Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)(RayTrainWorker pid=175613) /tmp/ipykernel_160001/3839218723.py:23: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors.This means writing to this tensor will result in undefined behavior.You may want to copy the array to protect its data or make it writable before converting it to a tensor.This type of warning will be suppressed for the rest of this program.(Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n\n\n\nTrial Progress",
        "c0971ac4-5848-491a-829e-7b79fa210c57": "ray.tune.integration.xgboost.TuneReportCheckpointCallback.after_training#\n\n\nTuneReportCheckpointCallback.after_training(model: Any) \u2192 Any#\nRun after training is finished.",
        "51c46c71-9c02-415e-bcd0-d7d432feefde": "This \"\n                \"means the same schedule will be trained multiple \"\n                \"times.Do you want to set `n_samples=1`?\")\n        self._trial = trial\n        if self._trial.config and self._policy:\n            logger.warning(\n                \"Trial was initialized with a config, which was overwritten. \"\"Did you start the PBT replay with a `config` parameter?\")\n        elif self._trial.config and not self._policy:\n            # Only train with initial policy\n            self.config = self._trial.config\n        elif not self._trial.config and not self._policy:\n            raise ValueError(\n                \"No replay policy found and trial initialized without a \"\n                \"valid config.Either pass a `config` argument to `tune.Tuner()`\"\n                \"or consider not using PBT replay for this run.\"",
        "ccf71489-de31-4adc-8383-3a9db3c3bbe5": "ray.tune.search.bayesopt.BayesOptSearch.on_trial_complete#\n\n\nBayesOptSearch.on_trial_complete(trial_id: str, result: Optional[Dict] = None, error: bool = False)[source]#\nNotification for the completion of trial.\n\nParameters\n\ntrial_id \u2013 Id of the trial.\nThis is a short alphanumerical string.\nresult \u2013 Dictionary of result.\nMay be none when some error occurs.\nerror \u2013 Boolean representing a previous error state.\nThe result should be None when error is True.",
        "b56fc3bb-fecd-4fed-bbd8-c21fda6e31c7": "def train_func(config):\n    for epoch in range(1, config[\"epochs\"] + 1):\n        # Model training here\n        # ...\n\n        # Report metrics and save a checkpoint\n        metrics = {\"metric\": \"my_metric\"}\n        if epoch % CHECKPOINT_FREQ == 0:\n            with tempfile.TemporaryDirectory() as tempdir:\n                # Save a checkpoint in tempdir.\n                train.report(metrics, checkpoint=Checkpoint.from_directory(tempdir))\n        else:\n            train.report(metrics)\n\n\ntuner = tune.Tuner(train_func, param_space={\"epochs\": NUM_EPOCHS})\nresult_grid = tuner.fit()\n\n\n\nSee here for more information on creating checkpoints.",
        "8f56f5e9-dcd8-4f16-b8ba-fd0b08a9c31d": "ray.rllib.core.learner.learner.Learner._check_result#\n\n\nLearner._check_result(result: Mapping[str, Any]) \u2192 None[source]#\nChecks whether the result has the correct format.\nAll the keys should be referencing the module ids that got updated. There is a\nspecial key ALL_MODULES that hold any extra information that is not specific\nto a module.\n\nParameters\nresult \u2013 The result of the update.\n\nRaises\nValueError \u2013 If the result are not in the correct format.",
        "d00bfa6e-ede2-4862-abc6-df50ada0cd94": "Set up your dataset and model.\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\n\ndef get_dataset():\n    return datasets.FashionMNIST(\n        root=\"/tmp/data\",\n        train=True,\n        download=True,\n        transform=ToTensor(),\n    )\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28 * 28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, inputs):\n        inputs = self.flatten(inputs)\n        logits = self.linear_relu_stack(inputs)\n        return logits",
        "dc0905e0-8076-429c-ac66-b5d9deae2458": "Example\n>>> from ray import air\n>>> from ray import tune\n>>> from ray.rllib.algorithms.dreamer import DreamerConfig\n>>> config = DreamerConfig()\n>>> # Print out some default values.\n>>> print(config.clip_param)  \n>>> # Update the config object.\n>>> config = config.training(  \n...     lr=tune.grid_search([0.001, 0.0001]), clip_param=0.2)\n>>> # Set the config object's env.\n>>> config = config.environment(env=\"CartPole-v1\")  \n>>> # Use to_dict() to get the old-style python config dict\n>>> # when running with tune.\n>>> tune.Tuner(  \n...     \"Dreamer\",\n...     run_config=air.RunConfig(stop={\"episode_reward_mean\": 200}),\n...     param_space=config.to_dict(),\n... ).fit()\n\n\n\n\ntraining(*, td_model_lr: Optional[float] = <ray.rllib.utils.from_config._NotProvided object>, actor_lr: Optional[float] = <ray.rllib.utils.from_config._NotProvided object>, critic_lr: Optional[float] = <ray.rllib.utils.from_config._NotProvided object>, grad_clip: Optional[float] = <ray.rllib.utils.from_config._NotProvided object>, lambda_: Optional[float] = <ray.rllib.utils.from_config._NotProvided object>, dreamer_train_iters: Optional[int] = <ray.rllib.utils.from_config._NotProvided object>, batch_size: Optional[int] = <ray.rllib.utils.from_config._NotProvided object>, batch_length: Optional[int] = <ray.rllib.utils.",
        "509fcd0e-b388-42cb-b713-bf103a05c93b": "How do I restore a multi-agent Algorithm with a subset of the original policies?#\nImagine you have trained a multi-agent Algorithm with e.g.100 different Policies and created\na checkpoint from this Algorithm.The checkpoint now includes 100 sub-directories in the\npolicies/ dir, named after the different policy IDs.After careful evaluation of the different policies, you would like to restore the\nAlgorithm\nand continue training it, but only with a subset of the original 100 policies,\nfor example only with the policies, whose IDs are \u201cpolA\u201d and \u201cpolB\u201d.You can use the original checkpoint (with the 100 policies in it) and the\nAlgorithm.from_checkpoint() utility to achieve this in an efficient way.This example here shows this for five original policies that you would like reduce to\ntwo policies:\nfrom ray.rllib.algorithms.ppo import PPOConfig\nfrom ray.rllib.examples.env.multi_agent import MultiAgentCartPole\n\n# Set up an Algorithm with 5 Policies.",
        "3ded0e50-498b-4d62-bbc9-805a98c68e4e": "if len(self.trials) == 1:\n            return self.trials[0]\n\n        metric = self._validate_metric(metric)\n        mode = self._validate_mode(mode)\n\n        if scope not in [\"all\", \"last\", \"avg\", \"last-5-avg\", \"last-10-avg\"]:\n            raise ValueError(\n                \"ExperimentAnalysis: attempting to get best trial for \"\n                'metric {} for scope {} not in [\"all\", \"last\", \"avg\", '\n                '\"last-5-avg\", \"last-10-avg\"]. '\"If you didn't pass a `metric` parameter to `tune.run()`, \"\n                \"you have to pass one when fetching the best trial.\".format(\n                    metric, scope\n                )\n            )\n        best_trial = None\n        best_metric_score = None\n\n        for trial in self.trials:\n            if metric not in trial.metric_analysis:\n                continue\n\n            if scope in [\"last\", \"avg\", \"last-5-avg\",",
        "c3790290-a8c8-44d0-883d-fc01c5ebfb1f": "# 1: Wrap the pretrained sentiment analysis model in a Serve deployment.\n@serve.deployment(route_prefix=\"/\")\nclass SentimentAnalysisDeployment:\n    def __init__(self):\n        self._model = pipeline(\"sentiment-analysis\")\n\n    def __call__(self, request: Request) -> Dict:\n        return self._model(request.query_params[\"text\"])[0]\n\n\n# 2: Deploy the deployment.\nserve.run(SentimentAnalysisDeployment.bind())\n\n# 3: Query the deployment and print the result.\nprint(\n    requests.get(\n        \"http://localhost:8000/\", params={\"text\": \"Ray Serve is great!\"}\n    ).json()\n)\n# {'label': 'POSITIVE', 'score': 0.9998476505279541}",
        "1979dc69-6e12-4427-9baa-a29d6ce5b1f5": "task_state_counts:\n                object_summary.task_state_counts[task_state] = 0\n            object_summary.task_state_counts[task_state] += 1\n\n            ref_type = object[\"reference_type\"]\n            if ref_type not in object_summary.ref_type_counts:\n                object_summary.ref_type_counts[ref_type] = 0\n            object_summary.ref_type_counts[ref_type] += 1\n            object_summary.total_objects += 1\n            total_objects += 1\n\n            size_bytes = object[\"object_size\"]\n            # object_size's unit is byte by default.It is -1, if the size is\n            # unknown.if size_bytes != -1:\n                object_summary.total_size_mb += size_bytes / 1024**2\n                total_size_mb += size_bytes / 1024**2\n\n            key_to_workers[key].add(object[\"pid\"])\n            key_to_nodes[key].add(object[\"ip\"])\n\n        # Convert set of pid & node ips to length.",
        "c4d2c144-7fb9-457f-a573-7c917fc5411b": "# First make sure, values are clipped.value = tf.clip_by_value(value, lower_bound, upper_bound)\n    # Tensor of batch indices: [0, B=batch size).batch_indices = tf.cast(\n        tf.range(0, tf.shape(value)[0]),\n        dtype=dtype or tf.float32,\n    )\n    # Calculate the step deltas (how much space between each bucket's central value?).bucket_delta = (upper_bound - lower_bound) / (num_buckets - 1)\n    # Compute the float indices (might be non-int numbers: sitting between two buckets).idx = (-lower_bound + value) / bucket_delta\n    # k\n    k = tf.math.floor(idx)\n    # k+1\n    kp1 = tf.math.ceil(idx)\n    # In case k == kp1 (idx is exactly on the bucket boundary), move kp1 up by 1.0.# Otherwise, this would result in a NaN in the returned two-hot tensor.kp1 = tf.where(tf.equal(k, kp1), kp1 + 1.0, kp1)\n    # Iff `kp1` is one beyond our last index (because incoming value is larger than\n    # `upper_bound`), move it to one before k (kp1's weight is going to be 0.0 anyways,\n    # so it doesn't matter where it points to; we are just avoiding an index error\n    # with this).kp1 = tf.where(tf.equal(kp1, num_buckets), kp1 - 2.0, kp1)\n    # The actual values found at k and k+1 inside the set of buckets.",
        "f91a1eeb-8feb-44ec-b942-17cad329d310": "50]\nEpoch 0:   4%|\u258d         | 6/134 [01:46<37:45, 17.70s/it, v_num=0, train_loss=12.50]\nEpoch 0:   5%|\u258c         | 7/134 [02:03<37:17, 17.62s/it, v_num=0, train_loss=12.50]\nEpoch 0:   6%|\u258c         | 8/134 [02:20<36:52, 17.56s/it, v_num=0, train_loss=12.50]\nEpoch 0:   7%|\u258b         | 9/134 [02:37<36:30, 17.52s/it, v_num=0, train_loss=12.50]\nEpoch 0:   7%|\u258b         | 9/134 [02:37<36:32, 17.54s/it, v_num=0, train_loss=12.50]\nEpoch 0:   7%|\u258b         | 10/134 [02:55<36:12, 17.52s/it, v_num=0, train_loss=12.50]\nEpoch 0:   7%|\u258b         | 10/134 [02:55<36:14, 17.54s/it, v_num=0, train_loss=0.669]\nEpoch 0:   8%|\u258a         | 11/134 [03:12<35:55, 17.53s/it, v_num=0, train_loss=0.",
        "a2900ab4-a547-4094-8d53-b05a38895d8a": "SGD(\n        net.parameters(),\n        lr=config[\"lr\"],\n    )\n    optimizer = hvd.DistributedOptimizer(optimizer)\n\n    num_steps = 5\n    print(hvd.size())\n    np.random.seed(1 + hvd.rank())\n    torch.manual_seed(1234)\n    # To ensure consistent initialization across workers,\n    hvd.broadcast_parameters(net.state_dict(), root_rank=0)\n    hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n\n    start = time.time()\n    x_max = config[\"x_max\"]\n    for step in range(1, num_steps + 1):\n        features = torch.Tensor(np.random.rand(1) * 2 * x_max - x_max).to(device)\n        if mode == \"square\":\n            labels = sq(features)\n        else:\n            labels = qu(features)\n        optimizer.zero_grad()\n        outputs = net(features)\n        loss = torch.nn.MSELoss()(outputs, labels)\n        loss.backward()\n\n        optimizer.step()\n        time.sleep(0.1)\n        train.report(dict(loss=loss.item()))\n    total = time.time() - start\n    print(f\"Took {total:0.3f} s.",
        "ae7f64d8-871c-4d92-b0bb-21e5aa43b4fa": "if len(result) == 1:\n                return result[0]\n            return result\n\n        # For the rest of the resources, there should only be a single entry\n        # for a particular id.assert len(result) == 1\n        return result[0]\n\n    def _print_api_warning(\n        self,\n        resource: StateResource,\n        api_response: dict,\n        warn_data_source_not_available: bool = True,\n        warn_data_truncation: bool = True,\n        warn_limit: bool = True,\n        warn_server_side_warnings: bool = True,\n    ):\n        \"\"\"Print the API warnings.Args:\n            resource: Resource names, i.e.'jobs', 'actors', 'nodes',\n                see `StateResource` for details.api_response: The dictionarified `ListApiResponse` or `SummaryApiResponse`.warn_data_source_not_available: Warn when some data sources\n                are not available.warn_data_truncation: Warn when results were truncated at\n                the data source.warn_limit: Warn when results were limited.warn_server_side_warnings: Warn when the server side generates warnings\n                (E.g., when callsites not enabled for listing objects)\n        \"\"\"\n        # Print warnings if anything was given.",
        "0b147746-7a52-4ebc-8a0c-8f02b397a1c5": "ray stack#\nTake a stack dump of all Python workers on the local machine.\nray stack [OPTIONS]",
        "cc803b71-1835-4d4d-ab3a-87a0402dcbd1": "Prepare your data#\nWe are using tiny_shakespeare for fine-tuning, which contains 40,000 lines of Shakespeare from a variety of Shakespeare\u2019s plays. Featured in Andrej Karpathy\u2019s blog post \u2018The Unreasonable Effectiveness of Recurrent Neural Networks\u2019.\nDataset samples:\nBAPTISTA:\nI know him well: you are welcome for his sake.\n\nGREMIO:\nSaving your tale, Petruchio, I pray,\nLet us, that are poor petitioners, speak too:\nBaccare! you are marvellous forward.\n\nPETRUCHIO:\nO, pardon me, Signior Gremio; I would fain be doing.\n\n\nHere, we have adopted similar pre-processing logic from another demo: GPT-J-6B Fine-Tuning with Ray Train and DeepSpeed.\n\n\nimport ray\nimport pandas as pd\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ndef split_text(batch: pd.DataFrame) -> pd.DataFrame:\n    text = list(batch[\"text\"])\n    flat_text = \"\".join(text)\n    split_text = [\n        x.strip()\n        for x in flat_text.split(\"\\n\")\n        if x.strip() and not x.strip()[-1] == \":\"\n    ]\n    return pd.DataFrame(split_text, columns=[\"text\"])",
        "6048b47b-a6c7-4ded-807b-28e8ab160290": "training(*, sgd_minibatch_size: Optional[int] = <ray.rllib.utils.from_config._NotProvided object>, shuffle_sequences: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>, num_sgd_iter: Optional[int] = <ray.rllib.utils.from_config._NotProvided object>, replay_buffer_config: Optional[dict] = <ray.rllib.utils.from_config._NotProvided object>, lr_schedule: Optional[List[List[Union[int, float]]]] = <ray.rllib.utils.from_config._NotProvided object>, vf_share_layers: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>, mcts_config: Optional[dict] = <ray.rllib.utils.from_config._NotProvided object>, ranked_rewards: Optional[dict] = <ray.rllib.utils.from_config._NotProvided object>, num_steps_sampled_before_learning_starts: Optional[int] = <ray.rllib.utils.from_config._NotProvided object>, **kwargs) \u2192 ray.rllib.algorithms.alpha_zero.alpha_zero.AlphaZeroConfig[source]#\nSets the training related configuration.Parameters\n\nsgd_minibatch_size \u2013 Total SGD batch size across all devices for SGD.shuffle_sequences \u2013 Whether to shuffle sequences in the batch when training\n(recommended).num_sgd_iter \u2013 Number of SGD iterations in each outer loop.replay_buffer_config \u2013 Replay buffer config.",
        "bd9dc21c-2414-43d6-b454-8ddf091ad214": "Verify and Save Results#\nThen let\u2019s take a small batch and verify the inference results with visualization.\n\n\nfrom torchvision.transforms.functional import convert_image_dtype, to_tensor\n\nbatch = ds.take_batch(batch_size=2)\nfor image, labels, boxes in zip(batch[\"image\"], batch[\"labels\"], batch[\"boxes\"]):\n    image = convert_image_dtype(to_tensor(image), torch.uint8)\n    labels = [weights.meta[\"categories\"][i] for i in labels]\n    boxes = torch.from_numpy(boxes)\n    img = to_pil_image(draw_bounding_boxes(\n        image,\n        boxes,\n        labels=labels,\n        colors=\"red\",\n        width=4,\n    ))\n    display(img)",
        "21216440-8b76-46bb-ad4e-294462c32258": "Ray Clusters Overview#\nRay enables seamless scaling of workloads from a laptop to a large cluster. While Ray\nworks out of the box on single machines with just a call to ray.init, to run Ray\napplications on multiple nodes you must first deploy a Ray cluster.\nA Ray cluster is a set of worker nodes connected to a common Ray head node.\nRay clusters can be fixed-size, or they may autoscale up and down according\nto the resources requested by applications running on the cluster.",
        "82bc7d38-671b-4064-80e0-02cb840f424a": "iter_torch_batches(\n                    batch_size=32, dtypes=torch.float\n                ):\n                    inputs, labels = torch.unsqueeze(batch[\"x\"], 1), batch[\"y\"]\n                    outputs = model(inputs)\n                    loss = loss_fn(outputs, labels)\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n                    print(f\"epoch: {epoch}, loss: {loss.item()}\")\n                train.report(\n                    {},\n                    checkpoint=LegacyTorchCheckpoint.from_state_dict(\n                        model.state_dict()\n                    ),\n                )\n        train_dataset = ray.data.from_items([{\"x\": x,",
        "7b6e06a1-5637-489c-82e3-88e7eaa3dcc2": "\",\n                len(self.live_trials),\n                self.max_concurrent,\n            )\n            return\n\n        suggestion = self.searcher.suggest(trial_id)\n        if suggestion not in (None, Searcher.FINISHED):\n            self.live_trials.add(trial_id)\n            self.num_unfinished_live_trials += 1\n        return suggestion\n\n    def on_trial_complete(\n        self, trial_id: str, result: Optional[Dict] = None, error: bool = False\n    ):\n        if not self._limit_concurrency:\n            return self.searcher.on_trial_complete(trial_id, result=result, error=error)\n\n        if trial_id not in self.live_trials:\n            return\n        elif self.batch:\n            self.cached_results[trial_id] = (result, error)\n            self.num_unfinished_live_trials -= 1\n            if self.num_unfinished_live_trials <= 0:\n                # Update the underlying searcher once the\n                # full batch is completed.for trial_id, (result,",
        "f9906168-8e95-477d-b48d-b1b5b38f7080": "optimizer = torch.optim.AdamW(\n        itertools.chain(unet_trainable_parameters, text_trainable_parameters),\n        lr=config[\"lr\"],\n    )\n\n    train_dataset = train.get_dataset_shard(\"train\")\n\n    # Train!num_train_epochs = config[\"num_epochs\"]\n\n    print(f\"Running {num_train_epochs} epochs.\")global_step = 0\n    for _ in range(num_train_epochs):\n        if global_step >= config[\"max_train_steps\"]:\n            print(f\"Stopping training after reaching {global_step} steps.\")\n            break\n\n        for _, batch in enumerate(\n            train_dataset.iter_torch_batches(\n                batch_size=config[\"train_batch_size\"],\n                device=train.torch.get_device(),\n            )\n        ):\n            batch = collate(batch, torch.bfloat16)\n\n            optimizer.zero_grad()\n\n            # Convert images to latent space\n            latents = vae.encode(batch[\"images\"]).latent_dist.sample() * 0.",
        "805bf647-5ed0-4c4a-8a76-85ec5776b051": "Specifying Experimental Features#\n\n\nAlgorithmConfig.experimental(*, _tf_policy_handles_more_than_one_loss: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>, _disable_preprocessor_api: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>, _disable_action_flattening: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>, _disable_execution_plan_api: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>, _disable_initialize_loss_from_dummy_batch: Optional[bool] = <ray.rllib.utils.from_config._NotProvided object>) \u2192 ray.rllib.algorithms.algorithm_config.AlgorithmConfig[source]\nSets the config\u2019s experimental settings.Parameters\n\n_tf_policy_handles_more_than_one_loss \u2013 Experimental flag.If True, TFPolicy will handle more than one loss/optimizer.Set this to True, if you would like to return more than\none loss term from your loss_fn and an equal number of optimizers\nfrom your optimizer_fn.In the future, the default for this will be\nTrue._disable_preprocessor_api \u2013 Experimental flag.If True, no (observation) preprocessor will be created and\nobservations will arrive in model as they are returned by the env.In the future, the default for this will be True._disable_action_flattening \u2013 Experimental flag.If True, RLlib will no longer flatten the policy-computed actions into\na single tensor (for storage in SampleCollectors/output files/etc..),\nbut leave (possibly nested) actions as-is.Disabling flattening affects:\n- SampleCollectors: Have to store possibly nested action structs.- Models that have the previous action(s) as part of their input.- Algorithms reading from offline files (incl.action information).",
        "49fec38a-932e-46c8-89af-4f96dcd0407a": "ray.tune.ExperimentAnalysis.stats#\n\n\nExperimentAnalysis.stats() \u2192 Dict[source]#\nReturns a dictionary of the statistics of the experiment.\nIf experiment_checkpoint_path pointed to a directory of\nexperiments, the dict will be in the format of\n{experiment_session_id: stats}.",
        "cfb0afc1-02ec-46cd-9be3-54068b43708c": "]\n\n        ray_worker_node_extra_envs = {\n            RAY_ON_SPARK_COLLECT_LOG_TO_PATH: collect_log_to_path or \"\"\n        }\n\n        if num_gpus_worker_node > 0:\n            task_resources = context.resources()\n\n            if \"gpu\" not in task_resources:\n                raise RuntimeError(\n                    \"Couldn't get the gpu id, Please check the GPU resource \"\n                    \"configuration\"\n                )\n            gpu_addr_list = [\n                int(addr.strip()) for addr in task_resources[\"gpu\"].addresses\n            ]\n\n            available_physical_gpus = get_spark_task_assigned_physical_gpus(\n                gpu_addr_list\n            )\n            ray_worker_node_cmd.append(\n                f\"--num-gpus={len(available_physical_gpus)}\",",
        "25d3ea69-7a56-447d-a2f3-2a5a3ac7b408": "ray.train.lightning.RayFSDPStrategy.root_device#\n\n\nproperty RayFSDPStrategy.root_device: torch.device#\nReturn the root device.",
        "2be71554-af86-46e6-b447-50302398c154": "Source code for ray.rllib.utils.exploration.exploration\nfrom gymnasium.spaces import Space\nfrom typing import Dict, List, Optional, Union, TYPE_CHECKING\n\nfrom ray.rllib.env.base_env import BaseEnv\nfrom ray.rllib.models.action_dist import ActionDistribution\nfrom ray.rllib.models.modelv2 import ModelV2\nfrom ray.rllib.policy.sample_batch import SampleBatch\nfrom ray.rllib.utils.annotations import DeveloperAPI, PublicAPI\nfrom ray.rllib.utils.framework import try_import_torch, TensorType\nfrom ray.rllib.utils.typing import LocalOptimizer, AlgorithmConfigDict\n\nif TYPE_CHECKING:\n    from ray.rllib.policy.policy import Policy\n    from ray.rllib.utils import try_import_tf\n\n    _, tf, _ = try_import_tf()\n\n_, nn = try_import_torch()\n\n\n[docs]@PublicAPI\nclass Exploration:\n    \"\"\"Implements an exploration strategy for Policies.An Exploration takes model outputs, a distribution, and a timestep from\n    the agent and computes an action to apply to the environment using an\n    implemented exploration schema.\n    \"\"\"",
        "fbdadea1-1f5d-494a-a277-72ede6fed846": "ray.train.xgboost.XGBoostTrainer.restore#\n\n\nclassmethod XGBoostTrainer.restore(path: Union[str, os.PathLike], storage_filesystem: Optional[pyarrow._fs.FileSystem] = None, datasets: Optional[Dict[str, Union[Dataset, Callable[[], Dataset]]]] = None, preprocessor: Optional[Preprocessor] = None, scaling_config: Optional[ray.air.config.ScalingConfig] = None, **kwargs) \u2192 BaseTrainer#\nRestores a Train experiment from a previously interrupted/failed run.Restore should be used for experiment-level fault tolerance in the event\nthat the head node crashes (e.g., OOM or some other runtime error) or the\nentire cluster goes down (e.g., network error affecting all nodes).",
        "664c69d6-d933-47e1-9667-1ed1f9a3bd70": "logger.info(\n            \"Joining process group, url={}, world_rank={}, \"\n            \"world_size={}, backend={}\".format(url, world_rank, world_size, backend)\n        )\n        torch.distributed.init_process_group(\n            backend=backend, init_method=url, rank=world_rank, world_size=world_size\n        )\n\n        for pid, policy in self.policy_map.items():\n            if not isinstance(policy, (TorchPolicy, TorchPolicyV2)):\n                raise ValueError(\n                    \"This policy does not support torch distributed\", policy\n                )\n            policy.distributed_world_size = world_size\n\n[docs]    def creation_args(self) -> dict:\n        \"\"\"Returns the kwargs dict used to create this worker.\"\"\"return self._original_kwargs\n\n[docs]    @DeveloperAPI\n    def get_host(self) -> str:\n        \"\"\"Returns the hostname of the process running this evaluator.\"\"\"return platform.node()\n\n[docs]    @DeveloperAPI\n    def get_node_ip(self) -> str:\n        \"\"\"Returns the IP address of the node that this worker runs on.\"\"\"",
        "a0e049b4-a54f-421d-b0be-8458d0980eda": "train_one_step() (in module ray.rllib.execution.train_ops)\n\ntrain_test_split() (ray.data.Dataset method)\n\nTrainable\n\n(class in ray.tune)\n\n\ntrainable_name (ray.tune.experiment.trial.Trial attribute)\n\ntrainable_variables() (ray.rllib.models.modelv2.ModelV2 method)\n\nTrainContext (class in ray.train.context)\n\nTrainer\n\nTrainer configuration\n\ntrainer() (ray.train.lightning.LightningConfigBuilder method)\n\ntrainer_resources (ray.train.ScalingConfig attribute)\n\nTraining epoch\n\nTraining iteration\n\nTraining step\n\ntraining() (ray.rllib.algorithms.a2c.a2c.A2CConfig method)\n\n(ray.rllib.algorithms.a3c.a3c.A3CConfig method)\n\n(ray.rllib.algorithms.algorithm_config.AlgorithmConfig method)\n\n(ray.rllib.algorithms.alpha_zero.alpha_zero.AlphaZeroConfig method)\n\n(ray.rllib.algorithms.apex_dqn.apex_dqn.ApexDQNConfig method)\n\n(ray.rllib.algorithms.appo.appo.APPOConfig method)\n\n(ray.rllib.algorithms.ars.ars.ARSConfig method)\n\n(ray.rllib.algorithms.bandit.bandit.BanditLinTSConfig method)\n\n(ray.rllib.algorithms.bandit.bandit.BanditLinUCBConfig method)\n\n(ray.rllib.algorithms.bc.bc.BCConfig method)\n\n(ray.rllib.algorithms.cql.cql.CQLConfig method)\n\n(ray.rllib.algorithms.crr.crr.",
        "87c6ab06-4a01-4e4e-93c5-9dd3658c3fe3": "ray.train.huggingface.TransformersTrainer#\n\n\nclass ray.train.huggingface.TransformersTrainer(*args, **kwargs)[source]#\nBases: ray.train.torch.torch_trainer.TorchTrainer\nA Trainer for data parallel HuggingFace Transformers on PyTorch training.This Trainer runs the transformers.Trainer.train() method on multiple\nRay Actors.The training is carried out in a distributed fashion through PyTorch\nDDP.These actors already have the necessary torch process group already\nconfigured for distributed PyTorch training.If you have PyTorch >= 1.12.0\ninstalled, you can also run FSDP training by specifying the fsdp argument\nin TrainingArguments.DeepSpeed is\nalso supported - see GPT-J-6B Fine-Tuning with Ray Train and DeepSpeed.For more information on configuring FSDP or DeepSpeed, refer to Hugging Face\ndocumentation.The training function ran on every Actor will first run the\nspecified trainer_init_per_worker function to obtain an instantiated\ntransformers.Trainer object.The trainer_init_per_worker function\nwill have access to preprocessed train and evaluation datasets.If the datasets dict contains a training dataset (denoted by\nthe \u201ctrain\u201d key), then it will be split into multiple dataset\nshards, with each Actor training on a single shard.All the other datasets will not be split.Please note that if you use a custom transformers.Trainer subclass,\nthe get_train_dataloader method will be wrapped around to disable\nsharding by transformers.IterableDatasetShard, as the dataset will\nalready be sharded on the Ray AIR side.You can also provide datasets.Dataset object or other dataset objects\nallowed by transformers.Trainer directly in the trainer_init_per_worker\nfunction, without specifying the datasets dict.",
        "766a20ed-51b4-4461-83dc-b5c7ed9ceec1": "ray.tune.Trainable.uses_cloud_checkpointing#\n\n\nproperty Trainable.uses_cloud_checkpointing#",
        "8dbb5d64-e91c-418d-812f-e54dadc3cbf4": "ray.rllib.core.rl_module.marl_module.MultiAgentRLModule.load_state#\n\n\nMultiAgentRLModule.load_state(path: Union[str, pathlib.Path], modules_to_load: Optional[Set[str]] = None) \u2192 None[source]#\nLoads the weights of an MultiAgentRLModule from dir.\n\nNote\nIf you want to load a module that is not already\nin this MultiAgentRLModule, you should add it to this MultiAgentRLModule\nbefore loading the checkpoint.\n\n\nParameters\n\npath \u2013 The path to the directory to load the state from.\nmodules_to_load \u2013 The modules whose state is to be loaded from the path. If\nthis is None, all modules that are checkpointed will be loaded into this\nmarl module.",
        "a5b42803-2c9b-43b1-a2fc-a7c97ccf3a96": "\"evaluation\": {\n                \"episode_reward_max\": np.nan,\n                \"episode_reward_min\": np.nan,\n                \"episode_reward_mean\": np.nan,\n                \"sampler_results\": {\n                    \"episode_reward_max\": np.nan,\n                    \"episode_reward_min\": np.nan,\n                    \"episode_reward_mean\": np.nan,\n                },\n            },\n        }\n\n        super().__init__(\n            config=config,\n            logger_creator=logger_creator,\n            **kwargs,\n        )\n\n        # Check, whether `training_iteration` is still a tune.Trainable property\n        # and has not been overridden by the user in the attempt to implement the\n        # algos logic (this should be done now inside `training_step`).",
        "98e4e051-d88a-4434-a357-cd49b6039870": "local\n  iterations: 48\n  iterations_since_restore: 49\n  loss: 15.6130748612977\n  node_ip: 127.0.0.1\n  pid: 46679\n  time_since_restore: 5.2078468799591064\n  time_this_iter_s: 0.10803008079528809\n  time_total_s: 5.2078468799591064\n  timestamp: 1658500031\n  timesteps_since_restore: 0\n  training_iteration: 49\n  trial_id: 5b6c4ba2\n  warmup_time: 0.002663135528564453\n  \nResult for multi_objective_5d51f2d2:\n  date: 2022-07-22_15-27-14\n  done: false\n  experiment_id: 1433194530b14db4b77ce40a69d65407\n  gain: 10.610216987384797\n  hostname: Kais-MacBook-Pro.local\n  iterations: 47\n  iterations_since_restore: 48\n  loss: 2.053420165872076\n  node_ip: 127.0.0.1\n  pid: 46686\n  time_since_restore: 5.178762912750244\n  time_this_iter_s: 0.10710978507995605\n  time_total_s: 5.178762912750244\n  timestamp: 1658500034\n  timesteps_since_restore: 0\n  training_iteration: 48\n  trial_id: 5d51f2d2\n  warmup_time: 0.",
        "3883d294-21e3-4110-84d1-193f34c9427d": "if len(self._inferred_metrics) >= limit:\n            return self._inferred_metrics\n        self._inferred_metrics = {}\n        for t in trials:\n            if not t.last_result:\n                continue\n            for metric, value in t.last_result.items():\n                if metric not in self.DEFAULT_COLUMNS:\n                    if metric not in AUTO_RESULT_KEYS:\n                        if type(value) in self.VALID_SUMMARY_TYPES:\n                            self._inferred_metrics[metric] = metric\n\n                if len(self._inferred_metrics) >= limit:\n                    return self._inferred_metrics\n        return self._inferred_metrics\n\n    def _current_best_trial(self, trials: List[Trial]):\n        if not trials:\n            return None, None\n\n        metric, mode = self._metric, self._mode\n        # If no metric has been set, see if exactly one has been reported\n        # and use that one.`mode` must still be set.",
        "c6e17b21-a8b7-4c02-91b8-c8599b5ce161": "ray.tune.search.Repeater.on_trial_result#\n\n\nRepeater.on_trial_result(trial_id: str, result: Dict) \u2192 None#\nOptional notification for result during training.\nNote that by default, the result dict may include NaNs or\nmay not include the optimization metric. It is up to the\nsubclass implementation to preprocess the result to\navoid breaking the optimization process.\n\nParameters\n\ntrial_id \u2013 A unique string ID for the trial.\nresult \u2013 Dictionary of metrics for current training progress.\nNote that the result dict may include NaNs or\nmay not include the optimization metric. It is up to the\nsubclass implementation to preprocess the result to\navoid breaking the optimization process.",
        "86ab9bb6-08e8-432f-911c-82c2f6d2ccff": "prune_columns = False\n\n        block_accessor = BlockAccessor.for_block(block)\n        if (\n            prune_columns\n            and isinstance(block_accessor, TableBlockAccessor)\n            and block_accessor.num_rows() > 0\n        ):\n            return block_accessor.select(list(columns))\n        else:\n            return block\n\n\nclass SimpleShuffleGroupbyOp(_GroupbyOp, SimpleShufflePlan):\n    pass\n\n\nclass PushBasedGroupbyOp(_GroupbyOp, PushBasedShufflePlan):\n    pass\n\n\n[docs]@PublicAPI\nclass GroupedData:\n    \"\"\"Represents a grouped dataset created by calling ``Dataset.groupby()``.The actual groupby is deferred until an aggregation is applied.\n    \"\"\"[docs]    def __init__(self, dataset: Dataset, key: str):\n        \"\"\"Construct a dataset grouped by key (internal API).The constructor is not part of the GroupedData API.Use the ``Dataset.groupby()`` method to construct one.\n        \"\"\"",
        "af326ba3-ffcd-4606-8a8b-1d7d9f415017": "fit() (ray.data.preprocessor.Preprocessor method)\n\n(ray.data.preprocessors.Categorizer method)\n\n(ray.data.preprocessors.Concatenator method)\n\n(ray.data.preprocessors.CustomKBinsDiscretizer method)\n\n(ray.data.preprocessors.LabelEncoder method)\n\n(ray.data.preprocessors.MaxAbsScaler method)\n\n(ray.data.preprocessors.MinMaxScaler method)\n\n(ray.data.preprocessors.MultiHotEncoder method)\n\n(ray.data.preprocessors.Normalizer method)\n\n(ray.data.preprocessors.OneHotEncoder method)\n\n(ray.data.preprocessors.OrdinalEncoder method)\n\n(ray.data.preprocessors.PowerTransformer method)\n\n(ray.data.preprocessors.RobustScaler method)\n\n(ray.data.preprocessors.SimpleImputer method)\n\n(ray.data.preprocessors.StandardScaler method)\n\n(ray.data.preprocessors.UniformKBinsDiscretizer method)\n\n(ray.train.data_parallel_trainer.DataParallelTrainer method)\n\n(ray.train.gbdt_trainer.GBDTTrainer method)\n\n(ray.train.horovod.HorovodTrainer method)\n\n(ray.train.huggingface.AccelerateTrainer method)\n\n(ray.train.huggingface.TransformersTrainer method)\n\n(ray.train.lightgbm.LightGBMTrainer method)\n\n(ray.train.lightning.LightningTrainer method)\n\n(ray.train.tensorflow.TensorflowTrainer method)\n\n(ray.train.torch.TorchTrainer method)\n\n(ray.train.trainer.BaseTrainer method)\n\n(ray.train.xgboost.XGBoostTrainer method)\n\n(ray.tune.Tuner method)",
        "94afa98b-ab1a-4132-8b07-876cd4178d78": "\",\n         \"default\": \"/\",\n         \"type\": \"string\"\n      },\n      \"import_path\": {\n         \"title\": \"Import Path\",\n         \"description\": \"An import path to a bound deployment node.Should be of the form \\\"module.submodule_1...submodule_n.dag_node\\\".This is equivalent to \\\"from module.submodule_1...submodule_n import dag_node\\\".Only works with Python applications.This field is REQUIRED when deploying Serve config to a Ray cluster.\",\n         \"type\": \"string\"\n      },\n      \"runtime_env\": {\n         \"title\": \"Runtime Env\",\n         \"description\": \"The runtime_env that the deployment graph will be run in.Per-deployment runtime_envs will inherit from this.working_dir and py_modules may contain only remote URIs.\",\n         \"default\": {},\n         \"type\": \"object\"\n      },\n      \"host\": {\n         \"title\": \"Host\",\n         \"description\": \"Host for HTTP servers to listen on.Defaults to \\\"0.0.0.0\\\", which exposes Serve publicly.Cannot be updated once your Serve application has started running.The Serve application must be shut down and restarted with the new host instead.",
        "db06322a-525d-4d8a-a305-88397d6d2570": "Example:\n            >>> from ray.job_submission import JobSubmissionClient\n            >>> client = JobSubmissionClient(\"http://127.0.0.1:8265\") # doctest: +SKIP\n            >>> client.submit_job( # doctest: +SKIP\n            ...     entrypoint=\"python script.py\",\n            ...     runtime_env={\n            ...         \"working_dir\": \"./\",\n            ...         \"pip\": [\"requests==2.26.0\"]\n            ...     }\n            ... )  # doctest: +SKIP\n            'raysubmit_4LamXRuQpYdSMg7J'\n\n        Args:\n            entrypoint: The shell command to run for this job.submission_id: A unique ID for this job.runtime_env: The runtime environment to install and run this job in.metadata: Arbitrary data to store along with this job.job_id: DEPRECATED.This has been renamed to submission_id\n            entrypoint_num_cpus: The quantity of CPU cores to reserve for the execution\n                of the entrypoint command, separately from any tasks or actors launched\n                by it.",
        "4d9f70e7-fd07-4433-b840-7a37440440b0": "ray.rllib.policy.Policy.from_state#\n\n\nstatic Policy.from_state(state: Dict[str, Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor, dict, tuple]]) \u2192 Policy[source]#\nRecovers a Policy from a state object.\nThe state of an instantiated Policy can be retrieved by calling its\nget_state method. This only works for the V2 Policy classes (EagerTFPolicyV2,\nSynamicTFPolicyV2, and TorchPolicyV2). It contains all information necessary\nto create the Policy. No access to the original code (e.g. configs, knowledge of\nthe policy\u2019s class, etc..) is needed.\n\nParameters\nstate \u2013 The state to recover a new Policy instance from.\n\nReturns\nA new Policy instance.",
        "15c9a45e-73ac-404e-895f-8d04c33ce3d6": "RLModule Configuration#\n\n\n\n\n\n\nRLModuleConfig(observation_space,\u00a0...)\nA utility config class to make it constructing RLModules easier.\n\nRLModuleConfig.to_dict()\nReturns a serialized representation of the config.\n\nRLModuleConfig.from_dict(d)\nCreates a config from a serialized representation.\n\nRLModuleConfig.get_catalog()\nReturns the catalog for this config.",
        "e33b3007-096f-4fc1-ab2c-7d1ea89640e3": "ray.rllib.policy.policy.Policy.make_rl_module#\n\n\nPolicy.make_rl_module() \u2192 RLModule[source]#\nReturns the RL Module (only for when RLModule API is enabled.)\nIf RLModule API is enabled (self.config.rl_module(_enable_rl_module_api=True),\nthis method should be implemented and should return the RLModule instance to\nuse for this Policy. Otherwise, RLlib will error out.",
        "7dfb223b-041b-4aa2-9ffe-fb697b9b5572": "No intelligence is applied to separating the commands; the\ninput is split at the first ';;', even if it is in the middle of a\nquoted string.If a file \".pdbrc\" exists in your home directory or in the current\ndirectory, it is read in and executed as if it had been typed at the\ndebugger prompt.This is particularly useful for aliases.If both\nfiles exist, the one in the home directory is read first and aliases\ndefined there can be overridden by the local file.This behavior can be\ndisabled by passing the \"readrc=False\" argument to the Pdb constructor.Aside from aliases, the debugger is not directly programmable; but it\nis implemented as a class from which you can derive your own debugger\nclass, which you can make as fancy as you like.\n\n\nDebugger commands\n=================\n\n\"\"\"\n# NOTE: the actual command documentation is collected from docstrings of the\n# commands and is appended to __doc__ after the class has been defined.\n\nimport os\nimport io\nimport re\nimport sys\nimport cmd\nimport bdb\nimport dis\nimport code\nimport glob\nimport pprint\nimport signal\nimport inspect\nimport tokenize\nimport traceback\nimport linecache\n\n\nclass Restart(Exception):\n    \"\"\"Causes a debugger to be restarted for the debugged python program.\"\"\"",
        "bf51cbff-93ae-4a38-861c-560931310b61": "return (\n            hasattr(self, \"observation_space\")\n            and isinstance(self.observation_space, gym.spaces.Dict)\n            and set(self.observation_space.spaces.keys()) == self.get_agent_ids()\n        )\n\n    @DeveloperAPI\n    def _check_if_action_space_maps_agent_id_to_sub_space(self) -> bool:\n        \"\"\"Checks if action space maps from agent ids to spaces of individual agents.\"\"\"return (\n            hasattr(self, \"action_space\")\n            and isinstance(self.action_space, gym.spaces.Dict)\n            and set(self.action_space.keys()) == self.get_agent_ids()\n        )\n\n\n[docs]@PublicAPI\ndef make_multi_agent(\n    env_name_or_creator: Union[str, EnvCreator],\n) -> Type[\"MultiAgentEnv\"]:\n    \"\"\"Convenience wrapper for any single-agent env to be converted into MA.Allows you to convert a simple (single-agent) `gym.Env` class\n    into a `MultiAgentEnv` class.This function simply stacks n instances\n    of the given ```gym.Env``` class into one unified ``MultiAgentEnv`` class\n    and returns this class, thus pretending the agents act together in the\n    same environment, whereas - under the hood - they live separately from\n    each other in n parallel single-agent envs.Agent IDs in the resulting and are int numbers starting from 0\n    (first agent).",
        "5eeb0ef2-565a-46f7-a5c1-17899d90410b": "ray.train.CheckpointConfig.num_to_keep#\n\n\nCheckpointConfig.num_to_keep: Optional[int] = None#",
        "f9b9f65e-cad9-4121-b677-81af7edf0065": "ray.train.lightning.RayDDPStrategy.launcher#\n\n\nproperty RayDDPStrategy.launcher: Optional[pytorch_lightning.strategies.launchers.base._Launcher]#",
        "5bab6423-d99a-41ed-b174-de72060aca91": "super().__init__(\n            action_space=action_space, model=model, framework=framework, **kwargs\n        )\n\n        self.action_space_struct = get_base_struct_from_space(self.action_space)\n\n    @override(Exploration)\n    def get_exploration_action(\n        self,\n        *,\n        action_distribution: ActionDistribution,\n        timestep: Union[int, TensorType],\n        explore: bool = True\n    ):\n        # Instantiate the distribution object.",
        "d7a41ff0-cb31-4af1-92c3-9a222ae667d2": "ray.train.torch.TorchTrainer#\n\n\nclass ray.train.torch.TorchTrainer(*args, **kwargs)[source]#\nBases: ray.train.data_parallel_trainer.DataParallelTrainer\nA Trainer for data parallel PyTorch training.At a high level, this Trainer does the following:\n\nLaunches multiple workers as defined by the scaling_config.Sets up a distributed PyTorch environment\non these workers as defined by the torch_config.Ingests the input datasets based on the dataset_config.Runs the input train_loop_per_worker(train_loop_config)\non all workers.For more details, see the PyTorch User Guide.Example\nimport os\nimport tempfile\n\nimport torch\nfrom torch import nn\nfrom torch.nn.parallel import DistributedDataParallel\n\nimport ray\nfrom ray.train import Checkpoint, CheckpointConfig, RunConfig, ScalingConfig\nfrom ray.train.torch import TorchTrainer\n\n# If using GPUs, set this to True.use_gpu = False\n# Number of processes to run training on.num_workers = 4\n\n# Define your network structure.class NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.layer1 = nn.Linear(1, 32)\n        self.relu = nn.ReLU()\n        self.layer2 = nn.Linear(32, 1)\n\n    def forward(self, input):\n        return self.layer2(self.relu(self.layer1(input)))\n\n# Training loop.def train_loop_per_worker(config):\n\n    # Read configurations.",
        "9b473382-8c0b-4614-9a1a-a7376749a786": "Args:\n                siblings: A list of NestedTaskSummary's to merge together\n\n            Returns\n                Index 0: A list of NestedTaskSummary's which have been merged\n                Index 1: The smallest timestamp amongst the siblings\n            \"\"\"\n            if not len(siblings):\n                return siblings, None\n\n            # Group by name\n            groups = {}\n            min_timestamp = None\n\n            for child in siblings:\n                child.children, child_min_timestamp = merge_sibings_for_task_group(\n                    child.children\n                )\n                if child_min_timestamp and child_min_timestamp < (\n                    child.timestamp or sys.maxsize\n                ):\n                    child.timestamp = child_min_timestamp\n\n                if child.name not in groups:\n                    groups[child.",
        "89cd5d7a-5227-4a18-a5e7-9ddda94f8676": "Serialization#\nSince Ray processes do not share memory space, data transferred between workers and nodes will need to serialized and deserialized. Ray uses the Plasma object store to efficiently transfer objects across different processes and different nodes. Numpy arrays in the object store are shared between workers on the same node (zero-copy deserialization).",
        "b2ead861-0cff-4965-8d7d-5c465c1c9fac": "Exit Handler#\n\nArgo version:#\n# https://github.com/argoproj/argo-workflows/tree/master/examples#exit-handlers\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: exit-handlers-\nspec:\n  entrypoint: intentional-fail\n  onExit: exit-handler                  # invoke exit-handler template at end of the workflow\n  templates:\n  # primary workflow template\n  - name: intentional-fail\n    container:\n      image: alpine:latest\n      command: [sh, -c]\n      args: [\"echo intentional failure; exit 1\"]\n\n  # Exit handler templates\n  # After the completion of the entrypoint template, the status of the\n  # workflow is made available in the global variable {{workflow.status}}.",
        "0db5b69e-efd0-48be-bacf-eaddbe7f0667": "Trial name              date               done    experiment_taghostname        iterations_since_restorenode_ip       pidshould_checkpoint    time_since_restore  time_this_iter_s  time_total_s  timestamp  training_iterationtrial_id   \n\n\nTorchTrainer_f5aa9_000002023-03-01_13-08-41True                 0ip-10-0-26-109                       24410.0.26.109175347True                            108.703            4.2088       108.703 1677704918                 244f5aa9_00000",
        "586c6c86-1b04-4760-9c57-43f3116fb7c1": "ray.tune.search.bayesopt.BayesOptSearch.optimizer#\n\n\nBayesOptSearch.optimizer = None#",
        "0c538563-46a2-4714-82ef-91ca0ff54b8e": "**self._get_additional_update_kwargs(train_results),\n            )\n            for key, res in additional_results.items():\n                if key in train_results:\n                    train_results[key].update(res)\n        else:\n            # Move train batches (of size `train_batch_size`) onto learner queue.self.place_processed_samples_on_learner_thread_queue()\n            # Extract most recent train results from learner thread.train_results = self.process_trained_results()\n\n        # Sync worker weights (only those policies that were actually updated).",
        "c4a7d697-896e-45c9-b35d-c3bc7fe7ae51": "\"\"\"\nMinimal Ray Train + Accelerate example adapted from\nhttps://github.com/huggingface/accelerate/blob/main/examples/nlp_example.py\n\nFine-tune a BERT model with Hugging Face Accelerate and Ray Train\n\"\"\"\n\nimport evaluate\nimport torch\nfrom accelerate import Accelerator\nfrom datasets import load_dataset\nfrom tempfile import TemporaryDirectory\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    get_linear_schedule_with_warmup,\n    set_seed,\n)\n\nimport ray.train\nfrom ray.train import ScalingConfig, Checkpoint\nfrom ray.train.torch import TorchTrainer\n\n\ndef train_func(config):\n    \"\"\"Your training function that will be launched on each worker.\"\"\"",
        "2849c686-9115-47d5-bbf7-b68ae9b3ecf8": "self._report()\n\n    def on_train_end(self, args, state, control, **kwargs):\n        # Final callback.Train metrics are logged right before this.# Use last eval metrics\n        self.delayed_report[\"metrics\"] = {\n            **self.last_metrics,\n            **self.delayed_report[\"metrics\"],\n        }\n        self._report()\n\n\n[docs]@PublicAPI(stability=\"alpha\")\nclass RayTrainReportCallback(TrainerCallback):\n    \"\"\"A simple callback to report checkpoints and metrics to Ray Tarin.This callback overrides the `TrainerCallback.on_save()` method.After\n    a new checkpoint get saved, it fetches the latest metric dictionary\n    from `TrainerState.log_history` and reports it with the latest checkpoint\n    to Ray Train.If you want more customized reporting logics, please implement your own\n    callbacks following the Transformers integration user guides.Note that users should ensure that the logging, evaluation, and saving frequencies\n    are properly configured so that the monitoring metric is always up-to-date\n    when `transformers.Trainer` saves a checkpoint.",
        "b65edd6e-55d2-48a7-b930-70d5d8ba5e19": "ray.train.data_parallel_trainer.DataParallelTrainer.fit#\n\n\nDataParallelTrainer.fit() \u2192 ray.air.result.Result#\nRuns training.\n\nReturns\nA Result object containing the training result.\n\nRaises\n\nTrainingFailedError \u2013 If any failures during the execution of\nself.as_trainable()`, or during the Tune execution loop \u2013 \n\n\n\nPublicAPI (beta): This API is in beta and may change before becoming stable.",
        "790b577e-da39-4143-b55c-72ad42824065": "Runtime Env API#\n\n\n\n\n\n\nray.runtime_env.RuntimeEnvConfig([...])\nUsed to specify configuration options for a runtime environment.\n\nray.runtime_env.RuntimeEnv(*[,\u00a0py_modules,\u00a0...])\nThis class is used to define a runtime environment for a job, task, or actor.",
        "a9b214a6-e0d7-4396-95b5-c652c751145f": "ray.tune.Trainable.training_iteration#\n\n\nproperty Trainable.training_iteration#\nCurrent training iteration (same as self.iteration).\nThis value is automatically incremented every time train() is called\nand is automatically inserted into the training result dict.",
        "7727e13a-c645-44ea-8580-4aab5ea8db2d": ")\n                    actions = action_dist.sample()\n\n                # Compute action-logp and action-prob from distribution and add to\n                # `extra_fetches`, if possible.if action_dist is not None:\n                    logp = action_dist.logp(actions)\n            else:\n                fwd_out = self.model.forward_inference(input_dict)\n                # For recurrent models, we need to remove the time dimension.fwd_out = self.maybe_remove_time_dimension(fwd_out)\n\n                # ACTION_DIST_INPUTS field returned by `forward_exploration()` ->\n                # Create a distribution object.",
        "decb50c6-e475-4f63-b46e-ca0817c00e6f": "Tune Scikit-Learn API  (tune.sklearn)#",
        "679033e9-1d73-400d-8fa9-17d93bd4f33b": "final_p\n            + (self.initial_p - self.final_p)\n            * (1.0 - (t / self.schedule_timesteps)) ** self.power\n        )",
        "fde144e6-6714-4f51-ae32-164e3c64eb9b": "More details for starting and connecting to a remote cluster can be found\nhere: https://docs.ray.io/en/master/cluster/getting-started.html\nYou can also define an environment variable called RAY_ADDRESS in\nthe same format as the address parameter to connect to an existing\ncluster with ray.init() or ray.init(address=\u201dauto\u201d).Parameters\n\naddress \u2013 The address of the Ray cluster to connect to.The provided\naddress is resolved as follows:\n1.If a concrete address (e.g., localhost:<port>) is provided, try to\nconnect to it.Concrete addresses can be prefixed with \u201cray://\u201d to\nconnect to a remote cluster.For example, passing in the address\n\u201cray://123.45.67.89:50005\u201d will connect to the cluster at the given\naddress.2.If no address is provided, try to find an existing Ray instance\nto connect to.This is done by first checking the environment\nvariable RAY_ADDRESS.If this is not defined, check the address\nof the latest cluster started (found in\n/tmp/ray/ray_current_cluster) if available.If this is also empty,\nthen start a new local Ray instance.3.If the provided address is \u201cauto\u201d, then follow the same process\nas above.However, if there is no existing cluster found, this will\nthrow a ConnectionError instead of starting a new local Ray\ninstance.4.If the provided address is \u201clocal\u201d, start a new local Ray\ninstance, even if there is already an existing local Ray instance.num_cpus \u2013 Number of CPUs the user wishes to assign to each\nraylet.By default, this is set based on virtual cores.num_gpus \u2013 Number of GPUs the user wishes to assign to each\nraylet.By default, this is set based on detected GPUs.resources \u2013 A dictionary mapping the names of custom resources to the\nquantities for them available.labels \u2013 [Experimental] The key-value labels of the node.object_store_memory \u2013 The amount of memory (in bytes) to start the\nobject store with.",
        "f7b7e264-94e3-46a9-8218-369ef8cc6b0b": "Environment\n\nenvironment() (ray.rllib.algorithms.algorithm_config.AlgorithmConfig method)\n\nEpisode\n\nEPISODES (ray.rllib.utils.replay_buffers.replay_buffer.StorageUnit attribute)\n\nEPS_ID (ray.rllib.policy.sample_batch.SampleBatch attribute)\n\nEpsilonGreedy (class in ray.rllib.utils.exploration.epsilon_greedy)\n\nerror (ray.train.Result attribute)\n\n(ray.util.state.common.RuntimeEnvState attribute)\n\n\nerror_file (ray.tune.experiment.trial.Trial attribute)\n\nerror_message (ray.util.state.common.TaskState attribute)\n\nerror_type (ray.job_submission.JobDetails attribute)\n\n(ray.job_submission.JobInfo attribute)\n\n(ray.util.state.common.TaskState attribute)\n\n\nerrors (ray.tune.ResultGrid property)\n\nESConfig (class in ray.rllib.algorithms.es.es)\n\nestimate_inmemory_data_size() (ray.data.datasource.Reader method)\n\nEvalsLog (ray.tune.integration.xgboost.TuneReportCallback attribute)\n\n(ray.tune.integration.xgboost.TuneReportCheckpointCallback attribute)\n\n\nevaluate() (ray.rllib.algorithms.algorithm.Algorithm method)",
        "1ddcf8f8-b03b-4363-82b2-fa44be44fb6f": "wait() (in module ray)\n\n(ray.util.placement_group.PlacementGroup method)\n\n\nwait_for_gpu() (in module ray.tune.utils)\n\nwait_for_resources() (ray.autoscaler._private.fake_multi_node.test_utils.DockerCluster static method)\n\nwall_time_s (ray.data.block.BlockExecStats attribute)\n\nwarn_if_infinite_kl_divergence() (in module ray.rllib.utils.tf_utils)\n\n(in module ray.rllib.utils.torch_utils)\n\n\nwas_current_actor_reconstructed (ray.runtime_context.RuntimeContext property)\n\nwhat_to_compile (ray.rllib.core.learner.learner.FrameworkHyperparameters attribute)\n\nwindow() (ray.data.Dataset method)\n\nwith_parameters() (in module ray.tune)\n\nwith_resources() (in module ray.tune)\n\nWorker process / worker\n\nworker_id (ray.util.state.common.TaskState attribute)\n\n(ray.util.state.common.WorkerState attribute)\n\n\nworker_launch_time_ms (ray.util.state.common.WorkerState attribute)\n\nworker_launched_time_ms (ray.util.state.common.WorkerState attribute)\n\nworker_pid (ray.util.state.common.TaskState attribute)\n\nworker_type (ray.util.state.common.WorkerState attribute)\n\n\n\nWorkerCrashedError\n\nWorkerSet (class in ray.rllib.evaluation.worker_set)\n\nWorkerState (class in ray.util.state.common)\n\nworld_size (ray.train.lightning.RayDDPStrategy property)\n\n(ray.train.lightning.RayDeepSpeedStrategy property)\n\n(ray.train.lightning.RayFSDPStrategy property)",
        "38d4a48f-e5d0-46ec-93d4-e179b0d8aab8": "Starting Ray#\nThis page covers how to start Ray on your single machine or cluster of machines.\n\nTip\nBe sure to have installed Ray before following the instructions on this page.",
        "cf95cfa8-b5d4-4778-90fe-9a0e47d95ac0": "FIFOScheduler (Default Scheduler)#\n\n\n\n\n\n\nFIFOScheduler()\nSimple scheduler that just runs trials in submission order.",
        "566d9a46-75b9-4ce4-a4d2-c007758b7761": "\",\n         \"type\": \"object\",\n         \"properties\": {\n            \"node_id\": {\n               \"title\": \"Node Id\",\n               \"description\": \"ID of the node that the actor is running on.\",\n               \"type\": \"string\"\n            },\n            \"node_ip\": {\n               \"title\": \"Node Ip\",\n               \"description\": \"IP address of the node that the actor is running on.\",\n               \"type\": \"string\"\n            },\n            \"actor_id\": {\n               \"title\": \"Actor Id\",\n               \"description\": \"Actor ID.\",\n               \"type\": \"string\"\n            },\n            \"actor_name\": {\n               \"title\": \"Actor Name\",\n               \"description\": \"Actor name.",
        "be813cb7-495b-4578-8b99-aa6b16363abb": "Examples:\n        >>> import pandas as pd\n        >>> import ray\n        >>> from ray.data.preprocessors import MinMaxScaler\n        >>>\n        >>> df = pd.DataFrame({\"X1\": [-2, 0, 2], \"X2\": [-3, -3, 3], \"X3\": [1, 1, 1]})   # noqa: E501\n        >>> ds = ray.data.from_pandas(df)  # doctest: +SKIP\n        >>> ds.to_pandas()  # doctest: +SKIP\n           X1  X2  X3\n        0  -2  -3   1\n        1   0  -3   1\n        2   2   3   1\n\n        Columns are scaled separately.>>> preprocessor = MinMaxScaler(columns=[\"X1\", \"X2\"])\n        >>> preprocessor.fit_transform(ds).to_pandas()  # doctest: +SKIP\n            X1   X2  X3\n        0  0.0  0.0   1\n        1  0.5  0.0   1\n        2  1.0  1.0   1\n\n        Constant-valued columns get filled with zeros.",
        "0411c9a6-c7be-438f-a23d-9adfea390476": "ray.rllib.policy.sample_batch.SampleBatch.set_training#\n\n\nSampleBatch.set_training(training: Union[bool, tensorflow.python.ops.array_ops.placeholder] = True)[source]#\nSets the is_training flag for this SampleBatch.",
        "30766c26-3179-435b-994c-073361849ec7": "Example:\n\n        .. testcode::\n\n            import ray\n            from ray import train\n            from ray.train import ScalingConfig\n            from ray.train.torch import TorchTrainer\n\n            def train_loop_per_worker():\n                print(train.get_context().get_local_world_size())\n\n            train_dataset = ray.data.from_items(\n                [{\"x\": x, \"y\": x + 1} for x in range(32)])\n            trainer = TorchTrainer(train_loop_per_worker,\n                scaling_config=ScalingConfig(num_workers=1),\n                datasets={\"train\": train_dataset})\n            trainer.fit()\n\n        .. testoutput::\n            :hide:\n\n            ...\n    \"\"\"\n    session = _get_session()\n    if not hasattr(session, \"local_world_size\"):\n        raise RuntimeError(\n            \"`get_local_world_size` can only be called for TrainSession! \"\"Make sure you only use that in `train_loop_per_worker` function\"\n            \"that is passed into `DataParallelTrainer`.\")\n    return session.local_world_size",
        "6076f052-554e-4014-b5d0-139b5b409c59": "If True, RolloutWorkers will NOT limit the\nnumber of collected batches within the same sample() call based on\nthe number of sub-environments within the worker (no sub-environments\npresent).\n\n\nReturns\nThis updated AlgorithmConfig object.",
        "2924dbe5-5da0-4226-80e3-4ff22362bdd8": "Performance tips#",
        "ef9f2781-3d12-4b1c-a5b4-a319d50b1dda": "prefetch_batches=prefetch_batches,\n            drop_last=drop_last,\n            local_shuffle_buffer_size=local_shuffle_buffer_size,\n            local_shuffle_seed=local_shuffle_seed,\n            unsqueeze_label_tensor=unsqueeze_label_tensor,\n            unsqueeze_feature_tensors=unsqueeze_feature_tensors,\n        )\n\n[docs]    @ConsumptionAPI\n    def to_tf(\n        self,\n        feature_columns: Union[str, List[str]],\n        label_columns: Union[str, List[str]],\n        *,\n        prefetch_batches: int = 1,\n        batch_size: int = 1,\n        drop_last: bool = False,\n        local_shuffle_buffer_size: Optional[int] = None,\n        local_shuffle_seed: Optional[int] = None,\n        # Deprecated\n        prefetch_blocks: int = 0,\n    ) -> \"tf.data.Dataset\":\n        \"\"\"Return a `TensorFlow Dataset <https://www.tensorflow.org/api_docs/python/tf/data/Dataset/>`_\n        over this :class:`~ray.data.",
        "5eceee97-2141-418d-b5e2-1bcbebfa6cca": ")\n            if not isinstance(v.max_object_store_memory_fraction, (float, int)):\n                raise ValueError(\n                    f\"Error configuring dataset `{k}`: \"\n                    \"max_object_store_memory_fraction \"\n                    \"must be None or a float with value -1 or >=0, but got \"\n                    f\"{v.max_object_store_memory_fraction}.\")\n            if not (\n                v.max_object_store_memory_fraction == -1\n                or v.max_object_store_memory_fraction >= 0\n            ):\n                raise ValueError(\n                    f\"Error configuring dataset `{k}`: \"\n                    \"max_object_store_memory_fraction \"\n                    \"must be None or a float with value -1 or >=0, but got \"\n                    f\"{v.max_object_store_memory_fraction}.\"",
        "f0debb9b-a219-4207-ade4-8a033989a3b2": "Examples:\n        >>> from ray.rllib.execution.rollout_ops import synchronous_parallel_sample\n        >>> algo = [...] # doctest: +SKIP\n        >>> train_batch = synchronous_parallel_sample(algo.workers) # doctest: +SKIP\n        >>> # This trains the policy on one batch.>>> results = multi_gpu_train_one_step(algo, train_batch)) # doctest: +SKIP\n        {\"default_policy\": ...}\n\n    Updates the NUM_ENV_STEPS_TRAINED and NUM_AGENT_STEPS_TRAINED counters as well as\n    the LOAD_BATCH_TIMER and LEARN_ON_BATCH_TIMER timers of the Algorithm instance.\n    \"\"\"if log_once(\"mulit_gpu_train_one_step_deprecation_warning\"):\n        deprecation_warning(\n            old=(\"ray.rllib.execution.train_ops.\"\"multi_gpu_train_one_step\")\n        )\n    config = algorithm.config\n    workers = algorithm.workers\n    local_worker = workers.local_worker()\n    num_sgd_iter = config.get(\"num_sgd_iter\", 1)\n    sgd_minibatch_size = config.get(\"sgd_minibatch_size\", config[\"train_batch_size\"])\n\n    # Determine the number of devices (GPUs or 1 CPU) we use.num_devices = int(math.ceil(config[\"num_gpus\"] or 1))\n\n    # Make sure total batch size is dividable by the number of devices.# Batch size per tower.",
        "466f65d2-67c0-4678-8fd2-6a5587ce9e82": "(RayTrainWorker pid=1223, ip=172.31.85.193) ***** Running Evaluation *****\n(RayTrainWorker pid=1223, ip=172.31.85.193)   Num examples = 1043\n(RayTrainWorker pid=1223, ip=172.31.85.193)   Batch size = 16\n(RayTrainWorker pid=1223, ip=172.31.85.193) The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n\n\n(RayTrainWorker pid=1223, ip=172.31.85.193) {'loss': 0.926, 'learning_rate': 0.015, 'epoch': 1.0}\n(RayTrainWorker pid=1223, ip=172.31.85.193) {'eval_loss': 0.6529427766799927, 'eval_matthews_correlation': 0.0, 'eval_runtime': 0.9428, 'eval_samples_per_second': 288.51, 'eval_steps_per_second': 5.303, 'epoch': 1.0}",
        "44fe1f52-38df-41c0-bdae-fa94a10e1647": "now = time.time()\n        if now - self.last_sync_up_time >= self.sync_period:\n            result = self.sync_up(\n                local_dir=local_dir, remote_dir=remote_dir, exclude=exclude\n            )\n            self.last_sync_up_time = now\n            return result\n\n    def sync_down_if_needed(\n        self, remote_dir: str, local_dir: str, exclude: Optional[List] = None\n    ):\n        \"\"\"Syncs down if time since last sync down is greater than sync_period.Args:\n            remote_dir: Remote directory to sync down from.This is an URI\n                (``protocol://remote/path``).local_dir: Local directory to sync to.exclude: Pattern of files to exclude, e.g.``[\"*/checkpoint_*]`` to exclude trial checkpoints.\n        \"\"\"",
        "b35dfa52-706f-472f-9f60-3c1363b06419": "if not self.default_metric or not self.default_mode:\n            raise ValueError(\n                \"To fetch the `best_trial`, pass a `metric` and `mode` \"\n                \"parameter to `tune.run()`.Alternatively, use the \"\n                \"`get_best_trial(metric, mode)` method to set the metric \"\n                \"and mode explicitly.\")\n        return self.get_best_trial(self.default_metric, self.default_mode)\n\n    @property\n    def best_config(self) -> Dict:\n        \"\"\"Get the config of the best trial of the experiment\n\n        The best trial is determined by comparing the last trial results\n        using the `metric` and `mode` parameters passed to `tune.run()`.If you didn't pass these parameters, use\n        `get_best_config(metric, mode, scope)` instead.\n        \"\"\"if not self.default_metric or not self.default_mode:\n            raise ValueError(\n                \"To fetch the `best_config`, pass a `metric` and `mode` \"\n                \"parameter to `tune.run()`.Alternatively, use the \"\n                \"`get_best_config(metric, mode)` method to set the metric \"\n                \"and mode explicitly.\"",
        "cce62a20-ed38-46b0-aee6-f9f6aefd38e9": "003987789154052734\n  \nResult for objective_4d4ed536:\n  date: 2022-07-22_15-19-33\n  done: false\n  experiment_id: 6c18c359d1574792ac99ed37265d5d87\n  hostname: Kais-MacBook-Pro.local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 8.373189005362395\n  neg_mean_loss: -8.373189005362395\n  node_ip: 127.0.0.1\n  pid: 45963\n  time_since_restore: 0.10463309288024902\n  time_this_iter_s: 0.10463309288024902\n  time_total_s: 0.10463309288024902\n  timestamp: 1658499573\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: 4d4ed536\n  warmup_time: 0.0028281211853027344\n  \nResult for objective_4d51b38c:\n  date: 2022-07-22_15-19-33\n  done: false\n  experiment_id: 5c9cf6fc35c4411b8ec13e0b90b791a4\n  hostname: Kais-MacBook-Pro.local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 1.2722313329577961\n  neg_mean_loss: -1.2722313329577961\n  node_ip: 127.0.0.1\n  pid: 45965\n  time_since_restore: 0.10346817970275879\n  time_this_iter_s: 0.",
        "ef9de9fe-7188-4cd4-84fd-74b22d359b03": "ray.util.placement_group.PlacementGroup.bundle_count#\n\n\nproperty PlacementGroup.bundle_count: int#",
        "cb913d4c-fd24-4f08-bf9f-48cde65cd0c9": "Args:\n        object_refs: Object ref of the object to get or a list of object refs\n            to get.timeout (Optional[float]): The maximum amount of time in seconds to\n            wait before returning.Set this to None will block until the\n            corresponding object becomes available.Setting ``timeout=0`` will\n            return the object immediately if it's available, else raise\n            GetTimeoutError in accordance with the above docstring.Returns:\n        A Python object or a list of Python objects.Raises:\n        GetTimeoutError: A GetTimeoutError is raised if a timeout is set and\n            the get takes longer than timeout to return.Exception: An exception is raised if the task that created the object\n            or that created one of the objects raised an exception.\n    \"\"\"worker = global_worker\n    worker.check_connected()\n\n    if hasattr(worker, \"core_worker\") and worker.core_worker.current_actor_is_asyncio():\n        global blocking_get_inside_async_warned\n        if not blocking_get_inside_async_warned:\n            logger.warning(\n                \"Using blocking ray.get inside async actor. \"\"This blocks the event loop.Please use `await` \"\n                \"on object ref with asyncio.gather if you want to \"\n                \"yield execution to the event loop instead.\"",
        "99b8bcd2-0f15-4ff9-ae5d-fa6163e53a9e": "return {\"action_dist\": Distribution}\n\n[docs]    @OverrideToImplementCustomLogic_CallToSuperRecommended\n    def output_specs_exploration(self) -> SpecType:\n        \"\"\"Returns the output specs of the forward_exploration method.Override this method to customize the output specs of the inference call.The default implementation requires the forward_exploration to reutn a dict\n        that has `action_dist` key and its value is an instance of\n        `Distribution`.This assumption must always hold.\n        \"\"\"return {\"action_dist\": Distribution}\n\n[docs]    def output_specs_train(self) -> SpecType:\n        \"\"\"Returns the output specs of the forward_train method.\"\"\"return {}\n\n[docs]    def input_specs_inference(self) -> SpecType:\n        \"\"\"Returns the input specs of the forward_inference method.\"\"\"return self._default_input_specs()\n\n[docs]    def input_specs_exploration(self) -> SpecType:\n        \"\"\"Returns the input specs of the forward_exploration method.\"\"\"return self._default_input_specs()\n\n[docs]    def input_specs_train(self) -> SpecType:\n        \"\"\"Returns the input specs of the forward_train method.\"\"\"return self._default_input_specs()\n\n    def _default_input_specs(self) -> SpecType:\n        \"\"\"Returns the default input specs.\"\"\"",
        "746ed21e-dfc8-4e08-9e19-f44a749ec5d2": "JobInfo (class in ray.job_submission)\n\nJobState (class in ray.util.state.common)\n\nJobStatus (class in ray.job_submission)\n\nJobSubmissionClient (class in ray.job_submission)\n\nJobType (class in ray.job_submission)\n\njoin() (ray.rllib.evaluation.sampler.AsyncSampler method)\n\njson_request() (in module ray.serve.http_adapters)\n\njson_to_multi_ndarray() (in module ray.serve.http_adapters)\n\njson_to_ndarray() (in module ray.serve.http_adapters)\n\nJsonLoggerCallback (class in ray.tune.logger)\n\nJsonReader (class in ray.rllib.offline.json_reader)\n\nJupyterNotebookReporter (class in ray.tune)\n\njvm_options (ray.job_config.JobConfig attribute)\n\n\n\nK\n\n\nkeep_alive_timeout_s (ray.serve.schema.HTTPOptionsSchema attribute)\n\nkey (ray.train.horovod.HorovodConfig attribute)\n\nkeys() (ray.rllib.algorithms.algorithm_config.AlgorithmConfig method)\n\n(ray.rllib.core.rl_module.marl_module.MultiAgentRLModule method)\n\n(ray.rllib.policy.policy_map.PolicyMap method)\n\n(ray.rllib.policy.sample_batch.SampleBatch method)\n\n(ray.runtime_env.RuntimeEnv method)\n\n(ray.runtime_env.RuntimeEnvConfig method)\n\n\n\n\nkill() (in module ray)\n\nkill_node() (ray.autoscaler._private.fake_multi_node.test_utils.DockerCluster method)\n\nknown_fields (ray.runtime_env.RuntimeEnv attribute)\n\n(ray.runtime_env.RuntimeEnvConfig attribute)",
        "b1e4b492-7df4-49ed-ad87-892387b47b4b": "serialize_lineage()\n                ds = ray.data.Dataset.deserialize_lineage(serialized_ds)\n                print(ds)\n\n            . testoutput::\n\n                Dataset(\n                   num_blocks=1,\n                   num_rows=150,\n                   schema={\n                      sepal length (cm): double,\n                      sepal width (cm): double,\n                      petal length (cm): double,\n                      petal width (cm): double,\n                      target: int64\n                   }\n                )\n\n        Args:\n            serialized_ds: The serialized Dataset that we wish to deserialize.Returns:\n            A deserialized ``Dataset`` instance.\n        \"\"\"",
        "85bad2a4-fa4f-401c-8a69-d57f6843b823": "__init__(action_space,\u00a0*,\u00a0framework,\u00a0model)\nInitialize RE3.\n\nbefore_compute_actions(*[,\u00a0timestep,\u00a0...])\nHook for preparations before policy.compute_actions() is called.\n\nget_exploration_optimizer(optimizers)\nMay add optimizer(s) to the Policy's own optimizers.\n\nget_state([sess])\nReturns the current exploration state.\n\non_episode_end(policy,\u00a0*[,\u00a0environment,\u00a0...])\nHandles necessary exploration logic at the end of an episode.\n\non_episode_start(policy,\u00a0*[,\u00a0environment,\u00a0...])\nHandles necessary exploration logic at the beginning of an episode.\n\npostprocess_trajectory(policy,\u00a0sample_batch)\nCalculate states' latent representations/embeddings.\n\nset_state(state[,\u00a0sess])\nSets the Exploration object's state to the given values.",
        "47484453-28ac-4581-afc2-75a3330e9118": "ASHA (tune.schedulers.ASHAScheduler)#\nThe ASHA scheduler can be used by\nsetting the scheduler parameter of tune.TuneConfig, which is taken in by Tuner, e.g.\nfrom ray import tune\nfrom tune.schedulers import ASHAScheduler\n\nasha_scheduler = ASHAScheduler(\n    time_attr='training_iteration',\n    metric='loss',\n    mode='min',\n    max_t=100,\n    grace_period=10,\n    reduction_factor=3,\n    brackets=1,\n)\ntuner = tune.Tuner(\n    train_fn,\n    tune_config=tune.TuneConfig(scheduler=asha_scheduler),\n)\nresults = tuner.fit()\n\n\nCompared to the original version of HyperBand, this implementation provides better\nparallelism and avoids straggler issues during eliminations.\nWe recommend using this over the standard HyperBand scheduler.\nAn example of this can be found here: Asynchronous HyperBand Example.\nEven though the original paper mentions a bracket count of 3, discussions with the authors concluded\nthat the value should be left to 1 bracket.\nThis is the default used if no value is provided for the brackets argument.\n\n\n\n\n\n\nAsyncHyperBandScheduler([time_attr,\u00a0metric,\u00a0...])\nImplements the Async Successive Halving.\n\nASHAScheduler\nalias of ray.tune.schedulers.async_hyperband.AsyncHyperBandScheduler",
        "d7a333b7-aad9-4f2d-80d3-4c38624d7fa9": "Walkthrough using Ray with SLURM#\nMany SLURM deployments require you to interact with slurm via sbatch, which executes a batch script on SLURM.\nTo run a Ray job with sbatch, you will want to start a Ray cluster in the sbatch job with multiple srun commands (tasks), and then execute your python script that uses Ray. Each task will run on a separate node and start/connect to a Ray runtime.\nThe below walkthrough will do the following:\n\nSet the proper headers for the sbatch script.\nLoad the proper environment/modules.\nFetch a list of available computing nodes and their IP addresses.\nLaunch a head ray process in one of the node (called the head node).\nLaunch Ray processes in (n-1) worker nodes and connects them to the head node by providing the head node address.\nAfter the underlying ray cluster is ready, submit the user specified task.\n\nSee slurm-basic.sh for an end-to-end example.",
        "b92c2f3e-ecf8-4a05-8785-c6a28992cd9f": "pieces = [_SerializedPiece(piece) for piece in pieces]\n            # Fetch Parquet metadata in parallel using Ray tasks.return list(\n                _fetch_metadata_parallel(\n                    pieces,\n                    _fetch_metadata_serialization_wrapper,\n                    PIECES_PER_META_FETCH,\n                    **ray_remote_args,\n                )\n            )\n        else:\n            return _fetch_metadata(pieces)\n\n\ndef _handle_read_os_error(error: OSError, paths: Union[str, List[str]]) -> str:\n    # NOTE: this is not comprehensive yet, and should be extended as more errors arise.# NOTE: The latter patterns are raised in Arrow 10+, while the former is raised in\n    # Arrow < 10.\n    aws_error_pattern = (\n        r\"^(?:(.*)AWS Error \\[code \\d+\\]: No response body\\.(.*))|\"\n        r\"(?:(.*)AWS Error UNKNOWN \\(HTTP status 400\\) during HeadObject operation: \"\n        r\"No response body\\.(.*))|\"\n        r\"(?:(.*)AWS Error ACCESS_DENIED during HeadObject operation: No response \"\n        r\"body\\.(.",
        "2835aa29-2a36-495d-9280-10ee37af3b26": "[docs]@DeveloperAPI\n@client_mode_hook\ndef timeline(filename=None):\n    \"\"\"Return a list of profiling events that can viewed as a timeline.\n\n    Ray profiling must be enabled by setting the RAY_PROFILING=1 environment\n    variable prior to starting Ray, and RAY_task_events_report_interval_ms set\n    to be positive (default 1000)\n\n    To view this information as a timeline, simply dump it as a json file by\n    passing in \"filename\" or using using json.dump, and then load go to\n    chrome://tracing in the Chrome web browser and load the dumped file.\n\n    Args:\n        filename: If a filename is provided, the timeline is dumped to that\n            file.\n\n    Returns:\n        If filename is not provided, this returns a list of profiling events.\n            Each profile event is a dictionary.\n    \"\"\"\n    return state.chrome_tracing_dump(filename=filename)",
        "b64932f3-ab2b-48fa-8ecc-1b22c4890feb": "@Deprecated\nclass TorchWorkerProfiler:\n    \"\"\"Utility class for running PyTorch Profiler on a Train worker.\n\n    Args:\n        trace_dir (Optional[str]): The directory to store traces on the\n           worker node. If ``None``, this will use a default temporary dir.\n    \"\"\"\n\n    WORKER_TRACE_DIR_NAME = \"pytorch_profiler_worker_traces\"\n\n    def __init__(self, trace_dir: Optional[str] = None):\n        raise DeprecationWarning(\n            \"The `ray.train.torch.TorchWorkerProfiler` API is deprecated in Ray 2.0.\",\n        )\n\n\nclass _TorchAccelerator(Accelerator):\n    \"\"\"A utility that implements methods to accelerate PyTorch training.Arguments:\n        amp: If true, perform training with automatic mixed precision.Otherwise, use full precision.\n    \"\"\"def __init__(self, amp: bool = False):\n        self.amp_is_enabled = amp\n        self.scaler = GradScaler() if amp else None\n        self._seed = None\n\n    def prepare_model(\n        self,\n        model: torch.nn.Module,\n        move_to_device: bool = True,\n        parallel_strategy: Optional[str] = \"ddp\",\n        parallel_strategy_kwargs: Optional[Dict[str, Any]] = None,\n    ) -> torch.nn.Module:\n        \"\"\"Prepares the model for distributed execution.",
        "28b19786-20aa-4cd2-a13b-e32da365ff44": "ray.tune.grid_search#\n\n\nray.tune.grid_search(values: Iterable) \u2192 Dict[str, Iterable][source]#\nSpecify a grid of values to search over.\nValues specified in a grid search are guaranteed to be sampled.\nIf multiple grid search variables are defined, they are combined with the\ncombinatorial product. This means every possible combination of values will\nbe sampled.\nExample\n>>> from ray import tune\n>>> param_space={\n...   \"x\": tune.grid_search([10, 20]),\n...   \"y\": tune.grid_search([\"a\", \"b\", \"c\"])\n... }\n\n\nThis will create a grid of 6 samples:\n{\"x\": 10, \"y\": \"a\"}, {\"x\": 10, \"y\": \"b\"}, etc.\nWhen specifying num_samples in the\nTuneConfig, this will specify\nthe number of random samples per grid search combination.\nFor instance, in the example above, if num_samples=4,\na total of 24 trials will be started -\n4 trials for each of the 6 grid search combinations.\n\nParameters\nvalues \u2013 An iterable whose parameters will be used for creating a trial grid.\n\n\nPublicAPI (beta): This API is in beta and may change before becoming stable.",
        "f118c1e2-1e0e-4201-a2dd-cfc22442d3d7": "metrics = None\n            all_batches = []\n            # No evaluation worker set ->\n            # Do evaluation using the local worker.Expect error due to the\n            # local worker not having an env.if self.evaluation_workers is None:\n                # If unit=episodes -> Run n times `sample()` (each sample\n                # produces exactly 1 episode).# If unit=ts -> Run 1 `sample()` b/c the\n                # `rollout_fragment_length` is exactly the desired ts.",
        "dd4e5df3-db48-482a-8e1a-218c3d243569": "Overview view#\n\nThe Overview view provides a high-level status of the Ray Cluster.\nOverview metrics\nThe Overview Metrics page provides the Cluster-level hardware utilization and autoscaling status (number of pending, active, and failed nodes).\nRecent Jobs\nThe Recent Jobs pane provides a list of recently submitted Ray Jobs.\nServe applications\nThe Serve Applications pane provides a list of recently deployed Serve applications\nEvents view\n\nThe Events view displays a list of events associated with a specific type (e.g., Autoscaler or Job) in chronological order. The same information is accessible with the ray list cluster-events (Ray state APIs) CLI commands.\nTwo types of events are available:\n\nJob: Events related to Ray Jobs API.\nAutoscaler: Events related to the Ray autoscaler.",
        "a2f847b8-3273-4e71-8138-ea9b3a2a84d6": "extend(samples)\n                split.append(split_lst)\n\n                adapt_iter = len(split) - 1\n                prefix = \"DynaTrajInner_\" + str(adapt_iter)\n                metrics = post_process_metrics(prefix, workers, metrics)\n\n                if len(split) > num_inner_steps:\n                    out = concat_samples(buf)\n                    out[\"split\"] = np.array(split)\n                    buf = []\n                    split = []\n\n                    yield out, metrics\n                    metrics = {}\n                else:\n                    inner_adaptation(workers, samples)\n\n        # Iterator for Inner Adaptation Data gathering (from pre->post\n        # adaptation).rollouts = from_actors(workers.remote_workers())\n        rollouts = rollouts.batch_across_shards()\n        rollouts = rollouts.transform(inner_adaptation_steps)\n\n        # Meta update step with outer combine loop for multiple MAML\n        # iterations.",
        "aa0f6448-6dc6-431f-bb19-09aad8b3f258": "Constructor#\n\n\n\n\n\n\nWorkerSet(*[,\u00a0env_creator,\u00a0validate_env,\u00a0...])\nSet of RolloutWorkers with n @ray.remote workers and zero or one local worker.\n\nWorkerSet.stop()\nCalls stop on all rollout workers (including the local one).\n\nWorkerSet.reset(new_remote_workers)\nHard overrides the remote workers in this set with the given one.",
        "be6e7215-c0c0-4345-8aa3-be366583349a": "Then we use the map_batches() API to apply the model to the whole dataset.\nThe first parameter of map_batches is the user-defined function (UDF), which can either be a function or a class. Since we are using a class in this case, the UDF will run as long-running Ray actors. For class-based UDFs, we use the compute argument to specify ActorPoolStrategy with the number of parallel actors.\nThe batch_size argument indicates the number of images in each batch. See the Ray dashboard\nfor GPU memory usage to experiment with the batch_size when using your own model and dataset.\nYou should aim to max out the batch size without running out of GPU memory.\nThe num_gpus argument specifies the number of GPUs needed for each ResnetModel instance. In this case, we want 1 GPU for each model replica. If you are doing CPU inference, you can remove the num_gpus=1.\n\n\npredictions = transformed_ds.map_batches(\n    ResnetModel,\n    compute=ray.data.ActorPoolStrategy(\n        size=4\n    ),  # Use 4 GPUs. Change this number based on the number of GPUs in your cluster.\n    num_gpus=1,  # Specify 1 GPU per model replica.\n    batch_size=720,  # Use the largest batch size that can fit on our GPUs\n)",
        "eaf34c6f-ed2c-4896-b9ad-9de09c3c2576": "LLMs and Gen AI#\nLarge language models (LLMs) and generative AI are rapidly changing industries, and demand compute at an astonishing pace. Ray provides a distributed compute framework for scaling these models, allowing developers to train and deploy models faster and more efficiently. With specialized libraries for data streaming, training, fine-tuning, hyperparameter tuning, and serving, Ray simplifies the process of developing and deploying large-scale AI models.\n\n\n\n\nExplore LLMs and Gen AI examples",
        "6782f293-e371-4e1d-8936-378d1e31f1b4": "types)\n                    }\n                )\n            elif pa is not None and isinstance(schema, pa.Schema):\n                from ray.data.extensions import ArrowTensorType\n\n                if any(isinstance(type_, ArrowTensorType) for type_ in schema.types):\n                    meta = pd.DataFrame(\n                        {\n                            col: pd.Series(\n                                dtype=(\n                                    dtype.to_pandas_dtype()\n                                    if not isinstance(dtype, ArrowTensorType)\n                                    else np.",
        "60a1c99f-eff6-482d-aea9-af3818f12902": "0002067089080810547\n  timestamp: 1658500339\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: 15fbf8dc\n  warmup_time: 0.005033969879150391\n  \nResult for objective_two_101e702a:\n  date: 2022-07-22_15-32-19\n  done: false\n  experiment_id: 8c013d0ff6434dfe9719fa317f95feb8\n  hostname: Kais-MacBook-Pro.local\n  iterations: 94\n  iterations_since_restore: 95\n  mean_loss: 2.86283543260466\n  neg_mean_loss: -2.86283543260466\n  node_ip: 127.0.0.1\n  pid: 47268\n  time_since_restore: 10.181840896606445\n  time_this_iter_s: 0.10625004768371582\n  time_total_s: 10.181840896606445\n  timestamp: 1658500339\n  timesteps_since_restore: 0\n  training_iteration: 95\n  trial_id: 101e702a\n  warmup_time: 0.003309965133666992\n  \nResult for objective_two_1022212a:\n  date: 2022-07-22_15-32-19\n  done: false\n  experiment_id: c3c0bdb8b68146c68f2c34e08fa2f184\n  hostname: Kais-MacBook-Pro.local\n  iterations: 94\n  iterations_since_restore: 95\n  mean_loss: 9.520519990087298\n  neg_mean_loss: -9.520519990087298\n  node_ip: 127.0.0.",
        "d1c53476-fce5-41e5-b538-af8209402b5f": "ray.rllib.policy.policy.Policy.compute_actions_from_input_dict#\n\n\nPolicy.compute_actions_from_input_dict(input_dict: Union[ray.rllib.policy.sample_batch.SampleBatch, Dict[str, Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor, dict, tuple]]], explore: Optional[bool] = None, timestep: Optional[int] = None, episodes: Optional[List[Episode]] = None, **kwargs) \u2192 Tuple[Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor], List[Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor]], Dict[str, Union[numpy.array, jnp.ndarray, tf.Tensor, torch.Tensor]]][source]#\nComputes actions from collected samples (across multiple-agents).\nTakes an input dict (usually a SampleBatch) as its main data input.\nThis allows for using this method in case a more complex input pattern\n(view requirements) is needed, for example when the Model requires the\nlast n observations, the last m actions/rewards, or a combination\nof any of these.\n\nParameters\n\ninput_dict \u2013 A SampleBatch or input dict containing the Tensors\nto compute actions. input_dict already abides to the\nPolicy\u2019s as well as the Model\u2019s view requirements and can\nthus be passed to the Model as-is.\nexplore \u2013 Whether to pick an exploitation or exploration\naction (default: None -> use self.config[\u201cexplore\u201d]).\ntimestep \u2013 The current (sampling) time step.\nepisodes \u2013 This provides access to all of the internal episodes\u2019\nstate, which may be useful for model-based or multi-agent\nalgorithms.",
        "4378e7e7-11c0-45b9-a6c4-f89464d6d316": "trial_id\n        run[\"trial_log_dir\"] = trial.local_path\n        if trial.remote_path:\n            run[\"trial_remote_log_dir\"] = trial.remote_path\n        trial_ip = trial.get_ray_actor_ip()\n        if trial_ip:\n            run[\"trial_ip\"] = trial_ip\n        return run\n\n    def log_trial_start(self, trial: \"Trial\"):\n        if trial in self._trial_to_run:\n            # Cleanup an existing run if the trial has been restarted\n            self._trial_to_run[trial].close()\n\n        trial.init_local_path()\n        self._trial_to_run[trial] = self._create_run(trial)\n\n        if trial.evaluated_params:\n            self._log_trial_hparams(trial)\n\n    def log_trial_result(self, iteration: int, trial: \"Trial\", result: Dict):\n        tmp_result = result.copy()\n\n        step = result.get(TIMESTEPS_TOTAL, None) or result[TRAINING_ITERATION]\n\n        for k in [\"config\", \"pid\", \"timestamp\", TIME_TOTAL_S, TRAINING_ITERATION]:\n            tmp_result.pop(k,",
        "c9760664-aaeb-4049-bbf3-12b265bf453d": "Raises:\n            Empty: if the queue is empty.\n        \"\"\"return self.get(block=False)\n\n[docs]    def get_nowait_batch(self, num_items: int) -> List[Any]:\n        \"\"\"Gets items from the queue and returns them in a\n        list in order.Raises:\n            Empty: if the queue does not contain the desired number of items\n        \"\"\"\n        if not isinstance(num_items, int):\n            raise TypeError(\"Argument 'num_items' must be an int\")\n        if num_items < 0:\n            raise ValueError(\"'num_items' must be nonnegative\")\n\n        return ray.get(self.actor.get_nowait_batch.remote(num_items))\n\n[docs]    def shutdown(self, force: bool = False, grace_period_s: int = 5) -> None:\n        \"\"\"Terminates the underlying QueueActor.All of the resources reserved by the queue will be released.Args:\n            force: If True, forcefully kill the actor, causing an\n                immediate failure.If False, graceful\n                actor termination will be attempted first, before falling back\n                to a forceful kill.grace_period_s: If force is False, how long in seconds to\n                wait for graceful termination before falling back to\n                forceful kill.\n        \"\"\"",
        "00a8e2b6-6611-406c-90fe-cf53495b8ae9": "ray.rllib.core.learner.learner.Learner#\n\n\nclass ray.rllib.core.learner.learner.Learner(*, module_spec: Optional[Union[ray.rllib.core.rl_module.rl_module.SingleAgentRLModuleSpec, ray.rllib.core.rl_module.marl_module.MultiAgentRLModuleSpec]] = None, module: Optional[ray.rllib.core.rl_module.rl_module.RLModule] = None, learner_group_scaling_config: Optional[ray.rllib.core.learner.scaling_config.LearnerGroupScalingConfig] = None, learner_hyperparameters: Optional[ray.rllib.core.learner.learner.LearnerHyperparameters] = None, framework_hyperparameters: Optional[ray.rllib.core.learner.learner.FrameworkHyperparameters] = None)[source]#\nBases: object\nBase class for Learners.This class will be used to train RLModules.It is responsible for defining the loss\nfunction, and updating the neural network weights that it owns.It also provides a\nway to add/remove modules to/from RLModules in a multi-agent scenario, in the\nmiddle of training (This is useful for league based training).TF and Torch specific implementation of this class fills in the framework-specific\nimplementation details for distributed training, and for computing and applying\ngradients.User should not need to sub-class this class, but instead inherit from\nthe TF or Torch specific sub-classes to implement their algorithm-specific update\nlogic.Parameters\n\nmodule_spec \u2013 The module specification for the RLModule that is being trained.If the module is a single agent module, after building the module it will\nbe converted to a multi-agent module with a default key.Can be none if the\nmodule is provided directly via the module argument.",
        "b8454a9d-8716-4bd1-b4b6-048c5bdbd263": "ret = {}\n\n            def fold_mapping(item):\n                item = tf.convert_to_tensor(item)\n                shape = tf.shape(item)\n                b_dim, t_dim = shape[0], shape[1]\n                other_dims = shape[2:]\n                return tf.reshape(\n                    item, tf.concat([[b_dim * t_dim], other_dims], axis=0)\n                )\n\n            for k, v in input_dict.items():\n                if k not in (STATE_IN, STATE_OUT):\n                    ret[k] = tree.map_structure(fold_mapping, v)\n                else:\n                    # state in already has time dimension.",
        "dc05658c-1521-4439-99c2-5e4c8a65bf9b": "if meta_provider is None:\n        meta_provider = get_image_metadata_provider()\n    return read_datasource(\n        ImageDatasource(),\n        paths=paths,\n        filesystem=filesystem,\n        parallelism=parallelism,\n        meta_provider=meta_provider,\n        ray_remote_args=ray_remote_args,\n        open_stream_args=arrow_open_file_args,\n        partition_filter=partition_filter,\n        partitioning=partitioning,\n        size=size,\n        mode=mode,\n        include_paths=include_paths,\n        ignore_missing_paths=ignore_missing_paths,\n    )",
        "7ca505ce-5071-41cb-ac7e-ed743a027da6": "Tips for fine-tuning batching parameters#\nmax_batch_size ideally should be a power of 2 (2, 4, 8, 16, \u2026) because CPUs and GPUs are both optimized for data of these shapes. Large batch sizes incur a high memory cost as well as latency penalty for the first few requests.\nbatch_wait_timeout_s should be set considering the end to end latency SLO (Service Level Objective). For example, if your latency target is 150ms, and the model takes 100ms to evaluate the batch, the batch_wait_timeout_s should be set to a value much lower than 150ms - 100ms = 50ms.\nWhen using batching in a Serve Deployment Graph, the relationship between an upstream node and a downstream node might affect the performance as well. Consider a chain of two models where first model sets max_batch_size=8 and second model sets max_batch_size=6. In this scenario, when the first model finishes a full batch of 8, the second model will finish one batch of 6 and then to fill the next batch, which will initially only be partially filled with 8 - 6 = 2 requests, incurring latency costs. The batch size of downstream models should ideally be multiples or divisors of the upstream models to ensure the batches play well together.",
        "bbea6a63-ee6b-4c6a-b0fd-88477f680906": "self.generate_text, prompt, streamer)\n        return StreamingResponse(\n            self.consume_streamer(streamer), media_type=\"text/plain\"\n        )\n\n    def generate_text(self, prompt: str, streamer: TextIteratorStreamer):\n        input_ids = self.tokenizer([prompt], return_tensors=\"pt\").input_ids\n        self.model.generate(input_ids, streamer=streamer, max_length=10000)\n\n    async def consume_streamer(self, streamer: TextIteratorStreamer):\n        while True:\n            try:\n                for token in streamer:\n                    logger.info(f'Yielding token: \"{token}\"')\n                    yield token\n                break\n            except Empty:\n                # The streamer raises an Empty exception if the next token\n                # hasn't been generated yet.`await` here to yield control\n                # back to the event loop so other coroutines can run.await asyncio.sleep(0.001)",
        "68baa808-e6c8-474d-9b86-bfa381fca8c3": "return len(self._live_trials) == self._n\n\n    def successive_halving(\n        self, metric: str, metric_op: float\n    ) -> Tuple[List[Trial], List[Trial]]:\n        if self._halves == 0 and not self.stop_last_trials:\n            return self._live_trials, []\n        assert self._halves > 0\n        self._halves -= 1\n        self._n /= self._eta\n        self._n = int(np.ceil(self._n))\n\n        self._r *= self._eta\n        self._r = int(min(self._r, self._max_t_attr - self._cumul_r))\n        self._cumul_r = self._r\n        sorted_trials = sorted(\n            self._live_trials, key=lambda t: metric_op * self._live_trials[t][metric]\n        )\n\n        good, bad = sorted_trials[-self._n :], sorted_trials[: -self._n]\n        return good, bad\n\n    def update_trial_stats(self, trial: Trial, result: Dict):\n        \"\"\"Update result for trial.Called after trial has finished\n        an iteration - will decrement iteration count.TODO(rliaw): The other alternative is to keep the trials\n        in and make sure they're not set as pending later.\"\"\"",
        "503d6cf6-c71d-4f21-98c8-21263be72118": "local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 28.091327935768636\n  neg_mean_loss: -28.091327935768636\n  node_ip: 127.0.0.1\n  pid: 45117\n  time_since_restore: 0.10419368743896484\n  time_this_iter_s: 0.10419368743896484\n  time_total_s: 0.10419368743896484\n  timestamp: 1658498851\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a0a42d1e\n  warmup_time: 0.005752086639404297\n  \nResult for objective_a0c11456:\n  date: 2022-07-22_15-07-31\n  done: false\n  experiment_id: c1cb9895c3f04e73b7cce9435cd92c68\n  hostname: Kais-MacBook-Pro.local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 5.202230381709309\n  neg_mean_loss: -5.202230381709309\n  node_ip: 127.0.0.1\n  pid: 45117\n  time_since_restore: 0.10060286521911621\n  time_this_iter_s: 0.10060286521911621\n  time_total_s: 0.10060286521911621\n  timestamp: 1658498851\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a0c11456\n  warmup_time: 0.",
        "6dbb98db-0fcf-43e8-8be7-aff80b630655": "ray.train.lightning.RayDDPStrategy.local_rank#\n\n\nproperty RayDDPStrategy.local_rank: int#",
        "305d63a4-351d-432f-b94f-a675efd5f2ab": "d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ray/anaconda3/lib/python3.9/site-packages/torch/include -isystem /home/ray/anaconda3/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /home/ray/anaconda3/lib/python3.9/site-packages/torch/include/TH -isystem /home/ray/anaconda3/lib/python3.9/site-packages/torch/include/THC -isystem /home/ray/anaconda3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /home/ray/anaconda3/lib/python3.9/site-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o \n(RayTrainWorker pid=36675, ip=10.0.13.222) [2/3] c++ -MMD -MF cpu_adam.o.",
        "071eb646-ff39-4e07-9238-528c2ac0a45f": "# For old output engine, this is Verbosity.V3_TRIAL_DETAILS\n            # Todo (krfricke): Currently uses number to pass test_configs::test_repr\n            self.verbose = get_air_verbosity(AirVerbosity.DEFAULT) or 3\n\n        # Convert Paths to strings\n        if isinstance(self.local_dir, Path):\n            self.local_dir = str(self.local_dir)\n\n        if isinstance(self.storage_path, Path):\n            self.storage_path = str(self.storage_path)\n\n        # TODO(justinvyu): [code_removal] Legacy stuff below.",
        "c821759b-b034-43b3-9546-9d69a76668b7": "Retry policy#\nWhen a task or actor is killed by the memory monitor it will be retried with exponential backoff. There is a cap on the retry delay, which is 60 seconds. If tasks are killed by the memory monitor, it retries infinitely (not respecting max_retries). If actors are killed by the memory monitor, it doesn\u2019t recreate the actor infinitely (It respects max_restarts, which is 0 by default).",
        "4d6cd175-8561-44a7-9c86-bb7c3d040251": ")\n\n    if _use_storage_context():\n        local_path, remote_path = None, None\n        sync_config = sync_config or SyncConfig()\n        # TODO(justinvyu): Fix telemetry for the new persistence.else:\n        (\n            storage_path,\n            local_path,\n            remote_path,\n            sync_config,\n        ) = _resolve_and_validate_storage_path(\n            storage_path=storage_path, local_dir=local_dir, sync_config=sync_config\n        )\n\n        air_usage.tag_ray_air_storage_config(\n            local_path=local_path, remote_path=remote_path, sync_config=sync_config\n        )\n\n    checkpoint_config = checkpoint_config or CheckpointConfig()\n\n    # For backward compatibility\n    # TODO(jungong): remove after 2.7 release.if keep_checkpoints_num is not None:\n        warnings.warn(\n            \"keep_checkpoints_num is deprecated and will be removed. \"\"use checkpoint_config.num_to_keep instead.",
        "68485db0-adbc-4f1a-b335-93e5eefcd21d": ")\n    )\n    applications: Dict[str, ApplicationDetails] = Field(\n        description=\"Details about all live applications running on the cluster.\")\n\n[docs]    @staticmethod\n    def get_empty_schema_dict() -> Dict:\n        \"\"\"Empty Serve instance details dictionary.Represents no Serve instance running on the cluster.\n        \"\"\"return {\n            \"deploy_mode\": \"UNSET\",\n            \"controller_info\": {},\n            \"http_proxies\": {},\n            \"applications\": {},\n        }\n\n    def _get_status(self) -> ServeStatus:\n        return ServeStatus(\n            proxies={\n                node_id: proxy.status for node_id, proxy in self.http_proxies.items()\n            },\n            applications={\n                app_name: ApplicationStatusOverview(\n                    status=app.status,\n                    message=app.message,\n                    last_deployed_time_s=app.last_deployed_time_s,",
        "be25ddb4-68f9-45d9-bf67-abb219346a5d": "114596            5.61385         0.00672579      5.61385  1667430183                        0                   307676d_00004   0.00323987\n\n\n\n\n2022-11-02 16:03:13,913\tINFO tune.py:788 -- Total run time: 28.53 seconds (27.28 seconds for the tuning loop).\n\n\n\n\n\nTune Status\n\n\nCurrent time:2022-11-02 16:03:22\nRunning for: 00:00:08.49        \nMemory:      9.9/16.0 GiB       \n\n\n\n\n\nSystem Info\n      Using FIFO scheduling algorithm.Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/3.44 GiB heap, 0.0/1.72 GiB objects\n    \n\n\n\nTrial Status\n\n\nTrial name                      status    loc              mean      sd  iter  total time (s)    loss",
        "124efe1e-25f8-4fe6-b781-2631442ee477": "**spec\n    ) -> bool:\n        return _set_search_properties_backwards_compatible(\n            self.searcher.set_search_properties, metric, mode, config, **spec\n        )",
        "80088cdd-4c73-48cc-af15-66a5ee768e94": "if (\n        sys.platform == \"win32\"\n        and not netloc\n        and len(parsed_path) >= 3\n        and parsed_path[0] == \"/\"  # The problematic leading slash\n        and parsed_path[1].isalpha()  # Ensure it is a drive letter.and parsed_path[2:4] in (\":\", \":/\")\n    ):\n        parsed_path = parsed_path[1:]\n\n    return netloc + parsed_path + query\n\n\ndef _wrap_s3_serialization_workaround(filesystem: \"pyarrow.fs.FileSystem\"):\n    # This is needed because pa.fs.S3FileSystem assumes pa.fs is already\n    # imported before deserialization. See #17085.\n    import pyarrow as pa\n    import pyarrow.fs\n\n    if isinstance(filesystem, pa.fs.S3FileSystem):\n        return _S3FileSystemWrapper(filesystem)\n    return filesystem\n\n\ndef _unwrap_s3_serialization_workaround(\n    filesystem: Union[\"pyarrow.fs.FileSystem\", \"_S3FileSystemWrapper\"]\n):\n    if isinstance(filesystem, _S3FileSystemWrapper):\n        return filesystem.unwrap()\n    else:\n        return filesystem",
        "13d3b6c2-00f1-46e9-ad66-8e43c684b322": "System (component) logs#\n\ndashboard.[log|err]: A log file of a Ray Dashboard..log files contain logs generated from the dashboard\u2019s logger..err files contain stdout and stderr printed from the dashboard.They are usually empty except when the dashboard crashes unexpectedly.dashboard_agent.log: Every Ray node has one dashboard agent.This is a log file of the agent.gcs_server.[out|err]: The GCS server is a stateless server that manages Ray cluster metadata.It exists only in the head node.io-worker-[worker_id]-[pid].[out|err]: Ray creates IO workers to spill/restore objects to external storage by default from Ray 1.3+.This is a log file of IO workers.log_monitor.[log|err]: The log monitor is in charge of streaming logs to the driver..log files contain logs generated from the log monitor\u2019s logger..err files contain the stdout and stderr printed from the log monitor.They are usually empty except when the log monitor crashes unexpectedly.monitor.[out|err]: Stdout and stderr of a cluster launcher.monitor.log: Ray\u2019s Cluster Launcher operates from a monitor process.It also manages the Autoscaler.plasma_store.[out|err]: Deprecated.python-core-driver-[worker_id]_[pid].log: Ray drivers consist of CPP core and a Python or Java frontend.CPP code generates this log file.python-core-worker-[worker_id]_[pid].log: Ray workers consist of CPP core and a Python or Java frontend.CPP code generates this log file.raylet.[out|err]: A log file of raylets.redis-shard_[shard_index].[out|err]: Redis shard log files.redis.[out|err]: Redis log files.runtime_env_agent.log: Every Ray node has one agent that manages Runtime Environment creation, deletion, and caching.This is the log file of the agent containing logs of create or delete requests and cache hits and misses.",
        "953e65fb-b591-4d3a-a763-19a9bf8299b2": "Note\nFrom Ray 2.6.0 onwards, RLlib is adopting a new stack for training and model customization,\ngradually replacing the ModelV2 API and some convoluted parts of Policy API with the RLModule API.\nClick here for details.",
        "13fb7afc-410c-42a7-a8ba-961f31454c08": "More XGBoost Examples#\n\nXGBoost Dynamic Resources Example:\nTrains a basic XGBoost model with Tune with the class-based API and a ResourceChangingScheduler, ensuring all resources are being used at all time.",
        "6ab04e03-4d2f-4f52-8352-47600661eb1d": "Pattern: Using resources to limit the number of concurrently running tasks#\nIn this pattern, we use resources to limit the number of concurrently running tasks.\nBy default, Ray tasks require 1 CPU each and Ray actors require 0 CPU each, so the scheduler limits task concurrency to the available CPUs and actor concurrency to infinite.\nTasks that use more than 1 CPU (e.g., via mutlithreading) may experience slowdown due to interference from concurrent ones, but otherwise are safe to run.\nHowever, tasks or actors that use more than their proportionate share of memory may overload a node and cause issues like OOM.\nIf that is the case, we can reduce the number of concurrently running tasks or actors on each node by increasing the amount of resources requested by them.\nThis works because Ray makes sure that the sum of the resource requirements of all of the concurrently running tasks and actors on a given node does not exceed the node\u2019s total resources.\n\nNote\nFor actor tasks, the number of running actors limits the number of concurrently running actor tasks we can have.",
        "66053e42-096e-44c5-beee-7555c05be403": "update_priorities_in_replay_buffer(\n                    self.local_replay_buffer,\n                    self.config,\n                    train_batch,\n                    train_results,\n                )\n\n                last_update = self._counters[LAST_TARGET_UPDATE_TS]\n                if cur_ts - last_update >= self.config.target_network_update_freq:\n                    to_update = self.workers.local_worker().get_policies_to_train()\n                    self.workers.local_worker().foreach_policy_to_train(\n                        lambda p, pid: pid in to_update and p.update_target()\n                    )\n                    self._counters[NUM_TARGET_UPDATES] += 1\n                    self._counters[LAST_TARGET_UPDATE_TS] = cur_ts\n\n                # Update weights and global_vars - after learning on the local worker -\n                # on all remote workers.",
        "1b2d035c-dc3c-4a0e-9cd7-fdaccee3bfea": "\u201cDEFAULT\u201d#\n\"DEFAULT\" is the default strategy used by Ray.\nRay schedules tasks or actors onto a group of the top k nodes.\nSpecifically, the nodes are sorted to first favor those that already have tasks or actors scheduled (for locality),\nthen to favor those that have low resource utilization (for load balancing).\nWithin the top k group, nodes are chosen randomly to further improve load-balancing and mitigate delays from cold-start in large clusters.\nImplementation-wise, Ray calculates a score for each node in a cluster based on the utilization of its logical resources.\nIf the utilization is below a threshold (controlled by the OS environment variable RAY_scheduler_spread_threshold, default is 0.5), the score is 0,\notherwise it is the resource utilization itself (score 1 means the node is fully utilized).\nRay selects the best node for scheduling by randomly picking from the top k nodes with the lowest scores.\nThe value of k is the max of (number of nodes in the cluster * RAY_scheduler_top_k_fraction environment variable) and RAY_scheduler_top_k_absolute environment variable.\nBy default, it\u2019s 20% of the total number of nodes.\nCurrently Ray handles actors that don\u2019t require any resources (i.e., num_cpus=0 with no other resources) specially by randomly choosing a node in the cluster without considering resource utilization.\nSince nodes are randomly chosen, actors that don\u2019t require any resources are effectively SPREAD across the cluster.\n@ray.remote\ndef func():\n    return 1\n\n\n@ray.remote(num_cpus=1)\nclass Actor:\n    pass\n\n\n# If unspecified, \"DEFAULT\" scheduling strategy is used.\nfunc.remote()\nactor = Actor.remote()\n# Explicitly set scheduling strategy to \"DEFAULT\".\nfunc.options(scheduling_strategy=\"DEFAULT\").remote()\nactor = Actor.options(scheduling_strategy=\"DEFAULT\").remote()\n\n# Zero-CPU (and no other resources) actors are randomly assigned to nodes.\nactor = Actor.options(num_cpus=0).remote()",
        "5b47f1f0-ff3c-49a8-817c-cd9d4b1c2fc9": "grad_clip \u2013 If specified, clip the global norm of gradients by this amount.\n\n\nReturns\nThis updated AlgorithmConfig object.",
        "0f686d05-2851-4115-8bd1-f8bfd2e0402c": "\"Checking serializability...\"\n        )\n        with printer.indent():\n            for name, obj in closure.nonlocals.items():\n                serializable, _ = _inspect_serializability(\n                    obj,\n                    name=name,\n                    depth=depth - 1,\n                    parent=parent,\n                    failure_set=failure_set,\n                    printer=printer,\n                )\n                found = found or not serializable\n                if found:\n                    break\n    if not found:\n        printer.print(\n            f\"WARNING: Did not find non-serializable object in {base_obj}. \"\"This may be an oversight.\")\n    return found\n\n\ndef _inspect_generic_serialization(base_obj, depth, parent, failure_set, printer):\n    \"\"\"Adds the first-found non-serializable element to the failure_set.\"\"\"assert not inspect.isfunction(base_obj)\n    functions = inspect.getmembers(base_obj, predicate=inspect.",
        "f933d2f2-0e97-488f-a803-4d0f650b8636": "The subclass must be serializable, since Ray Train copies it from the driver script to the driving actor of the Trainer. Ray Train calls its configure method on the main actor of the Trainer group to create the data iterators for each worker.\nIn general, you can use DataConfig for any shared setup that has to occur ahead of time before the workers start iterating over data. The setup runs at the start of each Trainer run.",
        "82c01faf-2f18-4a73-925f-d67620fb8835": "Warning\nWhen using the CLI, do not wrap the entrypoint command in quotes.  For example, use\nray job submit --working_dir=\".\" -- python script.py instead of ray job submit --working_dir=\".\" -- \"python script.py\".\nOtherwise you may encounter the error /bin/sh: 1: python script.py: not found.\n\n\nWarning\nYou must provide the entrypoint command, python script.py, last (after the --), and any other arguments to ray job submit (e.g., --working_dir=\".\") must be provided before the  two hyphens (--).\nFor example, use ray job submit --working_dir=\".\" -- python script.py instead of ray job submit -- python script.py --working_dir=\".\".\nThis syntax supports the use of -- to separate arguments to ray job submit from arguments to the entrypoint command.",
        "9a009ea6-9b20-425d-b973-05b7746ead06": "ray.rllib.core.learner.learner.LearnerSpec#\n\n\nclass ray.rllib.core.learner.learner.LearnerSpec(learner_class: Type[ray.rllib.core.learner.learner.Learner], module_spec: Optional[Union[ray.rllib.core.rl_module.rl_module.SingleAgentRLModuleSpec, ray.rllib.core.rl_module.marl_module.MultiAgentRLModuleSpec]] = None, module: Optional[ray.rllib.core.rl_module.rl_module.RLModule] = None, learner_group_scaling_config: ray.rllib.core.learner.scaling_config.LearnerGroupScalingConfig = <factory>, learner_hyperparameters: ray.rllib.core.learner.learner.LearnerHyperparameters = <factory>, framework_hyperparameters: ray.rllib.core.learner.learner.FrameworkHyperparameters = <factory>)[source]#\nBases: object\nThe spec for constructing Learner actors.\n\nParameters\n\nlearner_class \u2013 The Learner class to use.\nmodule_spec \u2013 The underlying (MA)RLModule spec to completely define the module.\nmodule \u2013 Alternatively the RLModule instance can be passed in directly. This\nonly works if the Learner is not an actor.\nbackend_config \u2013 The backend config for properly distributing the RLModule.\nlearner_hyperparameters \u2013 The extra config for the loss/additional update. This\nshould be a subclass of LearnerHyperparameters. This is useful for passing\nin algorithm configs that contains the hyper-parameters for loss\ncomputation, change of training behaviors, etc. e.g lr, entropy_coeff.\n\n\n\nMethods",
        "a68cc2a4-c831-4179-bcf2-ecbeacc712f4": "1050560474395752\n  time_this_iter_s: 0.1050560474395752\n  time_total_s: 0.1050560474395752\n  timestamp: 1658499771\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: c3762426\n  warmup_time: 0.0028579235076904297\n  \nResult for objective_c385528e:\n  date: 2022-07-22_15-22-51\n  done: false\n  experiment_id: 3044e8f1500f4b16aba04b72105c67be\n  hostname: Kais-MacBook-Pro.local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 14.516317633001044\n  neg_mean_loss: -14.516317633001044\n  node_ip: 127.0.0.1\n  pid: 46256\n  time_since_restore: 0.10402488708496094\n  time_this_iter_s: 0.10402488708496094\n  time_total_s: 0.10402488708496094\n  timestamp: 1658499771\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: c385528e\n  warmup_time: 0.0027010440826416016\n  \nResult for objective_c387a7c8:\n  date: 2022-07-22_15-22-51\n  done: false\n  experiment_id: fc7f3d46b136437cab526c2fa6ea2944\n  hostname: Kais-MacBook-Pro.local\n  iterations: 0\n  iterations_since_restore: 1\n  mean_loss: 14.",
        "9beb19a5-8931-4b30-a0cf-e51175c6c3e5": "Learner (Alpha)#\nLearner allows you to abstract the training\nlogic of RLModules. It supports both gradient-based and non-gradient-based updates (e.g.\npolyak averaging, etc.) The API enables you to distribute the Learner using data-\ndistributed parallel (DDP). The Learner achieves the following:\n\nFacilitates gradient-based updates on RLModule.\nProvides abstractions for non-gradient based updates such as polyak averaging, etc.\nReporting training statistics.\nCheckpoints the modules and optimizer states for durable training.\n\nThe Learner class supports data-distributed-\nparallel style training using the\nLearnerGroup API. Under this paradigm,\nthe LearnerGroup maintains multiple\ncopies of the same Learner with identical\nparameters and hyperparameters. Each of these\nLearner instances computes the loss and gradients on a\nshard of a sample batch and then accumulates the gradients across the\nLearner instances. Learn more about data-distributed\nparallel learning in\nthis article.\nLearnerGroup also allows for\nasynchronous training and (distributed) checkpointing for durability during training.",
        "5bf9a260-1109-4d00-ad7d-1128679e329e": "pre_backward(closure_loss)\nRun before precision plugin executes backward.\n\nprocess_dataloader(dataloader)\nWraps the dataloader if necessary.\n\nreduce(tensor[,\u00a0group,\u00a0reduce_op])\nReduces a tensor from several distributed processes to one aggregated tensor.\n\nremove_checkpoint(filepath)\nRemove checkpoint filepath from the filesystem.\n\nsave_checkpoint(checkpoint,\u00a0filepath[,\u00a0...])\nSave model/training states as a checkpoint file through state-dump and file-write.\n\nsetup_optimizers(trainer)\nCreates optimizers and schedulers.\n\nsetup_precision_plugin()\nAttaches the precision plugin to the accelerator.\n\n\n\nAttributes\n\n\n\n\n\n\nDEEPSPEED_ENV_VAR\n\n\naccelerator\n\n\ncheckpoint_io\n\n\ndeepspeed_engine\n\n\ndistributed_sampler_kwargs\n\n\nglobal_rank\n\n\nhandles_gradient_accumulation\nWhether the plugin handles gradient accumulation internally.\n\nis_distributed\n\n\nis_global_zero\nWhether the current process is the rank zero process not only on the local node, but for all nodes.\n\nlauncher\n\n\nlightning_module\nReturns the pure LightningModule without potential wrappers.\n\nlightning_restore_optimizer\nOverride to disable Lightning restoring optimizers/schedulers.\n\nlocal_rank\n\n\nmodel\nReturns the potentially wrapped LightningModule.\n\nnode_rank\n\n\nnum_nodes\n\n\nnum_processes\n\n\noptimizers\n\n\nparallel_devices\n\n\nprecision_plugin\n\n\nprocess_group_backend\n\n\nrestore_checkpoint_after_setup\nOverride to delay restoring from checkpoint till after pre-dispatch.\n\nroot_device\nReturn the root device.\n\nstrategy_name\n\n\ntorch_distributed_backend\nDeprecated property.\n\nworld_size\n\n\nzero_stage_3",
        "4c03f709-3003-4f4f-9987-8818a4a55f23": "Redirecting Ray logs to stderr#\nBy default, Ray writes logs to files under the /tmp/ray/session_*/logs directory. If you prefer to redirect logs to stderr of the host pods instead, set the environment variable RAY_LOG_TO_STDERR=1 on all Ray nodes. This practice is not recommended but may be useful if your log processing tool only captures log records written to stderr.\n\nAlert\nThere are known issues with this feature. For example, it may break features like Worker log redirection to Driver. If those features are wanted, use the Fluent Bit solution above.\nFor Clusters on VMs, do not redirect logs to stderr. Follow this guide to persist logs.\n\nRedirecting logging to stderr also prepends a ({component}) prefix, for example (raylet), to each log record messages.\n[2022-01-24 19:42:02,978 I 1829336 1829336] (gcs_server) grpc_server.cc:103: GcsServer server started, listening on port 50009.\n[2022-01-24 19:42:06,696 I 1829415 1829415] (raylet) grpc_server.cc:103: ObjectManager server started, listening on port 40545.\n2022-01-24 19:42:05,087 INFO (dashboard) dashboard.py:95 -- Setup static dir for dashboard: /mnt/data/workspace/ray/python/ray/dashboard/client/build\n2022-01-24 19:42:07,500 INFO (dashboard_agent) agent.py:105 -- Dashboard agent grpc address: 0.0.0.0:49228\n\n\nThese prefixes allow you to filter the stderr stream of logs down to the component of interest. Note that multi-line log records do not have this component marker at the beginning of each line.\nFollow the steps below to set the environment variable RAY_LOG_TO_STDERR=1 on all Ray nodes",
        "0beb6e2b-3748-4ec1-a2ad-53a6111a30de": "Optimizing transforms#",
        "9d945764-4590-4235-b622-5a23789092e9": "Args:\n            global_vars: Global variables by str key, broadcast from the\n                driver.\n        \"\"\"# Store the current global time step (sum over all policies' sample\n        # steps).# Make sure, we keep global_timestep as a Tensor for tf-eager\n        # (leads to memory leaks if not doing so).if self.framework == \"tf2\":\n            self.global_timestep.assign(global_vars[\"timestep\"])\n        else:\n            self.global_timestep = global_vars[\"timestep\"]\n        # Update our lifetime gradient update counter.num_grad_updates = global_vars.get(\"num_grad_updates\")\n        if num_grad_updates is not None:\n            self.num_grad_updates = num_grad_updates\n\n[docs]    @DeveloperAPI\n    def export_checkpoint(\n        self,\n        export_dir: str,\n        filename_prefix=DEPRECATED_VALUE,\n        *,\n        policy_state: Optional[PolicyState] = None,\n        checkpoint_format: str = \"cloudpickle\",\n    ) -> None:\n        \"\"\"Exports Policy checkpoint to a local directory and returns an AIR Checkpoint.Args:\n            export_dir: Local writable directory to store the AIR Checkpoint\n                information into.",
        "c1cc4638-cc34-4d34-a48d-a807f35e0dd0": "remote_workers = [\n            Worker.remote(self.config, {}, self.env_creator, noise_id, idx + 1)\n            for idx in range(self.config.num_rollout_workers)\n        ]\n        self.workers = WorkerSet._from_existing(\n            local_worker=None,\n            remote_workers=remote_workers,\n        )\n\n        self.episodes_so_far = 0\n        self.reward_list = []\n        self.tstart = time.time()\n\n    @override(Algorithm)\n    def get_policy(self, policy=DEFAULT_POLICY_ID):\n        if policy != DEFAULT_POLICY_ID:\n            raise ValueError(\n                \"ES has no policy '{}'!Use {} \"\n                \"instead.\".format(policy, DEFAULT_POLICY_ID)\n            )\n        return self.policy\n\n    @override(Algorithm)\n    def step(self):\n        config = self.config\n\n        theta = self.policy.get_flat_weights()\n        assert theta.dtype == np.float32\n        assert len(theta.shape) == 1\n\n        # Put the current policy weights in the object store.",
        "e8e12f7d-9db5-4933-b7da-14f60fef51e9": "Building your own ReplayBuffer#\nHere is an example of how to implement your own toy example of a ReplayBuffer class and make SimpleQ use it:\nclass LessSampledReplayBuffer(ReplayBuffer):\n    @override(ReplayBuffer)\n    def sample(\n        self, num_items: int, evict_sampled_more_then: int = 30, **kwargs\n    ) -> Optional[SampleBatchType]:\n        \"\"\"Evicts experiences that have been sampled > evict_sampled_more_then times.\"\"\"\n        idxes = [random.randint(0, len(self) - 1) for _ in range(num_items)]\n        often_sampled_idxes = list(\n            filter(lambda x: self._hit_count[x] >= evict_sampled_more_then, set(idxes))\n        )\n\n        sample = self._encode_sample(idxes)\n        self._num_timesteps_sampled += sample.count\n\n        for idx in often_sampled_idxes:\n            del self._storage[idx]\n            self._hit_count = np.append(\n                self._hit_count[:idx], self._hit_count[idx + 1 :]\n            )\n\n        return sample",
        "1baa1c67-9b96-4fc7-b0e2-6c30a47b6c4a": "Ingesting into Model Trainers#\nNow that we\u2019ve learned more about our data and we have cleaned up our dataset a bit, we now look at how we can feed this dataset into some dummy model trainers.\nFirst, let\u2019s do a full global random shuffle of the dataset to decorrelate these samples.\n\n\nds = ds.random_shuffle()\n\n\n\n\nShuffle Map: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:01<00:00,  1.34it/s]\nShuffle Reduce: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:01<00:00,  1.09it/s]\n\n\n\n\nWe define a dummy Trainer actor, where each trainer will consume a dataset shard in batches and simulate model training.\n\nNote\nIn a real training workflow, we would feed ds to Ray Train, which would do this sharding and creation of training actors for us, under the hood.\n\n\n\n@ray.remote\nclass Trainer:\n    def __init__(self, rank: int):\n        pass\n\n    def train(self, shard: ray.data.Dataset) -> int:\n        for batch in shard.iter_batches(batch_size=256):\n            pass\n        return shard.count()\n\ntrainers = [Trainer.remote(i) for i in range(4)]\ntrainers\n\n\n\n\n[Actor(Trainer, 9326d43345699213608f324003000000),\n Actor(Trainer, f0ce2ce44528fbf748c9c1a103000000),\n Actor(Trainer, 7ba39c8f82ebd78c68e92ec903000000),\n Actor(Trainer, b95fe3494b7bc2d8f42abbba03000000)]\n\n\n\n\nNext, we split the dataset into len(trainers) shards, ensuring that the shards are of equal size.",
        "07da622f-d7ee-4c67-8071-d287e50465a3": ")\n        model_filename = metadata[self.MODEL_FILENAME_KEY]\n        with self.as_directory() as checkpoint_dir:\n            model_path = os.path.join(checkpoint_dir, model_filename)\n            return keras.models.load_model(model_path)\n\n\n@PublicAPI(stability=\"beta\")\nclass LegacyTensorflowCheckpoint(Checkpoint):\n    \"\"\"A :py:class:`~ray.air.checkpoint.Checkpoint` with TensorFlow-specific\n    functionality.Create this from a generic :py:class:`~ray.air.checkpoint.Checkpoint` by calling\n    ``TensorflowCheckpoint.from_checkpoint(ckpt)``.\n    \"\"\"_SERIALIZED_ATTRS = Checkpoint._SERIALIZED_ATTRS + (\"_flavor\", \"_h5_file_path\")\n\n    class Flavor(Enum):\n        # Various flavors with which TensorflowCheckpoint is generated.# This is necessary metadata to decide how to load model from a checkpoint.MODEL_WEIGHTS = 1\n        SAVED_MODEL = 2\n        H5 = 3\n\n    def __init__(\n        self,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(*args, **kwargs)\n        self._flavor = None\n        # Will only be set when `self._flavor` is `H5`.",
        "aeacc3f8-a96f-4a73-aa0c-9d404beead0c": "mixins: To add arbitrary stateful components, you can add mixin classes to the policy. Methods defined by these mixins will have higher priority than the base policy class, so you can use these to override methods (as in the case of LearningRateSchedule), or define extra methods and attributes (e.g., KLCoeffMixin, ValueNetworkMixin). Like any other Python superclass, these should be initialized at some point, which is what the setup_mixins function does:\ndef setup_mixins(policy, obs_space, action_space, config):\n    ValueNetworkMixin.__init__(policy, obs_space, action_space, config)\n    KLCoeffMixin.__init__(policy, config)\n    LearningRateSchedule.__init__(policy, config[\"lr\"], config[\"lr_schedule\"])",
        "b8f989f8-8458-4fa9-a4c3-c5447b1a79aa": "Debugging Application Failures#\nRay distributes users\u2019 code to multiple processes across many machines. Application failures mean bugs in users\u2019 code.\nRay provides a debugging experience that\u2019s similar to debugging a single-process Python program.",
        "06c25e53-511d-46c4-9756-81b9251177a9": "ray.rllib.core.learner.learner_group.LearnerGroup.shutdown#\n\n\nLearnerGroup.shutdown()[source]#\nShuts down the LearnerGroup.",
        "65b99269-cddc-433e-96ca-df2cbbc9bd2b": "class _DeploymentHandleBase:\n    def __init__(\n        self,\n        deployment_name: str,\n        app_name: str,\n        *,\n        handle_options: Optional[_HandleOptions] = None,\n        _router: Optional[Router] = None,\n        _is_for_sync_context: bool = False,\n        _request_counter: Optional[metrics.Counter] = None,\n        _recorded_telemetry: bool = False,\n    ):\n        self.deployment_id = DeploymentID(deployment_name, app_name)\n        self.handle_options = handle_options or _HandleOptions()\n        self._is_for_sync_context = _is_for_sync_context\n        self._recorded_telemetry = _recorded_telemetry\n\n        self.request_counter = _request_counter or metrics.Counter(\n            \"serve_handle_request_counter\",\n            description=(\n                \"The number of handle.remote() calls that have been \"\n                \"made on this handle.\"",
        "d0065cb5-7bfe-43fc-8547-302056e1edc2": "self.workers.local_worker().set_weights(weights)\n\n[docs]    @PublicAPI\n    def add_policy(\n        self,\n        policy_id: PolicyID,\n        policy_cls: Optional[Type[Policy]] = None,\n        policy: Optional[Policy] = None,\n        *,\n        observation_space: Optional[gym.spaces.Space] = None,\n        action_space: Optional[gym.spaces.Space] = None,\n        config: Optional[Union[AlgorithmConfig, PartialAlgorithmConfigDict]] = None,\n        policy_state: Optional[PolicyState] = None,\n        policy_mapping_fn: Optional[Callable[[AgentID, EpisodeID], PolicyID]] = None,\n        policies_to_train: Optional[\n            Union[\n                Container[PolicyID],\n                Callable[[PolicyID, Optional[SampleBatchType]], bool],\n            ]\n        ] = None,\n        evaluation_workers: bool = True,\n        module_spec: Optional[SingleAgentRLModuleSpec] = None,\n    ) -> Optional[Policy]:\n        \"\"\"Adds a new policy to this Algorithm.Args:\n            policy_id: ID of the policy to add.",
        "8c273783-30a9-4fb6-96e3-ff9212a0d2ab": "Debugging Failures#",
        "6c417c02-80a8-4707-9a40-a6f2b094d172": "def _prepare_for_ray_worker_node_startup():\n    \"\"\"\n    If we start multiple ray workers on a machine concurrently, some ray worker\n    processes might fail due to ray port conflicts, this is because race condition\n    on getting free port and opening the free port.To address the issue, this function use an exclusive file lock to delay the\n    worker processes to ensure that port acquisition does not create a resource\n    contention issue due to a race condition.After acquiring lock, it will allocate port range for worker ports\n    (for ray node config --min-worker-port and --max-worker-port).Because on a spark cluster, multiple ray cluster might be created, so on one spark\n    worker machine, there might be multiple ray worker nodes running, these worker\n    nodes might belong to different ray cluster, and we must ensure these ray nodes on\n    the same machine using non-overlapping worker port range, to achieve this, in this\n    function, it creates a file `/tmp/ray_on_spark_worker_port_allocation.txt` file,\n    the file format is composed of multiple lines, each line contains 2 number: `pid`\n    and `port_range_slot_index`, each port range slot allocates 1000 ports, and\n    corresponding port range is:\n     - range_begin (inclusive): 20000 + port_range_slot_index * 1000\n     - range_end (exclusive): range_begin + 1000\n    In this function, it first scans `/tmp/ray_on_spark_worker_port_allocation.txt`\n    file, removing lines that containing dead process pid, then find the first unused\n    port_range_slot_index, then regenerate this file, and return the allocated port\n    range.",
        "f0589da0-864c-4eef-a96a-3721a43644c3": "ray.train.huggingface.transformers.RayTrainReportCallback.on_init_end#\n\n\nRayTrainReportCallback.on_init_end(args: transformers.training_args.TrainingArguments, state: transformers.trainer_callback.TrainerState, control: transformers.trainer_callback.TrainerControl, **kwargs)#\nEvent called at the end of the initialization of the [Trainer].",
        "ec2fc4b6-b5d6-4358-b637-41cc19ba016a": "offline_data()`\n        self.input_ = \"sampler\"\n        self.input_config = {}\n        self.actions_in_input_normalized = False\n        self.postprocess_inputs = False\n        self.shuffle_buffer_size = 0\n        self.output = None\n        self.output_config = {}\n        self.output_compress_columns = [\"obs\", \"new_obs\"]\n        self.output_max_file_size = 64 * 1024 * 1024\n        self.offline_sampling = False\n\n        # `self.evaluation()`\n        self.evaluation_interval = None\n        self.evaluation_duration = 10\n        self.evaluation_duration_unit = \"episodes\"\n        self.evaluation_sample_timeout_s = 180.0\n        self.evaluation_parallel_to_training = False\n        self.evaluation_config = None\n        self.off_policy_estimation_methods = {}\n        self.ope_split_batch_by_episode = True\n        self.evaluation_num_workers = 0\n        self.custom_evaluation_function = None\n        self.always_attach_evaluation_results = False\n        self.",
        "a999435d-9ed9-4a99-a5e1-328dd43e220b": "return self.__worker_manager.num_actors()\n\n[docs]    @DeveloperAPI\n    def num_healthy_remote_workers(self) -> int:\n        \"\"\"Returns the number of healthy workers, including local and remote workers.\"\"\"return self.__worker_manager.num_healthy_actors()\n\n[docs]    @DeveloperAPI\n    def num_healthy_workers(self) -> int:\n        \"\"\"Returns the number of healthy workers, including local and remote workers.\"\"\"return int(bool(self._local_worker)) + self.num_healthy_remote_workers()\n\n[docs]    @DeveloperAPI\n    def num_in_flight_async_reqs(self) -> int:\n        \"\"\"Returns the number of in-flight async requests.\"\"\"return self.__worker_manager.num_outstanding_async_reqs()\n\n[docs]    @DeveloperAPI\n    def num_remote_worker_restarts(self) -> int:\n        \"\"\"Total number of times managed remote workers get restarted.\"\"\"",
        "5af1f705-8da0-4ef8-9aa7-8764308e0444": "local\n  iterations: 99\n  iterations_since_restore: 100\n  mean_loss: 3.3122882595656677\n  neg_mean_loss: -3.3122882595656677\n  node_ip: 127.0.0.1\n  pid: 45869\n  time_since_restore: 10.717580080032349\n  time_this_iter_s: 0.1054232120513916\n  time_total_s: 10.717580080032349\n  timestamp: 1658499535\n  timesteps_since_restore: 0\n  training_iteration: 100\n  trial_id: 3046455a\n  warmup_time: 0.0027010440826416016\n  \n\n\n\n\nHere are the hyperparamters found to minimize the mean loss of the defined objective.\n\n\nprint(\"Best hyperparameters found were: \", results.get_best_result().config)\n\n\n\n\nBest hyperparameters found were:  {'steps': 100, 'width': 15.42641286533492, 'height': -95.8496101281197, 'activation': 'relu, tanh'}",
        "03497b95-8e2b-4f32-824b-9d99ddfb8bdb": "Args:\n            trials: List of trials for which progress should be\n                displayed\n            done: True if the trials are finished, False otherwise\n            *sys_info: System information to be displayed\n\n        Returns:\n            Progress update to be rendered in a notebook, including HTML\n                tables and formatted error messages.Includes\n                - Duration of the tune job\n                - Memory consumption\n                - Trial progress table, with information about each experiment\n        \"\"\"\n        if not self._metrics_override:\n            user_metrics = self._infer_user_metrics(trials, self._infer_limit)\n            self._metric_columns.update(user_metrics)\n\n        current_time, running_for = _get_time_str(self._start_time, time.time())\n        used_gb, total_gb, memory_message = _get_memory_usage()\n\n        status_table = tabulate(\n            [\n                (\"Current time:\", current_time),\n                (\"Running for:\", running_for),\n                (\"Memory:\",",
        "837074c8-2ef7-474e-b65c-593d011f241f": "If ``datasets`` is not specified, ``LightningTrainer`` will use datamodule\n            or dataloaders specified in ``LightningConfigBuilder.fit_params`` instead.datasets_iter_config: Configuration for iterating over the input ray datasets.You can configure the per-device batch size, prefetch batch size, collate\n            function, and more.For valid arguments to pass, please refer to:\n            :py:meth:`Dataset.iter_torch_batches\n            <ray.data.Dataset.iter_torch_batches>`\n\n            Note that if you provide a ``datasets`` parameter, you must always specify\n            ``datasets_iter_config`` for it.resume_from_checkpoint: A checkpoint to resume training from.metadata: Dict that should be made available in `checkpoint.get_metadata()`\n            for checkpoints saved from this Trainer.Must be JSON-serializable.\n    \"\"\"",
        "8b674d5a-04fb-4e1a-a835-9b1c7d1eeeee": "If this is a single string,\n            this is interpreted as a file relative to the trialdir, to which\n            both streams are written.If this is a Sequence (e.g.a Tuple),\n            it has to have length 2 and the elements indicate the files to\n            which stdout and stderr are written, respectively.\n\n    \"\"\"",
        "e75f2c58-8e39-450e-85ec-fadfc0084679": "Step 3: Install a RayJob#\n# Step 3.1: Download `ray_v1alpha1_rayjob.yaml`\ncurl -LO https://raw.githubusercontent.com/ray-project/kuberay/master/ray-operator/config/samples/ray_v1alpha1_rayjob.yaml\n\n# Step 3.2: Create a RayJob\nkubectl apply -f ray_v1alpha1_rayjob.yaml",
        "a753c124-f54a-43de-826c-cbdb1f2dc82d": ")\n\n        transform_type = self._determine_transform_to_use()\n\n        if transform_type == BatchFormat.PANDAS:\n            return self._transform_pandas(_convert_batch_type_to_pandas(data))\n        elif transform_type == BatchFormat.NUMPY:\n            return self._transform_numpy(_convert_batch_type_to_numpy(data))\n\n    @DeveloperAPI\n    def _transform_pandas(self, df: \"pd.DataFrame\") -> \"pd.DataFrame\":\n        \"\"\"Run the transformation on a data batch in a Pandas DataFrame format.\"\"\"raise NotImplementedError()\n\n    @DeveloperAPI\n    def _transform_numpy(\n        self, np_data: Union[\"np.ndarray\", Dict[str, \"np.ndarray\"]]\n    ) -> Union[\"np.ndarray\", Dict[str, \"np.ndarray\"]]:\n        \"\"\"Run the transformation on a data batch in a NumPy ndarray format.\"\"\"raise NotImplementedError()\n\n[docs]    @classmethod\n    @DeveloperAPI\n    def preferred_batch_format(cls) -> BatchFormat:\n        \"\"\"Batch format hint for upstream producers to try yielding best block format.The preferred batch format to use if both `_transform_pandas` and\n        `_transform_numpy` are implemented.Defaults to Pandas.Can be overriden by Preprocessor classes depending on which transform\n        path is the most optimal.\n        \"\"\"",
        "2cfa670b-f942-4122-bd68-ad119f471d4e": "Describing datasets#\nDatasets are tabular. To view a dataset\u2019s column names and\ntypes, call Dataset.schema().\nimport ray\n\nds = ray.data.read_csv(\"s3://anonymous@air-example-data/iris.csv\")\n\nprint(ds.schema())\n\n\nColumn             Type\n------             ----\nsepal length (cm)  double\nsepal width (cm)   double\npetal length (cm)  double\npetal width (cm)   double\ntarget             int64\n\n\nFor more information like the number of rows, print the Dataset.\nimport ray\n\nds = ray.data.read_csv(\"s3://anonymous@air-example-data/iris.csv\")\n\nprint(ds)\n\n\nDataset(\n   num_blocks=...,\n   num_rows=150,\n   schema={\n      sepal length (cm): double,\n      sepal width (cm): double,\n      petal length (cm): double,\n      petal width (cm): double,\n      target: int64\n   }\n)",
        "84bbb3e7-271a-4659-9a22-afc4bc490a8c": "249)  [repeated 649x across cluster]\nDownloading (\u2026)l-00002-of-00003.bin:  18%|\u2588\u258a        | 1.75G/9.90G [00:07<00:34, 234MB/s] [repeated 643x across cluster]\n(RayTrainWorker pid=74502, ip=10.0.60.86)  [repeated 645x across cluster]\nDownloading (\u2026)l-00002-of-00003.bin:  41%|\u2588\u2588\u2588\u2588\u258f     | 4.09G/9.90G [00:15<00:21, 271MB/s] [repeated 644x across cluster]\n(RayTrainWorker pid=74273, ip=10.0.54.55)  [repeated 652x across cluster]\nDownloading (\u2026)l-00002-of-00003.bin:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 5.25G/9.90G [00:21<00:19, 242MB/s] [repeated 656x across cluster]\n(RayTrainWorker pid=74152, ip=10.0.63.141)  [repeated 647x across cluster]\nDownloading (\u2026)l-00002-of-00003.bin:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 6.66G/9.90G [00:25<00:13, 246MB/s] [repeated 646x across cluster]\n(RayTrainWorker pid=75132, ip=10.0.20.140)  [repeated 629x across cluster]\nDownloading (\u2026)l-00002-of-00003.bin:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 8.30G/9.90G [00:31<00:06,",
        "9743b2c4-55ec-43bf-9224-3c5db03544c4": "Twin Delayed DDPG (TD3)#\n \n[paper]\n[implementation]\nTD3 represents an improvement over DDPG. Its implementation is available in RLlib as TD3.\nTuned examples: TD3 Pendulum-v1, TD3 InvertedPendulum-v2, TD3 Mujoco suite (Ant-v2, HalfCheetah-v2, Hopper-v2, Walker2d-v2).\nTD3-specific configs (see also common configs):\n\n\nclass ray.rllib.algorithms.td3.td3.TD3Config(algo_class=None)[source]#\nDefines a configuration class from which a TD3 Algorithm can be built.\nExample\n>>> from ray.rllib.algorithms.td3 import TD3Config\n>>> config = TD3Config().training(lr=0.01).resources(num_gpus=1)\n>>> print(config.to_dict())  \n>>> # Build a Algorithm object from the config and run one training iteration.\n>>> algo = config.build(env=\"Pendulum-v1\")  \n>>> algo.train()",
        "b3e61b9d-7379-473e-9a48-54d0bb5c44c3": "(XGBoostTrainer pid=40725) Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n\n\n\n(pid=40725) Running: 0.0/10.0 CPU, 0.0/0.0 GPU, 0.0 MiB/512.0 MiB object_store_memory:   0%|          | 0/14 [00:01<?, ?it/s]\n                                                              \n\n                                                                       \n\n\n(XGBoostTrainer pid=40725) Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`",
        "2c72cd4e-78cd-4f86-a247-a3c854e450d4": "7\nflax==0.6.10\nflit_core @ file:///opt/conda/conda-bld/flit-core_1644941570762/work/source/flit_core\nfonttools==4.40.0\nfqdn==1.5.1\nfreezegun==1.1.0\nfrozenlist==1.3.3\nfsspec==2023.1.0\nfuture==0.18.3\ngast==0.4.0\ngin-config==0.5.0\ngitdb==4.0.10\nGitPython==3.1.31\nglfw==2.5.9\ngoogle-api-core==2.11.1\ngoogle-api-python-client==1.7.8\ngoogle-auth==2.20.0\ngoogle-auth-httplib2==0.1.0\ngoogle-auth-oauthlib==0.4.6\ngoogle-oauth==1.0.1\ngoogle-pasta==0.2.0\ngoogleapis-common-protos==1.59.1\ngpustat==1.1\nGPy==1.10.0\ngpytorch==1.10\ngraphviz==0.8.4\ngreenlet==2.0.2\ngrpcio==1.50.0\ngunicorn==20.1.0\ngymnasium==0.28.1\ngymnasium-notices==0.0.1\nh11==0.14.0\nh5py==3.7.0\nHEBO==0.3.2\nhigher==0.2.1\nhjson==3.1.0\nhpbandster==0.7.4\nhttplib2==0.22.0\nhuggingface-hub==0.15.1\nhumanfriendly==10.0\nhyperopt==0.2.",
        "01ead025-0aee-4fbf-b557-37c841d065ab": "def _configure_placement_group_based_on_context(\n    placement_group_capture_child_tasks: bool,\n    bundle_index: int,\n    resources: Dict,\n    placement_resources: Dict,\n    task_or_actor_repr: str,\n    placement_group: Union[PlacementGroup, str, None] = \"default\",\n) -> PlacementGroup:\n    \"\"\"Configure the placement group based on the given context.Based on the given context, this API returns the placement group instance\n    for task/actor scheduling.Params:\n        placement_group_capture_child_tasks: Whether or not the\n            placement group needs to be captured from the global\n            context.bundle_index: The bundle index for tasks/actor scheduling.resources: The scheduling resources.placement_resources: The scheduling placement resources for\n            actors.task_or_actor_repr: The repr of task or actor\n            function/class descriptor.placement_group: The placement group instance.- \"default\": Default placement group argument.Currently,\n                the default behavior is to capture the parent task'\n                placement group if placement_group_capture_child_tasks\n                is set.- None: means placement group is explicitly not configured.- Placement group instance: In this case, do nothing.Returns:\n        Placement group instance based on the given context.",
        "4532859a-9ee1-4036-bc6e-6489a021981d": "Running Tune experiments with Optuna#\nIn this tutorial we introduce Optuna, while running a simple Ray Tune experiment. Tune\u2019s Search Algorithms integrate with Optuna and, as a result, allow you to seamlessly scale up a Optuna optimization process - without sacrificing performance.\nSimilar to Ray Tune, Optuna is an automatic hyperparameter optimization software framework, particularly designed for machine learning. It features an imperative (\u201chow\u201d over \u201cwhat\u201d emphasis), define-by-run style user API. With Optuna, a user has the ability to dynamically construct the search spaces for the hyperparameters. Optuna falls in the domain of \u201cderivative-free optimization\u201d and \u201cblack-box optimization\u201d.\nIn this example we minimize a simple objective to briefly demonstrate the usage of Optuna with Ray Tune via OptunaSearch, including examples of conditional search spaces (string together relationships between hyperparameters), and the multi-objective problem (measure trade-offs among all important metrics). It\u2019s useful to keep in mind that despite the emphasis on machine learning experiments, Ray Tune optimizes any implicit or explicit objective. Here we assume optuna==2.9.1 library is installed. To learn more, please refer to Optuna website.\nPlease note that sophisticated schedulers, such as AsyncHyperBandScheduler, may not work correctly with multi-objective optimization, since they typically expect a scalar score to compare fitness among trials.\nClick below to see all the imports we need for this example.\nYou can also launch directly into a Binder instance to run this notebook yourself.\nJust click on the rocket symbol at the top of the navigation.\n\n\nimport time\nfrom typing import Dict, Optional, Any\n\nimport ray\nfrom ray import train, tune\nfrom ray.tune.search import ConcurrencyLimiter\nfrom ray.tune.search.optuna import OptunaSearch",
        "2c408f99-565c-48da-8cb6-3224c3bb311a": ")\n                if any(not subcolumns for subcolumns in feature_columns):\n                    raise ValueError(\"column list may not be empty\")\n\n        def make_generator():\n            for batch in self.iter_batches(\n                batch_size=batch_size,\n                batch_format=\"pandas\",\n                prefetch_blocks=prefetch_blocks,\n                prefetch_batches=prefetch_batches,\n                drop_last=drop_last,\n                local_shuffle_buffer_size=local_shuffle_buffer_size,\n                local_shuffle_seed=local_shuffle_seed,\n            ):\n                if label_column:\n                    label_tensor = convert_pandas_to_torch_tensor(\n                        batch,\n                        [label_column],\n                        label_column_dtype,",
        "c5281756-155b-447d-ade0-2d0744d3bc56": "ray.job_submission.JobType#\n\n\nclass ray.job_submission.JobType(value)[source]#\nBases: str, enum.Enum\nAn enumeration for describing the different job types.\n\nNote\nThis field is still experimental and may change in the future.\n\nPublicAPI (beta): This API is in beta and may change before becoming stable.\nAttributes\n\n\n\n\n\n\nSUBMISSION\nA job that was initiated by the Ray Jobs API.\n\nDRIVER\nA job that was initiated by a driver script.",
        "2729b911-fa6a-4eb5-9364-7f84caf2d161": "for key, value in extra_outs.items():\n            self._dummy_batch[key] = value\n            if key not in self.view_requirements:\n                if isinstance(value, (dict, np.ndarray)):\n                    # the assumption is that value is a nested_dict of np.arrays leaves\n                    space = get_gym_space_from_struct_of_tensors(value)\n                    self.view_requirements[key] = ViewRequirement(\n                        space=space, used_for_compute_actions=False\n                    )\n                else:\n                    raise ValueError(\n                        \"policy.compute_actions_from_input_dict() returns an \"\n                        \"extra action output that is neither a numpy array nor a dict.\"",
        "399e256c-302a-48c6-b6a6-60066f1a69bd": "try:\n            trainable._resources = pgf\n        except AttributeError as e:\n            raise RuntimeError(\n                \"Could not use `tune.with_resources()` on the supplied trainable. \"\"Wrap your trainable in a regular function before passing it \"\n                \"to Ray Tune.\") from e\n    else:\n\n        class ResourceTrainable(trainable):\n            @classmethod\n            def default_resource_request(\n                cls, config: Dict[str, Any]\n            ) -> Optional[PlacementGroupFactory]:\n                if not isinstance(pgf, PlacementGroupFactory) and callable(pgf):\n                    return pgf(config)\n                return pgf\n\n        ResourceTrainable.__name__ = trainable.__name__\n        trainable = ResourceTrainable\n\n    return trainable",
        "67cdca13-c938-485c-925b-18afcd99ba94": "Downloading tokenizer.model: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500k/500k [00:00<00:00, 18.2MB/s]\nDownloading (\u2026)cial_tokens_map.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 435/435 [00:00<00:00, 6.49MB/s]\nDownloading (\u2026)lve/main/config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]\nDownloading (\u2026)lve/main/config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 585/585 [00:00<00:00, 7.81MB/s]\nDownloading (\u2026)lve/main/config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 585/585 [00:00<00:00, 7.09MB/s]\nDownloading (\u2026)model.bin.index.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33.4k/33.4k [00:00<00:00, 35.1MB/s]\nDownloading shards:   0%|          | 0/3 [00:00<?, ?it/s]\n(RayTrainWorker pid=75547, ip=10.0.42.158) \nDownloading (\u2026)l-00001-of-00003.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]\nDownloading (\u2026)l-00001-of-00003.bin:   0%|          | 21.0M/9.95G [00:00<00:59, 167MB/s]\nDownloading (\u2026)l-00001-of-00003.bin:   0%|          | 41.",
        "f3722c85-dcc5-4ab9-9577-ca5d3e50aa45": "ray.tune.search.dragonfly.DragonflySearch.restore_from_dir#\n\n\nDragonflySearch.restore_from_dir(checkpoint_dir: str)#\nRestores the state of a searcher from a given checkpoint_dir.\nTypically, you should use this function to restore from an\nexperiment directory such as /ray_results/trainable.\ntuner = tune.Tuner(\n    cost,\n    run_config=train.RunConfig(\n        name=self.experiment_name,\n        local_dir=\"~/my_results\",\n    ),\n    tune_config=tune.TuneConfig(\n        search_alg=search_alg,\n        num_samples=5\n    ),\n    param_space=config\n)\ntuner.fit()\n\nsearch_alg2 = Searcher()\nsearch_alg2.restore_from_dir(\n    os.path.join(\"~/my_results\", self.experiment_name)",
        "d65a5857-bcb7-4a74-9d86-c99e8dca3efa": "ray.train.lightning.RayDeepSpeedStrategy.restore_checkpoint_after_setup#\n\n\nproperty RayDeepSpeedStrategy.restore_checkpoint_after_setup: bool#\nOverride to delay restoring from checkpoint till after pre-dispatch. This is useful when the plugin\nrequires all the setup hooks to run before loading checkpoint.\n\nReturns\nIf true, restore checkpoint after pre_dispatch.",
        "b322a600-6128-40a5-b4e5-d69fda25a259": "Running on a Cluster#\nThe Ray debugger supports setting breakpoints inside of tasks and actors that are running across your\nRay cluster. In order to attach to these from the head node of the cluster using ray debug, you\u2019ll\nneed to make sure to pass in the --ray-debugger-external flag to ray start when starting the\ncluster (likely in your cluster.yaml file or k8s Ray cluster spec).\nNote that this flag will cause the workers to listen for PDB commands on an external-facing IP address,\nso this should only be used if your cluster is behind a firewall.",
        "a0cda8d3-d796-489a-af97-5a8cf35e2ada": "[docs]@PublicAPI\nclass D4RLReader(InputReader):\n    \"\"\"Reader object that loads the dataset from the D4RL dataset.\"\"\"\n\n[docs]    @PublicAPI\n    def __init__(self, inputs: str, ioctx: IOContext = None):\n        \"\"\"Initializes a D4RLReader instance.\n\n        Args:\n            inputs: String corresponding to the D4RL environment name.\n            ioctx: Current IO context object.\n        \"\"\"\n        import d4rl\n\n        self.env = gym.make(inputs)\n        self.dataset = _convert_to_batch(d4rl.qlearning_dataset(self.env))\n        assert self.dataset.count >= 1\n        self.counter = 0\n\n    @override(InputReader)\n    def next(self) -> SampleBatchType:\n        if self.counter >= self.dataset.count:\n            self.counter = 0\n\n        self.counter += 1\n        return self.dataset.slice(start=self.counter, end=self.counter + 1)",
        "0a9b4c55-dcb7-4ad5-8a97-eacf615c145d": "saved_model, _ = _load_checkpoint_dict(self, \"TorchTrainer\")\n\n        if isinstance(saved_model, torch.nn.Module):\n            if model:\n                warnings.warn(\n                    \"TorchCheckpoint already contains all information needed. \"\"Discarding provided `model` argument.This means \"\n                    \"If you are using TorchPredictor directly, you should do \"\n                    \"`TorchPredictor.from_checkpoint(checkpoint)` by removing kwargs \"\n                    \"`model=`.\")\n        model = load_torch_model(saved_model=saved_model, model_definition=model)\n        return model",
        "5285b0f4-7aaf-455b-be91-948f82435f1e": "766667  |                   1  |\n  | LightningTrainer_9532b_00008 | TERMINATED |  10.0.37.7:491159 |            32  |            64  | 0.000489046 | 0.27384  |       0.966667  |                   2  |\n  | LightningTrainer_9532b_00009 | TERMINATED |  10.0.37.7:491494 |            64  |            256 | 0.000395127 | 0.09642  |       0.933333  |                   4  |\n  +------------------------------+------------+-------------------+----------------+----------------+-------------+----------+-----------------+----------------------+\n\n\nAs you can see in the training_iteration column, trials with a high loss\n(and low accuracy) have been terminated early. The best performing trial used\nlayer_1_size=32, layer_2_size=64, and lr=0.000489046.",
        "adda5fd4-8704-488f-b994-58f1f97fdfd7": "Converting to a Ray Serve Deployment#\nThrough Ray Serve, the core computing logic of Strategy can be deployed as a scalable distributed computing service.\nFirst, we can extract the indicator calculation of each institution into a separate StrategyOnRayServe class:\npublic class StrategyOnRayServe {\n\n  public String calcIndicator(Long time, String bank, String indicator) {\n    // do bank data calculation\n    return bank + \"-\" + indicator + \"-\" + time; // Demo;\n  }\n}\n\n\nNext, we start the Ray Serve runtime and deploy StrategyOnRayServe as a deployment.\n  public void deploy() {\n    Serve.start(true, false, null);\n\n    Deployment deployment =\n        Serve.deployment()\n            .setName(\"strategy\")\n            .setDeploymentDef(StrategyOnRayServe.class.getName())\n            .setNumReplicas(4)\n            .create();\n    deployment.deploy(true);\n  }\n\n\nThe Deployment.create makes a Deployment object named \u201cstrategy.\u201d After executing Deployment.deploy, this \u201cstrategy\u201d deployment is deployed in the instance of Ray Serve with four replicas, and we can access it for distributed parallel computing.",
        "c9e7afa3-3c50-44e4-ba80-33f3ff0e80ff": "Start Amazon EKS Cluster with GPUs for KubeRay#\nThis guide walks you through the steps to create an Amazon EKS cluster with GPU nodes specifically for KubeRay.\nThe configuration outlined here can be applied to most KubeRay examples found in the documentation.",
        "33c7b41f-0599-4289-9c03-88ae2e746ce5": "ray.data.preprocessors.Normalizer.preferred_batch_format#\n\n\nclassmethod Normalizer.preferred_batch_format() \u2192 ray.air.util.data_batch_conversion.BatchFormat#\nBatch format hint for upstream producers to try yielding best block format.\nThe preferred batch format to use if both _transform_pandas and\n_transform_numpy are implemented. Defaults to Pandas.\nCan be overriden by Preprocessor classes depending on which transform\npath is the most optimal.\nDeveloperAPI: This API may change across minor Ray releases.",
        "04b28d04-2ef0-4df3-8f7d-1040b15e6320": "initial_num_blocks() == 0:\n                return blocks, stage_info\n\n            num_mappers = blocks.initial_num_blocks()\n            num_reducers = num_mappers\n            if self._key is None:\n                num_reducers = 1\n                boundaries = []\n            else:\n                boundaries = sort.sample_boundaries(\n                    blocks.get_blocks(),\n                    SortKey(self._key),\n                    num_reducers,\n                    task_ctx,\n                )\n            ctx = DataContext.get_current()\n            if ctx.use_push_based_shuffle:\n                shuffle_op_cls = PushBasedGroupbyOp\n            else:\n                shuffle_op_cls = SimpleShuffleGroupbyOp\n            shuffle_op = shuffle_op_cls(\n                map_args=[boundaries,",
        "e330f48a-8a68-4468-9580-568478f38381": "Upscaling and downscaling speed#\nIf needed, you can also control the rate at which nodes should be added to or removed from the cluster. For applications with many short-lived tasks, you may wish to adjust the upscaling and downscaling speed to be more conservative.\nUse the RayCluster CR\u2019s autoscalerOptions field to do so. The autoscalerOptions field\ncarries the following subfields:\nupscalingMode: This controls the rate of Ray pod upscaling. The valid values are:\n\nConservative: Upscaling is rate-limited; the number of pending worker pods is at most the number\nof worker pods connected to the Ray cluster.\nDefault: Upscaling is not rate-limited.\nAggressive: An alias for Default; upscaling is not rate-limited.\n\nidleTimeoutSeconds (default 60s): This is the number of seconds to wait before scaling down an idle worker pod. Worker nodes are considered idle when they hold no active tasks, actors, or referenced objects (either in-memory or spilled to disk).",
        "d95179b5-5541-4a25-a927-abeb77fa438d": "head_setup_commands: []\n\n# Custom commands that will be run on worker nodes after common setup.worker_setup_commands: []\n\n# Command to start ray on the head node.You don't need to change this.head_start_ray_commands:\n    - ray stop\n    - ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml --dashboard-host=0.0.0.0\n\n# Command to start ray on worker nodes.You don't need to change this.worker_start_ray_commands:\n    - ray stop\n    - ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076\n\n\n\n\n\nAzure\n# An unique identifier for the head node and workers of this cluster.cluster_name: default\n\n# The maximum number of workers nodes to launch in addition to the head\n# node.max_workers: 2\n\n# The autoscaler will scale up the cluster faster with higher upscaling speed.# E.g., if the task requires adding more nodes then autoscaler will gradually\n# scale up the cluster in chunks of upscaling_speed*currently_running_nodes.# This number should be > 0.\nupscaling_speed: 1.0\n\n# This executes all commands on all nodes in the docker container,\n# and opens all the necessary ports to support the Ray cluster.# Empty object means disabled.docker:\n    image: \"rayproject/ray-ml:latest-gpu\" # You can change this to latest-cpu if you don't need GPU support and want a faster startup\n    # image: rayproject/ray:latest-gpu   # use this one if you don't need ML dependencies, it's faster to pull\n    container_name: \"ray_container\"\n    # If true, pulls latest version of image.Otherwise, `docker run` will only pull the image\n    # if no cached version is present.",
        "344fbbec-6698-4ec3-a8aa-a40d8d4bc0b8": "Exporting metrics into Arize#\nBesides using Prometheus to check out Ray metrics, Ray Serve also has the flexibility to export the metrics into other observability platforms.\nArize is a machine learning observability platform which can help you to monitor real-time model performance, root cause model failures/performance degradation using explainability & slice analysis and surface drift, data quality, data consistency issues etc.\nTo integrate with Arize, add Arize client code directly into your Serve deployment code. (Example code)",
        "9d5ff691-d7e0-403a-96c8-cedbabbc7c7f": "self.evaluation_workers.foreach_worker_async(\n                func=remote_fn,\n                healthy_only=True,\n            )\n            eval_results = self.evaluation_workers.fetch_ready_async_reqs()\n\n            batches = []\n            i = 0\n            for _, result in eval_results:\n                batch, metrics, seq_no = result\n                # Ignore results, if the weights seq-number does not match (is\n                # from a previous evaluation step) OR if we have already reached\n                # the configured duration (e.g.number of episodes to evaluate\n                # for).",
        "762bddd5-2df6-40b4-b144-d9c159f311ae": "Stack trace and CPU profiling#\npy-spy is a sampling profiler for Python programs. It lets you visualize what your Python program is spending time on without restarting the program or modifying the code in any way. This section describes how to configure RayCluster YAML file to enable py-spy and see Stack Trace and CPU Flame Graph via Ray Dashboard.",
        "e5256a6f-a206-4ed1-9ea7-29e9988cdbb3": "scrubbed = [b for b in hyperband if b is not None]\n            for bracket in sorted(scrubbed, key=lambda b: b.completion_percentage()):\n                for trial in bracket.current_trials():\n                    if (\n                        trial.status == Trial.PAUSED\n                        and trial in bracket.trials_to_unpause\n                    ) or trial.status == Trial.PENDING:\n                        return trial\n        return None\n\n[docs]    def debug_string(self) -> str:\n        \"\"\"This provides a progress notification for the algorithm.For each bracket, the algorithm will output a string as follows:\n\n            Bracket(Max Size (n)=5, Milestone (r)=33, completed=14.6%):\n            {PENDING: 2, RUNNING: 3, TERMINATED: 2}\n\n        \"Max Size\" indicates the max number of pending/running experiments\n        set according to the Hyperband algorithm.\"Milestone\" indicates the iterations a trial will run for before\n        the next halving will occur.\"Completed\" indicates an approximate progress metric.Some brackets,\n        like ones that are unfilled, will not reach 100%.\n        \"\"\"",
        "f81046d3-d29a-40fe-b949-00b516ac7a17": "observation_space=env.observation_space,\n                action_space=env.action_space,\n                model_config_dict = {\"hidden\": [128, 128]},\n                catalog_class = PPOCatalog,\n            )\n\n            class CustomPPOLearner(PPOTorchLearner):\n                def additional_update_for_module(\n                    self, *, module_id, hps, timestep, sampled_kl_values\n                ):\n\n                    results = super().additional_update_for_module(\n                        module_id=module_id,\n                        hps=hps,\n                        timestep=timestep,\n                        sampled_kl_values=sampled_kl_values,\n                    )\n\n                    # Try something else than the PPO paper here.",
        "c2e3a9bd-22e7-4d1d-8d80-fa673f196ef3": ")\n\n    def _block_num_rows(self) -> List[int]:\n        get_num_rows = cached_remote_fn(_get_num_rows)\n        return ray.get([get_num_rows.remote(b) for b in self.get_internal_block_refs()])\n\n    def _block_size_bytes(self) -> List[int]:\n        get_size_bytes = cached_remote_fn(_get_size_bytes)\n        return ray.get(\n            [get_size_bytes.remote(b) for b in self.get_internal_block_refs()]\n        )\n\n    def _meta_count(self) -> Optional[int]:\n        return self._plan.meta_count()\n\n    def _get_uuid(self) -> str:\n        return self._uuid\n\n    def _set_uuid(self, uuid: str) -> None:\n        self._uuid = uuid\n\n    def _get_epoch(self) -> int:\n        return self._epoch\n\n    def _set_epoch(self, epoch: int) -> None:\n        self._epoch = epoch\n\n    def _synchronize_progress_bar(self):\n        \"\"\"Flush progress bar output by shutting down the current executor.This should be called at the end of all blocking APIs (e.g., `take`), but not\n        async APIs (e.g., `iter_batches`).The streaming executor runs in a separate generator / thread, so it is\n        possible the shutdown logic runs even after a call to retrieve rows from the\n        stream has finished.",
        "3de4bc8e-231d-49f1-9924-2022e99bb562": "(TrainTrainable pid=8839, ip=10.0.60.59)                         Read how to opt-out here:                         \n(TrainTrainable pid=8839, ip=10.0.60.59)     https://aimstack.readthedocs.io/en/latest/community/telemetry.html    \n(TrainTrainable pid=8839, ip=10.0.60.59) --------------------------------------------------------------------------\n(TrainTrainable pid=8839, ip=10.0.60.59) comet_ml is installed but `COMET_API_KEY` is not set.",
        "e1afa308-7a6f-4dae-ab04-05c4f3b8b6da": "else:\n                    single_agent_spec = (\n                        single_agent_rl_module_spec or default_rl_module_spec\n                    )\n                    module_specs = {\n                        k: copy.deepcopy(\n                            current_rl_module_spec.module_specs.get(\n                                k, single_agent_spec\n                            )\n                        )\n                        for k in policy_dict.keys()\n                    }\n\n                # Now construct the proper MultiAgentRLModuleSpec.# We need to infer the multi-agent class from `current_rl_module_spec`\n                # and fill in the module_specs dict.",
        "a4ac8abb-146c-45f7-bc64-440f5d0ec9e8": "For multiple metric evaluation, this needs to be a string denoting\nthe scorer that would be used to find the best parameters for\nrefitting the estimator at the end.The refitted estimator is made available at the best_estimator_\nattribute and permits using predict directly on this\nGridSearchCV instance.Also for multiple metric evaluation, the attributes\nbest_index_, best_score_ and best_params_ will only be\navailable if refit is set and all of them will be determined\nw.r.t this specific scorer.If refit not needed, set to False.See scoring parameter to know more about multiple metric\nevaluation.Defaults to True.cv (int, cross-validation generator or iterable) \u2013 Determines\nthe cross-validation splitting strategy.Possible inputs for cv are:\n\nNone, to use the default 5-fold cross validation,\ninteger, to specify the number of folds in a (Stratified)KFold,\nAn iterable yielding (train, test) splits as arrays of indices.For integer/None inputs, if the estimator is a classifier and y\nis either binary or multiclass, StratifiedKFold is used.In all other cases, KFold is used.Defaults to None.verbose (int) \u2013 Controls the verbosity: 0 = silent, 1 = only status\nupdates, 2 = status and trial results.Defaults to 0.\nrandom_state (int or RandomState) \u2013 Pseudo random number generator\nstate used for random uniform\nsampling from lists of possible values instead of scipy.stats\ndistributions.If int, random_state is the seed used by the random number\ngenerator;\nIf RandomState instance, a seed is sampled from random_state;\nIf None, the random number generator is the RandomState instance\nused by np.random and no seed is provided.Defaults to None.Ignored when using BOHB.error_score ('raise' or int or float) \u2013 Value to assign to the score if\nan error occurs in estimator\nfitting.If set to \u2018raise\u2019, the error is raised.If a numeric value\nis given, FitFailedWarning is raised.",
        "0deaa77a-4f1e-4e49-8d6d-27b550120357": "Calling the actor#\nWe can interact with the actor by calling its methods with the remote\noperator. We can then call get on the object ref to retrieve the actual\nvalue.\n\n\n\nPython\n# Call the actor.\nobj_ref = counter.increment.remote()\nprint(ray.get(obj_ref))\n\n\n1\n\n\n\n\n\nJava\n// Call the actor.\nObjectRef<Integer> objectRef = counter.task(&Counter::increment).remote();\nAssert.assertTrue(objectRef.get() == 1);\n\n\n\n\n\nC++\n// Call the actor.\nauto object_ref = counter.Task(&Counter::increment).Remote();\nassert(*object_ref.Get() == 1);\n\n\n\n\nMethods called on different actors can execute in parallel, and methods called on the same actor are executed serially in the order that they are called. Methods on the same actor will share state with one another, as shown below.\n\n\n\nPython\n# Create ten Counter actors.\ncounters = [Counter.remote() for _ in range(10)]\n\n# Increment each Counter once and get the results. These tasks all happen in\n# parallel.\nresults = ray.get([c.increment.remote() for c in counters])\nprint(results)\n\n# Increment the first Counter five times. These tasks are executed serially\n# and share state.\nresults = ray.get([counters[0].increment.remote() for _ in range(5)])\nprint(results)\n\n\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n[2, 3, 4, 5, 6]",
        "5f7f3b8f-ac79-460c-aa7b-618451f14841": "For GCP, you can do so by:\n#   (Method 1) Copy the connection command from the GKE console\n#   (Method 2) \"gcloud container clusters get-credentials <your-cluster-name> --region <your-region> --project <your-project>\"\n#   (Method 3) \"kubectl config use-context ...\"\n\n# Install both CRDs and KubeRay operator v0.6.0.helm repo add kuberay https://ray-project.github.io/kuberay-helm/\nhelm install kuberay-operator kuberay/kuberay-operator --version 0.6.0\n\n# Create a Ray cluster\nkubectl apply -f https://raw.githubusercontent.com/ray-project/ray/master/doc/source/cluster/kubernetes/configs/ray-cluster.gpu.yaml\n\n# Set up port-forwarding\nkubectl port-forward --address 0.0.0.0 services/raycluster-head-svc 8265:8265\n\n# Step 3: Run the PyTorch image training benchmark.# Install Ray if needed\npip3 install -U \"ray[default]\"\n\n# Download the Python script\ncurl https://raw.githubusercontent.com/ray-project/ray/master/doc/source/cluster/doc_code/pytorch_training_e2e_submit.py -o pytorch_training_e2e_submit.py\n\n# Submit the training job to your ray cluster\npython3 pytorch_training_e2e_submit.py\n\n# Use the following command to follow this Job's logs:\n# Substitute the Ray Job's submission id.ray job logs 'raysubmit_xxxxxxxxxxxxxxxx' --address http://127.0.0.1:8265 --follow\n\n\nIn the rest of this document, we present a more detailed breakdown of the above workflow.",
        "c91c1659-2c98-4290-bbab-c60757d95fa2": ") -> Tuple[dict, int]:\n        \"\"\"Sample and batch and learn on it.This is typically used in combination with distributed allreduce.Args:\n            expected_batch_size: Expected number of samples to learn on.num_sgd_iter: Number of SGD iterations.sgd_minibatch_size: SGD minibatch size.standardize_fields: List of sample fields to normalize.Returns:\n            A tuple consisting of a dictionary of extra metadata returned from\n                the policies' `learn_on_batch()` and the number of samples\n                learned on.\n        \"\"\"",
        "2632bb66-57ed-44f7-aaf9-1cda3aa5b5d8": "ray.tune.schedulers.HyperBandScheduler.CONTINUE#\n\n\nHyperBandScheduler.CONTINUE = 'CONTINUE'#\nStatus for continuing trial execution",
        "8dd5d29f-c556-4d54-b0b6-1b4c40e359c2": "raise ValueError(\n                f\"Cannot concat data under key '{k}', b/c \"\n                \"sub-structures under that key don't match. \"f\"`samples`={samples}\\n Original error: \\n {e}\"\n            )\n\n    if concatd_seq_lens != [] and torch and torch.is_tensor(concatd_seq_lens[0]):\n        concatd_seq_lens = torch.Tensor(concatd_seq_lens)\n    elif concatd_seq_lens != [] and tf and tf.is_tensor(concatd_seq_lens[0]):\n        concatd_seq_lens = tf.convert_to_tensor(concatd_seq_lens)\n\n    # Return a new (concat'd) SampleBatch.return SampleBatch(\n        concatd_data,\n        seq_lens=concatd_seq_lens,\n        _time_major=time_major,\n        _zero_padded=zero_padded,\n        _max_seq_len=max_seq_len,\n        # Compute weighted average of the num_grad_updates for the batches\n        # (assuming they all come from the same policy)._num_grad_updates=(\n            concatd_num_grad_updates[1] / (concatd_num_grad_updates[0] or 1.0)\n        ),\n    )",
        "5d073f90-6559-44d5-9d19-5de861662c1c": "What can I work on?#\nWe use Github to track issues, feature requests, and bugs. Take a look at the\nones labeled \u201cgood first issue\u201d for a place to start.",
        "9db94ab7-d740-4006-a8ad-1d47b7d68be6": "Running the task in parallel requires two minor code modifications.\nTo execute your Ray task remotely, you must use a .remote() call.\nRay executes remote tasks asynchronously, even on a local cluster.\nThe items in the object_references list in the code snippet do not directly contain the results.\nIf you check the Python type of the first item using type(object_references[0]),\nyou see that it is actually an ObjectRef.\nThese object references correspond to futures for which you need to request the result.\nThe call :func:ray.get()<ray.get(...)> is for requesting the result. Whenever you call remote on a Ray task,\nit immediately returns one or more object references.\nConsider Ray tasks as the primary way of creating objects.\nThe following section is an example that links multiple tasks together and allows\nRay to pass and resolve the objects between them.\nLet\u2019s review the previous steps.\nYou started with a Python function, then decorated it with @ray.remote, making the function a Ray task.\nInstead of directly calling the original function in the code, you called .remote(...) on the Ray task.\nFinally, you retrieved the results from the Ray cluster using .get(...).\nConsider creating a Ray task from one of your own functions as an additional exercise.\nLet\u2019s review the performance gain from using Ray tasks.\nOn most laptops the runtime is around 0.71 seconds,\nwhich is slightly more than the slowest subtask, which is 0.7 seconds.\nYou can further improve the program by leveraging more of Ray\u2019s API.",
        "c9feb7b2-716c-48c4-8485-d8fa233275ab": "if cf.num_learner_workers > 0:\n                if cf.num_gpus_per_learner_worker:\n                    learner_bundles = [\n                        {\"GPU\": cf.num_learner_workers * cf.num_gpus_per_learner_worker}\n                    ]\n                elif cf.num_cpus_per_learner_worker:\n                    learner_bundles = [\n                        {\n                            \"CPU\": cf.num_cpus_per_learner_worker\n                            * cf.num_learner_workers,\n                        }\n                    ]\n            else:\n                learner_bundles = [\n                    {\n                        # sampling and training is not done concurrently when local is\n                        # used, so pick the max.",
        "a26cba36-d9da-46ea-9c73-38c1a68dee56": "ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer.__init__#\n\n\nMultiAgentPrioritizedReplayBuffer.__init__(capacity: int = 10000, storage_unit: str = 'timesteps', num_shards: int = 1, replay_mode: str = 'independent', replay_sequence_override: bool = True, replay_sequence_length: int = 1, replay_burn_in: int = 0, replay_zero_init_states: bool = True, underlying_buffer_config: Optional[dict] = None, prioritized_replay_alpha: float = 0.6, prioritized_replay_beta: float = 0.4, prioritized_replay_eps: float = 1e-06, **kwargs)[source]#\nInitializes a MultiAgentReplayBuffer instance.Parameters\n\ncapacity \u2013 The capacity of the buffer, measured in storage_unit.storage_unit \u2013 Either \u2018timesteps\u2019, \u2018sequences\u2019 or\n\u2018episodes\u2019.Specifies how experiences are stored.If they\nare stored in episodes, replay_sequence_length is ignored.If they are stored in episodes, replay_sequence_length is\nignored.num_shards \u2013 The number of buffer shards that exist in total\n(including this one).replay_mode \u2013 One of \u201cindependent\u201d or \u201clockstep\u201d.Determines,\nwhether batches are sampled independently or to an equal\namount.replay_sequence_override \u2013 If True, ignore sequences found in incoming\nbatches, slicing them into sequences as specified by\nreplay_sequence_length and replay_sequence_burn_in.This only has\nan effect if storage_unit is sequences.",
        "196261df-b770-465f-baed-b490ef41d505": "0\n1\n0.168750\n0.111393\n\n\n1\n2\n0.609375\n0.195086\n\n\n2\n3\n0.800000\n0.283543\n\n\n3\n4\n0.840625\n0.388538\n\n\n4\n5\n0.840625\n0.479402\n\n\n...\n...\n...\n...\n\n\n95\n96\n0.946875\n8.415694\n\n\n96\n97\n0.943750\n8.524299\n\n\n97\n98\n0.956250\n8.606126\n\n\n98\n99\n0.934375\n8.697471\n\n\n99\n100\n0.965625\n8.777758\n\n\n\n100 rows \u00d7 3 columns",
        "cb3c0989-822a-4234-b685-f9dddae68370": "Defining the Function Trainable#\nWe will define the training loop:\n\nLoad the hyperparameter configuration\nInitialize the model, resuming from a checkpoint if one exists (this is important for PBT, since the scheduler will pause and resume trials frequently when trials get exploited).\nRun the training loop and checkpoint.\n\n\n\ndef train_func(config):\n    # Load the hyperparam config passed in by the Tuner\n    h0 = config.get(\"h0\")\n    h1 = config.get(\"h1\")\n    h = np.array([h0, h1]).astype(float)\n    \n    lr = config.get(\"lr\")\n    train_step = 1\n    checkpoint_interval = config.get(\"checkpoint_interval\", 1)\n    logging_interval = config.get(\"logging_interval\", 10)\n    \n    # Initialize the model parameters\n    theta = get_init_theta()\n    \n    # Load a checkpoint if it exists\n    # This checkpoint could be a trial's own checkpoint to resume,\n    # or another trial's checkpoint placed by PBT that we will exploit\n    if train.get_checkpoint():\n        checkpoint_dict = train.get_checkpoint().",
        "c41be63f-f6b7-4b52-87e2-34bb9a91a275": "ray.rllib.policy.sample_batch.MultiAgentBatch.compress#\n\n\nMultiAgentBatch.compress(bulk: bool = False, columns: Set[str] = frozenset({'new_obs', 'obs'})) \u2192 None[source]#\nCompresses each policy batch (per column) in place.\n\nParameters\n\nbulk \u2013 Whether to compress across the batch dimension (0)\nas well. If False will compress n separate list items, where n\nis the batch size.\ncolumns \u2013 Set of column names to compress.",
        "a5eba347-c9da-47e2-8262-f43c51296315": "Source code for ray.train.lightning.lightning_trainer\nimport os\nimport pytorch_lightning as pl\n\nfrom copy import copy\nfrom inspect import isclass\nfrom typing import Any, Dict, Optional, Type\n\nfrom ray.air import session\nfrom ray.air.config import CheckpointConfig, RunConfig, ScalingConfig\nfrom ray.air.constants import MODEL_KEY\nfrom ray.air.checkpoint import Checkpoint\nfrom ray.data.preprocessor import Preprocessor\nfrom ray.train import DataConfig\nfrom ray.train.trainer import GenDataset\nfrom ray.train.torch import TorchTrainer\nfrom ray.train.torch.config import TorchConfig\nfrom ray.util import PublicAPI\nfrom ray.train.lightning._lightning_utils import (\n    RayDDPStrategy,\n    RayFSDPStrategy,\n    RayDeepSpeedStrategy,\n    RayLightningEnvironment,\n    RayDataModule,\n    RayModelCheckpoint,\n    prepare_trainer,\n)\n\n\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n[docs]@PublicAPI(stability=\"alpha\")\nclass LightningConfigBuilder:\n    \"\"\"Configuration Class to pass into LightningTrainer.Example:\n        . testcode::\n\n            import torch\n            import torch.nn as nn\n            import pytorch_lightning as pl\n            from ray.train.lightning import LightningConfigBuilder\n\n            class LinearModule(pl.LightningModule):\n                def __init__(self, input_dim,",
        "04c4c7ef-10f8-45f3-9526-c4589e56054e": "Total number of models: 6\nTOTAL TIME TAKEN: 108.69 seconds\n\n\n\n\n\n\n\nFinally, we can inspect the models we have trained and their errors.\n\n\nresults\n\n\n\n\nDataset(num_blocks=6, num_rows=6, schema={location_id: int32, model: object, error: float64})\n\n\n\n\n\n\n# sort values by location id\nresults_df = results.to_pandas()\nresults_df.sort_values(by=[\"location_id\"], ascending=True, inplace=True)\nresults_df\n\n\n\n\n\n\n\n\n\n\nlocation_id\nmodel\nerror\n\n\n\n\n0\n141\nLinearRegression()\n535.858862\n\n\n1\n141\nXGBRegressor(base_score=0.5, booster='gbtree',...\n527.156189\n\n\n2\n173\nLinearRegression()\n1279.122424\n\n\n3\n173\nXGBRegressor(base_score=0.5, booster='gbtree',...\n1377.166627\n\n\n4\n229\nLinearRegression()\n556.860355\n\n\n5\n229\nXGBRegressor(base_score=0.5, booster='gbtree',...\n559.876944\n\n\n\n\n\n\n\nresults_df.dtypes\n\n\n\n\nlocation_id      int32\nmodel           object\nerror          float64\ndtype: object",
        "48628e86-b479-4c64-b8a9-cb810f40c068": "ray.data.datasource.Partitioning.base_dir#\n\n\nPartitioning.base_dir: Optional[str] = None#\n\u201c/\u201d-delimited base directory that all partitioned paths should\nexist under (exclusive). File paths either outside of, or at the first\nlevel of, this directory will be considered unpartitioned. Specify\nNone or an empty string to search for partitions in all file path\ndirectories.",
        "651bc893-b763-416d-aeeb-b5932fdc52be": "# Define a dummy model\nclass DummyModel(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.layer = torch.nn.Linear(3, 1)\n\n    def forward(self, x):\n        return self.layer(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = F.binary_cross_entropy_with_logits(y_hat.flatten(), y.float())\n\n        # The metrics below will be reported to Loggers\n        self.log(\"train_loss\", loss)\n        self.log_dict({\"metric_1\": 1 / (batch_idx + 1), \"metric_2\": batch_idx * 100})\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=1e-3)",
        "71b2b063-1cea-4a46-996d-48c8071a3ae2": ">>> worker = ... # doctest: +SKIP\n            >>> weights = worker.get_weights() # doctest: +SKIP\n            >>> print(weights) # doctest: +SKIP\n            {\"default_policy\": {\"layer1\": array(...), \"layer2\": ...}}\n        \"\"\"\n        if policies is None:\n            policies = list(self.policy_map.keys())\n        policies = force_list(policies)\n\n        return {\n            # Make sure to only iterate over keys() and not items().Iterating over\n            # items will access policy_map elements even for pids that we do not need,\n            # i.e.those that are not in policies.Access to policy_map elements can\n            # cause disk access for policies that were offloaded to disk.Since these\n            # policies will be skipped in the for-loop accessing them is unnecessary,\n            # making subsequent disk access unnecessary.",
        "ad88717f-4774-4fc2-a903-78d21cc26193": "data_string = '{\"1001\": 301.27, \"1002\": 433.21, \"1003\": 502.22}'\n\n        order_data_dict = json.loads(data_string)\n        return order_data_dict\n\n    @task(multiple_outputs=True)\n    def transform(order_data_dict: dict):\n        \"\"\"\n        #### Transform task\n        A simple Transform task which takes in the collection of order data and\n        computes the total order value.\n        \"\"\"total_order_value = 0\n\n        for value in order_data_dict.values():\n            total_order_value += value\n\n        return {\"total_order_value\": total_order_value}\n\n    @task()\n    def load(total_order_value: float):\n        \"\"\"\n        #### Load task\n        A simple Load task which takes in the result of the Transform task and\n        instead of saving it to end user review, just prints it out.\n        \"\"\"print(f\"Total order value is: {total_order_value:.2f}\")\n\n    order_data = extract()\n    order_summary = transform(order_data)\n    load(order_summary[\"total_order_value\"])\n\n\ntutorial_etl_dag = tutorial_taskflow_api_etl()\n\n\n\n\nWorkflow version:#\nimport json\n\nimport ray\nfrom ray import workflow",
        "b24874e0-c351-40d6-a2a0-2b7e2b76b0f8": "return state\n\n        checkpoint = self._status_reporter.get_checkpoint()\n        if not checkpoint:\n            state.update(iteration=0, timesteps_total=0, episodes_total=0)\n        return state\n\n    def save_checkpoint(self, checkpoint_dir: str = \"\"):\n        if checkpoint_dir:\n            raise ValueError(\"Checkpoint dir should not be used with function API.\")if _use_storage_context():\n            # TRAIN -> SAVE remote calls get processed sequentially,\n            # so `_last_training_result.checkpoint` holds onto the latest ckpt.return self._last_training_result\n\n        checkpoint = self._status_reporter.get_checkpoint()\n\n        if not checkpoint:\n            # We drop a marker here to indicate that the checkpoint is empty\n            checkpoint = FuncCheckpointUtil.mk_null_checkpoint_dir(self.logdir)\n            parent_dir = checkpoint\n        elif isinstance(checkpoint, dict):\n            return checkpoint\n        elif isinstance(checkpoint, str):\n            parent_dir = TrainableUtil.find_checkpoint_dir(checkpoint)\n            # When the trainable is restored, a temporary checkpoint\n            # is created.However, when saved, it should become permanent.",
        "02c2a23b-0bf2-417f-a4c2-2d80b0bbac0b": "ray.job_submission.JobSubmissionClient.tail_job_logs#\n\n\nasync JobSubmissionClient.tail_job_logs(job_id: str) \u2192 Iterator[str][source]#\nGet an iterator that follows the logs of a job.\nExample\n>>> from ray.job_submission import JobSubmissionClient\n>>> client = JobSubmissionClient(\"http://127.0.0.1:8265\") \n>>> submission_id = client.submit_job( \n...     entrypoint=\"echo hi && sleep 5 && echo hi2\")\n>>> async for lines in client.tail_job_logs( \n...           'raysubmit_Xe7cvjyGJCyuCvm2'):\n...     print(lines, end=\"\") \nhi\nhi2\n\n\n\nParameters\njob_id \u2013 The job ID or submission ID of the job whose logs are being\nrequested.\n\nReturns\nThe iterator.\n\nRaises\nRuntimeError \u2013 If the job does not exist or if the request to the\n    job server fails.\n\n\nPublicAPI: This API is stable across Ray releases."
    },
    "relevant_docs": {
        "fd0a174e-6e05-4bbc-96a1-2f84fb8b6220": [
            "afafd081-e18a-4ae9-9218-64b163416609"
        ],
        "136a8d2d-1c2a-4c05-ab73-e33c0c12d37e": [
            "afafd081-e18a-4ae9-9218-64b163416609"
        ],
        "e604d93b-1ea9-449d-9e83-a90632e3cf0a": [
            "07ff7c94-dee6-486e-bcaf-87aa2c8b8120"
        ],
        "d4aee739-45bf-4325-a5ae-b5accf9479ee": [
            "07ff7c94-dee6-486e-bcaf-87aa2c8b8120"
        ],
        "d15e8a6e-8896-4823-8cc2-3cd2bdd77a7f": [
            "70b4df69-6aa3-493f-b8d1-93dc9e20850f"
        ],
        "64c6f995-60a3-45be-ae47-cd0cfb8cdb10": [
            "70b4df69-6aa3-493f-b8d1-93dc9e20850f"
        ],
        "737dedbb-dce3-4cef-ac63-a6204d7f55a6": [
            "94db4119-710b-400f-8f6c-5980d8aaac44"
        ],
        "9b82ed3b-3691-4c41-86dc-64bc39337052": [
            "94db4119-710b-400f-8f6c-5980d8aaac44"
        ],
        "55c7da48-be69-41d1-999b-1e0b9eb32cd2": [
            "3b56ca61-c572-4508-832b-612ec152db85"
        ],
        "b564d7ce-1288-4322-adf3-2e839183e878": [
            "3b56ca61-c572-4508-832b-612ec152db85"
        ],
        "878ec173-f6fe-4521-a68e-ae6b40a05785": [
            "55dcedf8-3f5e-43ba-8ecb-ae7bab95f663"
        ],
        "9a449243-6dcc-4d84-90e4-262340b7bd26": [
            "55dcedf8-3f5e-43ba-8ecb-ae7bab95f663"
        ],
        "bcbc0203-c37a-4802-b64e-e518852d7466": [
            "2466d669-55cb-40ad-9d99-cb55d8433a4c"
        ],
        "b13f5157-7e86-4033-8ba7-aa745debd49d": [
            "2466d669-55cb-40ad-9d99-cb55d8433a4c"
        ],
        "0ca94a11-e52c-4b33-b3d6-d82e45386a44": [
            "19592be9-6bd0-4ed2-8146-209428cbdd8f"
        ],
        "4ba54d8c-d3c0-4d2b-a1de-d60cfafae0a4": [
            "19592be9-6bd0-4ed2-8146-209428cbdd8f"
        ],
        "d2110d98-b296-4fea-9ea9-2d5fdc46a76a": [
            "4e009c04-54f1-430e-a2aa-b420f46b4d0b"
        ],
        "0e5c56a1-e9fc-4dde-8fc9-1b7680e05fe2": [
            "4e009c04-54f1-430e-a2aa-b420f46b4d0b"
        ],
        "30db5f0f-d4cc-44c0-9e81-aab44f9b1779": [
            "4b60bf0d-f007-4edd-b8f7-fcb861a46fb7"
        ],
        "776a5a22-b0c3-4cc3-b1f4-a88c5f642b9e": [
            "4b60bf0d-f007-4edd-b8f7-fcb861a46fb7"
        ],
        "b26974b9-b266-4a86-a9da-188072f87a2e": [
            "43d7a6ba-3856-4d1d-aeec-e3af78a021fa"
        ],
        "0cc1352a-cf72-4f06-8e24-80facf10ad3b": [
            "43d7a6ba-3856-4d1d-aeec-e3af78a021fa"
        ],
        "8666afe2-642b-4a62-8d52-2a278e5fba87": [
            "418a8185-c50e-4544-8baf-d81870f10038"
        ],
        "08f8ae5f-ebfa-40bf-b2e7-340f3444fa7b": [
            "418a8185-c50e-4544-8baf-d81870f10038"
        ],
        "c2eb2e5d-b14d-49d1-910f-0cb09e1d13cc": [
            "064bc078-aae6-4ac3-a834-cbf4d2be3145"
        ],
        "5ab5cb7d-3ecf-4966-a998-a71048caa9ff": [
            "064bc078-aae6-4ac3-a834-cbf4d2be3145"
        ],
        "e11b76f6-0c8e-4e9a-a6ef-648d1e9c6c93": [
            "5b508ede-3a92-41d4-9132-acc64f2bf716"
        ],
        "a340ca80-a09b-4177-84b8-7c5cf0f460cf": [
            "5b508ede-3a92-41d4-9132-acc64f2bf716"
        ],
        "9f60f638-54c2-4147-9a9d-e8b8de153267": [
            "26221784-4e63-428f-a8d2-bf141b735daa"
        ],
        "2edfa25c-1e64-4d1e-a2dc-38056d4f5e21": [
            "26221784-4e63-428f-a8d2-bf141b735daa"
        ],
        "5b58a9df-771e-4265-84b2-e517c9ac4a5a": [
            "78c6f1f2-399e-42eb-a6dc-6513ff8a2fe0"
        ],
        "b48413bc-2b03-4f83-b405-ac906b789487": [
            "78c6f1f2-399e-42eb-a6dc-6513ff8a2fe0"
        ],
        "b9d8aba2-7e15-4c59-8298-96b3661007ec": [
            "27e5fc4a-aff7-4b08-8e18-af68f8facc8a"
        ],
        "93e472c9-1a3e-4cd3-a810-94753748bf45": [
            "27e5fc4a-aff7-4b08-8e18-af68f8facc8a"
        ],
        "1c0934ec-56aa-4bc4-86d7-a5d6594fd8c2": [
            "74e6c400-210a-4681-973a-07929b2f8d80"
        ],
        "44887e3e-c92f-4dda-89a1-1e34bf923eee": [
            "74e6c400-210a-4681-973a-07929b2f8d80"
        ],
        "eb43cbec-3395-4edc-9965-eeb8e58deedb": [
            "164c9798-7825-46ef-9845-b6eb36e62bd6"
        ],
        "cf9caaac-dd9a-4599-b45f-e80aa65a1e01": [
            "164c9798-7825-46ef-9845-b6eb36e62bd6"
        ],
        "d46bcadb-e915-4ced-bdb6-4d1fec857102": [
            "c63e0fd1-30a6-4206-a1da-092878027fae"
        ],
        "f77f88eb-a155-4d92-b6fd-fa6f683e26f1": [
            "c63e0fd1-30a6-4206-a1da-092878027fae"
        ],
        "6b8826e1-0625-4332-9574-0fb027a64dbb": [
            "c4145c2d-808f-45e4-9fb9-9e1bb856cc1d"
        ],
        "f607ddc0-0530-4b97-a296-862527fa2e1c": [
            "c4145c2d-808f-45e4-9fb9-9e1bb856cc1d"
        ],
        "73ef397f-a8f3-4b07-9da6-a42e046a8f01": [
            "3d421d77-eda3-4a13-a527-10afafacd667"
        ],
        "f3a9250c-861e-45a4-b8a2-36b3ffbaa498": [
            "3d421d77-eda3-4a13-a527-10afafacd667"
        ],
        "32251ce8-47d3-4f11-b3f9-ca2755675e23": [
            "7f818411-0907-4a6a-ba56-d06285725bcb"
        ],
        "6e51481d-a42f-4b6f-9879-431184b722f9": [
            "7f818411-0907-4a6a-ba56-d06285725bcb"
        ],
        "5dde49c1-a573-4f55-93ec-be7ba62e6df7": [
            "2b6d1a36-e1d6-4b7d-81e0-8faade7a77b2"
        ],
        "14a09bde-50fa-4bbc-aa2d-afab59f097cd": [
            "2b6d1a36-e1d6-4b7d-81e0-8faade7a77b2"
        ],
        "53069e8b-d6f3-4024-b745-9a8e12106952": [
            "a0db1f91-70d7-47e3-95b2-bd274b810e1a"
        ],
        "abaf1c18-7244-4abb-89e1-efd1016a2dcc": [
            "a0db1f91-70d7-47e3-95b2-bd274b810e1a"
        ],
        "0a46e181-4460-4a9f-8907-2c4ec97ed0f2": [
            "61500051-fda4-4c34-9e56-e29f8d1eec40"
        ],
        "5320f57c-1eb6-4e9e-96cd-676475d57f06": [
            "61500051-fda4-4c34-9e56-e29f8d1eec40"
        ],
        "7758178a-1211-4a9b-879c-b4f4e3b33b13": [
            "b7cfc9b5-cf6c-4cba-a730-de2cd2e6c35b"
        ],
        "ddaa73e9-9197-47d0-8a1c-b8ef19f6f5ac": [
            "b7cfc9b5-cf6c-4cba-a730-de2cd2e6c35b"
        ],
        "34484cc6-3aea-40bb-b914-03c380ac4cb7": [
            "336cd42f-f859-438e-ac28-df3c4e4a0a0d"
        ],
        "eb0c4892-86be-4797-850c-231e340edf39": [
            "336cd42f-f859-438e-ac28-df3c4e4a0a0d"
        ],
        "f3425306-97dc-47df-8fb9-9490ccb1db55": [
            "459025f0-345e-4b7b-98f0-f70b394659e5"
        ],
        "fece11c6-78d4-4f8a-b3fd-d653c621d6ed": [
            "459025f0-345e-4b7b-98f0-f70b394659e5"
        ],
        "53ef319f-a9b6-4f6f-b7be-4cb52c128a9c": [
            "390a0173-2b51-4b67-9b85-6b98f487f73d"
        ],
        "2ee255cb-25f7-4338-8e4a-1388eb946d95": [
            "390a0173-2b51-4b67-9b85-6b98f487f73d"
        ],
        "d541080a-7b23-46c5-ad76-fd452bef4316": [
            "b5fbde7b-13c2-41c5-953b-83ed0093dd52"
        ],
        "497802d7-9cff-46d9-96eb-4f715e6bce87": [
            "b5fbde7b-13c2-41c5-953b-83ed0093dd52"
        ],
        "8bf623a5-578f-4200-b3a2-7755d1c856b1": [
            "5c186583-ccf7-405d-9489-fa83f23cd437"
        ],
        "f8440976-c516-4ac6-b7fb-67e267cad70c": [
            "5c186583-ccf7-405d-9489-fa83f23cd437"
        ],
        "195ad306-03b9-4a7e-893e-ab87c0678bb4": [
            "d3758d36-9db3-4f62-a3d8-5f5a549e3072"
        ],
        "181462b2-d298-430c-abb0-ae1bd38b5df6": [
            "d3758d36-9db3-4f62-a3d8-5f5a549e3072"
        ],
        "5accf0bb-ab77-44e9-8cda-ac8acda6b1d4": [
            "3a0dae48-f8e9-437b-af84-43523171541b"
        ],
        "d95be6ed-31de-4355-8faa-4384a4f3271a": [
            "3a0dae48-f8e9-437b-af84-43523171541b"
        ],
        "c4e474f8-afd0-4be1-936f-11f73c45436f": [
            "f6bd0ee7-968c-430f-8d21-e18a82f0143b"
        ],
        "e8178707-89f8-4432-bea5-244a7372f682": [
            "f6bd0ee7-968c-430f-8d21-e18a82f0143b"
        ],
        "c656ee78-ec9e-46a6-b8bb-3b0927ab0ef7": [
            "a4ce8f16-04ce-416c-8c1d-439f6c81114e"
        ],
        "44838465-5b78-4a1d-94f9-1fd0b32ec7c5": [
            "a4ce8f16-04ce-416c-8c1d-439f6c81114e"
        ],
        "030d44e0-1768-4dbf-a624-2ce459a00f3e": [
            "e5cfa1d0-2906-4d4f-9a75-f02b64bf13ce"
        ],
        "98f5ccba-1dd9-4aec-92bd-ddb5031a2a1d": [
            "e5cfa1d0-2906-4d4f-9a75-f02b64bf13ce"
        ],
        "7f71136a-ec4b-48d8-a564-a0170eeb5e4c": [
            "b2fa9cd8-c3b8-4cee-8d90-a4a9f4a8298c"
        ],
        "d87d360b-a528-4471-b2f7-7c1145723f4d": [
            "b2fa9cd8-c3b8-4cee-8d90-a4a9f4a8298c"
        ],
        "5939bdf2-ff00-4d36-a9ff-3fcdfa2f4119": [
            "aafc0c54-4287-406a-957d-c9c87790ca6d"
        ],
        "5b5d7c68-cb09-4853-91b9-135ca06a448f": [
            "aafc0c54-4287-406a-957d-c9c87790ca6d"
        ],
        "8c8a30e6-7075-4b9b-928b-39e57880e70f": [
            "f9549c15-e758-4114-a0e6-8503a21f329a"
        ],
        "acdee202-408e-4c95-99b0-753790b0bd96": [
            "f9549c15-e758-4114-a0e6-8503a21f329a"
        ],
        "90bb8c96-7144-4f6c-89ae-79cdfc081cf3": [
            "333e0551-340e-40fa-8d47-415910e7dc69"
        ],
        "a63be437-a9ab-4aed-a90e-c75c4f5fe6f2": [
            "333e0551-340e-40fa-8d47-415910e7dc69"
        ],
        "365065e7-c8e3-4ca8-babd-90cd8b3c0ab9": [
            "abd6134f-bc09-4374-a567-da8c9fc526cd"
        ],
        "e8df35d7-6c23-410c-b3f1-b5a24d8745db": [
            "abd6134f-bc09-4374-a567-da8c9fc526cd"
        ],
        "5bf2f3d1-2692-4dcf-b985-f7db6e7c4b65": [
            "be43b656-9c5e-4731-b550-07a5ea39026a"
        ],
        "b6167645-5aa4-4167-b0a1-154bd452909b": [
            "be43b656-9c5e-4731-b550-07a5ea39026a"
        ],
        "57d14b59-293d-4073-95ff-581a8b1a5a37": [
            "4e2b5a79-f462-405b-9184-6130f2dc0cd9"
        ],
        "5b52b549-e503-479c-ba87-33574f3bc6c6": [
            "4e2b5a79-f462-405b-9184-6130f2dc0cd9"
        ],
        "76491a52-ac5e-4caa-b745-f81bc1e238ed": [
            "058a937d-dc64-4577-b95a-57650694db95"
        ],
        "9f620350-2a9c-40f4-b3aa-f0fb5f52de7e": [
            "058a937d-dc64-4577-b95a-57650694db95"
        ],
        "2759be71-65b4-4a84-a80e-441036cac3ec": [
            "bdfe4035-f413-444f-bfe7-bd4f723a0f21"
        ],
        "3f9486e8-0039-4104-b33c-697ca45c3e18": [
            "bdfe4035-f413-444f-bfe7-bd4f723a0f21"
        ],
        "6709100f-9952-4d05-8b71-c7ae95c62c93": [
            "0cfb4e15-8a0c-4a4c-bc3d-d695fa73f732"
        ],
        "8e95f5f6-e502-465a-aa7a-c68ab56ee802": [
            "0cfb4e15-8a0c-4a4c-bc3d-d695fa73f732"
        ],
        "02e08896-6aec-43ab-ac34-e2af63e1ba2b": [
            "0293545e-8a78-431e-9529-ca62ab2f1d44"
        ],
        "39364e1c-0979-4b1c-a303-18bbb2afeab0": [
            "0293545e-8a78-431e-9529-ca62ab2f1d44"
        ],
        "39a607b1-03ab-48b0-8f53-e18dd9ef1efd": [
            "948789f1-851b-4114-928e-f286c3a649cd"
        ],
        "88c932df-c458-4468-82b1-f87482caf8b2": [
            "948789f1-851b-4114-928e-f286c3a649cd"
        ],
        "aa3e73ae-6b29-4bbf-ac15-6d2b1ec1293e": [
            "e7a3ef39-d32c-4449-9d46-f66ca83892a6"
        ],
        "f1a072f4-4da2-4c51-87ba-e12c603623dc": [
            "e7a3ef39-d32c-4449-9d46-f66ca83892a6"
        ],
        "2331f21a-a2b3-43eb-94a6-7a4534c3a296": [
            "a98d61b7-3bd8-4eb4-aeeb-5bfb8cd66cc4"
        ],
        "eceb7350-0d14-4f15-9c2b-ecc313790fbe": [
            "a98d61b7-3bd8-4eb4-aeeb-5bfb8cd66cc4"
        ],
        "54e81db0-a5e4-4484-a116-513f511c67c8": [
            "73896d27-c596-4a2a-b254-4bc12fa07afd"
        ],
        "8e813724-b1bc-4549-9c42-3eee935a02e2": [
            "73896d27-c596-4a2a-b254-4bc12fa07afd"
        ],
        "ec14660b-eb53-417a-9d1b-fde4b6e5b046": [
            "7ed0ad0d-0a25-4d74-8d80-32e1a4c7725c"
        ],
        "6cf2b02d-2f99-4f8a-b1b9-bd2f2cc5e0a5": [
            "7ed0ad0d-0a25-4d74-8d80-32e1a4c7725c"
        ],
        "09927f17-1685-45d3-9974-c24bedcfce0d": [
            "83de2df4-012f-4fd0-afe7-c7d4c7a3d9d6"
        ],
        "e6b64f92-c6c8-4943-92e4-e06063f41f02": [
            "83de2df4-012f-4fd0-afe7-c7d4c7a3d9d6"
        ],
        "2f9694e7-3231-49bc-837a-5a0298eac12b": [
            "5516e3a2-5397-4f66-a6cb-082f819abd1c"
        ],
        "4c8888e2-108b-49e5-b408-1848ab496196": [
            "5516e3a2-5397-4f66-a6cb-082f819abd1c"
        ],
        "7e7923b6-f9f4-4e84-9f6e-68aca27ee810": [
            "d3e95b1c-da2c-47c2-83e1-0d306465791f"
        ],
        "33350ec6-5fa0-4c66-a5da-263277da898d": [
            "d3e95b1c-da2c-47c2-83e1-0d306465791f"
        ],
        "681056f1-eceb-4abd-8355-6204b7c3db44": [
            "b6a6f5cf-cba3-4648-94a7-a0a91c6eb817"
        ],
        "7dc7fc28-af14-4019-b61e-3863008e778f": [
            "b6a6f5cf-cba3-4648-94a7-a0a91c6eb817"
        ],
        "288531a5-d2ae-4cfe-a0eb-569e81e0ba7e": [
            "5b364331-5587-41f1-8da1-138426ad1069"
        ],
        "a17cfc19-351b-4e2a-b7bc-0864d95f7510": [
            "5b364331-5587-41f1-8da1-138426ad1069"
        ],
        "8bd243b8-72f4-4d16-bcb3-fe647977654b": [
            "1dd9b303-7b60-4afc-9606-27c6ba56caea"
        ],
        "cd8c76d0-171f-495c-8e07-fa5c860dbea6": [
            "1dd9b303-7b60-4afc-9606-27c6ba56caea"
        ],
        "dc3a0e27-7ef7-40ed-9115-d5c25043a969": [
            "4f7fe93e-657e-45b1-add3-742e478c9754"
        ],
        "62d54059-933a-43af-9989-de0590559342": [
            "4f7fe93e-657e-45b1-add3-742e478c9754"
        ],
        "69d30129-8977-4e0a-929a-659a588b8243": [
            "73eb5280-1ada-4e01-9dec-cab4d906d60f"
        ],
        "b4dffca0-d48f-4b37-86d6-ec89bc1af2d9": [
            "73eb5280-1ada-4e01-9dec-cab4d906d60f"
        ],
        "a61db22e-33f5-4971-b597-e14bb07932f8": [
            "94d2c6db-2321-4379-9798-b5d3fa3ff6b1"
        ],
        "a3f98618-76fb-49bb-a272-407c473c2100": [
            "94d2c6db-2321-4379-9798-b5d3fa3ff6b1"
        ],
        "fa156a45-5c4e-4940-880f-f984de89c51e": [
            "3b4943ac-2b4b-46a8-8024-9154787872f1"
        ],
        "0f1617c9-7b07-46c8-a7dd-190af42f375c": [
            "3b4943ac-2b4b-46a8-8024-9154787872f1"
        ],
        "23a794f2-4e4b-4f49-b14a-41497b6d1b45": [
            "7c3141f5-e811-48d8-8661-a9b2ef23d646"
        ],
        "078a1960-2f26-4ba7-92d5-c66b824d6361": [
            "7c3141f5-e811-48d8-8661-a9b2ef23d646"
        ],
        "e419c581-36fa-4146-9cdc-b454cb5d0c51": [
            "1d3286a3-a210-4bc7-913a-78827917c363"
        ],
        "0ed2d0b8-e556-40ce-9838-0cededc9581d": [
            "1d3286a3-a210-4bc7-913a-78827917c363"
        ],
        "e9399756-331b-4d7e-8b0d-7fc1f17ffb12": [
            "2140c854-da29-4176-8a2d-acbd87f15fb7"
        ],
        "802b7c4a-f25b-4b17-a378-228fc1dde82e": [
            "2140c854-da29-4176-8a2d-acbd87f15fb7"
        ],
        "74f44529-6beb-409a-9468-638c5deb2134": [
            "90d18c07-e608-41a0-b8b0-fa66f6435ca5"
        ],
        "1d8f6141-59fd-4946-95bb-75233d776e9f": [
            "90d18c07-e608-41a0-b8b0-fa66f6435ca5"
        ],
        "73eff3a6-c527-4bcb-884e-21ee022c2329": [
            "705c4311-82f2-4c33-9f56-31ec73cc8914"
        ],
        "fef54bfa-19a1-4fa2-b1ed-f4126600140c": [
            "705c4311-82f2-4c33-9f56-31ec73cc8914"
        ],
        "f7ec42c8-7a2f-4e16-b38d-b0534766f3ef": [
            "ccbd38e0-fd60-46a3-a733-f0087d72b464"
        ],
        "63fd84ef-f81c-4ccb-9516-54f1a47b37a9": [
            "ccbd38e0-fd60-46a3-a733-f0087d72b464"
        ],
        "81d7592e-0249-422e-94b5-0b24487def6e": [
            "68291fa2-cb7f-4bc5-ba58-41206f55fecc"
        ],
        "c20ba6c1-b57b-4e3b-b8d6-5d2ab660b1c8": [
            "68291fa2-cb7f-4bc5-ba58-41206f55fecc"
        ],
        "daaa508a-c611-430c-8999-f5c641514c70": [
            "8c2ae503-4af6-4afe-b007-782311b10bbe"
        ],
        "6da660f4-9c53-4db6-800d-b5a75b15481d": [
            "8c2ae503-4af6-4afe-b007-782311b10bbe"
        ],
        "682adfe9-3f2b-4eee-bdc8-3874fe8cc52b": [
            "4b3e5f87-1fdd-453d-8b1e-8bc10d79d808"
        ],
        "c583b571-55b6-449c-a37d-ae77e555dbf7": [
            "4b3e5f87-1fdd-453d-8b1e-8bc10d79d808"
        ],
        "074aab18-d58f-4d0d-bc86-8cc9250857f5": [
            "3b184b7c-78aa-423b-a6ea-5157291ea193"
        ],
        "f8375970-8955-4bf2-b72a-5f2d209f754d": [
            "3b184b7c-78aa-423b-a6ea-5157291ea193"
        ],
        "6468104d-4f98-4472-8cd2-5fcaa67bd41e": [
            "35a63870-5208-420b-804c-93a9823e1c04"
        ],
        "01cf6793-c48e-402f-9e36-2995e4e6a851": [
            "35a63870-5208-420b-804c-93a9823e1c04"
        ],
        "78d197ac-f382-4f7d-828f-21d4e5e36e7d": [
            "5a9143a6-3c2b-4673-b9c7-9c92cd63d34f"
        ],
        "dd07bb71-f454-4c19-89fd-f0df5c104707": [
            "5a9143a6-3c2b-4673-b9c7-9c92cd63d34f"
        ],
        "95aa7e34-f56e-4577-810f-1018c9d016a9": [
            "d218de8a-19c3-45a3-8504-bd98ace16f34"
        ],
        "82192c0c-1941-49a9-8a46-c983949f463b": [
            "d218de8a-19c3-45a3-8504-bd98ace16f34"
        ],
        "68a3ffc0-bd10-4374-95f1-30870c1eb83d": [
            "1bb2ae16-8da7-44e9-b955-38ab88ca5d63"
        ],
        "c5557f9d-5ebc-4a6a-b1c8-9b12df7eb4c9": [
            "1bb2ae16-8da7-44e9-b955-38ab88ca5d63"
        ],
        "22085049-4e83-476f-b5b9-dd8e50ba02fd": [
            "afdf18c6-4fd2-40bd-8063-4943608993f7"
        ],
        "e4179b80-f787-40a2-ae4b-d6f22e271066": [
            "afdf18c6-4fd2-40bd-8063-4943608993f7"
        ],
        "ab38b4c4-b45c-466c-8105-5e387b787993": [
            "df7b07e1-42a7-4f4c-af95-ff0ec8b14c2d"
        ],
        "a4079e49-bcf2-4634-b523-3efc02d5c33c": [
            "df7b07e1-42a7-4f4c-af95-ff0ec8b14c2d"
        ],
        "64e14736-ce45-4a7e-85a6-9482fb82ebdf": [
            "4e72355e-3255-4fd1-84c2-7e5d233a229a"
        ],
        "a9e81ea1-22e8-4781-b0dd-f660181325e5": [
            "4e72355e-3255-4fd1-84c2-7e5d233a229a"
        ],
        "2fd233c3-9577-41f0-9e34-c6c6329747d4": [
            "8b2c7c31-d145-4fad-863e-e9bcfee0d795"
        ],
        "71fae422-2eba-4da9-a5c0-4b98c67e521a": [
            "8b2c7c31-d145-4fad-863e-e9bcfee0d795"
        ],
        "f3dae851-ea29-4091-b418-11ec3b5972b6": [
            "78871974-2b66-4f0e-b3b3-a6b12b5cf607"
        ],
        "f2fb37c9-5600-4a8c-b89e-5c54a3d59fa8": [
            "78871974-2b66-4f0e-b3b3-a6b12b5cf607"
        ],
        "31b51dde-7049-438c-b3b2-408648a25546": [
            "84dd30ba-6405-4b1f-83b2-4535a495a903"
        ],
        "071c4f2f-23f8-4425-8cf8-9d51b8bd6af1": [
            "84dd30ba-6405-4b1f-83b2-4535a495a903"
        ],
        "61c60bbe-05aa-42b1-8eed-4e0373004281": [
            "4ac5062c-26ae-4483-a734-429972d4d8b4"
        ],
        "c5b2b116-4397-4557-a3dc-5c4422bc22c7": [
            "4ac5062c-26ae-4483-a734-429972d4d8b4"
        ],
        "355487dc-9de2-4093-925b-cc683dda0512": [
            "929692f3-451e-4520-8ee7-856d6fcfe989"
        ],
        "d2fce595-663f-45b2-bd56-439839bffb7b": [
            "929692f3-451e-4520-8ee7-856d6fcfe989"
        ],
        "5883bcfe-4838-4dfd-a1cb-8d065c89d166": [
            "bbac7849-29b2-4f52-9610-fc35a8f66583"
        ],
        "9b30c572-cd88-4638-99e2-8754ebf4070a": [
            "bbac7849-29b2-4f52-9610-fc35a8f66583"
        ],
        "4d9a01eb-eb3c-45d5-8d24-df6c81308f32": [
            "0fe856d9-be17-4d34-8776-7c4e34bb7e36"
        ],
        "9da955e1-20d2-4cb9-918e-c0afb10c74bc": [
            "0fe856d9-be17-4d34-8776-7c4e34bb7e36"
        ],
        "d24f1142-1262-4918-bee8-bf20b017d821": [
            "a51e6a38-a016-48e1-93e0-649d1b0cd232"
        ],
        "b607d8e8-4c78-4eff-98fd-6d44be331d60": [
            "a51e6a38-a016-48e1-93e0-649d1b0cd232"
        ],
        "ed61f0f2-2a9d-4b5e-ad4d-c1ad7e542ae7": [
            "51f1e266-0d58-49a1-a90a-7fac2fb27bac"
        ],
        "bb0c77a9-a310-4952-9997-e681e4e214da": [
            "51f1e266-0d58-49a1-a90a-7fac2fb27bac"
        ],
        "a8db73f7-490c-437a-80f6-3a4991957eaf": [
            "1df50a2b-9065-41a0-bbbf-45525d07beb7"
        ],
        "30ef8ecd-4642-4721-855c-f0f8a39890ca": [
            "1df50a2b-9065-41a0-bbbf-45525d07beb7"
        ],
        "5af260df-ea4a-4273-9250-c0008e265c54": [
            "85e15933-0a24-4a3b-a06f-8df1bd40688f"
        ],
        "f274303c-749e-4ce8-b908-1001ece4936b": [
            "85e15933-0a24-4a3b-a06f-8df1bd40688f"
        ],
        "a3abfa97-39f7-4002-b0f2-cd4b2d5b1ad4": [
            "899587e4-9814-41bf-a87c-14ee1eab16b6"
        ],
        "c8cf0196-2e14-4ea4-b299-8b3889920171": [
            "899587e4-9814-41bf-a87c-14ee1eab16b6"
        ],
        "ae17d6ad-9860-448f-803f-ccac64a7a98b": [
            "9a019f9f-637f-402e-9290-4e73df2ef157"
        ],
        "98908899-8195-4d5f-9946-c7d3b6a98cee": [
            "9a019f9f-637f-402e-9290-4e73df2ef157"
        ],
        "decac94b-49c5-47fb-94c9-3eaa47c5cb8d": [
            "464db224-7a20-4ae6-8b0a-2516d9a031a8"
        ],
        "aeaf13d3-5b9c-45b1-a816-be0f612883e3": [
            "464db224-7a20-4ae6-8b0a-2516d9a031a8"
        ],
        "14a49440-05e5-4ad0-b486-31c451e58a62": [
            "d09b8151-46ab-46a5-b390-2f374ee29d2b"
        ],
        "6d6edfff-be41-4ab3-b5cf-ee9779d507fa": [
            "d09b8151-46ab-46a5-b390-2f374ee29d2b"
        ],
        "9a099e49-8c7b-4a4e-ab60-356852700045": [
            "621a5828-cd84-4e44-b02d-673c1b529282"
        ],
        "b78f983e-235d-4e36-bc1b-de8355c7394e": [
            "621a5828-cd84-4e44-b02d-673c1b529282"
        ],
        "4bbef8d8-ea9f-425c-b89f-0788c4887543": [
            "0013e4f0-5ccb-4506-8ef7-6d0d8f1cf312"
        ],
        "ac1a8e57-b2a6-42e8-bcd1-686c4b811967": [
            "0013e4f0-5ccb-4506-8ef7-6d0d8f1cf312"
        ],
        "82a7eb96-7ea7-456b-b7a9-7915ef52a516": [
            "5be5d41a-9dd6-4b7c-a8ab-cf10652314f5"
        ],
        "a2149854-f182-4e93-bb38-b22d61405378": [
            "5be5d41a-9dd6-4b7c-a8ab-cf10652314f5"
        ],
        "93d23266-54d0-4a24-bd53-0fb419bf5c58": [
            "b6678ac7-e167-4996-a90c-05baeb92ec70"
        ],
        "886e03a6-351d-49fc-8a97-5bbc0e0e6d19": [
            "b6678ac7-e167-4996-a90c-05baeb92ec70"
        ],
        "f657be53-aa1d-43a9-9b65-1a64e24cb0d7": [
            "9e55dfe0-bc07-4c2c-8492-86863a489372"
        ],
        "3b624636-caf9-438c-b67c-314d6198e23b": [
            "9e55dfe0-bc07-4c2c-8492-86863a489372"
        ],
        "2bbbd2ba-96b2-43af-b9b9-1b939064cecb": [
            "2c756da0-ff54-44b9-979e-2768c3288a27"
        ],
        "2d0fec54-a5f1-41f8-91d9-f501848bd667": [
            "2c756da0-ff54-44b9-979e-2768c3288a27"
        ],
        "221e90fa-9d59-4763-9eab-a6242ce7cd08": [
            "10579eeb-9098-4750-a93a-4e5851e08733"
        ],
        "2e7c54aa-2a2e-499f-8bfd-37463dfc2dc3": [
            "10579eeb-9098-4750-a93a-4e5851e08733"
        ],
        "19740f2f-f3b8-403b-bd60-f8ce4f1a92ed": [
            "2cfb6ada-7bf7-41a8-a43e-2fff1d9f0683"
        ],
        "c41fbefb-23a7-4237-b9bf-76fafd17f34d": [
            "2cfb6ada-7bf7-41a8-a43e-2fff1d9f0683"
        ],
        "6944aa3d-0920-4d4c-be1b-dc52dc72704c": [
            "2cfb6ada-7bf7-41a8-a43e-2fff1d9f0683"
        ],
        "9b12ee52-c046-49b8-a9f6-b9686127daac": [
            "2cfb6ada-7bf7-41a8-a43e-2fff1d9f0683"
        ],
        "79d1e307-d4b0-4df3-a41a-07af7c1e7339": [
            "2cfb6ada-7bf7-41a8-a43e-2fff1d9f0683"
        ],
        "d9be8b48-9a91-45be-9a9a-065fffdf89a0": [
            "b0b9528b-a6a0-4ed6-a4a6-06431482a27f"
        ],
        "96220907-da7a-42bf-8e08-123a4c7851c1": [
            "b0b9528b-a6a0-4ed6-a4a6-06431482a27f"
        ],
        "29b2f76f-a356-4aca-af41-952cef5c4154": [
            "fb3b5325-b896-476f-8b2c-a577f08fdab5"
        ],
        "e09d9fdc-1d6f-4876-903e-ba03115f501b": [
            "fb3b5325-b896-476f-8b2c-a577f08fdab5"
        ],
        "393b6491-edea-4f45-9af2-3b9c730a233f": [
            "99204f19-2c5c-4127-8f3d-a010f81722c7"
        ],
        "f774c312-0052-4ef1-bbd3-1824da37d1fe": [
            "99204f19-2c5c-4127-8f3d-a010f81722c7"
        ],
        "69c10e03-204d-41e2-a355-a1cebc2a1193": [
            "cb1cc4dc-96ab-438a-9871-86a6ddc882fc"
        ],
        "fc06444c-f6eb-4819-979b-d3a02060cdf5": [
            "cb1cc4dc-96ab-438a-9871-86a6ddc882fc"
        ],
        "7a98d460-3969-4b45-984a-c0b0af7d0b3e": [
            "f3d01534-038f-4360-a669-d281788ec33e"
        ],
        "2e309c86-bead-4e35-99c4-de504776f2aa": [
            "f3d01534-038f-4360-a669-d281788ec33e"
        ],
        "bbb429b7-7a6d-4fd3-9af5-a230a96eb093": [
            "651e6388-5664-45a2-a733-673396de7753"
        ],
        "9bb1b232-40de-4559-bff4-fea78312ee45": [
            "651e6388-5664-45a2-a733-673396de7753"
        ],
        "90b72fe5-0196-4153-89da-f3b8ff1585c6": [
            "91ee936c-a55a-4ebc-904f-8cb45c03669d"
        ],
        "082c78b5-d821-46af-a929-6bf3d5c7dfe2": [
            "91ee936c-a55a-4ebc-904f-8cb45c03669d"
        ],
        "da52716b-8411-4703-8afc-2540afaa8e96": [
            "ef88c71a-20ff-43aa-adf8-94405c21010c"
        ],
        "c3577ecd-7b24-4a0e-847f-317a44a7b344": [
            "ef88c71a-20ff-43aa-adf8-94405c21010c"
        ],
        "38027964-7fdc-4ff5-ad00-b5607645ad5c": [
            "bda71e34-4101-4ba4-9286-ad4bf3b77e6c"
        ],
        "3c688d68-a361-412c-87eb-7b165d6059de": [
            "bda71e34-4101-4ba4-9286-ad4bf3b77e6c"
        ],
        "e5e95cce-0782-4edb-8ab1-a7a9ec0f58d5": [
            "07ac20f9-e0d4-4b1e-a320-37147db3f5d2"
        ],
        "0c484f41-d088-4c8d-a909-fb3986000545": [
            "07ac20f9-e0d4-4b1e-a320-37147db3f5d2"
        ],
        "cfb2807d-3a63-4ca7-8c05-ceb3052eff27": [
            "e02b28af-bb3a-4bf1-82e4-94b8dcf3bcfe"
        ],
        "c33dc332-b76f-41ab-836f-1271c66478b2": [
            "e02b28af-bb3a-4bf1-82e4-94b8dcf3bcfe"
        ],
        "d1e32e70-dfad-400a-a216-7ab6d04bb20b": [
            "3070edc7-5e65-48b4-a29b-98ec52601e43"
        ],
        "b596053c-79ec-45e2-ab97-306130ee0cbc": [
            "3070edc7-5e65-48b4-a29b-98ec52601e43"
        ],
        "798e9809-1fcd-41f9-ada1-3c5ad8b2c124": [
            "8d8f1dbd-648f-44c6-a554-93beec1ddd73"
        ],
        "e71ee23e-5d35-4f17-92f4-c853993352ef": [
            "8d8f1dbd-648f-44c6-a554-93beec1ddd73"
        ],
        "8e81b9b2-0fff-4295-8e58-edd23f62b2f4": [
            "49ffb5b3-396b-4eb2-8d5d-bc1457e1a861"
        ],
        "a6807b19-7b57-4e10-a01f-8a838b5e77c6": [
            "49ffb5b3-396b-4eb2-8d5d-bc1457e1a861"
        ],
        "4914dfc0-2187-4dab-abe7-b9a9b8bdc464": [
            "e1e7873e-ffb5-4bd7-bf29-cf72884955de"
        ],
        "1e102c09-361c-4e0f-a669-5d9b203671e4": [
            "e1e7873e-ffb5-4bd7-bf29-cf72884955de"
        ],
        "b5db08e6-f7ea-4df2-ac55-ec7303a41a60": [
            "5ea3e811-4056-4992-8520-eaf85d59c2be"
        ],
        "41b35444-2c28-4fef-81c0-0213ad9ada38": [
            "5ea3e811-4056-4992-8520-eaf85d59c2be"
        ],
        "632042b8-f965-4e45-bccc-442e5f616af0": [
            "e258aa7a-c142-498a-baa7-c6b7a1c0187c"
        ],
        "b58019ad-dcf0-4a36-9748-37b86c70efea": [
            "e258aa7a-c142-498a-baa7-c6b7a1c0187c"
        ],
        "f21a1cf3-2637-4711-b1ca-ddc4e86ae1b6": [
            "019e503c-f173-46b2-9ecb-d07da755c3a4"
        ],
        "3f9bfe9f-8cca-49ec-8801-6146345c73b1": [
            "019e503c-f173-46b2-9ecb-d07da755c3a4"
        ],
        "3dc0aa33-4afb-40a1-b4ee-773d5bc80f49": [
            "72eadc9e-92ff-4176-851a-44f42bb07428"
        ],
        "a5ebe3eb-65bf-42cc-af60-21b800a6d1f6": [
            "72eadc9e-92ff-4176-851a-44f42bb07428"
        ],
        "a54ebbc6-5c08-4fcc-84bf-51ded8ec8642": [
            "b960a7eb-5204-4f99-9473-82fe17dfc61e"
        ],
        "c86f1472-be6b-42a8-8991-da44fe9a96dd": [
            "b960a7eb-5204-4f99-9473-82fe17dfc61e"
        ],
        "adb73783-2bff-4936-94f8-85e9e2aa6369": [
            "2a48f762-5834-4aed-aad4-d9d6b5db1040"
        ],
        "d0240698-2084-4130-a0a6-a7d92da1d247": [
            "2a48f762-5834-4aed-aad4-d9d6b5db1040"
        ],
        "3a3307e5-726d-4d2a-b00b-74d4f9b6cdff": [
            "ae55b3a3-ef45-43e2-823f-04d776f09da4"
        ],
        "75584f2f-42fc-407d-874a-d0eaa4dbbda3": [
            "ae55b3a3-ef45-43e2-823f-04d776f09da4"
        ],
        "832f9f80-8177-434e-a042-6718a00bfe4b": [
            "7229ae73-1db5-4bb3-b204-80daf6c13578"
        ],
        "353756af-c641-4dfc-8e25-55060f0a9d4c": [
            "7229ae73-1db5-4bb3-b204-80daf6c13578"
        ],
        "3ce341e4-d1e9-49e3-8297-d116c3f43ed6": [
            "5caeceef-e88b-4cf7-aa5c-c0f47f91b628"
        ],
        "54e17a88-24b4-472c-a9d4-4338976d4619": [
            "5caeceef-e88b-4cf7-aa5c-c0f47f91b628"
        ],
        "61beb636-46ba-456d-a777-33f1ec2b8fd2": [
            "711db2c2-8063-4f1e-b8f3-9c93dbaa1b3b"
        ],
        "2f2e7878-40f4-41ee-8db5-a033fa7dda6c": [
            "711db2c2-8063-4f1e-b8f3-9c93dbaa1b3b"
        ],
        "66f43b02-73a0-4f2d-b62c-6918241ca240": [
            "86121a35-cd6b-478e-8e3a-85a9101b3eda"
        ],
        "36e2e533-279f-440d-8b58-99bf00a469b5": [
            "86121a35-cd6b-478e-8e3a-85a9101b3eda"
        ],
        "8a510204-f12f-47ed-ad04-7c30375c0f68": [
            "60ad83e8-a4e3-44bc-8847-296f3162ea52"
        ],
        "2879e9f8-6639-4ad4-b3db-307f82354e5d": [
            "60ad83e8-a4e3-44bc-8847-296f3162ea52"
        ],
        "2259fa3c-01bb-413e-a368-b2348ab658e3": [
            "12a77f5b-be8f-4c0b-af16-0be04d074aa1"
        ],
        "e66e24c5-cdeb-4b42-bd0d-83532d8aa8e8": [
            "12a77f5b-be8f-4c0b-af16-0be04d074aa1"
        ],
        "feba3902-986a-4c1b-a823-5e55b89fd7ee": [
            "0b3897e9-9ed6-4b3d-9467-044d4f65b217"
        ],
        "da6126f5-94b4-4b47-b2a0-ee6bace80306": [
            "0b3897e9-9ed6-4b3d-9467-044d4f65b217"
        ],
        "9f830925-6ced-4865-b875-e965839ee526": [
            "62eac653-f08d-40c7-a133-0a4d6f36f7cb"
        ],
        "e98712e2-2e63-4eab-8ba5-a951640e5711": [
            "62eac653-f08d-40c7-a133-0a4d6f36f7cb"
        ],
        "3a8c5782-f80f-47bc-b395-d02e3a6a7a32": [
            "ee6a8cc6-bbf5-4278-87e9-ccc3e9475026"
        ],
        "d24e8f81-3262-4184-8162-08885408db5d": [
            "ee6a8cc6-bbf5-4278-87e9-ccc3e9475026"
        ],
        "e3047da0-c55a-49e9-be6b-8df5b0470515": [
            "c1088fa4-765c-4e23-96a7-f7b4658750eb"
        ],
        "c612c7b9-ff4d-4787-9682-cfdd9b3a28a1": [
            "c1088fa4-765c-4e23-96a7-f7b4658750eb"
        ],
        "16a2ead7-7c89-4135-8204-714f3642c7d2": [
            "c7103200-e8ff-40d3-ae22-6ab55e4b7178"
        ],
        "e61979a3-9f5f-4629-8a3b-067895e5a16d": [
            "c7103200-e8ff-40d3-ae22-6ab55e4b7178"
        ],
        "58612c9d-dd7a-4c9e-80b7-d695795a63fc": [
            "fbf12b71-8ef8-46b7-a5cc-9b1bad0852f1"
        ],
        "266f0637-fc2c-4b3a-bf2b-be497d64b4a6": [
            "fbf12b71-8ef8-46b7-a5cc-9b1bad0852f1"
        ],
        "7b407290-a2f5-4c09-990e-4afc7f375be3": [
            "170c2e34-c5da-4117-ad6b-de1a602e95a8"
        ],
        "ccc77ec4-a43c-4b13-ab65-d3aeb336ebb0": [
            "170c2e34-c5da-4117-ad6b-de1a602e95a8"
        ],
        "ac1c2976-d794-41e0-ad5d-564e7a1d8d0c": [
            "ace2a4ee-5cff-4261-86a9-4ca603b03026"
        ],
        "475c3dec-9c33-4a9d-bfa5-4c7329a4fd97": [
            "ace2a4ee-5cff-4261-86a9-4ca603b03026"
        ],
        "e3fc049d-f4c7-4722-9d52-d8c7239996ce": [
            "ab16e6b4-6fd8-41bb-a03c-da4e25c8fb0c"
        ],
        "8bc88cd1-380d-4b37-81f8-d08c43fcd810": [
            "ab16e6b4-6fd8-41bb-a03c-da4e25c8fb0c"
        ],
        "0f95384e-7357-49c0-ba7f-ac209a4de6d0": [
            "bb0da904-ff8d-4f21-b6c6-4f77dca18972"
        ],
        "752a1247-cab2-4e16-a8eb-2a7fdf6168b0": [
            "bb0da904-ff8d-4f21-b6c6-4f77dca18972"
        ],
        "f93569a3-726b-42e0-a26f-71dce182d3d5": [
            "39ab13ac-ed9e-48d0-9c33-51b6d23d3ed1"
        ],
        "6d9a1c95-0baf-48e0-b103-dbf2fe121260": [
            "39ab13ac-ed9e-48d0-9c33-51b6d23d3ed1"
        ],
        "df3d44b7-875b-4e18-b650-5b3710b649f8": [
            "4c5acc7c-4398-4515-864f-b4aed9ee9dd9"
        ],
        "d456bf84-9c81-435f-9ca5-46cb64727a5c": [
            "4c5acc7c-4398-4515-864f-b4aed9ee9dd9"
        ],
        "114abf11-1ff1-4258-acd8-885056bb2fd5": [
            "8690e8ca-6675-459b-bdb1-660c49a04890"
        ],
        "46569864-ca8c-4f03-aeed-eaa78fcb819d": [
            "8690e8ca-6675-459b-bdb1-660c49a04890"
        ],
        "1168b393-71d6-4bb0-b16b-7db68e38e7f4": [
            "e9f100ee-f241-4182-82e7-d384e489717f"
        ],
        "ed4569cb-1d35-4905-963b-9b93da217929": [
            "e9f100ee-f241-4182-82e7-d384e489717f"
        ],
        "81a7c463-373e-48b9-986f-e8681fce6476": [
            "9f936f2a-daa6-43aa-89a4-186e72d4eb95"
        ],
        "4a7a7b82-212f-45ba-b6b5-e87c688782bf": [
            "9f936f2a-daa6-43aa-89a4-186e72d4eb95"
        ],
        "32b7257f-1baf-466b-8a92-e199819bd57f": [
            "0e8f0a87-7a57-4659-bf38-fda8bb61cb4c"
        ],
        "08639778-13ba-48a0-83ca-b2b194e98fbb": [
            "0e8f0a87-7a57-4659-bf38-fda8bb61cb4c"
        ],
        "8c174f80-fdee-40a7-b55c-7e7c6913ef68": [
            "d8658a00-d2b8-46af-9309-13818813e377"
        ],
        "6a7e0d75-0d81-4b29-8f35-efaa85f3324d": [
            "d8658a00-d2b8-46af-9309-13818813e377"
        ],
        "e87fca33-4188-442a-a8bf-2a3cf2a516f4": [
            "bd7d57fb-ddba-4ab5-b6f2-6e6f0369d74f"
        ],
        "06159a75-d764-4e01-a46f-49cf83c24fff": [
            "bd7d57fb-ddba-4ab5-b6f2-6e6f0369d74f"
        ],
        "55e9e5cc-c8cb-4477-ad83-e3f775caa31a": [
            "84a3ab73-7bd0-466b-999b-ca716be02494"
        ],
        "cd066a5e-b5b1-466b-945c-532b5da3372b": [
            "84a3ab73-7bd0-466b-999b-ca716be02494"
        ],
        "9075d957-cf21-4de2-bb55-5c8cc144b894": [
            "ad22cbab-593c-404b-9624-73c17396cc33"
        ],
        "746fbf50-d0d2-4fb7-93e4-36854b0c0c00": [
            "ad22cbab-593c-404b-9624-73c17396cc33"
        ],
        "2a2d397e-88fb-44f8-bfef-ffcbe07733e6": [
            "ed588c9c-d7d9-4433-a920-145c240b7a71"
        ],
        "9e9cbfbd-e4b4-4d86-9b26-d99452c12dec": [
            "ed588c9c-d7d9-4433-a920-145c240b7a71"
        ],
        "d97274fc-aebe-449b-9752-9d9ef736ff1a": [
            "5915d0ba-517b-46ca-9140-023e0d445120"
        ],
        "c881ea7f-5135-45bb-b7c8-2f975b74b90a": [
            "5915d0ba-517b-46ca-9140-023e0d445120"
        ],
        "d4e02a55-3f61-4c74-b96a-7ccbfdb491fe": [
            "e4e5ec3b-d43f-4286-990c-823273547552"
        ],
        "8cb864fc-86aa-442d-a10b-1330810ae161": [
            "e4e5ec3b-d43f-4286-990c-823273547552"
        ],
        "b0ec4672-3417-44e5-9fb4-5da16352c764": [
            "e4e5ec3b-d43f-4286-990c-823273547552"
        ],
        "68159d91-6ec2-4838-b457-422b91aea363": [
            "e4e5ec3b-d43f-4286-990c-823273547552"
        ],
        "2c2d8177-9333-4734-b9fc-d39db08ffe97": [
            "797ffd19-75db-4dd4-9342-a1daeae2397b"
        ],
        "8e1f9a0d-1c0b-4acb-9f93-4610467e0e37": [
            "797ffd19-75db-4dd4-9342-a1daeae2397b"
        ],
        "3630d05d-e95e-4de8-ab04-c750f19091f6": [
            "683fcad0-2090-4659-a55c-c86d1cbfa2c4"
        ],
        "eca24b82-a03e-42a8-9ffb-9267a780a1db": [
            "683fcad0-2090-4659-a55c-c86d1cbfa2c4"
        ],
        "0ff63a35-fa15-40f9-911f-cb5d1c2b270e": [
            "5f0de405-2959-4a5f-8b70-7c17eb9ece49"
        ],
        "713e381b-1408-4805-b42a-617153a7ac02": [
            "5f0de405-2959-4a5f-8b70-7c17eb9ece49"
        ],
        "667f4f8b-e2a7-469e-bf35-cb7f98435015": [
            "5676fd4f-d2cc-443e-ae1b-850d713abe8e"
        ],
        "b6c43a08-a7e4-4b24-a956-ae60e842eaa6": [
            "5676fd4f-d2cc-443e-ae1b-850d713abe8e"
        ],
        "e7b6c848-2c1d-45c8-b5e5-45c7270b3119": [
            "962eea72-9d45-42b7-ab2a-9aaa3b3e8caa"
        ],
        "bb179de5-4556-4646-ae08-6e15d7367bf3": [
            "962eea72-9d45-42b7-ab2a-9aaa3b3e8caa"
        ],
        "a87891a4-3f3b-4099-b984-786181fbec01": [
            "4eb01ca4-95cc-47de-ba1b-708534cee678"
        ],
        "e1d14d2c-956a-4062-a6b9-6493322ccb44": [
            "4eb01ca4-95cc-47de-ba1b-708534cee678"
        ],
        "949b4a7d-6bcf-4bcd-aa48-a686fe3dc0c1": [
            "07385b10-b2c4-46d3-bfec-8e556374efbe"
        ],
        "b0138896-4de9-4e75-b5fa-16372ed53737": [
            "07385b10-b2c4-46d3-bfec-8e556374efbe"
        ],
        "6e3e88a4-d30d-44c6-8006-49c815450529": [
            "9d50bff6-9daf-426d-8cf1-5c3054a23a1d"
        ],
        "0da5e6e7-ebed-4986-ad67-e94de47f0610": [
            "9d50bff6-9daf-426d-8cf1-5c3054a23a1d"
        ],
        "b7338f7e-8c8a-4e73-b839-6272d926d485": [
            "94e7b86f-20a6-4258-b148-315fbbe6829c"
        ],
        "04b511da-bc73-4184-bdec-a09d85005ed1": [
            "94e7b86f-20a6-4258-b148-315fbbe6829c"
        ],
        "bf9cb9bf-927a-4493-9044-71023d1a9a97": [
            "2c0e30b0-4e91-4c54-a074-c05ae91b3a60"
        ],
        "6eb44506-1ab6-4547-90fe-8b841781d2c5": [
            "2c0e30b0-4e91-4c54-a074-c05ae91b3a60"
        ],
        "895b02cd-c4e5-4bfb-8bd5-06de8870f92f": [
            "d6dd7474-ee7a-4280-8eea-a507b5949a7f"
        ],
        "dd9257c4-39a7-4062-9ce1-41989e0c5e0d": [
            "d6dd7474-ee7a-4280-8eea-a507b5949a7f"
        ],
        "fc37c54f-31e9-4d9f-a0a9-9816c0c0d855": [
            "15ffee5e-49a2-4237-b19a-2b67dd59a61b"
        ],
        "04babad9-563f-4f94-9012-d5a8a3e8f4d9": [
            "15ffee5e-49a2-4237-b19a-2b67dd59a61b"
        ],
        "4695a2e4-c4c0-4267-8d42-75b0636d4de8": [
            "160e725c-38a0-4617-a42d-343f8209a88e"
        ],
        "15e3cdbe-656e-409f-ba9f-8e5f86201ca3": [
            "160e725c-38a0-4617-a42d-343f8209a88e"
        ],
        "6d32bf8a-9f66-47f1-9ca1-2f818382ffe1": [
            "c77eb138-7475-4418-ba16-ebf60343fccc"
        ],
        "a6492ccf-a09b-477d-ae84-577fcf5fabd9": [
            "c77eb138-7475-4418-ba16-ebf60343fccc"
        ],
        "80f05b53-be47-4e90-8245-8fb8e8ed8f6f": [
            "335ddbc6-e713-4fd3-b426-1d0978dc4e54"
        ],
        "a49ab74f-2804-4b0a-8864-ebc30ea64488": [
            "335ddbc6-e713-4fd3-b426-1d0978dc4e54"
        ],
        "c982ad73-6282-40be-bcb2-97a2a24160df": [
            "c054f750-f552-4bef-a2c1-dc9fb6d33367"
        ],
        "02a3cc1a-a0ab-4adb-bc51-3c21ec481160": [
            "c054f750-f552-4bef-a2c1-dc9fb6d33367"
        ],
        "8db50e5c-c8d7-4c4c-862c-a6797e7e3e6f": [
            "cfe875dd-fedf-44b3-9efa-e1609b8a1faf"
        ],
        "9b6f3584-626d-488d-938e-9aa1779ddc82": [
            "cfe875dd-fedf-44b3-9efa-e1609b8a1faf"
        ],
        "54ceb8af-c4c3-47fc-a123-bb6cd19643e0": [
            "d432778e-a36d-40e1-8a6b-ccda85f88db5"
        ],
        "14dbeea3-bd1b-437c-a684-66b2318b14d1": [
            "d432778e-a36d-40e1-8a6b-ccda85f88db5"
        ],
        "8d77d2a2-5ae8-4aa2-bbba-25e4418c2e0f": [
            "c52985d2-6588-48e3-9768-aa26b2627119"
        ],
        "db107d7e-b4e3-4022-83ef-5e7e40be3cd8": [
            "c52985d2-6588-48e3-9768-aa26b2627119"
        ],
        "3a83aa56-d76f-45d3-8980-e74c08ad8a72": [
            "46afc16d-e068-47ed-a8c1-7ade6f0a3307"
        ],
        "a8295e1c-e2d4-4d98-83bc-e8f0f87f70ed": [
            "46afc16d-e068-47ed-a8c1-7ade6f0a3307"
        ],
        "f51eb4c5-5c01-4843-a27b-c1950c7116d4": [
            "480f6e47-db8c-4099-8e43-100498aee253"
        ],
        "1808a6b3-b84d-45f4-8ac1-44b0805a19f0": [
            "480f6e47-db8c-4099-8e43-100498aee253"
        ],
        "2f59aec1-45f5-49e7-aac8-129001a1ebd3": [
            "469e0a1d-97b5-4d60-8fcb-e629cf7cd0e9"
        ],
        "d40c4676-1d9a-4ecd-8452-a72dfcf53cde": [
            "469e0a1d-97b5-4d60-8fcb-e629cf7cd0e9"
        ],
        "338da2c0-f42a-4f14-9236-8c560beba869": [
            "38e8afd7-53cd-409a-bf5e-e9eb438e5b3c"
        ],
        "7225f03a-b629-4596-861e-bf92ebfaaae7": [
            "38e8afd7-53cd-409a-bf5e-e9eb438e5b3c"
        ],
        "b6fa7703-ce97-44df-be66-8bd044cf91d0": [
            "d98febd6-0870-423a-937d-1eb95deb8a56"
        ],
        "532e4d20-882d-454d-8a45-416647faa8bf": [
            "d98febd6-0870-423a-937d-1eb95deb8a56"
        ],
        "b25be35a-ec61-41db-b347-7b4c2794839f": [
            "51440d6a-b324-425f-94e8-3ae8d4a4c83d"
        ],
        "bebda70c-e225-4afd-af9f-7c796bd99955": [
            "51440d6a-b324-425f-94e8-3ae8d4a4c83d"
        ],
        "a5df538d-e3b5-41cc-8f31-5dd54a33e5ff": [
            "31c59f74-e1e4-49a0-9460-24d31ce05fdf"
        ],
        "d7ec1695-5744-4400-b7ae-6fa40418c0ca": [
            "31c59f74-e1e4-49a0-9460-24d31ce05fdf"
        ],
        "122800a2-ef46-473a-b0e7-58555c298dc1": [
            "1fe4a4df-c48a-4de0-9087-863c88e5c13a"
        ],
        "2285a409-15ab-4e17-81ff-a3dab5f10256": [
            "1fe4a4df-c48a-4de0-9087-863c88e5c13a"
        ],
        "08199d87-ddad-4438-9ed7-26c4ae27f7ca": [
            "96005992-b3c6-4a81-a7c6-b79dc643c999"
        ],
        "db8e2723-9d0f-4093-b62b-df9d81ee818e": [
            "96005992-b3c6-4a81-a7c6-b79dc643c999"
        ],
        "0620e33f-6d41-4579-8baf-1c519bb37f02": [
            "96005992-b3c6-4a81-a7c6-b79dc643c999"
        ],
        "5b62c036-9863-40ae-ab40-bf9c6016af6a": [
            "96005992-b3c6-4a81-a7c6-b79dc643c999"
        ],
        "276cc1d3-4629-4d18-ab4c-95ae0613de37": [
            "96005992-b3c6-4a81-a7c6-b79dc643c999"
        ],
        "1766f593-04bb-4e1b-9083-b9c6191b6595": [
            "96005992-b3c6-4a81-a7c6-b79dc643c999"
        ],
        "091fa6f2-9518-4f93-98c5-c69d04d52b56": [
            "96005992-b3c6-4a81-a7c6-b79dc643c999"
        ],
        "fbf2b23f-93e0-406b-8c1d-4fa84f3d802b": [
            "96005992-b3c6-4a81-a7c6-b79dc643c999"
        ],
        "9670396c-4dbe-4d43-bdcd-af745a0f0a01": [
            "96005992-b3c6-4a81-a7c6-b79dc643c999"
        ],
        "1b62906e-e39f-4f0d-b85c-458b4afd9384": [
            "1a64be70-8cc4-4d36-b155-543529579151"
        ],
        "62a638b5-56a4-497a-a7e7-5d87cee4e7b0": [
            "1a64be70-8cc4-4d36-b155-543529579151"
        ],
        "475dbcde-25f6-45e3-9cbd-cbdca4a5ded2": [
            "0f20d391-ea2d-43d1-9939-1e3aa94d073b"
        ],
        "86eb00f2-e206-4e3b-8616-5b9ee8095eaa": [
            "0f20d391-ea2d-43d1-9939-1e3aa94d073b"
        ],
        "f9ac6f5b-0b6c-4637-a8db-d7f96b1009fd": [
            "c2c8ace5-136b-46b5-815f-dad7fe9be1fd"
        ],
        "69cc25d2-20ca-4ecb-a8ba-62b75d771bd3": [
            "c2c8ace5-136b-46b5-815f-dad7fe9be1fd"
        ],
        "81ccbd6f-0219-419c-8d5b-f7c513c90215": [
            "4af4cb8b-4bd3-46e9-82b4-ffe63ff27b23"
        ],
        "94fc7842-0456-4292-b02a-acf514a361da": [
            "4af4cb8b-4bd3-46e9-82b4-ffe63ff27b23"
        ],
        "b5ea5750-b978-407a-a131-926f2686e61d": [
            "34720444-6bc4-4adc-8726-b496bfcb49c0"
        ],
        "2766fc0a-a47a-4c82-a25f-2ca479c14ca0": [
            "34720444-6bc4-4adc-8726-b496bfcb49c0"
        ],
        "596da1d5-761d-484f-802c-b86e088fea5d": [
            "4e3a2c09-0a4b-4bd3-89f7-0c86bc70f4ab"
        ],
        "6e998006-306f-4275-9ae7-19e5126934fb": [
            "4e3a2c09-0a4b-4bd3-89f7-0c86bc70f4ab"
        ],
        "7f205a2e-e8e2-4545-8429-c301f06b7868": [
            "4e3a2c09-0a4b-4bd3-89f7-0c86bc70f4ab"
        ],
        "1f76e0b4-3d57-474e-8144-d51993968ef6": [
            "4e3a2c09-0a4b-4bd3-89f7-0c86bc70f4ab"
        ],
        "4b79de81-1b14-466c-aadf-0a53d827b2e8": [
            "4e3a2c09-0a4b-4bd3-89f7-0c86bc70f4ab"
        ],
        "6c3bfc21-d4bd-429c-94cc-940a3b711425": [
            "b2e42ad0-f37d-467d-a00d-0ca9797c3f56"
        ],
        "73af72ce-0261-4b7e-be71-1def78e03020": [
            "b2e42ad0-f37d-467d-a00d-0ca9797c3f56"
        ],
        "4db43461-5609-46b4-a625-51108f469477": [
            "9cd1363b-cfbf-4d45-933e-e2c13d587253"
        ],
        "6afe6ca0-075f-4889-9151-efc79992e0ae": [
            "9cd1363b-cfbf-4d45-933e-e2c13d587253"
        ],
        "218fe62f-f5c6-47d7-bfb9-65933e82fbd9": [
            "20f90da8-0442-4c2c-b853-cfe40fab4730"
        ],
        "af149d25-5296-4899-85fa-84aebf068e85": [
            "20f90da8-0442-4c2c-b853-cfe40fab4730"
        ],
        "cafac4b3-e2e2-4742-b7be-0108a66cd60e": [
            "8b829944-ced6-4ffb-8afe-2a6ae314dbf5"
        ],
        "8e9d7c27-9f42-4104-9e88-32b52dd8632f": [
            "8b829944-ced6-4ffb-8afe-2a6ae314dbf5"
        ],
        "57ff6cb7-8f24-42af-a3b7-df236b97494b": [
            "35c7b17d-0850-4136-bd47-cb19329c2418"
        ],
        "b337e054-9d86-46e3-8c17-b7aebea9d10f": [
            "35c7b17d-0850-4136-bd47-cb19329c2418"
        ],
        "fc4b50d9-9241-42e7-b1ee-6971d6b3dced": [
            "6f35bbf5-9a9f-4cc9-9e5c-8efa8312fe46"
        ],
        "bad1d6bf-1dab-477b-a7b1-52c3fae061e0": [
            "6f35bbf5-9a9f-4cc9-9e5c-8efa8312fe46"
        ],
        "292696f8-bd0a-4130-8bbc-57b46f908ce4": [
            "862ab291-aabf-416f-9f26-9bda4a4849bf"
        ],
        "b6a82f1d-e0c8-4968-b1c5-1b6db251a459": [
            "862ab291-aabf-416f-9f26-9bda4a4849bf"
        ],
        "092efc77-b4b5-42bc-9d17-c56eedf1e696": [
            "e6fa45c9-f2f7-4349-b78b-9b45e5d9e34c"
        ],
        "9e2c950b-a419-4c93-a865-672e11de3233": [
            "e6fa45c9-f2f7-4349-b78b-9b45e5d9e34c"
        ],
        "41a632e7-49fc-4900-bb4a-e8d6fc61e0b7": [
            "7f2e099f-02bd-4072-9c77-6588af614ac0"
        ],
        "0c689663-ff04-4222-991a-f62f47e88235": [
            "7f2e099f-02bd-4072-9c77-6588af614ac0"
        ],
        "ea32513e-adbc-4608-8d6c-21549d0eb5dc": [
            "d3ad3ab8-21ad-4753-86ca-38dcb6dfed1d"
        ],
        "87312900-6264-43e8-81f3-de36a011e826": [
            "d3ad3ab8-21ad-4753-86ca-38dcb6dfed1d"
        ],
        "48ead8da-eaa9-4772-ae75-33701b070e62": [
            "8e09bc01-b16e-4e9a-aaa4-8e5bd23efd1d"
        ],
        "85a72149-866b-4f47-896a-015060ebdb5e": [
            "8e09bc01-b16e-4e9a-aaa4-8e5bd23efd1d"
        ],
        "061ea14d-e5a2-4184-8b26-4de0b8d85b08": [
            "cfc9edd9-fbaf-48cd-a11c-7cd50856dc78"
        ],
        "88bfde33-5c40-402a-845c-f247ba7eced0": [
            "cfc9edd9-fbaf-48cd-a11c-7cd50856dc78"
        ],
        "5760f666-d7dd-41d3-8f53-1596d33aced1": [
            "254daae6-8763-47ec-893d-26f8cc1bfc67"
        ],
        "2bbc981a-61f4-4e79-ab88-a777ac1038c9": [
            "254daae6-8763-47ec-893d-26f8cc1bfc67"
        ],
        "7935a5b1-eb5d-4f84-94c7-7e311f349804": [
            "8565c47c-f5fd-4a06-a98f-2b38c448346f"
        ],
        "e9305d34-fb1d-42ce-b700-d548832656ee": [
            "8565c47c-f5fd-4a06-a98f-2b38c448346f"
        ],
        "df786523-b788-4e4f-8eff-6c6c86e68dba": [
            "9f0acc96-8732-4002-8e3f-3d8550fa967b"
        ],
        "d51b423b-feef-40ef-9f54-14090cc87536": [
            "9f0acc96-8732-4002-8e3f-3d8550fa967b"
        ],
        "4aa5e879-6fed-4413-96bc-4ad476babc3d": [
            "acea1daa-9a6e-4792-9fcf-dc6fe8aa73e4"
        ],
        "828786da-428d-44f9-8aac-9628d5fa09e6": [
            "acea1daa-9a6e-4792-9fcf-dc6fe8aa73e4"
        ],
        "099a971e-b58a-4e03-84e7-4e626d619c6e": [
            "2c01de33-31ac-4e11-9204-83b34992db94"
        ],
        "673e6d04-84c7-43b1-9d8a-1937f0ef0fa8": [
            "2c01de33-31ac-4e11-9204-83b34992db94"
        ],
        "b046c739-73d4-4223-bc37-eb398336ca80": [
            "fdfd3f34-82a0-4c3a-87d6-81bd4afd9b2f"
        ],
        "2f726a1b-1b1c-4606-916c-85b6fe517c02": [
            "fdfd3f34-82a0-4c3a-87d6-81bd4afd9b2f"
        ],
        "709dbf6d-6381-4a89-ae2b-6891ff27cbd8": [
            "9e23f533-aacc-4551-b3c6-92e95f1261e8"
        ],
        "efc72820-2bfa-4669-a21d-88f40892cccc": [
            "9e23f533-aacc-4551-b3c6-92e95f1261e8"
        ],
        "13bfc5fd-05c8-45b2-a38e-58d3d41cb39c": [
            "b6ff6a78-4843-4355-8cc4-b38422f9549b"
        ],
        "1532dd17-e924-4de0-9ea5-7ccedd6a125b": [
            "b6ff6a78-4843-4355-8cc4-b38422f9549b"
        ],
        "68713d88-4ad3-4ffa-9e0a-0cd532f1fdf6": [
            "370c3667-f0b6-416a-bad6-256178677801"
        ],
        "e67428f4-f822-4405-afd5-74fe672be6a2": [
            "370c3667-f0b6-416a-bad6-256178677801"
        ],
        "c6f9a6c4-b916-4656-88f4-6cf0647f182e": [
            "f6bf6e51-2164-46cc-a719-7a46199d0d25"
        ],
        "ffb9f3f7-a0f3-4d80-a1a1-6d815fee7ce9": [
            "f6bf6e51-2164-46cc-a719-7a46199d0d25"
        ],
        "d305b81e-e45a-4809-bf42-15eead753c7e": [
            "f6bf6e51-2164-46cc-a719-7a46199d0d25"
        ],
        "0de1bc4e-975e-460f-88c9-8e45136319c0": [
            "f6bf6e51-2164-46cc-a719-7a46199d0d25"
        ],
        "f28133cd-7fb6-40da-91a7-9d58a667fafb": [
            "f6bf6e51-2164-46cc-a719-7a46199d0d25"
        ],
        "cd1830fe-7128-4453-92e1-37f2a916bc91": [
            "f6bf6e51-2164-46cc-a719-7a46199d0d25"
        ],
        "85063366-4971-4981-9ab0-a6ab76608f46": [
            "f6bf6e51-2164-46cc-a719-7a46199d0d25"
        ],
        "49972e01-77fe-4cc4-96f4-1e1067d21dc9": [
            "f6bf6e51-2164-46cc-a719-7a46199d0d25"
        ],
        "54e6ba1e-d65e-4c53-bcd3-8fa3241c7d0c": [
            "f6bf6e51-2164-46cc-a719-7a46199d0d25"
        ],
        "e6360042-7bfc-405b-b59a-7ba252810970": [
            "f6bf6e51-2164-46cc-a719-7a46199d0d25"
        ],
        "9e66279b-d552-415c-8e34-d0d145aba54b": [
            "ff4fec03-af1b-41a5-8197-d968d21834d4"
        ],
        "64531d89-3a7b-4e3d-9e87-588d739f900f": [
            "ff4fec03-af1b-41a5-8197-d968d21834d4"
        ],
        "762829f5-6e23-4766-97b4-804af07a277e": [
            "1529b91d-6bf3-4301-9018-c97d2f2d3ac4"
        ],
        "9e27e484-233a-4112-bf26-12ac6e8cf31b": [
            "1529b91d-6bf3-4301-9018-c97d2f2d3ac4"
        ],
        "c74f0c86-4e31-483f-b685-8b19fb9747ec": [
            "ae07332e-a19d-4fdd-a939-5f27291e4e93"
        ],
        "c8154fd2-5e0d-43cd-85c3-436773ee32b4": [
            "ae07332e-a19d-4fdd-a939-5f27291e4e93"
        ],
        "6b95f697-42be-40cc-be14-fa30fca5fc2a": [
            "1eb66c8e-643e-4168-832d-2f0cc9d36f9c"
        ],
        "f3e22096-da53-42f9-881e-096e448f6ce8": [
            "1eb66c8e-643e-4168-832d-2f0cc9d36f9c"
        ],
        "b1ed2906-9640-4377-9de2-622e889ab26f": [
            "4ac8696d-5571-4d01-a5f7-76c77e4d89ea"
        ],
        "b13605ee-ba50-41f7-a944-f63606790a0d": [
            "4ac8696d-5571-4d01-a5f7-76c77e4d89ea"
        ],
        "bdbf2427-152a-43ef-87e4-0812da13141c": [
            "c2fb50aa-2ce4-4019-b291-f161445bea0e"
        ],
        "0fc1dba1-6b46-473c-be3a-964cc3ec6486": [
            "c2fb50aa-2ce4-4019-b291-f161445bea0e"
        ],
        "db769226-b775-4510-ba15-d85b4d53c4aa": [
            "08ebb830-a825-4091-aa71-debbdc302b2c"
        ],
        "7d85c81c-2f56-4be4-9f2b-e6292755a07f": [
            "08ebb830-a825-4091-aa71-debbdc302b2c"
        ],
        "a87262b2-3c04-482f-8e6d-8d42110f3707": [
            "44cf8606-51b6-45c4-81ff-23367d3d59d8"
        ],
        "e93250dc-77df-4a5c-9853-d03021bc5029": [
            "44cf8606-51b6-45c4-81ff-23367d3d59d8"
        ],
        "416ddba2-221d-4777-b4bd-1e040e74c905": [
            "a6b6c807-4ba5-4876-bbba-76b15abd1395"
        ],
        "321dbc49-5aa9-45b1-a0fc-b115ad331131": [
            "a6b6c807-4ba5-4876-bbba-76b15abd1395"
        ],
        "9f73620b-e7cc-4f9d-a6e7-e1ce00b3f84d": [
            "1ae39665-bb34-4d3a-8319-6184406178b7"
        ],
        "976d90c9-9e60-4016-a5a4-0d67690e580c": [
            "1ae39665-bb34-4d3a-8319-6184406178b7"
        ],
        "9973bd43-ca44-4e91-b25f-16927d69398e": [
            "452017f7-5110-4ca4-8787-2a9e5d65a9eb"
        ],
        "5754ecaa-1d52-49fe-a0ce-ef14ac50ae78": [
            "452017f7-5110-4ca4-8787-2a9e5d65a9eb"
        ],
        "cb7bb2d1-cbbf-4cb5-808f-ff939153d34d": [
            "b7387b1c-7e00-44f4-8f44-8dc2daf1a137"
        ],
        "b5e263f2-ad21-41c0-bea5-2bbac2fe2714": [
            "b7387b1c-7e00-44f4-8f44-8dc2daf1a137"
        ],
        "baceeb1c-7019-43d7-bbbe-3ef12df02f21": [
            "c95f9f31-e29a-4e7d-af7f-ba7c18be8f95"
        ],
        "a726d4f8-20b8-4f2e-b266-9c278ff3ee6d": [
            "c95f9f31-e29a-4e7d-af7f-ba7c18be8f95"
        ],
        "5d860af1-4136-4b8b-8e96-e98248bd9454": [
            "038db77a-be9c-4554-ae45-dfcef190f4e8"
        ],
        "5a0d3b55-e5c2-4572-95b5-2a57b822c811": [
            "038db77a-be9c-4554-ae45-dfcef190f4e8"
        ],
        "149db263-097e-4e2d-b876-7138ff0374f0": [
            "9689017c-cad3-499d-b519-abd0689b2491"
        ],
        "51e58b15-efa9-4be9-8687-d4aa3f8b0ff8": [
            "9689017c-cad3-499d-b519-abd0689b2491"
        ],
        "4c15171c-011b-4b47-ba78-e1ca6df9aaa0": [
            "bd200f05-c0de-48a5-a19e-8f524fb4baaa"
        ],
        "45c99fdf-4ab3-44a9-97b0-48b59fa76749": [
            "bd200f05-c0de-48a5-a19e-8f524fb4baaa"
        ],
        "683c89ce-1f79-4d73-8e1c-09ad38d28ecf": [
            "bf15ad7b-1ebe-4e59-a318-c1a6a6c091eb"
        ],
        "7bb3ab5b-a0ca-4357-a135-e860be39029c": [
            "bf15ad7b-1ebe-4e59-a318-c1a6a6c091eb"
        ],
        "8fb8e450-601d-4b69-ab4f-94e8b53c29a9": [
            "8f4381bd-3d5d-4743-8f18-faf9982b1279"
        ],
        "9d619532-56b8-4521-8efc-f3858a77e2b9": [
            "8f4381bd-3d5d-4743-8f18-faf9982b1279"
        ],
        "a100d70d-6a4e-41ab-b037-6bdc36e9c75f": [
            "295c183e-9e15-400b-a9d6-c27d10ecea4a"
        ],
        "f0477083-9e1f-49e8-9ccf-8f68cdf45b4d": [
            "295c183e-9e15-400b-a9d6-c27d10ecea4a"
        ],
        "0b922f76-c7a6-4dbf-99b3-2043c6f43f07": [
            "b4a51bb9-c270-4fb8-bf83-d392ff02a5da"
        ],
        "412bbbb9-dd45-44f0-b7a8-1502abc0c758": [
            "b4a51bb9-c270-4fb8-bf83-d392ff02a5da"
        ],
        "2c903d2b-4108-43fc-8b91-35d66b6c372a": [
            "cf482f2d-1f6f-4e95-8290-11ebb851fe37"
        ],
        "48c42f60-b4a3-413c-9432-0028dcdaa746": [
            "cf482f2d-1f6f-4e95-8290-11ebb851fe37"
        ],
        "458a6654-58a6-44ef-843b-45cff2342eda": [
            "044ff9f5-6fe2-4b72-aca4-5d6b4bb7808f"
        ],
        "3fe6f122-5c88-4abc-9aab-014866122cdb": [
            "044ff9f5-6fe2-4b72-aca4-5d6b4bb7808f"
        ],
        "165942a4-8e14-467a-9417-1020b23b4011": [
            "17473fdd-84e9-4b05-b823-af3c337e214a"
        ],
        "5690246b-c679-41f6-8452-5349ab1d522d": [
            "17473fdd-84e9-4b05-b823-af3c337e214a"
        ],
        "7de9c5f1-82fe-4a94-90cd-9ed0b7721f9d": [
            "0b414adb-08d3-458a-847c-ee6ca9262499"
        ],
        "a9a6206e-fc42-41af-ad84-cca720299aca": [
            "0b414adb-08d3-458a-847c-ee6ca9262499"
        ],
        "0ff09109-cc57-498d-8247-1a243ff8bd20": [
            "b3680ad9-c0b1-4ba6-874e-483646918d81"
        ],
        "2eb1e2de-ee53-4e3b-9a37-020075e17e24": [
            "b3680ad9-c0b1-4ba6-874e-483646918d81"
        ],
        "e64acac7-e77c-4af9-b00c-826d5f35a8be": [
            "a8b60efa-460f-4787-910a-0379cab25920"
        ],
        "8f89458e-361c-429e-b3c5-b9408a4ecbcf": [
            "a8b60efa-460f-4787-910a-0379cab25920"
        ],
        "90004619-7484-4f95-a7d4-0693a2ba809e": [
            "f722ead5-dba3-42e9-88a4-f18a6b7f9bf1"
        ],
        "f1d45a9d-296d-428d-81ca-e8f2669bf71b": [
            "f722ead5-dba3-42e9-88a4-f18a6b7f9bf1"
        ],
        "6bc52614-1771-4d9e-966b-de2fa9d00bc8": [
            "ac846ccb-1d5f-4abc-90d2-137838c752d3"
        ],
        "24df6a4d-a9e1-4fad-ac19-77b638e401e8": [
            "ac846ccb-1d5f-4abc-90d2-137838c752d3"
        ],
        "1c8f7624-365d-4d98-8953-b312c3b65987": [
            "80e280e4-11e8-44a0-847a-e1e07d42db20"
        ],
        "33e1c989-9dd4-4934-87a2-f66de8999c08": [
            "80e280e4-11e8-44a0-847a-e1e07d42db20"
        ],
        "522fcc24-44a2-467b-bcb0-acbb9ed95aa9": [
            "372e8c06-a453-4ab2-ac46-83013f98a9aa"
        ],
        "9c69f72a-2ba6-4981-bb3a-8cf2cb0b2f59": [
            "372e8c06-a453-4ab2-ac46-83013f98a9aa"
        ],
        "c2dfc80c-1184-4ddb-ae4f-ddaffd7a635a": [
            "afba90d7-2e98-485b-9af6-5a944b694e06"
        ],
        "7d80245e-04b0-4710-8991-4e8ffeb3ce48": [
            "afba90d7-2e98-485b-9af6-5a944b694e06"
        ],
        "2525a9ac-8b4a-4285-bbe4-a28d60bb548e": [
            "f75480c8-561c-46ac-9a4d-d727f923230f"
        ],
        "03f205d5-b4fe-4349-afb4-f035f847e693": [
            "f75480c8-561c-46ac-9a4d-d727f923230f"
        ],
        "e042fa45-abc6-4b07-aebc-72462f0d6dbe": [
            "6f4e6e02-ebd5-4158-b046-f940b4e06abe"
        ],
        "12c70957-9cfa-4c7f-bb50-d95089978659": [
            "6f4e6e02-ebd5-4158-b046-f940b4e06abe"
        ],
        "d592f2fc-1f40-442f-a1d2-a9a2e7ed5b01": [
            "5995504e-74cb-4714-b147-cec4a7e7a96e"
        ],
        "ccfd344d-f00f-4a9d-a4f8-af4c03492917": [
            "5995504e-74cb-4714-b147-cec4a7e7a96e"
        ],
        "e94d02ab-3596-4f86-a257-db48a651bfde": [
            "5da281eb-901d-4980-8664-6bbd35d7ffac"
        ],
        "646546ec-7486-400d-8d4e-64f95d113dd2": [
            "5da281eb-901d-4980-8664-6bbd35d7ffac"
        ],
        "d8482a72-4e7b-4e83-96b1-2ca3ca255871": [
            "7c153ea1-8184-4853-b318-94fa9e2b41ee"
        ],
        "6917fa8d-08a3-475c-ae53-fa54cfe1d16a": [
            "7c153ea1-8184-4853-b318-94fa9e2b41ee"
        ],
        "2c6348e6-577e-41f9-956c-90b294500eaa": [
            "b0a4db69-16c8-4e5d-a9a4-f61fcf78e275"
        ],
        "16320090-bbc2-4633-9791-e7db1326ec23": [
            "b0a4db69-16c8-4e5d-a9a4-f61fcf78e275"
        ],
        "af8c95ce-c262-4f1d-90de-c130d4cc19af": [
            "f178e299-b3ca-45c1-83c2-4160cbaf87b0"
        ],
        "0c545402-41f6-4c4c-b8cd-da5017a9206c": [
            "f178e299-b3ca-45c1-83c2-4160cbaf87b0"
        ],
        "d6e3e5c4-fd14-4a82-9174-8e98e035e65f": [
            "e30917ee-e8ad-4582-bfcc-feeb6ebb156c"
        ],
        "5704315a-8980-4fc7-b338-73e559d24a68": [
            "e30917ee-e8ad-4582-bfcc-feeb6ebb156c"
        ],
        "f0a61a14-378a-4a3c-aac5-9092510addd9": [
            "75695de0-e05c-4780-b18a-e2899af4fd67"
        ],
        "c87e70a0-7209-400c-a652-10083de53284": [
            "75695de0-e05c-4780-b18a-e2899af4fd67"
        ],
        "e9d77733-02c3-471a-8c3b-6c161cf5a80b": [
            "49be9df1-927c-494c-8b45-00fc1f454837"
        ],
        "6900360f-f27f-45a9-8ce2-509df3ff0971": [
            "49be9df1-927c-494c-8b45-00fc1f454837"
        ],
        "419c0704-9a73-4453-9224-594f30489f99": [
            "7e6f3263-a00a-4ae6-9004-441765c72e0c"
        ],
        "d5bb28c1-c07e-443e-905a-5f5d6ca89e79": [
            "7e6f3263-a00a-4ae6-9004-441765c72e0c"
        ],
        "79cee793-ad75-4238-99dd-fe1637a32b62": [
            "e694ad76-0086-43ed-8484-083072534364"
        ],
        "2cc9a56e-2943-4e8b-b72d-7555d431fcb6": [
            "e694ad76-0086-43ed-8484-083072534364"
        ],
        "8b196101-7d4f-458a-b522-7c026072eaf5": [
            "0dd26e96-e113-4de5-ab17-6d95c9bb8e27"
        ],
        "77a98426-e92d-4e9b-9848-ee5728435f26": [
            "0dd26e96-e113-4de5-ab17-6d95c9bb8e27"
        ],
        "60d4aac6-4370-41d4-9432-a569ac56ab82": [
            "4a4ee07e-9852-4615-9adb-dcee39215494"
        ],
        "196108ad-94d4-4437-bc67-6e20400975cd": [
            "4a4ee07e-9852-4615-9adb-dcee39215494"
        ],
        "7a16f1ff-058d-4e97-8a5a-a5e08fa556ff": [
            "6f0ce03a-1903-4b43-b44b-95e781cf2699"
        ],
        "4a481c83-85ca-486d-b3c3-519086e902f2": [
            "6f0ce03a-1903-4b43-b44b-95e781cf2699"
        ],
        "f46128e7-790f-47f8-baca-e3ca4221684e": [
            "aabc8e72-b147-4676-8ca4-3591a5e7b15b"
        ],
        "32bb9f4f-bea8-46c0-99f0-1cf84c025c22": [
            "aabc8e72-b147-4676-8ca4-3591a5e7b15b"
        ],
        "70e1bfe0-5e46-4f7b-b8e6-29d1d782ce34": [
            "6a71b2bd-16fe-45bf-837e-7e4ce2b1331a"
        ],
        "c6be1df4-4b8a-46bf-98fb-d02a838227c0": [
            "6a71b2bd-16fe-45bf-837e-7e4ce2b1331a"
        ],
        "7d4852b0-eec8-414a-b57c-4d13f90dc114": [
            "9d2f2b0b-b724-4a87-b77f-fb0fd080f1a6"
        ],
        "3062270e-8781-40f8-97f0-4e18c7ee87bf": [
            "9d2f2b0b-b724-4a87-b77f-fb0fd080f1a6"
        ],
        "15034cc2-d4e8-45a8-9e34-bbdea4bcde75": [
            "30a97f86-c31f-4c51-9320-835401cd8bae"
        ],
        "b8ffd34a-27fb-45a2-9180-ba4e84dacc5d": [
            "30a97f86-c31f-4c51-9320-835401cd8bae"
        ],
        "4351bb96-c867-4c0e-8008-e1aafbd104ea": [
            "1769ef33-b7e8-4c29-a63f-a1161fadf08a"
        ],
        "9c87ac30-89f8-4ffc-a2aa-242d718d942c": [
            "1769ef33-b7e8-4c29-a63f-a1161fadf08a"
        ],
        "64ecae78-97f9-40c1-a569-a00c55b58c64": [
            "f94e24ab-5f53-48d1-bac5-f360121870f7"
        ],
        "df969523-a6f9-45e5-8d2f-8afa14763452": [
            "f94e24ab-5f53-48d1-bac5-f360121870f7"
        ],
        "b48c9b8f-5e31-4860-9276-0fdcecb16509": [
            "1b28d587-84e7-4066-a1f3-975b948b66e7"
        ],
        "903ab68c-d7e2-4c1d-898d-3365b7d52150": [
            "1b28d587-84e7-4066-a1f3-975b948b66e7"
        ],
        "91e95589-a552-4a2c-9c13-29a6e5f78c0b": [
            "b47d567d-3127-4fdd-9226-84c17aee3356"
        ],
        "b3befe78-8f18-42fb-8954-c4f92da1c7bb": [
            "b47d567d-3127-4fdd-9226-84c17aee3356"
        ],
        "4ecc8f8f-f337-4cb5-9125-90acc22e3076": [
            "be0a9e07-0cd4-44ec-bb4d-de397b9a624c"
        ],
        "7b2b1f6a-0cea-4bf2-8bd8-5ba3df8a97da": [
            "be0a9e07-0cd4-44ec-bb4d-de397b9a624c"
        ],
        "c3dc7409-76c1-4091-bdea-67aef57b441a": [
            "ccd3ebe7-2e1e-4eb2-ac3f-fd07788b6ab5"
        ],
        "2f1b2927-6eab-4d9a-82ae-025615191e6e": [
            "ccd3ebe7-2e1e-4eb2-ac3f-fd07788b6ab5"
        ],
        "cbe9e607-9cbe-4559-81bc-3851d10a625d": [
            "0a7ace9a-1281-41ed-87ba-dd9173f5b33e"
        ],
        "9068dab9-709e-439a-9fd0-ac5b193193c1": [
            "0a7ace9a-1281-41ed-87ba-dd9173f5b33e"
        ],
        "768a1e87-2a4e-47bb-9ff0-b42004f0838d": [
            "eaf9f90d-6101-493c-b073-cadb166c7511"
        ],
        "024b7552-898f-4446-b608-e8c3c9afc136": [
            "eaf9f90d-6101-493c-b073-cadb166c7511"
        ],
        "8d0514a1-968d-48ad-a25a-d9373e184a79": [
            "2f8e0ae1-4fc3-430e-b9cb-72c885641c80"
        ],
        "1f50bf14-fcf6-4c28-8a72-d3cf2e2a9f7c": [
            "2f8e0ae1-4fc3-430e-b9cb-72c885641c80"
        ],
        "af9766ff-7bcc-44c9-b36c-3c925142e06b": [
            "576d03e2-7b09-47b5-acf1-6d0edf73255b"
        ],
        "ff256a89-58d3-4596-8c7d-7743dad863cd": [
            "576d03e2-7b09-47b5-acf1-6d0edf73255b"
        ],
        "b19faa0d-f4f6-4723-9f60-07bc6bb95191": [
            "9266ceae-e24a-4db7-95aa-2a6caf7ecda2"
        ],
        "5586f85e-2e29-4cd9-bc00-46598934d826": [
            "9266ceae-e24a-4db7-95aa-2a6caf7ecda2"
        ],
        "031da581-61ea-4ecd-9de6-963f503c15be": [
            "8643bc8c-0d77-45e0-b6cb-0fcaa972e8d7"
        ],
        "0b7438b6-5b77-48a7-a0d1-00f4930ebae4": [
            "8643bc8c-0d77-45e0-b6cb-0fcaa972e8d7"
        ],
        "4f55a342-5445-4de4-a768-fa35e699ff44": [
            "fd32ad23-9f8c-41d8-9d4b-7d4f709138ab"
        ],
        "e428a095-f085-49ac-87e9-3fd833bcc544": [
            "fd32ad23-9f8c-41d8-9d4b-7d4f709138ab"
        ],
        "403a621f-1940-4953-a56c-02355300d498": [
            "f1ea3cc9-a715-4603-915d-5b7752f820b0"
        ],
        "9388379b-1ea1-41a1-8aa4-f27ea601317a": [
            "f1ea3cc9-a715-4603-915d-5b7752f820b0"
        ],
        "14ae70d4-0454-461d-8b95-19ce50c59671": [
            "373e2b8b-8e7b-4b7c-9ea2-7e9211f9d779"
        ],
        "2177f27a-b9a8-4588-a719-67cf5c183163": [
            "373e2b8b-8e7b-4b7c-9ea2-7e9211f9d779"
        ],
        "b91d013a-0639-423e-939e-1fca62022e75": [
            "4ce5e4e9-59fe-4dbd-9d37-49a0b090e725"
        ],
        "1e240f3b-2e12-42ec-a5e1-8c50c2ced5a7": [
            "4ce5e4e9-59fe-4dbd-9d37-49a0b090e725"
        ],
        "e04b42b7-7fe4-4f0f-97a8-c2fa7bccc531": [
            "7da9d501-b09f-4514-a9a6-e56586b0848f"
        ],
        "365d6873-e4d6-47b4-a03e-bec5eb35fedc": [
            "7da9d501-b09f-4514-a9a6-e56586b0848f"
        ],
        "4007918b-5684-4c2e-aee9-207dc1b66cd2": [
            "bbdf7b97-1a09-4772-b0d5-c9e1887ef93e"
        ],
        "bb2b4b5b-d707-4518-9d9f-e9d51865dc36": [
            "bbdf7b97-1a09-4772-b0d5-c9e1887ef93e"
        ],
        "27fca8ef-92c8-4755-be02-6c304cc817d7": [
            "16c52537-bdbd-4729-a531-53d85816a0d9"
        ],
        "4c3e4ffe-70d5-4952-8c65-5f2aa41adbbf": [
            "16c52537-bdbd-4729-a531-53d85816a0d9"
        ],
        "56ed0355-990a-46ce-85b3-7d9bac1efb97": [
            "435de8cb-68c2-49cc-a9e1-4cc6860b488f"
        ],
        "59ae5358-40a9-4d4c-ac4d-30ddeaa002fd": [
            "435de8cb-68c2-49cc-a9e1-4cc6860b488f"
        ],
        "4c7780f5-8b4a-43bb-8d7b-c2801e87a058": [
            "509e0adb-6360-4ac5-b224-41983d25e341"
        ],
        "2eb9bd7a-eed8-4cb4-9492-1e70b4894e19": [
            "509e0adb-6360-4ac5-b224-41983d25e341"
        ],
        "6769e55d-caab-4314-a0ad-bfcc9e0dfc54": [
            "13cf9286-d472-4747-b5b3-5da53bf77d57"
        ],
        "fbb9c2c0-9967-443a-8657-157c7d2afc55": [
            "13cf9286-d472-4747-b5b3-5da53bf77d57"
        ],
        "210719f3-175b-437b-80e2-82f4fedbece6": [
            "ee739339-074c-4cf8-ae94-59f4752bdd5f"
        ],
        "e4e5ba5a-9012-4fd8-984c-8a30b99c1723": [
            "ee739339-074c-4cf8-ae94-59f4752bdd5f"
        ],
        "a2486d56-2863-4a2a-b667-92db9f64f7e5": [
            "a33f7220-3f5d-42f8-927c-7528bebc97b5"
        ],
        "b96e2c47-7742-4bcc-9e2f-c3a0b3b8fe46": [
            "a33f7220-3f5d-42f8-927c-7528bebc97b5"
        ],
        "734056ec-8a87-4e09-b2f9-118a5ff97613": [
            "46200a7e-d6c4-4770-89d1-3ecb2be1df41"
        ],
        "879d2e20-7398-45ec-aee8-afda6c3e9b88": [
            "46200a7e-d6c4-4770-89d1-3ecb2be1df41"
        ],
        "54cd0fd9-3ca7-4f54-83be-2593edb1b2b5": [
            "d8e709a9-2b01-4deb-a65d-11b267cb6151"
        ],
        "dee5aa71-bd2a-4b1d-ac98-50f63d048806": [
            "d8e709a9-2b01-4deb-a65d-11b267cb6151"
        ],
        "76b9e321-943f-4a8f-8987-30e29314c3e2": [
            "4675f32f-6d24-4523-aef2-dd898e1b50d2"
        ],
        "d3597438-080a-48d8-a65f-25f6362b9270": [
            "4675f32f-6d24-4523-aef2-dd898e1b50d2"
        ],
        "7cd93d56-ffb2-4924-854d-7f04da391d27": [
            "1a99d330-62d4-4ddf-b22a-b6bdfe06fddb"
        ],
        "a08b7bcb-01b2-494d-b55d-48cd34ab85bf": [
            "1a99d330-62d4-4ddf-b22a-b6bdfe06fddb"
        ],
        "8e82c668-2fd4-4153-8aea-caf7d15a4ffe": [
            "1a99d330-62d4-4ddf-b22a-b6bdfe06fddb"
        ],
        "22490d08-8f26-4232-b991-00bc4c4a896a": [
            "1a99d330-62d4-4ddf-b22a-b6bdfe06fddb"
        ],
        "c7827027-ee08-4c7c-8600-59007cd21700": [
            "1a99d330-62d4-4ddf-b22a-b6bdfe06fddb"
        ],
        "d666e383-300d-47e3-9b04-e91c5238f117": [
            "e34acd89-6a74-4abe-a072-31adbc218707"
        ],
        "005361f1-e695-47da-b986-1996e2ba8962": [
            "e34acd89-6a74-4abe-a072-31adbc218707"
        ],
        "76aa5f17-033d-4839-8ddb-8f90a83af0fb": [
            "42f7c036-0c04-403a-870b-1d1ef7749ee5"
        ],
        "ca01d708-a7be-4b42-8a53-72349bc93d8a": [
            "42f7c036-0c04-403a-870b-1d1ef7749ee5"
        ],
        "07e26ce3-483f-425b-9aba-fa52dff246cb": [
            "6cdf542c-8e01-4cef-8b89-076c32962ece"
        ],
        "497ccc1b-c37b-41b5-afaa-87699d27ff36": [
            "6cdf542c-8e01-4cef-8b89-076c32962ece"
        ],
        "dd73c7bd-bf40-4452-870b-4bcc0d03a009": [
            "96ce8bc2-2978-47d7-814b-717b33f8a30a"
        ],
        "7211a79d-ec04-4ccd-b775-4a149569c59c": [
            "96ce8bc2-2978-47d7-814b-717b33f8a30a"
        ],
        "4c8d62a8-e980-408f-91ed-edbd24692670": [
            "097fcf03-a573-42bd-a411-542c4bf2a4aa"
        ],
        "c8c4e305-6767-4f8b-9dcb-23ffef864f40": [
            "097fcf03-a573-42bd-a411-542c4bf2a4aa"
        ],
        "8a1b7fd3-b2cc-4de2-a084-a78d0b58be7c": [
            "f33fb97d-69d4-4e03-81ae-a5262c416883"
        ],
        "fdfc643c-7344-4791-b3ab-5485430c8147": [
            "f33fb97d-69d4-4e03-81ae-a5262c416883"
        ],
        "da8d20f6-da69-4bc1-9ea6-7ac5266263c8": [
            "b2bed103-d4d6-4510-8b82-3cb5882b2be1"
        ],
        "58b12790-e0c3-41a2-8128-d32a28f71727": [
            "b2bed103-d4d6-4510-8b82-3cb5882b2be1"
        ],
        "81a6f7cf-483f-44c8-904e-064fccad0670": [
            "4057cd71-e8b0-4231-9404-5dfcccc078fe"
        ],
        "4e3b7d05-d460-4ab3-ac7d-bebd916a7d4d": [
            "4057cd71-e8b0-4231-9404-5dfcccc078fe"
        ],
        "7ff8e921-2175-4c98-863a-4d7e107bdeb8": [
            "a26a0911-2a90-43d4-a599-346eabe28ca0"
        ],
        "ff9e0b4f-465c-4c95-aa43-07e99eaadf1d": [
            "a26a0911-2a90-43d4-a599-346eabe28ca0"
        ],
        "0f894297-80d8-4e1f-b4f8-490e7f056740": [
            "6f324b29-469d-4882-9f61-5089620fe271"
        ],
        "c9e40cec-e3fd-4a98-98b7-4e29aca5b231": [
            "6f324b29-469d-4882-9f61-5089620fe271"
        ],
        "49cf8639-d1b8-4494-aa1e-b65443c30247": [
            "eee179f0-cc31-4582-8091-72fdce983a0f"
        ],
        "b6c19c8c-9e05-4115-9f5e-4afda1777953": [
            "eee179f0-cc31-4582-8091-72fdce983a0f"
        ],
        "6e30336e-a297-4a06-aea2-de0e10452cba": [
            "3ab88eae-5f4f-4377-b392-de77d2d9c588"
        ],
        "ca2ebf0c-8d32-4a82-9ed8-37df59a321e8": [
            "3ab88eae-5f4f-4377-b392-de77d2d9c588"
        ],
        "98813e73-86b7-4a61-aed8-c16c3b29d300": [
            "c835ea07-933b-4eb6-bc88-69c5086752a0"
        ],
        "0f3ceda2-dfd8-4452-889a-26e141eea82d": [
            "c835ea07-933b-4eb6-bc88-69c5086752a0"
        ],
        "d9035f6e-027e-44a7-b1b6-4fc7fbda6557": [
            "035a7c98-1392-4cee-b844-90ac6302da6b"
        ],
        "7eaba21b-fd3a-430f-9260-36c8f9de7a09": [
            "035a7c98-1392-4cee-b844-90ac6302da6b"
        ],
        "009904c3-3c6c-4852-b88c-3d667865785f": [
            "7ae5ccc9-67f7-4a1f-b0f2-6957b0095db8"
        ],
        "7553fc2c-bf27-4bd6-a676-b8fb4c5a95d9": [
            "7ae5ccc9-67f7-4a1f-b0f2-6957b0095db8"
        ],
        "ac993544-fe41-4805-913f-c8e1d2a450bf": [
            "9093458b-1ac6-485f-8643-2fe46c753d08"
        ],
        "8848bcb4-21cf-40de-9e70-c4275dee5d1d": [
            "9093458b-1ac6-485f-8643-2fe46c753d08"
        ],
        "05f57811-1356-4945-a853-770e95ba8f74": [
            "d0fdc4c8-70d8-4d58-905e-55bba327cd02"
        ],
        "1600f545-49cd-4578-a5d3-0e76bbf652ee": [
            "d0fdc4c8-70d8-4d58-905e-55bba327cd02"
        ],
        "fe185ccf-1fcd-4abe-b9ca-43f920547654": [
            "ed79501a-01e5-4fc6-aa00-e9a1b543fb30"
        ],
        "d96c8741-fcc4-40d1-b4ce-83e6c2679505": [
            "ed79501a-01e5-4fc6-aa00-e9a1b543fb30"
        ],
        "792147bc-73b5-4d15-9b36-2d513cf8f017": [
            "eaf08b3b-1898-47cd-a020-3067913c792c"
        ],
        "e05c5853-1e89-4b8f-8731-6169b51204e4": [
            "eaf08b3b-1898-47cd-a020-3067913c792c"
        ],
        "78ab1784-ee5b-4027-ba73-57d98539da93": [
            "98aa1543-6a82-4d4b-bf8b-28e77ba01edd"
        ],
        "c42bdcc7-ca0f-449b-8f59-93d641d675b3": [
            "98aa1543-6a82-4d4b-bf8b-28e77ba01edd"
        ],
        "92cfd3c1-1ffb-4561-a6db-832f95a05b2d": [
            "f0b4d50a-ba08-488b-b088-2bbbbacc492b"
        ],
        "2049badf-9372-4860-bcab-1ebb85d79738": [
            "f0b4d50a-ba08-488b-b088-2bbbbacc492b"
        ],
        "5777f05b-df38-4824-889d-140a686bdb57": [
            "fe3c5034-630d-4a36-9a43-a20219a1ee29"
        ],
        "313c04fc-b383-4520-b8ed-c2fecd34ea8a": [
            "fe3c5034-630d-4a36-9a43-a20219a1ee29"
        ],
        "339181b3-43fc-4d1c-a707-5821aa25e0a5": [
            "cc61bbd5-1914-4428-a09a-b5bc5aa86d31"
        ],
        "569f54dd-6720-4489-a3b2-b1163266d425": [
            "cc61bbd5-1914-4428-a09a-b5bc5aa86d31"
        ],
        "456baaf1-0cf6-409a-83b0-fba99ee2b44c": [
            "74e19511-18c4-4e74-b255-bac75f517c5d"
        ],
        "607c76d4-1db9-4e73-9cbb-837ad0132c29": [
            "74e19511-18c4-4e74-b255-bac75f517c5d"
        ],
        "51b2b0b3-fd3f-4c53-affe-27b911fdbdb2": [
            "e49b51c3-f991-4664-8041-f8ecb7804d11"
        ],
        "15a45b31-05c1-4a81-8d36-bda3354c92f8": [
            "e49b51c3-f991-4664-8041-f8ecb7804d11"
        ],
        "d94aef91-bf58-4db4-a41e-dd0724946694": [
            "e1f92f9c-b8dc-4a5e-8847-bd645d11bec5"
        ],
        "b438a067-ced1-4767-9162-f71cefad798a": [
            "e1f92f9c-b8dc-4a5e-8847-bd645d11bec5"
        ],
        "b16ef337-3fe0-4311-8827-52268179718e": [
            "e1f92f9c-b8dc-4a5e-8847-bd645d11bec5"
        ],
        "ab6ae1c4-f123-4900-a3fd-2044647fd25f": [
            "e1f92f9c-b8dc-4a5e-8847-bd645d11bec5"
        ],
        "75654974-7977-4eec-bcc4-015138829ed1": [
            "e1f92f9c-b8dc-4a5e-8847-bd645d11bec5"
        ],
        "1d9f792a-29be-49db-a79f-116d2f9ac3d6": [
            "e1f92f9c-b8dc-4a5e-8847-bd645d11bec5"
        ],
        "61e19421-e47c-4a73-b8d6-7d3f56d0f456": [
            "e1f92f9c-b8dc-4a5e-8847-bd645d11bec5"
        ],
        "201658c2-cd27-42bb-900e-24bbd85cbdf1": [
            "e1f92f9c-b8dc-4a5e-8847-bd645d11bec5"
        ],
        "dba8aee6-7b45-41f4-ad32-073929359b94": [
            "e1f92f9c-b8dc-4a5e-8847-bd645d11bec5"
        ],
        "affcfa0b-9f7c-4194-9777-1b1037582c56": [
            "e1f92f9c-b8dc-4a5e-8847-bd645d11bec5"
        ],
        "8990e30a-5fa1-4e0d-bb3c-ab1b6299ad00": [
            "d1206441-e701-4ee4-84b7-555bd26f3509"
        ],
        "371612a5-f318-4a52-8b2f-65a74b444b5f": [
            "d1206441-e701-4ee4-84b7-555bd26f3509"
        ],
        "97682ee6-46ea-4cc1-bbb4-760e23bf2357": [
            "1026f648-a7e8-42ee-af28-50595f00b56c"
        ],
        "0390fe2c-39e5-44ce-9a9e-0f59cc3487c8": [
            "1026f648-a7e8-42ee-af28-50595f00b56c"
        ],
        "9301c610-0299-4072-b074-23e45ed1eccb": [
            "06ea0883-f926-4527-b5e7-9ef7afb5fddd"
        ],
        "ec685c51-ddec-4df2-be23-0fec789b0d22": [
            "06ea0883-f926-4527-b5e7-9ef7afb5fddd"
        ],
        "13b51452-792a-4804-89e5-8fb2208142df": [
            "5b58c850-3bed-4dec-80a9-669b7c14ea24"
        ],
        "af6fb0ce-8a4a-4117-91b5-05e6582931f5": [
            "5b58c850-3bed-4dec-80a9-669b7c14ea24"
        ],
        "726f2ff4-4ff0-42c0-8977-6c16671d26b9": [
            "ee0d1faa-16fa-4eca-8224-671f17953d02"
        ],
        "1aa422d5-9bde-4740-be34-e5e1523ee617": [
            "ee0d1faa-16fa-4eca-8224-671f17953d02"
        ],
        "1eb49956-43bb-40e8-935f-2ec248b12867": [
            "07c9da02-70ab-405c-bcd2-917735199933"
        ],
        "a20f04ab-4de3-4305-a64e-c370d43835ef": [
            "07c9da02-70ab-405c-bcd2-917735199933"
        ],
        "1414df9e-4313-4aa1-8724-5601efc6cf27": [
            "3e9afc61-80e7-4872-927b-fe54fa405bc9"
        ],
        "ba28ed94-7783-4e85-b8c6-d1c1dad8f579": [
            "3e9afc61-80e7-4872-927b-fe54fa405bc9"
        ],
        "fa2952ea-17d6-4462-b273-c549bb89b4b7": [
            "0e76fa2c-19fd-4d12-9222-9e2f59dbe2e4"
        ],
        "2b8764cf-0c1d-4f8c-9ed6-02e136d55f6a": [
            "0e76fa2c-19fd-4d12-9222-9e2f59dbe2e4"
        ],
        "cde66041-1226-4405-803e-566d3e136e43": [
            "c0343a57-6fff-47cf-bb90-58ec46aba93d"
        ],
        "288aa216-5cde-4d20-802a-40b0345236d2": [
            "c0343a57-6fff-47cf-bb90-58ec46aba93d"
        ],
        "d21f766c-7f6b-4e3e-8a9e-1f9999f572ca": [
            "53222acf-4a00-4cce-a2af-555159425782"
        ],
        "62272161-e142-4317-800a-d5fbbf6ba593": [
            "53222acf-4a00-4cce-a2af-555159425782"
        ],
        "1c9107f4-75ec-4ede-893b-adc42a65d74d": [
            "60746287-20bd-4e2a-ba17-8d45e83aca57"
        ],
        "6e163dc3-3d0e-4d2c-a3fe-ba2ea3dfc06a": [
            "60746287-20bd-4e2a-ba17-8d45e83aca57"
        ],
        "0c4c8a85-5090-4c86-8a5d-840b18ed8dde": [
            "53f00b51-dd69-4aba-a21c-1a58c2213ab1"
        ],
        "fffc30fe-b363-468c-adb8-1aa167b6ecb0": [
            "53f00b51-dd69-4aba-a21c-1a58c2213ab1"
        ],
        "bc04e6a5-0a59-465f-96f4-4eb373151125": [
            "48295f23-f910-4f50-9c3b-ed0dad67d8e7"
        ],
        "786d56b9-a595-4ea4-a9d3-ba96086153d7": [
            "48295f23-f910-4f50-9c3b-ed0dad67d8e7"
        ],
        "82dd0f80-989a-495e-9b06-f820e331ecd8": [
            "de171646-188a-437d-9dff-e234c33b58d4"
        ],
        "c2a30696-1fda-487b-812d-4c5fd9e606af": [
            "de171646-188a-437d-9dff-e234c33b58d4"
        ],
        "a0863b68-b6d0-4b14-a090-3d0e3db32a5f": [
            "084e7c19-6be6-4d2c-b201-07319d0487b3"
        ],
        "951c7c22-4cd2-405e-a32c-6ce1a53d972b": [
            "084e7c19-6be6-4d2c-b201-07319d0487b3"
        ],
        "4ba67166-3f27-486c-badc-1bf39214e1de": [
            "312aa466-f8cc-41c5-b834-7eab1db944a2"
        ],
        "922e8b90-4775-4128-9294-6d5368453244": [
            "312aa466-f8cc-41c5-b834-7eab1db944a2"
        ],
        "a8fffaa8-9554-45c2-b766-28bb7c64bda6": [
            "86c26df3-8c8c-423d-8056-30cbcfcdcf3c"
        ],
        "5981b948-f965-45b8-8b8a-76d1c70ea185": [
            "86c26df3-8c8c-423d-8056-30cbcfcdcf3c"
        ],
        "3257951c-7709-432a-83b7-ef47a711ce4d": [
            "9e62d724-9e94-4233-9627-ebbf458717b1"
        ],
        "78821e0f-1c68-477a-83dc-adcf549139eb": [
            "9e62d724-9e94-4233-9627-ebbf458717b1"
        ],
        "6840fb49-8a41-4009-b831-2c107a7d6eb4": [
            "ad09a9ac-4407-43c7-8b08-e61cc8f1e3f3"
        ],
        "bfff69e4-87ae-4c54-b4af-7029cd6ac006": [
            "ad09a9ac-4407-43c7-8b08-e61cc8f1e3f3"
        ],
        "9ed98555-51cc-4373-a78f-ad416084cd16": [
            "bebdf575-bf60-4892-9c70-e6042f703acd"
        ],
        "96cdaa44-ebfd-45ea-8c1c-66a3b36e271e": [
            "bebdf575-bf60-4892-9c70-e6042f703acd"
        ],
        "2acc5302-565d-4af8-90f1-f3f92f0ec7de": [
            "8fea3508-d598-42ba-b2a6-0012d0db9c19"
        ],
        "825a4da7-6ddf-440f-b1df-557d28465a94": [
            "8fea3508-d598-42ba-b2a6-0012d0db9c19"
        ],
        "8bed96b3-1660-447e-863a-3a646f89c892": [
            "95dc5861-fbb8-47d5-83dd-40151492d28c"
        ],
        "c55d4b0c-260e-471c-9a2b-f4895510be86": [
            "95dc5861-fbb8-47d5-83dd-40151492d28c"
        ],
        "67888b7b-f246-4706-8dda-18f8e6ee62ee": [
            "7592cf3b-37db-4bfd-b89f-1ccd71258df1"
        ],
        "3bba7b3f-220b-4f8b-b623-74846041e086": [
            "7592cf3b-37db-4bfd-b89f-1ccd71258df1"
        ],
        "11fa95db-bbc4-4050-b173-c1a6e7cef9fb": [
            "48576780-c641-41e0-8d40-ee756235300d"
        ],
        "49e829e5-dae7-4e5f-8e3c-01d70b129b60": [
            "48576780-c641-41e0-8d40-ee756235300d"
        ],
        "2bb82ed2-5883-416d-b0ca-61df3bb88ce5": [
            "48576780-c641-41e0-8d40-ee756235300d"
        ],
        "f386bc9f-5716-4fba-a061-487654586f54": [
            "48576780-c641-41e0-8d40-ee756235300d"
        ],
        "c50c3b79-3c80-4134-bbd8-753a24985e99": [
            "48576780-c641-41e0-8d40-ee756235300d"
        ],
        "de9b5e82-aa07-479f-8629-52eeaed804ed": [
            "48576780-c641-41e0-8d40-ee756235300d"
        ],
        "9895324b-421f-41bb-acec-a7e3504e7d87": [
            "48576780-c641-41e0-8d40-ee756235300d"
        ],
        "e30f7daa-3f1e-483c-9b48-c7a3d0552514": [
            "48576780-c641-41e0-8d40-ee756235300d"
        ],
        "030688c7-15ba-433d-bf81-f53bc819220f": [
            "48576780-c641-41e0-8d40-ee756235300d"
        ],
        "d8642a0f-970f-4784-8d91-9c77166bfd85": [
            "48576780-c641-41e0-8d40-ee756235300d"
        ],
        "482b7373-d1d2-4600-8ccf-325e643660d0": [
            "5273a768-1be6-4c63-852d-792f689abf87"
        ],
        "ab740159-7c3d-49cd-a316-0e27391f4ddf": [
            "5273a768-1be6-4c63-852d-792f689abf87"
        ],
        "6956ce71-8829-4a9a-b70b-05a947158815": [
            "e56d37f1-14b6-4359-8157-6325e19dc820"
        ],
        "f1265b7d-5c99-4d42-a238-cb6333ad1120": [
            "e56d37f1-14b6-4359-8157-6325e19dc820"
        ],
        "78ee80cc-9e95-4738-8dd1-df52c06c3dcf": [
            "cae6a7c4-7971-46ef-af86-1377ba42cba8"
        ],
        "a3deb7c0-497c-4ba9-aba2-1260fa41276c": [
            "cae6a7c4-7971-46ef-af86-1377ba42cba8"
        ],
        "84421c5a-c5a7-4c85-91d8-b4df3d120266": [
            "8d1c2848-6310-4f55-9342-5a1da16bc251"
        ],
        "9c2f9510-ec77-4aa5-bfea-94f781769d8e": [
            "8d1c2848-6310-4f55-9342-5a1da16bc251"
        ],
        "bb04242f-b744-4826-9e20-ae05006022df": [
            "d5b9e33f-d362-4fdf-8215-027d04725d18"
        ],
        "8de7c6c9-346f-4c32-8616-7f12d4ac1700": [
            "d5b9e33f-d362-4fdf-8215-027d04725d18"
        ],
        "4afaf275-221e-4c62-a77e-0ba08145dbc8": [
            "cf3bd0fc-b0ad-4b06-885d-a58cfd457a10"
        ],
        "86f595a8-b842-4f35-954d-767b033ede10": [
            "cf3bd0fc-b0ad-4b06-885d-a58cfd457a10"
        ],
        "061b2e74-b31a-4299-baa4-c8ec8ab061ef": [
            "0a3e5e8d-d0e3-4570-9b76-4ca9e98f31b4"
        ],
        "54442706-c0f1-4c0a-a2ad-073966e84b9a": [
            "0a3e5e8d-d0e3-4570-9b76-4ca9e98f31b4"
        ],
        "12eba783-def8-4bc3-9f94-18a090ea733d": [
            "abbe1b15-b395-4e22-86de-2ac7b064811a"
        ],
        "40fde95a-b184-4868-a0a3-76a7daab393a": [
            "abbe1b15-b395-4e22-86de-2ac7b064811a"
        ],
        "111ecef4-c316-43ff-95f0-8d349657f63c": [
            "174094f0-270b-48c2-aaf2-11623d008268"
        ],
        "d84e1b72-c719-4e08-8006-5c84cfefdcbc": [
            "174094f0-270b-48c2-aaf2-11623d008268"
        ],
        "8b74d414-a9e2-47c0-a9e2-024141279c72": [
            "8e39a8dc-389a-4257-8867-db2370c00d1b"
        ],
        "081ba77b-4833-43e6-8e7a-1652824c74da": [
            "8e39a8dc-389a-4257-8867-db2370c00d1b"
        ],
        "75fcdd1c-0566-4c80-8c02-579c57b464a2": [
            "3a79d506-b5c2-40cd-a8fd-cdbbee935c75"
        ],
        "028417e3-f182-4885-ada4-45af09418f77": [
            "3a79d506-b5c2-40cd-a8fd-cdbbee935c75"
        ],
        "24596305-2553-4bb2-b65e-de96d343d868": [
            "ea4eaadb-50c9-40a0-b705-c0179a6e6214"
        ],
        "a8b3eb45-f43b-49c2-88a5-bf57e4992fa9": [
            "ea4eaadb-50c9-40a0-b705-c0179a6e6214"
        ],
        "e99efe3e-9b61-4542-afa8-af0dc88dec84": [
            "52567013-aa58-4a18-be47-abc55021e7b4"
        ],
        "85996b69-fc7f-4909-8719-6d91f61dce00": [
            "52567013-aa58-4a18-be47-abc55021e7b4"
        ],
        "62e55d28-8539-4ab5-a80c-a7e3d02406e9": [
            "25a2580c-784d-4b2a-840f-09a58bc2f693"
        ],
        "28f5cd29-330a-4d39-8b0a-ff176a523cce": [
            "25a2580c-784d-4b2a-840f-09a58bc2f693"
        ],
        "e037b2fd-e811-4986-8717-bb944b812493": [
            "5688abf8-c3ff-4918-80a5-c4b4651f66ba"
        ],
        "5af11d51-9306-4665-bb80-985803e5d7a1": [
            "5688abf8-c3ff-4918-80a5-c4b4651f66ba"
        ],
        "715ac410-0cb6-43e0-b00f-c66275ec8a92": [
            "5688abf8-c3ff-4918-80a5-c4b4651f66ba"
        ],
        "d82a99bf-a9f0-4c07-9fd4-5ad21eef5623": [
            "5688abf8-c3ff-4918-80a5-c4b4651f66ba"
        ],
        "14138c32-cd52-49f9-9fa1-dbd48bf3081c": [
            "5688abf8-c3ff-4918-80a5-c4b4651f66ba"
        ],
        "fdc1af2f-653d-4837-a87f-95fc68a24285": [
            "5688abf8-c3ff-4918-80a5-c4b4651f66ba"
        ],
        "b9c30c10-d346-4c56-a606-cd17868e9270": [
            "5688abf8-c3ff-4918-80a5-c4b4651f66ba"
        ],
        "a6e06097-5b67-4fa2-b748-135c28ae430f": [
            "5688abf8-c3ff-4918-80a5-c4b4651f66ba"
        ],
        "f5e9ecbf-ebde-47b1-9559-33d873a8d129": [
            "5688abf8-c3ff-4918-80a5-c4b4651f66ba"
        ],
        "8cc804fc-6961-47b0-9787-4bfb0b13a0f2": [
            "5688abf8-c3ff-4918-80a5-c4b4651f66ba"
        ],
        "7b165dab-72d1-4908-b948-289bbf6c019c": [
            "5fb5244e-eebe-4715-bf19-a08a337cb8dd"
        ],
        "61a8f027-4a28-44a9-a3a5-d3604327269b": [
            "5fb5244e-eebe-4715-bf19-a08a337cb8dd"
        ],
        "ba2d77ba-d202-4e76-8cfe-fd908d0d72d0": [
            "e5bcaa91-2e61-4663-9db1-f0ef05538216"
        ],
        "ff18a957-f7bc-44bc-9606-23c16beabf2c": [
            "e5bcaa91-2e61-4663-9db1-f0ef05538216"
        ],
        "1c172e23-6f69-466f-a92f-4e37f900c68a": [
            "ac61f87d-eced-4962-996a-408f4dc70f5f"
        ],
        "d0077ea7-7133-42e1-b218-e6ed353a5553": [
            "ac61f87d-eced-4962-996a-408f4dc70f5f"
        ],
        "935a73af-0730-451d-9ae3-bd2fce66f1cf": [
            "bf1d9818-f2c4-4724-ab97-94c8d31f4164"
        ],
        "66ca3ba8-fc59-4eeb-ae9d-a77aa7e600cb": [
            "bf1d9818-f2c4-4724-ab97-94c8d31f4164"
        ],
        "7c867aa0-b62a-4df5-b320-08055f5a52cc": [
            "c0971ac4-5848-491a-829e-7b79fa210c57"
        ],
        "b1b38f67-653f-4867-969b-82d09e8b5709": [
            "c0971ac4-5848-491a-829e-7b79fa210c57"
        ],
        "6a98c84e-e41e-458b-9f9a-057682f3d510": [
            "51c46c71-9c02-415e-bcd0-d7d432feefde"
        ],
        "dd7375df-d571-47d1-8716-7c2804424a0b": [
            "51c46c71-9c02-415e-bcd0-d7d432feefde"
        ],
        "ec60d7d2-d308-47fb-a596-21ed4e1d30d9": [
            "ccf71489-de31-4adc-8383-3a9db3c3bbe5"
        ],
        "020ccdfe-2a34-47c7-98a6-3898163019e4": [
            "ccf71489-de31-4adc-8383-3a9db3c3bbe5"
        ],
        "94fa8b26-aead-4847-8860-d9cb9581ef9f": [
            "b56fc3bb-fecd-4fed-bbd8-c21fda6e31c7"
        ],
        "2f516a15-8e2b-43c7-b28b-bab5980044a7": [
            "b56fc3bb-fecd-4fed-bbd8-c21fda6e31c7"
        ],
        "574137cf-837f-4389-b5e1-6781ba63f54b": [
            "8f56f5e9-dcd8-4f16-b8ba-fd0b08a9c31d"
        ],
        "8b201023-b666-46c0-a5a5-474795ded87f": [
            "8f56f5e9-dcd8-4f16-b8ba-fd0b08a9c31d"
        ],
        "8f8557e1-76ae-4332-b090-da1e7ec77146": [
            "d00bfa6e-ede2-4862-abc6-df50ada0cd94"
        ],
        "0dd95013-a367-4586-aaf3-cedfda865ed0": [
            "d00bfa6e-ede2-4862-abc6-df50ada0cd94"
        ],
        "2f4b71d2-9d52-4fa2-bbd6-51d19ad6ffb9": [
            "dc0905e0-8076-429c-ac66-b5d9deae2458"
        ],
        "4fa121bf-eee1-42c4-876b-963a3e9374c8": [
            "dc0905e0-8076-429c-ac66-b5d9deae2458"
        ],
        "304f8644-80d8-4961-a3ab-d69a3e043187": [
            "509fcd0e-b388-42cb-b713-bf103a05c93b"
        ],
        "5b3c2f37-536b-4b37-8d8a-a2385601ebb8": [
            "509fcd0e-b388-42cb-b713-bf103a05c93b"
        ],
        "f812dc87-5925-4e2e-afbc-6cd912c8b4a8": [
            "3ded0e50-498b-4d62-bbc9-805a98c68e4e"
        ],
        "262e38fa-3673-4558-8d9b-9bf3a89b0a80": [
            "3ded0e50-498b-4d62-bbc9-805a98c68e4e"
        ],
        "93c56c30-640a-40e0-a34f-17d037863c4b": [
            "c3790290-a8c8-44d0-883d-fc01c5ebfb1f"
        ],
        "e9cd81d6-cbb1-4ff3-8bcf-4c0e39eff2cd": [
            "c3790290-a8c8-44d0-883d-fc01c5ebfb1f"
        ],
        "7568e425-2391-47bd-a2b1-4c6ba48d792b": [
            "1979dc69-6e12-4427-9baa-a29d6ce5b1f5"
        ],
        "8d8b1dee-2665-4df1-ba42-33015630f1c1": [
            "1979dc69-6e12-4427-9baa-a29d6ce5b1f5"
        ],
        "2533e519-07ff-4d2b-b160-a0f27be2cd7c": [
            "c4d2c144-7fb9-457f-a573-7c917fc5411b"
        ],
        "36475e7b-dcab-4e0f-8d23-5089b59d5e50": [
            "c4d2c144-7fb9-457f-a573-7c917fc5411b"
        ],
        "6719a255-4a10-41dc-9913-0a3327c57bd6": [
            "f91a1eeb-8feb-44ec-b942-17cad329d310"
        ],
        "2071ad15-e962-4afa-9305-97b5b8abdc31": [
            "f91a1eeb-8feb-44ec-b942-17cad329d310"
        ],
        "fc22982f-5aa1-4bd2-ae38-f475c225ec5e": [
            "a2900ab4-a547-4094-8d53-b05a38895d8a"
        ],
        "007fec7a-6729-493a-b76c-85323543b8a2": [
            "a2900ab4-a547-4094-8d53-b05a38895d8a"
        ],
        "c64ffe90-b431-4f0f-8e7c-352d0053e7c2": [
            "ae7f64d8-871c-4d92-b0bb-21e5aa43b4fa"
        ],
        "93a443a5-36e9-4e29-b6a7-43b4501f2c22": [
            "ae7f64d8-871c-4d92-b0bb-21e5aa43b4fa"
        ],
        "d8be37c8-6778-4c6d-bd10-a919ec5c6e63": [
            "0b147746-7a52-4ebc-8a0c-8f02b397a1c5"
        ],
        "9a19f67e-92c8-4b73-bc6f-6028a52e1492": [
            "0b147746-7a52-4ebc-8a0c-8f02b397a1c5"
        ],
        "ec0085c4-e57f-4caa-acbf-f787eb5abbf9": [
            "cc803b71-1835-4d4d-ab3a-87a0402dcbd1"
        ],
        "ba89af3b-afef-4a20-bc0b-1d7f2aaa6f22": [
            "cc803b71-1835-4d4d-ab3a-87a0402dcbd1"
        ],
        "df13734f-05a5-43a1-b5a1-df890487f903": [
            "6048b47b-a6c7-4ded-807b-28e8ab160290"
        ],
        "e23e5875-acd3-44aa-9eb5-b700973eff05": [
            "6048b47b-a6c7-4ded-807b-28e8ab160290"
        ],
        "9137745d-6401-470e-a97c-cda0a0b078fd": [
            "bd9dc21c-2414-43d6-b454-8ddf091ad214"
        ],
        "a6ed7a60-bc05-4bf1-81c1-84a435fbeb1a": [
            "bd9dc21c-2414-43d6-b454-8ddf091ad214"
        ],
        "52c730e7-8c0d-49ba-9926-93b501d3a199": [
            "21216440-8b76-46bb-ad4e-294462c32258"
        ],
        "e0b6f6b1-c251-4813-9fd5-8f0f4ca61e34": [
            "21216440-8b76-46bb-ad4e-294462c32258"
        ],
        "45b5c0d3-26bb-4397-ab4d-abcfa549d55a": [
            "82bc7d38-671b-4064-80e0-02cb840f424a"
        ],
        "a5cbd804-23e0-4c8e-a493-837f84ed7461": [
            "82bc7d38-671b-4064-80e0-02cb840f424a"
        ],
        "8649a740-cc76-4299-8e1d-0d53ece1ecc4": [
            "7b6e06a1-5637-489c-82e3-88e7eaa3dcc2"
        ],
        "1f97b736-3ee2-433e-948c-3d69fc6fd511": [
            "7b6e06a1-5637-489c-82e3-88e7eaa3dcc2"
        ],
        "f57d161a-9ea0-4644-aa64-9a44694200d9": [
            "f9906168-8e95-477d-b48d-b1b5b38f7080"
        ],
        "453bedf7-81ba-4c58-a7c9-fe2dd06c3c32": [
            "f9906168-8e95-477d-b48d-b1b5b38f7080"
        ],
        "628a4bd0-d849-45b3-b603-a3d61c5a9aed": [
            "805bf647-5ed0-4c4a-8a76-85ec5776b051"
        ],
        "82db0b9d-0ea0-4a26-9add-57626f5b090c": [
            "805bf647-5ed0-4c4a-8a76-85ec5776b051"
        ],
        "eb13dcc1-9542-4cd8-a9fb-31b32f334258": [
            "49fec38a-932e-46c8-89af-4f96dcd0407a"
        ],
        "8c96de78-8641-48e1-8a90-8fb8968cb847": [
            "49fec38a-932e-46c8-89af-4f96dcd0407a"
        ],
        "33de451f-82c7-464f-965e-b056a4cfdc97": [
            "cfb0afc1-02ec-46cd-9be3-54068b43708c"
        ],
        "4252b63b-eaa3-45d5-b005-52023a72a984": [
            "cfb0afc1-02ec-46cd-9be3-54068b43708c"
        ],
        "5e00d2a2-8bba-400a-9505-43aa1ec89381": [
            "25d3ea69-7a56-447d-a2f3-2a5a3ac7b408"
        ],
        "9215ed44-5cd4-4399-afb3-7c75b8cc2489": [
            "25d3ea69-7a56-447d-a2f3-2a5a3ac7b408"
        ],
        "9c36d1c1-9fe9-4774-94b7-26f972a42054": [
            "2be71554-af86-46e6-b447-50302398c154"
        ],
        "425265e0-9249-42c2-b775-312230153ce5": [
            "2be71554-af86-46e6-b447-50302398c154"
        ],
        "571788ff-7ebd-4297-9056-a5a203ca03b9": [
            "fbdadea1-1f5d-494a-a277-72ede6fed846"
        ],
        "490de506-c61c-4299-ab9f-28e859ea38db": [
            "fbdadea1-1f5d-494a-a277-72ede6fed846"
        ],
        "5ee5ccd0-34a6-4753-a005-1c819f81430c": [
            "664c69d6-d933-47e1-9667-1ed1f9a3bd70"
        ],
        "0a40da81-32fd-4ab8-8c15-1e8623dcf6f6": [
            "664c69d6-d933-47e1-9667-1ed1f9a3bd70"
        ],
        "514fbfa9-9fc7-408a-b9ac-113f8bd71426": [
            "a0e049b4-a54f-421d-b0be-8458d0980eda"
        ],
        "25437565-8e2a-4772-a53e-23906f8f34a0": [
            "a0e049b4-a54f-421d-b0be-8458d0980eda"
        ],
        "51556f67-17cc-408f-a354-f35810cfb0b9": [
            "87c6ab06-4a01-4e4e-93c5-9dd3658c3fe3"
        ],
        "1aac6d33-9bf9-473e-bd1b-562574c9e845": [
            "87c6ab06-4a01-4e4e-93c5-9dd3658c3fe3"
        ],
        "2b26ee56-376a-4efe-b61b-3cd0c20b7e75": [
            "766a20ed-51b4-4461-83dc-b5c7ed9ceec1"
        ],
        "64953893-8fd1-4698-ba10-fbc3507ae398": [
            "766a20ed-51b4-4461-83dc-b5c7ed9ceec1"
        ],
        "12c21964-a400-48e9-8d67-19f9ce11760a": [
            "8dbb5d64-e91c-418d-812f-e54dadc3cbf4"
        ],
        "daf318ac-be3c-4887-826f-8f8caac80a69": [
            "8dbb5d64-e91c-418d-812f-e54dadc3cbf4"
        ],
        "a0c7ecd2-2ce5-4fb2-b45a-5639d0f917d6": [
            "a5b42803-2c9b-43b1-a2fc-a7c97ccf3a96"
        ],
        "90819f73-5bac-40d2-be6f-d5f3d094a36e": [
            "a5b42803-2c9b-43b1-a2fc-a7c97ccf3a96"
        ],
        "324be9dd-e84e-4308-b1af-becc2ed4bcdd": [
            "a5b42803-2c9b-43b1-a2fc-a7c97ccf3a96"
        ],
        "664e9ee0-8686-4d9e-85a9-b96c0b945394": [
            "a5b42803-2c9b-43b1-a2fc-a7c97ccf3a96"
        ],
        "8cec7f86-8e67-4683-9a38-c4c6866b9835": [
            "a5b42803-2c9b-43b1-a2fc-a7c97ccf3a96"
        ],
        "b178c0be-52ce-400f-8bf6-1769795f63d8": [
            "98e4e051-d88a-4434-a357-cd49b6039870"
        ],
        "662983b7-e5a8-40ba-9d6b-780e14b2241c": [
            "98e4e051-d88a-4434-a357-cd49b6039870"
        ],
        "0fe7dd13-cb5d-4cd6-8ff4-514c60b7a0dc": [
            "3883d294-21e3-4110-84d1-193f34c9427d"
        ],
        "1519e291-529f-4284-8c64-fb0d664087b4": [
            "3883d294-21e3-4110-84d1-193f34c9427d"
        ],
        "3b29d0af-bbae-427f-89be-53de89368561": [
            "c6e17b21-a8b7-4c02-91b8-c8599b5ce161"
        ],
        "59e4c112-557c-4269-82b0-c1422a2d3774": [
            "c6e17b21-a8b7-4c02-91b8-c8599b5ce161"
        ],
        "3908e90b-6878-42a6-8fd0-84554f03d5b0": [
            "86ab9bb6-08e8-432f-911c-82c2f6d2ccff"
        ],
        "a25b64e5-1071-425e-b803-619e5de19a5f": [
            "86ab9bb6-08e8-432f-911c-82c2f6d2ccff"
        ],
        "c70c4cd5-f58d-4832-bcc7-035cd39e5ac9": [
            "af326ba3-ffcd-4606-8a8b-1d7d9f415017"
        ],
        "e71382c1-1f85-415d-a596-cf0d0207c86b": [
            "af326ba3-ffcd-4606-8a8b-1d7d9f415017"
        ],
        "91dcb736-cfe8-415b-835e-0bff7d594392": [
            "94afa98b-ab1a-4132-8b07-876cd4178d78"
        ],
        "fc40a7f4-a747-4f2b-9f43-13af3a8b9f5f": [
            "94afa98b-ab1a-4132-8b07-876cd4178d78"
        ],
        "229850a9-d834-42cb-9313-0cdbbc65ee50": [
            "db06322a-525d-4d8a-a305-88397d6d2570"
        ],
        "42475650-95c2-4533-b2aa-c65369708b74": [
            "db06322a-525d-4d8a-a305-88397d6d2570"
        ],
        "e052deca-81c8-4e0b-bf51-8938cbef8833": [
            "4d9f70e7-fd07-4433-b840-7a37440440b0"
        ],
        "fa604c72-e048-4b48-aade-e7fda055670e": [
            "4d9f70e7-fd07-4433-b840-7a37440440b0"
        ],
        "fc46e252-1d84-46c6-9c74-74dd10cfb689": [
            "15c9a45e-73ac-404e-895f-8d04c33ce3d6"
        ],
        "c0e90c68-a1d9-4145-b70b-1d7a97531300": [
            "15c9a45e-73ac-404e-895f-8d04c33ce3d6"
        ],
        "60f79f9b-782f-4933-b6c2-eb10356bb8dd": [
            "e33b3007-096f-4fc1-ab2c-7d1ea89640e3"
        ],
        "5f2b7b2f-3b01-4b1e-a9af-aaf3d02240c6": [
            "e33b3007-096f-4fc1-ab2c-7d1ea89640e3"
        ],
        "35ce165e-44d2-4b44-8e3a-fa8d830030f4": [
            "7dfb223b-041b-4aa2-9ffe-fb697b9b5572"
        ],
        "611fddef-f517-4773-a8af-fc69f13e623e": [
            "7dfb223b-041b-4aa2-9ffe-fb697b9b5572"
        ],
        "1cba3f92-9a1f-49c5-b060-612ad22e5217": [
            "bf51cbff-93ae-4a38-861c-560931310b61"
        ],
        "577ca9d2-6e17-4f7a-aa2e-94cfb3811601": [
            "bf51cbff-93ae-4a38-861c-560931310b61"
        ],
        "47b6b58e-bb5e-4191-908b-1782f1d3b3e9": [
            "5eeb0ef2-565a-46f7-a5c1-17899d90410b"
        ],
        "fc71e979-1ab9-43ee-a4f4-847110c29d64": [
            "5eeb0ef2-565a-46f7-a5c1-17899d90410b"
        ],
        "d33c8d88-d0a4-4510-95df-3b857269ef4e": [
            "f9b9f65e-cad9-4121-b677-81af7edf0065"
        ],
        "81f277e7-c6df-483c-9882-0ddf9d71c06c": [
            "f9b9f65e-cad9-4121-b677-81af7edf0065"
        ],
        "677582a2-bbe0-48d5-8e8b-cff0766d03be": [
            "5bab6423-d99a-41ed-b174-de72060aca91"
        ],
        "82b192fd-883d-42f4-bfb3-ac69b3b1bc5c": [
            "5bab6423-d99a-41ed-b174-de72060aca91"
        ],
        "a6a24e8a-7ce9-4a28-94a3-325884351e52": [
            "5bab6423-d99a-41ed-b174-de72060aca91"
        ],
        "1b10a544-612c-48af-9c29-1f993423c82d": [
            "5bab6423-d99a-41ed-b174-de72060aca91"
        ],
        "d51ecfa7-e5de-4568-b108-c279380fdac8": [
            "5bab6423-d99a-41ed-b174-de72060aca91"
        ],
        "77ab704d-5520-40b0-84c8-44d694e2ab6b": [
            "5bab6423-d99a-41ed-b174-de72060aca91"
        ],
        "8ea8c86b-4c87-4c58-a116-10d0eb435072": [
            "5bab6423-d99a-41ed-b174-de72060aca91"
        ],
        "c8a20c48-7040-4551-9d8d-392e7aff2f71": [
            "5bab6423-d99a-41ed-b174-de72060aca91"
        ],
        "205f0c5e-17ef-459c-801f-42996b04c47d": [
            "5bab6423-d99a-41ed-b174-de72060aca91"
        ],
        "8ee1a529-8fa1-4060-aedd-25b535dacbf6": [
            "5bab6423-d99a-41ed-b174-de72060aca91"
        ],
        "b737a5ab-b3c8-46bd-bfe4-88135e7e9cd6": [
            "d7a41ff0-cb31-4af1-92c3-9a222ae667d2"
        ],
        "82afda33-440b-47a7-9429-1b4886aa36a5": [
            "d7a41ff0-cb31-4af1-92c3-9a222ae667d2"
        ],
        "26166a2e-e411-48db-bb28-c1519ef05f8e": [
            "9b473382-8c0b-4614-9a1a-a7376749a786"
        ],
        "264f9e7f-1d09-4315-8333-d3ebeb95b2f1": [
            "9b473382-8c0b-4614-9a1a-a7376749a786"
        ],
        "f51f142b-6158-4b3f-af12-297e6e40d20f": [
            "89cd5d7a-5227-4a18-a5e7-9ddda94f8676"
        ],
        "16bfa376-b7e5-4ee6-beb3-c28ccb324322": [
            "89cd5d7a-5227-4a18-a5e7-9ddda94f8676"
        ],
        "81e6ddbf-0137-4db3-81d9-42249cf34471": [
            "b2ead861-0cff-4965-8d7d-5c465c1c9fac"
        ],
        "d8592020-e4ee-4b23-9233-026499a3d8ec": [
            "b2ead861-0cff-4965-8d7d-5c465c1c9fac"
        ],
        "f63f0d9f-337e-4e00-a341-1c9cb18aea72": [
            "0db5b69e-efd0-48be-bacf-eaddbe7f0667"
        ],
        "d1f88c12-4b7a-42b2-9dfc-59dca26ee05f": [
            "0db5b69e-efd0-48be-bacf-eaddbe7f0667"
        ],
        "acd80c3e-1213-40cd-a3f7-ed3823449ddb": [
            "586c6c86-1b04-4760-9c57-43f3116fb7c1"
        ],
        "69c89685-f93c-4e50-a043-3df6e800bc8e": [
            "586c6c86-1b04-4760-9c57-43f3116fb7c1"
        ],
        "548e0df7-665c-4c7f-b732-d78864cfb4e3": [
            "0c538563-46a2-4714-82ef-91ca0ff54b8e"
        ],
        "ee85494a-4fb3-4245-8827-5baf9c6c1b68": [
            "0c538563-46a2-4714-82ef-91ca0ff54b8e"
        ],
        "cb1b7cfd-aafb-431e-923b-db310fd65d8b": [
            "c4a7d697-896e-45c9-b35d-c3bc7fe7ae51"
        ],
        "333183e1-bf47-4d2b-89fc-7528eeb80c49": [
            "c4a7d697-896e-45c9-b35d-c3bc7fe7ae51"
        ],
        "704fff1b-4542-4f96-9ebb-a558325b4e9d": [
            "2849c686-9115-47d5-bbf7-b68ae9b3ecf8"
        ],
        "b2f21ab5-bfea-4789-9cfc-42e0a24bea39": [
            "2849c686-9115-47d5-bbf7-b68ae9b3ecf8"
        ],
        "dae95beb-5b26-44c4-bcb5-cbea25b272c5": [
            "b65edd6e-55d2-48a7-b930-70d5d8ba5e19"
        ],
        "3c4af451-a851-49d7-900f-7a71d4bd614f": [
            "b65edd6e-55d2-48a7-b930-70d5d8ba5e19"
        ],
        "0213544e-ee3e-471a-b059-76c8af33281b": [
            "790b577e-da39-4143-b55c-72ad42824065"
        ],
        "d9e61b9d-0bef-42d3-b5fb-6e5e65ee0333": [
            "790b577e-da39-4143-b55c-72ad42824065"
        ],
        "23ec397f-66da-492a-bae9-91dcb6a5e8ba": [
            "a9b214a6-e0d7-4396-95b5-c652c751145f"
        ],
        "dacb271d-0cd6-412b-83cf-d54daabfbe69": [
            "a9b214a6-e0d7-4396-95b5-c652c751145f"
        ],
        "bef28f95-fdca-43bc-9b51-e2b29c68abc4": [
            "7727e13a-c645-44ea-8580-4aab5ea8db2d"
        ],
        "9045fafc-2c23-42d0-96cb-aef22589f8ac": [
            "7727e13a-c645-44ea-8580-4aab5ea8db2d"
        ],
        "949a365c-c0e1-4629-8dc2-3163eefc041e": [
            "decb50c6-e475-4f63-b46e-ca0817c00e6f"
        ],
        "d9d08a64-ce52-415e-9648-e602b1ebabaa": [
            "decb50c6-e475-4f63-b46e-ca0817c00e6f"
        ],
        "b8f33451-a3a2-44d1-ab93-5d2deeb25056": [
            "679033e9-1d73-400d-8fa9-17d93bd4f33b"
        ],
        "36867603-080b-4cdc-9220-b05e764c59a5": [
            "679033e9-1d73-400d-8fa9-17d93bd4f33b"
        ],
        "fd7ee43d-d706-421a-9965-e9a49fd29942": [
            "fde144e6-6714-4f51-ae32-164e3c64eb9b"
        ],
        "23cd85c7-3d03-40bd-bc83-974f295d29ff": [
            "fde144e6-6714-4f51-ae32-164e3c64eb9b"
        ],
        "05854491-66cf-4645-8cc6-86340d547760": [
            "f7b7e264-94e3-46a9-8218-369ef8cc6b0b"
        ],
        "5a1dddea-87d4-44a6-834d-b8faa8e6dbdd": [
            "f7b7e264-94e3-46a9-8218-369ef8cc6b0b"
        ],
        "aa2d91de-908a-4db1-845e-298d99b10f33": [
            "1ddcf8f8-b03b-4363-82b2-fa44be44fb6f"
        ],
        "c3e5f214-5d09-48bd-9c8d-375792662a71": [
            "1ddcf8f8-b03b-4363-82b2-fa44be44fb6f"
        ],
        "b7f5462e-7f9b-411d-9b2e-ac22bfa527c9": [
            "38d4a48f-e5d0-46ec-93d4-e179b0d8aab8"
        ],
        "e1c73c36-0509-4b0a-b1bb-4e7fabbb08ed": [
            "38d4a48f-e5d0-46ec-93d4-e179b0d8aab8"
        ],
        "f965d9fa-64c7-49e6-9299-c1000cb971db": [
            "cf95cfa8-b5d4-4778-90fe-9a0e47d95ac0"
        ],
        "df73bce3-2a00-4701-bb75-461848b6b36a": [
            "cf95cfa8-b5d4-4778-90fe-9a0e47d95ac0"
        ],
        "d3f1b539-0c95-4886-9c32-396b67474939": [
            "566d9a46-75b9-4ce4-a4d2-c007758b7761"
        ],
        "ac4ed70d-7207-49aa-9efe-484fedf3432b": [
            "566d9a46-75b9-4ce4-a4d2-c007758b7761"
        ],
        "80bbef58-6430-4fa7-9693-be8b91067ea3": [
            "be813cb7-495b-4578-8b99-aa6b16363abb"
        ],
        "abd3fa7f-c709-478d-b247-0eb1bcc6b762": [
            "be813cb7-495b-4578-8b99-aa6b16363abb"
        ],
        "37fdd5e9-62cf-4d8e-a6e3-e006fbe241c9": [
            "0411c9a6-c7be-438f-a23d-9adfea390476"
        ],
        "0dc93cdd-38eb-44cb-9d92-4fa2795902a2": [
            "0411c9a6-c7be-438f-a23d-9adfea390476"
        ],
        "f8252e71-0e22-45fa-992c-16be241c4488": [
            "30766c26-3179-435b-994c-073361849ec7"
        ],
        "5c805a4c-09c7-4489-8690-e59544a23be5": [
            "30766c26-3179-435b-994c-073361849ec7"
        ],
        "217ee6de-2bae-4278-9e12-d5dc2acf7ca3": [
            "6076f052-554e-4014-b5d0-139b5b409c59"
        ],
        "1eb800d8-82f0-43b0-b898-e282c4965dc6": [
            "6076f052-554e-4014-b5d0-139b5b409c59"
        ],
        "da7d920d-3093-42ef-9c15-fa2cd1cbe1e8": [
            "2924dbe5-5da0-4226-80e3-4ff22362bdd8"
        ],
        "5d916972-955c-4409-a84d-3942390870f9": [
            "2924dbe5-5da0-4226-80e3-4ff22362bdd8"
        ],
        "b42e84f9-02e2-4616-b071-69e7e06ca49b": [
            "ef9f2781-3d12-4b1c-a5b4-a319d50b1dda"
        ],
        "b1a4825c-eb1b-4336-9748-5e9b8c75376d": [
            "ef9f2781-3d12-4b1c-a5b4-a319d50b1dda"
        ],
        "0bb3c257-4d28-4ad4-919f-1f8a4ae84dec": [
            "5eceee97-2141-418d-b5e2-1bcbebfa6cca"
        ],
        "ed072997-79b5-41c2-9496-7c1b77d52b1e": [
            "5eceee97-2141-418d-b5e2-1bcbebfa6cca"
        ],
        "253aa79e-791f-4b29-a355-be767412dbf0": [
            "f0debb9b-a219-4207-ade4-8a033989a3b2"
        ],
        "f5db71cf-946e-4c51-b8e2-2171b75bf056": [
            "f0debb9b-a219-4207-ade4-8a033989a3b2"
        ],
        "59792dda-7154-496a-a7a1-25bcc9b1817e": [
            "466f65d2-67c0-4678-8fd2-6a5587ce9e82"
        ],
        "c5433b93-2d4d-4f5e-9957-257972639b09": [
            "466f65d2-67c0-4678-8fd2-6a5587ce9e82"
        ],
        "39b432fb-4f8c-4453-9c6c-74e4022332f9": [
            "44fe1f52-38df-41c0-bdae-fa94a10e1647"
        ],
        "b8d98ba1-1dc3-457a-83b7-b03f0626832f": [
            "44fe1f52-38df-41c0-bdae-fa94a10e1647"
        ],
        "0697dbd9-cbb7-4455-b1a4-07e7c34cb7bf": [
            "b35dfa52-706f-472f-9f60-3c1363b06419"
        ],
        "106da036-259d-4504-a580-f9ab43c6353d": [
            "b35dfa52-706f-472f-9f60-3c1363b06419"
        ],
        "d393d960-557d-4303-9e80-fa75cf32b932": [
            "cce62a20-ed38-46b0-aee6-f9f6aefd38e9"
        ],
        "9e43c702-f398-420a-a845-f21c21aa708a": [
            "cce62a20-ed38-46b0-aee6-f9f6aefd38e9"
        ],
        "721ed848-f357-4f6c-9dd3-fceecf0fe84e": [
            "ef9de9fe-7188-4cd4-84fd-74b22d359b03"
        ],
        "61bc49d6-83fe-401f-ae29-6d9f4dd25449": [
            "ef9de9fe-7188-4cd4-84fd-74b22d359b03"
        ],
        "50a9fe96-fa0e-41bd-86c5-9adb2f1e0307": [
            "cb913d4c-fd24-4f08-bf9f-48cde65cd0c9"
        ],
        "08647d13-9f01-4179-88b0-d26c14210308": [
            "cb913d4c-fd24-4f08-bf9f-48cde65cd0c9"
        ],
        "5f006562-326a-43a7-b2dc-67b99c3fc42c": [
            "99b8bcd2-0f15-4ff9-ae5d-fa6163e53a9e"
        ],
        "39245bf6-570c-421c-a435-83db05564779": [
            "99b8bcd2-0f15-4ff9-ae5d-fa6163e53a9e"
        ],
        "b924d8ec-18f5-4b69-82e7-cce6f4289727": [
            "746ed21e-dfc8-4e08-9e19-f44a749ec5d2"
        ],
        "f63f89cc-2ce0-4b6b-8dae-d1d6d611be54": [
            "746ed21e-dfc8-4e08-9e19-f44a749ec5d2"
        ],
        "1c1a9360-6bf5-464b-90bc-9d9de2232431": [
            "b1e4b492-7df4-49ed-ad87-892387b47b4b"
        ],
        "b6f5b263-9e5f-43d7-b6d7-7e0c417963c2": [
            "b1e4b492-7df4-49ed-ad87-892387b47b4b"
        ],
        "d2a9e8da-07ad-4ad6-9e1a-28bf5b17acb3": [
            "85bad2a4-fa4f-401c-8a69-d57f6843b823"
        ],
        "8da7ea71-7b2f-4998-bbd8-c87d0089534b": [
            "85bad2a4-fa4f-401c-8a69-d57f6843b823"
        ],
        "d13c6769-991a-4718-b27c-b2bec143e0a8": [
            "47484453-28ac-4581-afc2-75a3330e9118"
        ],
        "5f88d2f5-b88c-4b67-95cf-ef9dfb9dcbe5": [
            "47484453-28ac-4581-afc2-75a3330e9118"
        ],
        "fb75f2e3-c4a5-4139-ba9a-22c4faaed420": [
            "d7a333b7-aad9-4f2d-80d3-4c38624d7fa9"
        ],
        "957f3e04-aea9-4b1e-8481-e91154d61b98": [
            "d7a333b7-aad9-4f2d-80d3-4c38624d7fa9"
        ],
        "0e5c0e49-2292-423d-80e4-49d0dd020bca": [
            "b92c2f3e-ecf8-4a05-8785-c6a28992cd9f"
        ],
        "f17efd7f-657b-4ce5-ba0d-2d0a487aad2d": [
            "b92c2f3e-ecf8-4a05-8785-c6a28992cd9f"
        ],
        "91b1595a-1593-493a-a3ff-80ff56c8cb3d": [
            "2835aa29-2a36-495d-9280-10ee37af3b26"
        ],
        "35497de1-2c2c-4507-bcf5-3967305b34eb": [
            "2835aa29-2a36-495d-9280-10ee37af3b26"
        ],
        "d45e1b96-98ab-4144-9eeb-4309618eb047": [
            "b64932f3-ab2b-48fa-8ecc-1b22c4890feb"
        ],
        "1c93d89a-f936-479d-bb8a-509581d9dbe3": [
            "b64932f3-ab2b-48fa-8ecc-1b22c4890feb"
        ],
        "b0626909-6a76-4ffb-9423-66a0ea76dcc9": [
            "28b19786-20aa-4cd2-a13b-e32da365ff44"
        ],
        "247cbd27-76d5-405e-932e-b70d372bbe9f": [
            "28b19786-20aa-4cd2-a13b-e32da365ff44"
        ],
        "cf9528c8-4019-4dc4-bcf0-294f73160940": [
            "f118c1e2-1e0e-4201-a2dd-cfc22442d3d7"
        ],
        "d1aa45bc-5364-49bf-b9cc-08b207e5fb71": [
            "f118c1e2-1e0e-4201-a2dd-cfc22442d3d7"
        ],
        "96e972fe-a165-4884-94f5-95ad1ba79341": [
            "dd4e5df3-db48-482a-8e1a-218c3d243569"
        ],
        "32c0fa3c-1069-4bd3-8831-daa29fecab3e": [
            "dd4e5df3-db48-482a-8e1a-218c3d243569"
        ],
        "aef0f80d-1c1b-4e35-b0d1-894c2e0335eb": [
            "a2f847b8-3273-4e71-8138-ea9b3a2a84d6"
        ],
        "672040e0-5199-498c-8e11-237c2f8915e7": [
            "a2f847b8-3273-4e71-8138-ea9b3a2a84d6"
        ],
        "58b5b53e-6622-46cb-9b8f-55f39a4fb832": [
            "aa0f6448-6dc6-431f-bb19-09aad8b3f258"
        ],
        "48a57197-a425-4777-b720-3a07f6ee8736": [
            "aa0f6448-6dc6-431f-bb19-09aad8b3f258"
        ],
        "a1bd51ed-d418-4b3e-8d96-001dda090967": [
            "be6e7215-c0c0-4345-8aa3-be366583349a"
        ],
        "befe1252-e0bd-4aa6-8ef7-f79d37c3083b": [
            "be6e7215-c0c0-4345-8aa3-be366583349a"
        ],
        "2e295f3e-d631-464b-bbfc-db85b313d4db": [
            "eaf34c6f-ed2c-4896-b9ad-9de09c3c2576"
        ],
        "bf3d0bd0-fbd0-4c90-bdf8-bd167b650887": [
            "eaf34c6f-ed2c-4896-b9ad-9de09c3c2576"
        ],
        "f9731797-6320-46ae-862e-36e52d3502f1": [
            "6782f293-e371-4e1d-8936-378d1e31f1b4"
        ],
        "7ffdbe15-7ee3-45d1-b90d-0fece77c0f1d": [
            "6782f293-e371-4e1d-8936-378d1e31f1b4"
        ],
        "b092b36b-32b0-40e8-925f-5c7850498289": [
            "60a1c99f-eff6-482d-aea9-af3818f12902"
        ],
        "bc4b2882-4887-492c-b040-7eb14ebc7405": [
            "60a1c99f-eff6-482d-aea9-af3818f12902"
        ],
        "f58971f0-a1c4-478a-a37e-1794d2a1f89c": [
            "d1c53476-fce5-41e5-b538-af8209402b5f"
        ],
        "710d8c13-1a0d-41d0-a1dc-18295dfeeb66": [
            "d1c53476-fce5-41e5-b538-af8209402b5f"
        ],
        "d78d9a5b-89f5-4694-aed4-ed7e69403d1d": [
            "4378e7e7-11c0-45b9-a6c4-f89464d6d316"
        ],
        "f0d828be-4be5-4b21-92ca-630f42d64e3f": [
            "4378e7e7-11c0-45b9-a6c4-f89464d6d316"
        ],
        "f8c78a9d-5fcc-4697-9910-24ccfd1e6545": [
            "c9760664-aaeb-4049-bbf3-12b265bf453d"
        ],
        "bc9f6c09-6d29-4dd8-a049-b8e3673f4e44": [
            "c9760664-aaeb-4049-bbf3-12b265bf453d"
        ],
        "0dd99c93-a07b-4786-b934-f46515ad311d": [
            "00a8e2b6-6611-406c-90fe-cf53495b8ae9"
        ],
        "a574605a-33a1-431b-9963-d75e388c4b3a": [
            "00a8e2b6-6611-406c-90fe-cf53495b8ae9"
        ],
        "f77d2cf6-82b7-426c-b339-081a3e1e571c": [
            "b8454a9d-8716-4bd1-b4b6-048c5bdbd263"
        ],
        "0283010e-978d-40b1-aa5f-57547718c38c": [
            "b8454a9d-8716-4bd1-b4b6-048c5bdbd263"
        ],
        "8c5eb60a-2393-4482-88b5-ca078c6c8cdf": [
            "dc05658c-1521-4439-99c2-5e4c8a65bf9b"
        ],
        "bc0fe842-af68-4363-99b2-b477d1be9e27": [
            "dc05658c-1521-4439-99c2-5e4c8a65bf9b"
        ],
        "f7cc3912-8ec5-4bc0-bd01-8fec4a2e6def": [
            "7ca505ce-5071-41cb-ac7e-ed743a027da6"
        ],
        "727ee0c6-c101-4776-801e-34a470d1b4e6": [
            "7ca505ce-5071-41cb-ac7e-ed743a027da6"
        ],
        "6d20f0ec-eec3-4ff5-a322-f945d863db86": [
            "bbea6a63-ee6b-4c6a-b0fd-88477f680906"
        ],
        "ebde839a-5f85-4750-accd-4e07b1ee0d55": [
            "bbea6a63-ee6b-4c6a-b0fd-88477f680906"
        ],
        "542cf206-050e-40ef-af7a-aca0484b6a50": [
            "68baa808-e6c8-474d-9b86-bfa381fca8c3"
        ],
        "24981b66-ba3f-4472-857a-138c6d6fd3bc": [
            "68baa808-e6c8-474d-9b86-bfa381fca8c3"
        ],
        "15cc5148-b3d9-4210-970b-e2b74074a161": [
            "503d6cf6-c71d-4f21-98c8-21263be72118"
        ],
        "c65391ec-ed33-4802-adbc-0f63c6d320ef": [
            "503d6cf6-c71d-4f21-98c8-21263be72118"
        ],
        "bb650006-0556-4d29-b1c2-fb12799b69fc": [
            "6dbb98db-0fcf-43e8-8be7-aff80b630655"
        ],
        "957f1151-4a3a-4ae0-b72a-cb8ef73cf25e": [
            "6dbb98db-0fcf-43e8-8be7-aff80b630655"
        ],
        "055c87dd-5f2f-4d9f-8fe8-2425c77c20bf": [
            "305d63a4-351d-432f-b94f-a675efd5f2ab"
        ],
        "206c39fd-e28c-42c7-83a3-0840af6237b3": [
            "305d63a4-351d-432f-b94f-a675efd5f2ab"
        ],
        "3123d6a9-53e7-4b5a-abdd-b15b96489b0c": [
            "071eb646-ff39-4e07-9238-528c2ac0a45f"
        ],
        "9310963b-7ce2-457e-8fed-469a5e706cd5": [
            "071eb646-ff39-4e07-9238-528c2ac0a45f"
        ],
        "d20b615d-dea9-4c02-8d0c-b2bb5ba55bfe": [
            "c821759b-b034-43b3-9546-9d69a76668b7"
        ],
        "ff83596f-d274-40b2-ae74-b9275721a894": [
            "c821759b-b034-43b3-9546-9d69a76668b7"
        ],
        "2788f64b-5811-4360-8566-ae9692144f8a": [
            "4d6cd175-8561-44a7-9c86-bb7c3d040251"
        ],
        "a03fda4b-cf0f-4334-b9ed-0c927f9073bf": [
            "4d6cd175-8561-44a7-9c86-bb7c3d040251"
        ],
        "62ffc323-59fa-450e-b9f8-62e533d98730": [
            "68485db0-adbc-4f1a-b335-93e5eefcd21d"
        ],
        "ffc115f8-f91f-41f7-b3c9-eec66f772da5": [
            "68485db0-adbc-4f1a-b335-93e5eefcd21d"
        ],
        "3f11e2dd-19cb-47f2-8e32-465f50a109d2": [
            "be25ddb4-68f9-45d9-bf67-abb219346a5d"
        ],
        "d4a226f6-760a-4387-a3b9-39ce47662abd": [
            "be25ddb4-68f9-45d9-bf67-abb219346a5d"
        ],
        "3117904f-b383-42b0-9a1c-943ecc965da7": [
            "124efe1e-25f8-4fe6-b781-2631442ee477"
        ],
        "1cec2a6b-8cb6-4fa5-a3ed-7f3b889bf43f": [
            "124efe1e-25f8-4fe6-b781-2631442ee477"
        ],
        "6d387310-949e-471c-bd9e-ec3e6fa94149": [
            "80088cdd-4c73-48cc-af15-66a5ee768e94"
        ],
        "4efa7739-9a79-4f8d-b7d6-bac1414952fe": [
            "80088cdd-4c73-48cc-af15-66a5ee768e94"
        ],
        "07dc306d-1582-496a-a2f5-3f0757374695": [
            "13d3b6c2-00f1-46e9-ad66-8e43c684b322"
        ],
        "1cfb02fb-0329-4177-b886-ad9373dcfd6d": [
            "13d3b6c2-00f1-46e9-ad66-8e43c684b322"
        ],
        "99052771-9074-4d69-9392-43375e9f34d6": [
            "953e65fb-b591-4d3a-a763-19a9bf8299b2"
        ],
        "383f33fb-0533-4052-a32e-ec510006d031": [
            "953e65fb-b591-4d3a-a763-19a9bf8299b2"
        ],
        "b835bea3-d7f0-479b-8e26-59ded90b8c64": [
            "13fb7afc-410c-42a7-a8ba-961f31454c08"
        ],
        "7a246cbf-7960-428a-94a6-e9e1af118e81": [
            "13fb7afc-410c-42a7-a8ba-961f31454c08"
        ],
        "7fac1424-6e86-418d-8e4b-2b089f8af685": [
            "6ab04e03-4d2f-4f52-8352-47600661eb1d"
        ],
        "e41ca7be-5891-4732-808f-a607813bc5fa": [
            "6ab04e03-4d2f-4f52-8352-47600661eb1d"
        ],
        "497edf46-1e8b-4cc0-8487-a7c5127aa068": [
            "66053e42-096e-44c5-beee-7555c05be403"
        ],
        "212d5044-1438-494a-820a-6f1424f0771a": [
            "66053e42-096e-44c5-beee-7555c05be403"
        ],
        "18090af4-2197-4b51-a15f-3d25621caf82": [
            "1b2d035c-dc3c-4a0e-9cd7-fdaccee3bfea"
        ],
        "238e977d-86e1-4f69-8c06-2653f1e369ed": [
            "1b2d035c-dc3c-4a0e-9cd7-fdaccee3bfea"
        ],
        "8a72dedc-9ba6-44cb-8794-a0520433a169": [
            "5b47f1f0-ff3c-49a8-817c-cd9d4b1c2fc9"
        ],
        "0b3d0c18-ddc8-46a2-ada2-ee967bab68cf": [
            "5b47f1f0-ff3c-49a8-817c-cd9d4b1c2fc9"
        ],
        "6f073bfd-0c8d-4bc0-a171-fe1e93e79d44": [
            "0f686d05-2851-4115-8bd1-f8bfd2e0402c"
        ],
        "cabe5174-2c8d-4518-ba60-23762a296af8": [
            "0f686d05-2851-4115-8bd1-f8bfd2e0402c"
        ],
        "9266e556-7c50-46f8-b84a-42d27f2975a4": [
            "f933d2f2-0e97-488f-a803-4d0f650b8636"
        ],
        "af4633fd-d012-4a09-adc1-b5332713a822": [
            "f933d2f2-0e97-488f-a803-4d0f650b8636"
        ],
        "254005e8-d8f9-4ec9-bfe0-fc18767b6512": [
            "82c01faf-2f18-4a73-925f-d67620fb8835"
        ],
        "55b993bf-1017-4b76-b555-32cff099c33d": [
            "82c01faf-2f18-4a73-925f-d67620fb8835"
        ],
        "988f61f9-7af4-4637-b23b-9b447305c14d": [
            "9a009ea6-9b20-425d-b973-05b7746ead06"
        ],
        "69dfc80a-412c-482e-a3c0-8e16c2bb42c9": [
            "9a009ea6-9b20-425d-b973-05b7746ead06"
        ],
        "9ef49628-5755-41fa-a235-62b91bc070d0": [
            "a68cc2a4-c831-4179-bcf2-ecbeacc712f4"
        ],
        "07abc708-529b-492d-a9c4-0f7de3c099ec": [
            "a68cc2a4-c831-4179-bcf2-ecbeacc712f4"
        ],
        "4591bd16-5f22-456d-88e8-949f68dc4645": [
            "9beb19a5-8931-4b30-a0cf-e51175c6c3e5"
        ],
        "a9a2f015-bc4a-4d72-bc92-dbef43721828": [
            "9beb19a5-8931-4b30-a0cf-e51175c6c3e5"
        ],
        "d98706b2-07e2-4ca5-9d4a-f3a17a77fe05": [
            "5bf9a260-1109-4d00-ad7d-1128679e329e"
        ],
        "fc9e3456-e446-42ac-8b52-71df5baf0379": [
            "5bf9a260-1109-4d00-ad7d-1128679e329e"
        ],
        "27a0a25d-25da-40e6-9837-8c24e7a43fb1": [
            "4c03f709-3003-4f4f-9987-8818a4a55f23"
        ],
        "c58ad9dd-0b9e-46de-a4e3-723045488dae": [
            "4c03f709-3003-4f4f-9987-8818a4a55f23"
        ],
        "99a8d56f-dbc1-4169-b3b3-81d2e46e0d24": [
            "0beb6e2b-3748-4ec1-a2ad-53a6111a30de"
        ],
        "0b883284-b0f4-445a-84b1-4ef392e6159c": [
            "0beb6e2b-3748-4ec1-a2ad-53a6111a30de"
        ],
        "f5e58c47-63b1-460d-978e-045e26793322": [
            "9d945764-4590-4235-b622-5a23789092e9"
        ],
        "1dd57ddc-ca86-49f1-bc66-79062e2e8a9a": [
            "9d945764-4590-4235-b622-5a23789092e9"
        ],
        "8972eff2-3efa-4f4b-9a07-a73d726d6af0": [
            "c1cc4638-cc34-4d34-a48d-a807f35e0dd0"
        ],
        "95e37cf3-6f3d-44a3-a0a8-f99b04fd79e4": [
            "c1cc4638-cc34-4d34-a48d-a807f35e0dd0"
        ],
        "e1ff34fb-3109-4ad2-8c55-bd8385741be6": [
            "e8e12f7d-9db5-4933-b7da-14f60fef51e9"
        ],
        "c94b7654-19da-476b-81fd-0779ac9f208d": [
            "e8e12f7d-9db5-4933-b7da-14f60fef51e9"
        ],
        "e9761bd3-1b76-41f4-9785-7c1302c4e36e": [
            "1baa1c67-9b96-4fc7-b0e2-6c30a47b6c4a"
        ],
        "7412669e-ffb8-479f-8e83-74923232d68a": [
            "1baa1c67-9b96-4fc7-b0e2-6c30a47b6c4a"
        ],
        "34c45532-2392-4087-ba05-1241adcc9b0d": [
            "07da622f-d7ee-4c67-8071-d287e50465a3"
        ],
        "fa212297-48a2-4235-ada6-6f22b31d4d5a": [
            "07da622f-d7ee-4c67-8071-d287e50465a3"
        ],
        "1a5af197-3225-4de8-94e3-c993b7df9e37": [
            "aeacc3f8-a96f-4a73-aa0c-9d404beead0c"
        ],
        "67f4d4d1-c8bb-453b-beef-2232cb01571c": [
            "aeacc3f8-a96f-4a73-aa0c-9d404beead0c"
        ],
        "70d3bc96-0cf6-48e2-8470-6d7e52120878": [
            "b8f989f8-8458-4fa9-a4c3-c5447b1a79aa"
        ],
        "8dc3fc66-a5fa-4011-94db-7edc8eb471c3": [
            "b8f989f8-8458-4fa9-a4c3-c5447b1a79aa"
        ],
        "12518d2f-a529-4d82-9b9c-7e0776a455f8": [
            "06c25e53-511d-46c4-9756-81b9251177a9"
        ],
        "c8d23dbc-c72c-4771-808c-fa1b4a74d055": [
            "06c25e53-511d-46c4-9756-81b9251177a9"
        ],
        "905449d1-b46b-4dd6-a0f2-01fa5086b9f2": [
            "65b99269-cddc-433e-96ca-df2cbbc9bd2b"
        ],
        "14f46b75-bff1-49f2-bfdf-bce2ff570eda": [
            "65b99269-cddc-433e-96ca-df2cbbc9bd2b"
        ],
        "84fa7aff-b5c0-49dd-ae5e-a7cb92798e24": [
            "d0065cb5-7bfe-43fc-8547-302056e1edc2"
        ],
        "94737cf2-7b96-4ce1-955b-1b6330ced78f": [
            "d0065cb5-7bfe-43fc-8547-302056e1edc2"
        ],
        "10bee57b-45ec-484a-9641-3fd5cb901524": [
            "8c273783-30a9-4fb6-96e3-ff9212a0d2ab"
        ],
        "bddac138-f1ec-4c9d-b4d9-5430fd8fa850": [
            "8c273783-30a9-4fb6-96e3-ff9212a0d2ab"
        ],
        "5f65b323-f06e-44c0-bd07-2a664f3174d7": [
            "6c417c02-80a8-4707-9a40-a6f2b094d172"
        ],
        "b134ba42-60d3-4d1c-8875-d5084fb0d4d8": [
            "6c417c02-80a8-4707-9a40-a6f2b094d172"
        ],
        "4ed55967-a537-4590-af4e-aeae9f0b9426": [
            "f0589da0-864c-4eef-a96a-3721a43644c3"
        ],
        "63e09c78-e508-466a-86e0-905cd17483bc": [
            "f0589da0-864c-4eef-a96a-3721a43644c3"
        ],
        "deb10552-08b1-4d58-9484-1f73d7890527": [
            "ec2fc4b6-b5d6-4358-b637-41cc19ba016a"
        ],
        "5f7ffba8-229b-45cb-85bf-2768aeb0331b": [
            "ec2fc4b6-b5d6-4358-b637-41cc19ba016a"
        ],
        "4aeacf9a-9a81-4150-bff1-1a34db09e573": [
            "a999435d-9ed9-4a99-a5e1-328dd43e220b"
        ],
        "8d726c6a-5a5f-4e6a-b5d9-ed78cde75067": [
            "a999435d-9ed9-4a99-a5e1-328dd43e220b"
        ],
        "b161040c-b0fd-4f19-a3ac-cdc9488cbceb": [
            "5af1f705-8da0-4ef8-9aa7-8764308e0444"
        ],
        "1eb368d5-0c4b-476b-9505-3fe2121a1046": [
            "5af1f705-8da0-4ef8-9aa7-8764308e0444"
        ],
        "5f951074-a90b-417f-8db4-24a2cb600758": [
            "03497b95-8e2b-4f32-824b-9d99ddfb8bdb"
        ],
        "fbc5e238-5615-45c2-b682-22e8baebafec": [
            "03497b95-8e2b-4f32-824b-9d99ddfb8bdb"
        ],
        "52cb307a-2411-45ac-be40-7a4f3fa2c1ef": [
            "837074c8-2ef7-474e-b65c-593d011f241f"
        ],
        "3fe1ca0f-ca33-46e6-bc52-43defaebc2a4": [
            "837074c8-2ef7-474e-b65c-593d011f241f"
        ],
        "0e001863-ff93-407f-8db3-2bd79eb43cbe": [
            "8b674d5a-04fb-4e1a-a835-9b1c7d1eeeee"
        ],
        "3ad0b35c-1ecb-4ce3-ab5e-f367f7f8bf8f": [
            "8b674d5a-04fb-4e1a-a835-9b1c7d1eeeee"
        ],
        "82f01afb-9b13-41f1-b056-ab2a90afeabf": [
            "e75f2c58-8e39-450e-85ec-fadfc0084679"
        ],
        "d99016d1-7aed-4229-970f-68f500f27454": [
            "e75f2c58-8e39-450e-85ec-fadfc0084679"
        ],
        "21227383-588d-4d35-bde6-2f498e35d146": [
            "e75f2c58-8e39-450e-85ec-fadfc0084679"
        ],
        "130b65da-abac-4e63-b5e4-e0ca6d554522": [
            "e75f2c58-8e39-450e-85ec-fadfc0084679"
        ],
        "7b20c082-a760-45e0-8f7f-63ea0636d8e0": [
            "e75f2c58-8e39-450e-85ec-fadfc0084679"
        ],
        "ee26228e-efe4-4370-a2f6-70b259afff6b": [
            "a753c124-f54a-43de-826c-cbdb1f2dc82d"
        ],
        "17f4668e-e2d2-4d6c-bada-8d2871a3be37": [
            "a753c124-f54a-43de-826c-cbdb1f2dc82d"
        ],
        "002fae7f-90b5-4224-977c-e8f6a7e65789": [
            "2cfa670b-f942-4122-bd68-ad119f471d4e"
        ],
        "4f78b3f0-537e-463a-9c41-73a15c19ea50": [
            "2cfa670b-f942-4122-bd68-ad119f471d4e"
        ],
        "bfe7ef1a-d4be-4f01-a8d9-10975f575452": [
            "84bbb3e7-271a-4659-9a22-afc4bc490a8c"
        ],
        "1b9aceeb-fad0-46e1-9002-c6e7cdfd19b5": [
            "84bbb3e7-271a-4659-9a22-afc4bc490a8c"
        ],
        "96f45658-8bd4-400a-aaad-9b3937c0998e": [
            "9743b2c4-55ec-43bf-9224-3c5db03544c4"
        ],
        "d9060b00-7d6f-4e90-8341-4f156e5ab517": [
            "9743b2c4-55ec-43bf-9224-3c5db03544c4"
        ],
        "bb981231-6e9b-4ca8-a6ae-bb6140d01e7e": [
            "b3e61b9d-7379-473e-9a48-54d0bb5c44c3"
        ],
        "e6449ed6-ed94-40fd-9cc5-c4169b4c61b4": [
            "b3e61b9d-7379-473e-9a48-54d0bb5c44c3"
        ],
        "13cf5871-3c03-4b46-91ef-ccab71ea58c4": [
            "2c72cd4e-78cd-4f86-a247-a3c854e450d4"
        ],
        "bc6db71c-edfd-4cf4-a7fa-a0b9b2ea569f": [
            "2c72cd4e-78cd-4f86-a247-a3c854e450d4"
        ],
        "c3c73920-1a1e-4f0c-b274-9aa0ba13f131": [
            "01ead025-0aee-4fbf-b557-37c841d065ab"
        ],
        "61dd4774-4451-46d0-ae02-7f020389ad5b": [
            "01ead025-0aee-4fbf-b557-37c841d065ab"
        ],
        "69200a91-0d4e-4321-90dc-faaab7452af7": [
            "4532859a-9ee1-4036-bc6e-6489a021981d"
        ],
        "64490ead-3ce4-41a6-be51-a2a6c8905919": [
            "4532859a-9ee1-4036-bc6e-6489a021981d"
        ],
        "aef24a02-b5b9-4844-86ee-367c0fe158bf": [
            "2c408f99-565c-48da-8cb6-3224c3bb311a"
        ],
        "cf9e90f2-66a9-4839-bcee-0621c6dfab03": [
            "2c408f99-565c-48da-8cb6-3224c3bb311a"
        ],
        "b02201c2-ec04-4954-914b-3b46c2eae3b2": [
            "c5281756-155b-447d-ade0-2d0744d3bc56"
        ],
        "75133eac-c804-40e2-9632-0a45f4924739": [
            "c5281756-155b-447d-ade0-2d0744d3bc56"
        ],
        "528c47a3-eb8c-4b09-8c3c-6d3db34a10e2": [
            "2729b911-fa6a-4eb5-9364-7f84caf2d161"
        ],
        "84388d8f-0fe9-4f2e-b996-872f33bcc198": [
            "2729b911-fa6a-4eb5-9364-7f84caf2d161"
        ],
        "9673d8db-317a-41b3-b5fa-0ec91e47020a": [
            "399e256c-302a-48c6-b6a6-60066f1a69bd"
        ],
        "3047b54f-fc08-4edf-b873-842ae1df9cfe": [
            "399e256c-302a-48c6-b6a6-60066f1a69bd"
        ],
        "b606fe6f-7cb0-46f6-b932-1b901712797a": [
            "67cdca13-c938-485c-925b-18afcd99ba94"
        ],
        "d419cf83-0f8d-4596-92ab-2bce69b64d86": [
            "67cdca13-c938-485c-925b-18afcd99ba94"
        ],
        "97564cb2-4c8a-4b82-b51f-73773aae8f09": [
            "f3722c85-dcc5-4ab9-9577-ca5d3e50aa45"
        ],
        "e456b9e5-a6d2-462b-9908-59a399032bea": [
            "f3722c85-dcc5-4ab9-9577-ca5d3e50aa45"
        ],
        "52e5967a-fed4-414e-981a-4f0f4df46840": [
            "d65a5857-bcb7-4a74-9d86-c99e8dca3efa"
        ],
        "f848c257-1a6f-46e0-aba2-f3224a0cd60f": [
            "d65a5857-bcb7-4a74-9d86-c99e8dca3efa"
        ],
        "076ad76f-80e0-4356-bcdf-d5797dd13193": [
            "b322a600-6128-40a5-b4e5-d69fda25a259"
        ],
        "bad3ae63-143c-45fc-93ff-312aa9c857a0": [
            "b322a600-6128-40a5-b4e5-d69fda25a259"
        ],
        "5c519ead-1a5b-4329-9a9e-b1824bc9c26a": [
            "a0cda8d3-d796-489a-af97-5a8cf35e2ada"
        ],
        "da168b28-6b5d-465c-9a32-0d18a2f5dac5": [
            "a0cda8d3-d796-489a-af97-5a8cf35e2ada"
        ],
        "9cee3d64-151f-4586-aac9-e0ca4a435756": [
            "0a9b4c55-dcb7-4ad5-8a97-eacf615c145d"
        ],
        "b861f256-0c97-4b8e-a91f-2adb4fbe03ce": [
            "0a9b4c55-dcb7-4ad5-8a97-eacf615c145d"
        ],
        "95cdf832-d4ee-4c66-b86d-cccb3619c3ed": [
            "5285b0f4-7aaf-455b-be91-948f82435f1e"
        ],
        "2427c8f6-1678-41c9-b618-129ed073ca05": [
            "5285b0f4-7aaf-455b-be91-948f82435f1e"
        ],
        "bc14467d-8ce3-4b6d-9b2a-73b01da66e02": [
            "adda5fd4-8704-488f-b994-58f1f97fdfd7"
        ],
        "015ff135-e49c-4914-bac6-53092bf21b4d": [
            "adda5fd4-8704-488f-b994-58f1f97fdfd7"
        ],
        "79026bbf-7dcc-4f0c-8bcf-10a9ff732e4c": [
            "c9e7afa3-3c50-44e4-ba80-33f3ff0e80ff"
        ],
        "6326709b-08b8-44e5-9721-862a01914794": [
            "c9e7afa3-3c50-44e4-ba80-33f3ff0e80ff"
        ],
        "62938856-20ca-445b-bf0b-76bf39460d6f": [
            "33c7b41f-0599-4289-9c03-88ae2e746ce5"
        ],
        "6058daa3-6d99-4180-a24c-ee4ea4ffca97": [
            "33c7b41f-0599-4289-9c03-88ae2e746ce5"
        ],
        "b49aca44-69ee-4383-b186-2c5ce5bd6cc0": [
            "04b28d04-2ef0-4df3-8f7d-1040b15e6320"
        ],
        "4a0b13a5-1814-4337-ad39-51c91e9abb38": [
            "04b28d04-2ef0-4df3-8f7d-1040b15e6320"
        ],
        "6418d7e8-066e-4a9c-b270-90201a90f8f4": [
            "e330f48a-8a68-4468-9580-568478f38381"
        ],
        "5bd904cb-3bcc-433f-a94c-3f20fb32f5fd": [
            "e330f48a-8a68-4468-9580-568478f38381"
        ],
        "acb33a89-38da-4f9a-8777-f637d4252e02": [
            "d95179b5-5541-4a25-a927-abeb77fa438d"
        ],
        "c0d76b57-a095-4c9a-90be-264b5d42ed9f": [
            "d95179b5-5541-4a25-a927-abeb77fa438d"
        ],
        "c4c76516-2d69-45bf-a537-e13aeede324e": [
            "344fbbec-6698-4ec3-a8aa-a40d8d4bc0b8"
        ],
        "9ec26588-9d5f-415f-95fb-33d37b582906": [
            "344fbbec-6698-4ec3-a8aa-a40d8d4bc0b8"
        ],
        "08de43f9-3f4e-4fae-85d0-2ea1df4e1cf6": [
            "9d5ff691-d7e0-403a-96c8-cedbabbc7c7f"
        ],
        "bcdf2136-eee2-4dd9-a052-ebe33fd72c69": [
            "9d5ff691-d7e0-403a-96c8-cedbabbc7c7f"
        ],
        "c9d53a6e-aaad-4619-a781-58e6af68d2f3": [
            "762bddd5-2df6-40b4-b144-d9c159f311ae"
        ],
        "4bacd123-c254-4c20-884c-a6099bdc600f": [
            "762bddd5-2df6-40b4-b144-d9c159f311ae"
        ],
        "43b2b72c-1809-45bd-a851-e66fe8b9233b": [
            "e5256a6f-a206-4ed1-9ea7-29e9988cdbb3"
        ],
        "f2e5d290-2757-4a26-bc44-913bde9971d3": [
            "e5256a6f-a206-4ed1-9ea7-29e9988cdbb3"
        ],
        "bdbea4cb-ef4d-40c3-8c3e-126dfbeef355": [
            "f81046d3-d29a-40fe-b949-00b516ac7a17"
        ],
        "d39ed950-564c-47c8-a669-ac54a9c9cf38": [
            "f81046d3-d29a-40fe-b949-00b516ac7a17"
        ],
        "b66bd5ba-1c1d-404b-acf0-5666b9d71b83": [
            "c2e3a9bd-22e7-4d1d-8d80-fa673f196ef3"
        ],
        "858fc68a-a8f8-409f-9485-f5ce09c45940": [
            "c2e3a9bd-22e7-4d1d-8d80-fa673f196ef3"
        ],
        "1f024e27-b711-471d-98e5-715502536b0d": [
            "3de4bc8e-231d-49f1-9924-2022e99bb562"
        ],
        "c4e4853b-cc02-4c71-9a7e-0b7cc0f76517": [
            "3de4bc8e-231d-49f1-9924-2022e99bb562"
        ],
        "d372bf95-5e32-43d6-9abc-487c058a633f": [
            "e1afa308-7a6f-4dae-ab04-05c4f3b8b6da"
        ],
        "d09ea20a-3a39-4c10-ad92-1cd8027f5a7e": [
            "e1afa308-7a6f-4dae-ab04-05c4f3b8b6da"
        ],
        "57472ee6-0532-46fc-a500-1f20d76e62cd": [
            "a4ac8abb-146c-45f7-bc64-440f5d0ec9e8"
        ],
        "72a362c6-f48a-4477-af65-d9cc2d6c37dd": [
            "a4ac8abb-146c-45f7-bc64-440f5d0ec9e8"
        ],
        "ff0704f2-2e8a-4cc2-9b6c-969e77c3736b": [
            "0deaa77a-4f1e-4e49-8d6d-27b550120357"
        ],
        "4de950f2-7e4e-4f60-82b3-b33bd67cc21a": [
            "0deaa77a-4f1e-4e49-8d6d-27b550120357"
        ],
        "65311a5e-087b-4680-b051-86d44b09b160": [
            "5f7f3b8f-ac79-460c-aa7b-618451f14841"
        ],
        "f51c19d2-00c1-40d7-a076-862293a795ff": [
            "5f7f3b8f-ac79-460c-aa7b-618451f14841"
        ],
        "c1b252b6-7089-44a1-ad5a-9ec8a0831bbc": [
            "c91c1659-2c98-4290-bbab-c60757d95fa2"
        ],
        "bd3caf1d-05d2-4514-8eee-a2655366ae74": [
            "c91c1659-2c98-4290-bbab-c60757d95fa2"
        ],
        "c83fc8ad-1085-49f7-a9ac-a64dd429e08d": [
            "2632bb66-57ed-44f7-aaf9-1cda3aa5b5d8"
        ],
        "733eaf84-ffa3-410b-b7c5-c958905da22c": [
            "2632bb66-57ed-44f7-aaf9-1cda3aa5b5d8"
        ],
        "c8bc3e3e-95d2-4b61-9844-e5f2cedb89bb": [
            "8dd5d29f-c556-4d54-b0b6-1b4c40e359c2"
        ],
        "c8f93afc-e437-4993-ac82-aebd61f3f61e": [
            "8dd5d29f-c556-4d54-b0b6-1b4c40e359c2"
        ],
        "0a610d61-c3eb-4e79-9998-352e8dce1243": [
            "5d073f90-6559-44d5-9d19-5de861662c1c"
        ],
        "f4601d69-8f99-4d87-9804-70d6d5dd8ed4": [
            "5d073f90-6559-44d5-9d19-5de861662c1c"
        ],
        "6bf3f38c-5035-41db-acfc-be355686f122": [
            "9db94ab7-d740-4006-a8ad-1d47b7d68be6"
        ],
        "83795c52-2889-4848-b6b1-4bfff29968ba": [
            "9db94ab7-d740-4006-a8ad-1d47b7d68be6"
        ],
        "44718ce0-532e-4177-87c7-eb13c175dbac": [
            "c9feb7b2-716c-48c4-8485-d8fa233275ab"
        ],
        "4e532210-4429-499d-905c-25a25cdb5bf7": [
            "c9feb7b2-716c-48c4-8485-d8fa233275ab"
        ],
        "6ecc286a-e3ec-4446-a067-841ea4760d06": [
            "a26cba36-d9da-46ea-9c73-38c1a68dee56"
        ],
        "33c51ae6-0d18-4c7f-a614-1a75f28566d0": [
            "a26cba36-d9da-46ea-9c73-38c1a68dee56"
        ],
        "50e8341f-2185-4b17-814c-34697f2a6a3b": [
            "196261df-b770-465f-baed-b490ef41d505"
        ],
        "b781fdfc-66e3-4dd0-8d1f-3cd3bcc04bfc": [
            "196261df-b770-465f-baed-b490ef41d505"
        ],
        "4033192a-a712-4431-bc5d-519a084c64ac": [
            "cb3c0989-822a-4234-b685-f9dddae68370"
        ],
        "4979b8d8-2d30-45d4-acbc-99b7b39e149e": [
            "cb3c0989-822a-4234-b685-f9dddae68370"
        ],
        "3212284f-1970-42b5-ae3b-cde2ea1ba92e": [
            "c41be63f-f6b7-4b52-87e2-34bb9a91a275"
        ],
        "20e50a48-9083-410c-a608-3d7123f69287": [
            "c41be63f-f6b7-4b52-87e2-34bb9a91a275"
        ],
        "c071d9a5-4cc7-44a0-844a-3b0977c3a75c": [
            "a5eba347-c9da-47e2-8262-f43c51296315"
        ],
        "8cf7b988-6699-4996-9a99-881b58eac301": [
            "a5eba347-c9da-47e2-8262-f43c51296315"
        ],
        "f8db3b76-b245-4344-ae15-5865921b1b04": [
            "04c4c7ef-10f8-45f3-9526-c4589e56054e"
        ],
        "91ce6a45-4764-4e69-9d31-3bfa8572191a": [
            "04c4c7ef-10f8-45f3-9526-c4589e56054e"
        ],
        "dfd11724-dba7-46f7-813f-557298b23505": [
            "48628e86-b479-4c64-b8a9-cb810f40c068"
        ],
        "2627109e-c064-4039-97a4-e4fa189493cf": [
            "48628e86-b479-4c64-b8a9-cb810f40c068"
        ],
        "05a8b384-f67e-477b-97d2-577a2c85d7df": [
            "651bc893-b763-416d-aeeb-b5932fdc52be"
        ],
        "f2cbca7e-586b-42e5-8f50-fd08d34f4492": [
            "651bc893-b763-416d-aeeb-b5932fdc52be"
        ],
        "4902d4b1-c377-4100-b738-0adf275750bc": [
            "71b2b063-1cea-4a46-996d-48c8071a3ae2"
        ],
        "a9765b1d-c2d7-4e6c-9818-311c3d2e2f60": [
            "71b2b063-1cea-4a46-996d-48c8071a3ae2"
        ],
        "8d9a5fd5-d2dc-41ce-9d9c-cf26820567a3": [
            "ad88717f-4774-4fc2-a903-78d21cc26193"
        ],
        "31c77949-9d42-463d-bcf0-c34872abf958": [
            "ad88717f-4774-4fc2-a903-78d21cc26193"
        ],
        "c5829924-7da1-49d6-a1d9-8d8c0f81c9fa": [
            "ad88717f-4774-4fc2-a903-78d21cc26193"
        ],
        "0837229c-ea75-4620-a9a6-8eb490bcba2a": [
            "ad88717f-4774-4fc2-a903-78d21cc26193"
        ],
        "f2ddf1f5-f0d2-4363-b7dc-3caea6ab38d6": [
            "ad88717f-4774-4fc2-a903-78d21cc26193"
        ],
        "f42b9402-bb7d-4a8c-9079-e22b4865d17e": [
            "ad88717f-4774-4fc2-a903-78d21cc26193"
        ],
        "dfd7d488-edae-417c-b9a9-4957c7f004e5": [
            "ad88717f-4774-4fc2-a903-78d21cc26193"
        ],
        "643d6143-92f1-471c-9900-0e1cdb1192e5": [
            "ad88717f-4774-4fc2-a903-78d21cc26193"
        ],
        "d3321424-8c86-4110-897e-7c6941dc15c7": [
            "ad88717f-4774-4fc2-a903-78d21cc26193"
        ],
        "53c33a5c-69d4-410b-9230-ee90dca843b7": [
            "ad88717f-4774-4fc2-a903-78d21cc26193"
        ],
        "88086299-cd29-4b46-be2f-cc3f109a137b": [
            "b24874e0-c351-40d6-a2a0-2b7e2b76b0f8"
        ],
        "58ef5825-34f2-4a9e-9a74-a3b5a0783988": [
            "b24874e0-c351-40d6-a2a0-2b7e2b76b0f8"
        ],
        "09cdfd22-c4ae-43f8-8b1a-644df42d938b": [
            "02c2a23b-0bf2-417f-a4c2-2d80b0bbac0b"
        ],
        "d844b962-5cc3-4a83-a9cc-855ec167e46e": [
            "02c2a23b-0bf2-417f-a4c2-2d80b0bbac0b"
        ]
    }
}
