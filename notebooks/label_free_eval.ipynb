{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e18de0d-660b-4706-be79-55a547aae68f",
   "metadata": {},
   "source": [
    "# Label-Free Evaluation with Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cdb1c0-9178-4c69-9570-bff157cbe1be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a470ac-0a4e-43a5-89f4-6678b1ff0f81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import ray\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9baf96d1-2e11-49fc-bbd5-984cbb95c89f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv; load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b13a087-ece2-4a3e-be2f-a4efc2dc3452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ray/default/llm-applications\n"
     ]
    }
   ],
   "source": [
    "EFS_DIR = Path(\"/efs/shared_storage/simon\")\n",
    "ROOT_DIR = Path(os.getcwd()).parent\n",
    "print (ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2a760-57f7-4630-9a60-b6405036807d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Credentials\n",
    "ray.init(runtime_env={\"env_vars\": {\n",
    "    \"OPENAI_API_BASE\": os.environ[\"OPENAI_API_BASE\"],\n",
    "    \"OPENAI_API_KEY\": os.environ[\"OPENAI_API_KEY\"], \n",
    "    \"ANYSCALE_API_BASE\": os.environ[\"ANYSCALE_API_BASE\"],\n",
    "    \"ANYSCALE_API_KEY\": os.environ[\"ANYSCALE_API_KEY\"],\n",
    "    \"DB_CONNECTION_STRING\": os.environ[\"DB_CONNECTION_STRING\"],\n",
    "}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb6f5b-67d7-4912-bd22-6d0e3dcb13af",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "328cec8e-df42-452c-a569-c96c4fd69e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_json(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def read_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e434d9-8985-4d3f-9bbc-77f72d78697b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "324debfb-4f20-4c84-8648-ee4dc020b652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sections = read_json(Path(ROOT_DIR, \"datasets/eval_full_corpus.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "115180cf-2773-4c06-bd55-da9ffb719faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "def to_doc(entry_dict):\n",
    "    return Document(text=entry_dict['text'], metadata={'source': entry_dict['source']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "bead60c9-5e68-4c70-a470-89e234e67d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = [to_doc(dict_) for dict_ in sections]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd23c91-1bd5-448e-b83e-a47d2784f8bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bb11c6f-b276-40a8-9882-d12cf9aaf58b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4181eff2-8403-40d2-998d-352892ca3c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLING_RATIO = 0.01\n",
    "sampling_percentage = SAMPLING_RATIO * 100 \n",
    "n_samples = int(SAMPLING_RATIO * len(sections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88ef73a9-4de9-4059-afc9-8d92b87b1bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_corpus = random.sample(sections, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de267fd5-5e1d-447d-afee-9f392942dd1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 1.0% of full corpus with 8944 sections, got 89 sections\n"
     ]
    }
   ],
   "source": [
    "print(f'Sampled {sampling_percentage}% of full corpus '\n",
    "      f'with {len(sections)} sections, got {len(val_corpus)} sections')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5e000-1938-430e-93ad-389a528e7228",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Generate synthetic evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9c7e53f4-d670-4d9d-87fc-bb245ebc6415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import uuid\n",
    "\n",
    "from llama_index.schema import Document, TextNode\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index import PromptHelper\n",
    "from llama_index.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a8878b56-0b91-448e-b2cf-19966f0694d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_QA_GENERATE_PROMPT_TMPL = PromptTemplate(\"\"\"\\\n",
    "Context information is below.\n",
    "\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "\n",
    "Given the context information and not prior knowledge.\n",
    "generate only questions based on the below query.\n",
    "\n",
    "You are a Teacher/ Professor. Your task is to setup \\\n",
    "{num_questions_per_chunk} questions for an upcoming \\\n",
    "quiz/examination. The questions should be diverse in nature \\\n",
    "across the document. Restrict the questions to the \\\n",
    "context information provided.\"\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f601d399-f13d-4db2-add6-9933862e28f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate queries as a convenience function\n",
    "def generate_qa_embedding_pairs(\n",
    "    docs,\n",
    "    llm=None,\n",
    "    qa_generate_prompt_tmpl=DEFAULT_QA_GENERATE_PROMPT_TMPL,\n",
    "    num_questions_per_chunk=2,\n",
    ") -> dict:\n",
    "    \"\"\"Generate examples given a set of nodes.\"\"\"\n",
    "    corpus = {\n",
    "        doc['source']: doc\n",
    "        for doc in docs\n",
    "    }\n",
    "\n",
    "    llm = llm or OpenAI(model=\"gpt-3.5-turbo\")\n",
    "    prompt_helper = PromptHelper.from_llm_metadata(llm.metadata)\n",
    "\n",
    "    queries = {}\n",
    "    relevant_docs = {}\n",
    "    corpus = {}\n",
    "    for doc in tqdm(docs):\n",
    "        text = doc['text']\n",
    "        source = doc['source']\n",
    "        if not text.strip():\n",
    "            continue\n",
    "            \n",
    "        # truncate text to fit in LLM context window\n",
    "        text = prompt_helper.truncate(qa_generate_prompt_tmpl, [text])[0]\n",
    "        \n",
    "        # generate hypothetical questions\n",
    "        query = qa_generate_prompt_tmpl.format(\n",
    "            context_str=text, num_questions_per_chunk=num_questions_per_chunk\n",
    "        )\n",
    "        response = llm.complete(query)\n",
    "\n",
    "        # process questions\n",
    "        result = str(response).strip().split(\"\\n\")\n",
    "        questions = [\n",
    "            re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip() for question in result\n",
    "        ]\n",
    "        questions = [question for question in questions if len(question) > 0]\n",
    "\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        corpus[doc_id] = doc\n",
    "        for question in questions:\n",
    "            question_id = str(uuid.uuid4())\n",
    "            queries[question_id] = question\n",
    "            relevant_docs[question_id] = [source]\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'queries': queries,\n",
    "        'corpus': corpus, \n",
    "        'relevant_docs': relevant_docs, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "076e8ae1-f442-43cd-8b84-65ff1812fcb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [01:24<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataset = generate_qa_embedding_pairs(val_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7018a77f-b265-4acb-88be-2ee003109d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_json(val_dataset, Path(ROOT_DIR, \"datasets/eval_sample_p1_synthetic.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5d2384a1-0570-46f3-825d-63289166e34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset = read_json(Path(ROOT_DIR, \"datasets/eval_sample_p1_synthetic.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b5369c-8848-4f67-8636-c3eac889486f",
   "metadata": {},
   "source": [
    "## Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6c981418-fd97-4ac4-af53-1723746b5897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, Document, ServiceContext\n",
    "from llama_index.embeddings import OpenAIEmbedding, LangchainEmbedding\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "bb9c24c0-86ec-49c2-936e-04654753c1db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_index(\n",
    "    docs,\n",
    "    chunk_size,\n",
    "    embed_model='text-embedding-ada-002',\n",
    "):\n",
    "    if embed_model == 'text-embedding-ada-002':\n",
    "        embed_model= OpenAIEmbedding(embed_batch_size=100)\n",
    "    else:\n",
    "        embed_model = HuggingFaceEmbeddings(model_name=embed_model)\n",
    "        embed_model = LangchainEmbedding(embed_model, embed_batch_size=100)\n",
    "        \n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        chunk_size=chunk_size,\n",
    "        embed_model=embed_model,\n",
    "    )\n",
    "    index = VectorStoreIndex.from_documents(docs, service_context=service_context, show_progress=True)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "36a9b966-9959-4471-9cf6-56bf75d99e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f18d65dbdd42e3831e882c12fd142b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/8944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a5af20fbc841b688005c190cd5406c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = build_index(docs, chunk_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "99698743-f9fc-40e1-bf53-39a3878f3085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ebb59080-ccaa-4977-9f5f-00ab436e0096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine.query('What is the default batch size for map_batches?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d900550-bbbd-4d02-9b3f-5c7264107020",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5db4a2da-6fdd-4e2d-b879-f18f9f7f59e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_index(\n",
    "    dataset,\n",
    "    index,\n",
    "    top_k=5,\n",
    "    verbose=False,\n",
    "):\n",
    "    corpus = dataset['corpus']\n",
    "    queries = dataset['queries']\n",
    "    relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "\n",
    "    eval_results = []\n",
    "    for query_id, query in tqdm(list(queries.items())):\n",
    "        retrieved_nodes = retriever.retrieve(query)\n",
    "        retrieved_sources = [node.node.metadata['source'] for node in retrieved_nodes]\n",
    "        expected_source = relevant_docs[query_id][0]\n",
    "        is_hit = expected_source in retrieved_sources  # assume 1 relevant doc\n",
    "        \n",
    "        eval_result = {\n",
    "            'is_hit': is_hit,\n",
    "            'retrieved': retrieved_sources,\n",
    "            'expected': expected_source,\n",
    "            'query': query_id,\n",
    "        }\n",
    "        eval_results.append(eval_result)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d952c182-e5cf-4a72-b78e-15d2d93519a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    docs, \n",
    "    eval_dataset,\n",
    "    chunk_size=1024,\n",
    "    embed_model=\"text-embedding-ada-002\",\n",
    "    top_k=5,\n",
    "    verbose=True,\n",
    "):\n",
    "    index = build_index(docs, chunk_size, embed_model)\n",
    "    results = evaluate_index(eval_dataset, index, top_k, verbose=verbose)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc3947-b9e4-4a83-b6c7-b7c5e76c0cf3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Chunk size experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "04e78912-3aa8-4cec-95fd-e28eefba3e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    {\n",
    "        'chunk_size': 128,\n",
    "    },\n",
    "    {\n",
    "        'chunk_size': 256,\n",
    "    },\n",
    "    {\n",
    "        'chunk_size': 512,\n",
    "    },    \n",
    "    {\n",
    "        'chunk_size': 1024,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4d6b85ea-7f90-49a1-9719-b919137b43ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with {'chunk_size': 128}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331297b789684f9ab4a7176375edae0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/8944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74ebd671a214f00b3c8d0842ad14ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/70753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [08:23<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8103448275862069\n",
      "Running experiment with {'chunk_size': 1024}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe29cedfbd2c4a619b775222cd4a4451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/8944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d877e4e92b441a9698c68b02099bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [05:43<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8103448275862069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_dfs = []\n",
    "hit_rates = []\n",
    "for experiment in experiments: \n",
    "    print(f'Running experiment with {experiment}')\n",
    "    val_result = evaluate(docs, val_dataset, **experiment)\n",
    "    df = pd.DataFrame(val_result)\n",
    "    result_dfs.append(df)\n",
    "    hit_rate = df['is_hit'].mean()\n",
    "    hit_rates.append(hit_rate)\n",
    "    print(hit_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ade78109-f1a0-49b0-809a-eb4f194596f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8189655172413793,\n",
       " 0.8362068965517241,\n",
       " 0.8103448275862069,\n",
       " 0.8103448275862069]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3cf1f-5cf3-4ec1-8b3e-943d0e7e418e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Embed model experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "77aabd39-2972-4c64-8450-cb618df7c199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    {\n",
    "        'embed_model': \"BAAI/bge-large-en\",\n",
    "    },\n",
    "    {\n",
    "        'embed_model': \"text-embedding-ada-002\",\n",
    "    },\n",
    "    {\n",
    "        'embed_model': \"thenlper/gte-base\",\n",
    "    },\n",
    "    {\n",
    "        'embed_model': \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "8cbd96cd-40d8-4944-aced-b07087d341f1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with {'embed_model': 'BAAI/bge-large-en'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f47eff060a646eebc7d5cfa19604f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b720e/.gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed180fd0e984fddbc3d1009e8fb7eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc6b5211b00442ab673841215b7953e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)364d9b720e/README.md:   0%|          | 0.00/78.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5f81c98d4f4e0fa34d1f997741d4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)4d9b720e/config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71acc164781417fa001df71f7d52768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d05ed9d16546009c04ff6273340fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf28153315d4abdbea1f8f1b2ebc8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b94a4c323a4b1abb3bdce05f9a2dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c9b7e629f643de80e3df7898b1a903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5343f5815c3a4ccdad26fb4135644dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b720e/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4832f846cad744a1b3aefaa664238f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213637ac32e74b3e93b2ad1b123afac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)364d9b720e/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783df0dca9ca4c20a5196f963b3b7826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d9b720e/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6990ad71c5e24a9196fd18a9bb770b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/8944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd944e879bc42298a4ef4275d270238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [03:42<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8448275862068966\n",
      "Running experiment with {'embed_model': 'text-embedding-ada-002'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38137ba884dd4e209bd2ab9d7b634285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/8944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f342702c8be94c6d893c711f19bbf364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [05:42<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8275862068965517\n",
      "Running experiment with {'embed_model': 'thenlper/gte-base'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf66dbab34d447c96178bd024c6ea96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/8944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acd1517f3b7410081eaff2c8c228a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [02:55<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9224137931034483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_dfs = []\n",
    "hit_rates = []\n",
    "for experiment in experiments: \n",
    "    print(f'Running experiment with {experiment}')\n",
    "    val_result = evaluate(docs, val_dataset, **experiment)\n",
    "    df = pd.DataFrame(val_result)\n",
    "    result_dfs.append(df)\n",
    "    hit_rate = df['is_hit'].mean()\n",
    "    hit_rates.append(hit_rate)\n",
    "    print(hit_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561009b-c32d-4193-aec3-b1af80452621",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Top K Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ddc474b1-823d-4ce2-8466-4cb9628859e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    {\n",
    "        'top_k': 2, \n",
    "    },\n",
    "    {\n",
    "        'top_k': 3,\n",
    "    },\n",
    "    {\n",
    "        'top_k': 4,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d17f0a2f-ab7b-4a0b-b059-353003736bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with {'top_k': 2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e99671ee2a74891ae4c9406aa75e293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/8944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4ba1064a81494c8741f948b2e5d26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [05:39<00:00,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "Running experiment with {'top_k': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36fd8dfe0f840e197f58412e8acb4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/8944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfce36ec726476eaa9fa21d1c848f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [05:42<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7758620689655172\n",
      "Running experiment with {'top_k': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6079869e53cc4c1ebd5809113e5b7111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/8944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116bf129f0224d8e9e87f280529d75d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [05:49<00:00,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8017241379310345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_dfs = []\n",
    "hit_rates = []\n",
    "for experiment in experiments: \n",
    "    print(f'Running experiment with {experiment}')\n",
    "    val_result = evaluate(docs, val_dataset, **experiment)\n",
    "    df = pd.DataFrame(val_result)\n",
    "    result_dfs.append(df)\n",
    "    hit_rate = df['is_hit'].mean()\n",
    "    hit_rates.append(hit_rate)\n",
    "    print(hit_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b874f49f-f20f-49bc-b6b9-9e6589a6cf78",
   "metadata": {},
   "source": [
    "### Sentence window approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ae6fb18e-12c0-4221-bd64-080e0f57bd18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from llama_index import ServiceContext, set_global_service_context\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "# create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "    ),\n",
    "    node_parser=node_parser,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "b2f89eb8-bb7f-41c0-b61a-76f1d2af0b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923ceeb10635495f8781ce36aeb48f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/8944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa669fe9c204f2bae12283c6b339b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/59775 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(docs, service_context=service_context, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29020bd4-5d82-4c6d-b764-9ccda3b88be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 40/116 [06:17<12:19,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +28h47m35s)\u001b[0m Adding 1 node(s) of type worker-node-type-0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 48/116 [07:40<11:23, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +28h48m50s)\u001b[0m Resized to 32 CPUs, 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 76/116 [12:05<06:23,  9.58s/it]"
     ]
    }
   ],
   "source": [
    "evaluate_index(val_dataset, index, top_k=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888a74b-0b31-4965-b54c-27be5cf44e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
